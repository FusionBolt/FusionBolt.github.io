[{"title":"关于glibc与GLIBC_XX","url":"/2022/03/29/glibc-version/","content":"\n是GLIBC的版本多还是miku的版本多? pixiv:67650124 \n\nglibc位置这个不同系统不一致，linux中比较多的存在于/lib/libc.so.6\n想要查找libc的位置可以通过ldd(linux)/otool(mac)查看依赖于libc.so的库（有的库会静态塞进去，这种的是看不了）\n有的时候ldd看到的错误信息也会包含glibc的路径，这些还是根据不同的情况来查找\n确认当前环境glibc版本信息ldd --version\n\n#include &lt;gnu/libc-version.h&gt;#include &lt;stdio.h&gt;int main()&#123;  printf(&quot;%s&quot;, gnu_get_libc_version());&#125;\n\n两者都可以\nGLIBC Version兼容性本质上这是一个so的不同版本兼容性问题。通常我们看到的so的版本号是 主版本号.次版本号，比如说2.6。链接的时候只会进行主版本号的判断，不同主版本号可能是不兼容的（不管实际如何，我们都应该视为不兼容，链接器也会报错的）。而次版本号保证新版本会兼容旧版本，比如说2.6兼容2.4\n关于自己编译的库查看GLIBC的依赖简单的命令查看\nstrings libxxx.so | grep &quot;^GLIBC&quot;\n\n你会看到多个版本号，由于新版本兼容旧版本，因此其中最新的一个GLIBC版本号是我们所需要的。这时你可能有很多小问号，让我们一个一个的来解决\n自己的库的GLIBC Version怎么来的？上面也提及了次版本号会高版本兼容低版本，但是如果依赖高版本的却运行于低版本时可能会出现找不到符号的情况，因此引入了基于符号的版本机制。即对应符号可以依赖于某个特定的次版本号\n我们从一个例子来将这些串联起来。以下以上面提到过的确认当前环境GLIBC信息的示例代码为例，实际GLIBC版本大概率不会相同，与你的系统环境有关\n首先使用strings查看，可以看到搜到了两个版本\nGLIBC_2.2.5GLIBC_2.34\n\n当然我想你可能已经尝试过前面确认当前版本GLIBC Version的命令，发现这里的符号和当前版本的符号并不相同。我们先讲解这些版本的来源，之后就会明白原因了\n那么为什么会有两个版本呢？两个版本又是怎么来的呢？让我们用nm查看一下其中的符号\n000000000000039c r __abi_tag0000000000004038 B __bss_start0000000000004038 b completed.0                 w __cxa_finalize@GLIBC_2.2.50000000000004028 D __data_start0000000000004028 W data_start0000000000001080 t deregister_tm_clones00000000000010f0 t __do_global_dtors_aux0000000000003df0 d __do_global_dtors_aux_fini_array_entry0000000000004030 D __dso_handle0000000000003df8 d _DYNAMIC0000000000004038 D _edata0000000000004040 B _end0000000000001170 T _fini0000000000001140 t frame_dummy0000000000003de8 d __frame_dummy_init_array_entry00000000000020a8 r __FRAME_END__0000000000004000 d _GLOBAL_OFFSET_TABLE_                 w __gmon_start__0000000000002008 r __GNU_EH_FRAME_HDR                 U gnu_get_libc_version@GLIBC_2.2.50000000000001000 T _init0000000000002000 R _IO_stdin_used                 w _ITM_deregisterTMCloneTable                 w _ITM_registerTMCloneTable                 U __libc_start_main@GLIBC_2.340000000000001149 T main                 U printf@GLIBC_2.2.500000000000010b0 t register_tm_clones0000000000001050 T _start0000000000004038 D __TMC_END__\n\n可以看到 __cxa_finalize, gnu_get_libc_version, printf是基于2.2.5，而__libc_start_main是基于2.34，这正好与我们前面看到的符号相关联。\n看到这里你应该已经明白了，自己的库中GLIBC版本是来源于所使用的符号所标明的版本，因此我们在当前环境编出来的库的依赖版本实际上是当前环境的库中对应符号所依赖的版本号\nlibc.so与libc.so.6libc.so虽然长得像so，但它并不是，甚至不是一个软链接。内容大致是这样的\n/* GNU ld script   Use the shared library, but some functions are only in   the static library, so try that secondarily.  */OUTPUT_FORMAT(elf64-x86-64)GROUP ( /usr/lib/libc.so.6 /usr/lib/libc_nonshared.a  AS_NEEDED ( /usr/lib/ld-linux-x86-64.so.2 ) )\n\n参考资料程序员的自我修养：链接、装载与库\n","categories":["C"],"tags":["Link"]},{"title":"LLVM Pass 其一：PassManager","url":"/2022/06/26/llvm-pass/llvm-pass-1/","content":"\n现身吧，青眼亚白龙！ 把他给我烧的一干二净，毁灭的焦热疾风弹！ \n\n上一期我们讲到了每个Pass基本的结构，这期我们从PassManager开始讲述Pass从创建到执行的整个流程，以及涉及到的种种问题\n声明include/llvm/IR/PassManager.h\ntemplate &lt;typename IRUnitT,          typename AnalysisManagerT = AnalysisManager&lt;IRUnitT&gt;,          typename... ExtraArgTs&gt;class PassManager : public PassInfoMixin&lt;                        PassManager&lt;IRUnitT, AnalysisManagerT, ExtraArgTs...&gt;&gt; &#123;  ...\tstd::vector&lt;std::unique_ptr&lt;PassConceptT&gt;&gt; Passes;&#125;\n\n关于声明中要注意的有一点：上一期我们提到继承了PassInfoMixin的类我们就可以视为是一个Pass（从语法角度来说），也就是说PassManager本身也是一个Pass\n接着来讲一下模板参数\nIRUnit对于每个Pass有其作用的范围，有的是作用在函数上的，有的是作用到一个CFG中的\n还记得上期里讲到新Pass是通过run传进去的参数来决定是作用到什么样的pass么\nAnalysisManagerT\n添加一个Passtemplate &lt;typename PassT&gt;LLVM_ATTRIBUTE_MINSIZE    std::enable_if_t&lt;!std::is_same&lt;PassT, PassManager&gt;::value&gt;    addPass(PassT &amp;&amp;Pass) &#123;  using PassModelT =      detail::PassModel&lt;IRUnitT, PassT, PreservedAnalyses, AnalysisManagerT,                        ExtraArgTs...&gt;;  // Do not use make_unique or emplace_back, they cause too many template  // instantiations, causing terrible compile times.  Passes.push_back(std::unique_ptr&lt;PassConceptT&gt;(      new PassModelT(std::forward&lt;PassT&gt;(Pass))));&#125;\n\n我们这里先不管enable_if_t的部分，参数也没什么可讲的，我们来看函数体的部分\n可以看到实际传给PassManager的其实是一个PassModelT的实例，而不是一个Pass\nPassModel\ninclude/llvm/IR/PassManagerInternal.h\ntemplate &lt;typename IRUnitT, typename PassT, typename PreservedAnalysesT,          typename AnalysisManagerT, typename... ExtraArgTs&gt;struct PassModel : PassConcept&lt;IRUnitT, AnalysisManagerT, ExtraArgTs...&gt; &#123;  ...\tPreservedAnalysesT run(IRUnitT &amp;IR, AnalysisManagerT &amp;AM,                         ExtraArgTs... ExtraArgs) override &#123;    return Pass.run(IR, AM, ExtraArgs...);  &#125;\tPassT Pass;&#125;\n\nPassModel做的事情也很简单，最重要的就是运行保存的Pass实例。\n上期提到了实现Pass时isRequired是可选的。对于非required的pass也不需要手动编写一个返回false的函数，而秘密就在于这个函数中\ntemplate &lt;typename T&gt;using has_required_t = decltype(std::declval&lt;T &amp;&gt;().isRequired());template &lt;typename T&gt;static std::enable_if_t&lt;is_detected&lt;has_required_t, T&gt;::value, bool&gt;passIsRequiredImpl() &#123;  return T::isRequired();&#125;template &lt;typename T&gt;static std::enable_if_t&lt;!is_detected&lt;has_required_t, T&gt;::value, bool&gt;passIsRequiredImpl() &#123;  return false;&#125;bool isRequired() const override &#123; return passIsRequiredImpl&lt;PassT&gt;(); &#125;\n\n而这部分类似的代码还存在于PassInstrumentation的代码中。对于PassInstrumentation来说接收的就是一个PassT，并不一定就是PassModel 。\ntemplate &lt;typename PassT&gt;using has_required_t = decltype(std::declval&lt;PassT &amp;&gt;().isRequired());template &lt;typename PassT&gt;static std::enable_if_t&lt;is_detected&lt;has_required_t, PassT&gt;::value, bool&gt;isRequired(const PassT &amp;Pass) &#123;  return Pass.isRequired();&#125;template &lt;typename PassT&gt;static std::enable_if_t&lt;!is_detected&lt;has_required_t, PassT&gt;::value, bool&gt;isRequired(const PassT &amp;Pass) &#123;  return false;&#125;\n\n添加一个PassManager除了可以添加一个常规的Pass，还可以添加一个PassManager到一个PassManager中，听起来很奇怪，但是PassManager的行为也是一种Pass\ninclude/llvm/IR/PassManager.h\ntemplate &lt;typename PassT&gt;LLVM_ATTRIBUTE_MINSIZE    std::enable_if_t&lt;std::is_same&lt;PassT, PassManager&gt;::value&gt;    addPass(PassT &amp;&amp;Pass) &#123;  for (auto &amp;P : Pass.Passes)    Passes.push_back(std::move(P));&#125;\n\n这里通过使用enable_if_t来判断这个PassT是否为PassManager。\n关于为什么要这么做，目前的PassManager run的部分没有处理嵌套的情况，注释中提到了\n\ncases rely on executing nested pass managers. Doing this could reduce implementation complexity and avoid potential invalidation issues that may happen with nested pass managers of the same type.\n\n大意就是减少实现复杂度以及减少问题\nRun先来大概看一遍代码\n/// Run all of the passes in this manager over the given unit of IR./// ExtraArgs are passed to each pass.PreservedAnalyses run(IRUnitT &amp;IR, AnalysisManagerT &amp;AM,                      ExtraArgTs... ExtraArgs) &#123;  PreservedAnalyses PA = PreservedAnalyses::all();  // Request PassInstrumentation from analysis manager, will use it to run  // instrumenting callbacks for the passes later.  // Here we use std::tuple wrapper over getResult which helps to extract  // AnalysisManager&#x27;s arguments out of the whole ExtraArgs set.  PassInstrumentation PI =      detail::getAnalysisResult&lt;PassInstrumentationAnalysis&gt;(          AM, IR, std::tuple&lt;ExtraArgTs...&gt;(ExtraArgs...));  for (unsigned Idx = 0, Size = Passes.size(); Idx != Size; ++Idx) &#123;    auto *P = Passes[Idx].get();    // Check the PassInstrumentation&#x27;s BeforePass callbacks before running the    // pass, skip its execution completely if asked to (callback returns    // false).    if (!PI.runBeforePass&lt;IRUnitT&gt;(*P, IR))      continue;    PreservedAnalyses PassPA;    &#123;      TimeTraceScope TimeScope(P-&gt;name(), IR.getName());      PassPA = P-&gt;run(IR, AM, ExtraArgs...);    &#125;    // Call onto PassInstrumentation&#x27;s AfterPass callbacks immediately after    // running the pass.    PI.runAfterPass&lt;IRUnitT&gt;(*P, IR, PassPA);    // Update the analysis manager as each pass runs and potentially    // invalidates analyses.    AM.invalidate(IR, PassPA);    // Finally, intersect the preserved analyses to compute the aggregate    // preserved set for this pass manager.    PA.intersect(std::move(PassPA));  &#125;  // Invalidation was handled after each pass in the above loop for the  // current unit of IR. Therefore, the remaining analysis results in the  // AnalysisManager are preserved. We mark this with a set so that we don&#x27;t  // need to inspect each one individually.  PA.preserveSet&lt;AllAnalysesOn&lt;IRUnitT&gt;&gt;();  return PA;&#125;\n\n可以看到这里从PassInstrumentationAnalysis获取了一个PassInstrumentation（简称PI），PI中存了各种各样的callback，在跑Pass的前后会执行对应的callback。\n这边的逻辑也比较简单，关键点在于Analysis与Instrumentation的各种callback相关的\n对Analysis的影响我们之前已经讲过通过PreservedAnalyses来管理Pass会导致哪些Analysis的结果失效，在跑Pass后会将结果的PreservedAnalyses用于修正AnalysisManager里保存的分析结果，也就是在这里AnalysisManager（以下简称AM）会实际更新内部保存的信息\nAM.invalidate(IR, PassPA);\n\n而在所有Pass跑完之后则preserve当前IRUnit类型的AnalysesSet，这里使用一个Set是为了避免和这个IRUnit类型的Analysis逐个比较。在最后preserve整个set的原因是在跑每个pass的时候都在不断的更新其中的AnalysisManager以及PreserveAnalyses信息，都跑完之后可以保证当前这个IRUnit类型的Analyses都确保是preserved的。\n我一开始对这里的写法感到奇怪，为什么都跑完了、修改过了还是preserved的。我最初的想法是被保存的Analysis，理解上更偏向于是被缓存了的Pass，但是仔细一想我觉得换一种说法来描述PreserveAnalyses就好理解了：PreserveAnalyses中记录的是在这之后能够正确获取结果的Analyses。也就是说跑完PassManager这个“Pass”之后所有的Analysis依然是能够正确获取的\n在编写自己Pass的时候要手动指定使得哪些Analysis失效，原因是因为你在这个Pass里面做过了修改并且没有更新AnalysisManager的信息，我觉得理论上来说如果每个人在Pass里面自己做了AM.invalidate的操作本质上是一样的，在这里只是PassManager帮你做了这个事情（这里不考虑这个做法是否有必要，只是讨论实现的本质）。那么如果要在Pass内部进行修改再做分析，也可以直接通过invalidate的操作更新AM之后再获取数据\n关于Analysis更详细的部分会在下一期讲述\nrunBeforePassinclude/llvm/IR/PassInstrumentation.h\ntemplate &lt;typename IRUnitT, typename PassT&gt;bool runBeforePass(const PassT &amp;Pass, const IRUnitT &amp;IR) const &#123;  if (!Callbacks)    return true;  bool ShouldRun = true;  if (!isRequired(Pass)) &#123;    for (auto &amp;C : Callbacks-&gt;ShouldRunOptionalPassCallbacks)      ShouldRun &amp;= C(Pass.name(), llvm::Any(&amp;IR));  &#125;  if (ShouldRun) &#123;    for (auto &amp;C : Callbacks-&gt;BeforeNonSkippedPassCallbacks)      C(Pass.name(), llvm::Any(&amp;IR));  &#125; else &#123;    for (auto &amp;C : Callbacks-&gt;BeforeSkippedPassCallbacks)      C(Pass.name(), llvm::Any(&amp;IR));  &#125;  return ShouldRun;&#125;\n\nrunBeforePass除了执行一些常规callback之外，不同之处在于做了是否要执行当前pass的判断。如果并非required的pass则根据callback中的函数来确定是否运行当前pass\n而runAfterPass就是简单的执行所有callback，这里就不再赘述\n更具体的PassManager讲完了基础的PassManager，我们再来看一下通过PassManager衍生出更加具体的PassManager都是怎样的。不过不管怎么衍生，关于执行的结果以及analysis处理以及callback这些的处理大致是一致的，只是加了一些对于某类IRUnit专用的处理操作\n主要有以下这么几种方式\n类型别名根据IRUnit的不同，有这么几类PassManager\n\n代码中是这样的\nPassManager.h\nusing ModulePassManager = PassManager&lt;Module&gt;;using FunctionPassManager = PassManager&lt;Function&gt;;\n\n这种没什么可讲的，就是简单的用了一个别名来标识\n针对Loop特化的PassManager\ninclude/llvm/Transforms/Scalar/LoopPassManager.h\n// Explicit specialization and instantiation declarations for the pass manager.// ...template &lt;&gt;class PassManager&lt;Loop, LoopAnalysisManager, LoopStandardAnalysisResults &amp;,                  LPMUpdater &amp;&gt;    : public PassInfoMixin&lt;          PassManager&lt;Loop, LoopAnalysisManager, LoopStandardAnalysisResults &amp;,                      LPMUpdater &amp;&gt;&gt; &#123;public:  explicit PassManager() = default;  ...&#125;\n\n通过成员可以看到多了一些Loop相关的处理\naddPass还是熟悉的enable_if，主要是根据参数是RepeatedPass还是普通Pass以及PassT是否满足HasRunOnLoopT产生了四种情况\ntemplate &lt;typename PassT&gt;LLVM_ATTRIBUTE_MINSIZE    std::enable_if_t&lt;is_detected&lt;HasRunOnLoopT, PassT&gt;::value&gt;    addPass(PassT &amp;&amp;Pass) &#123;  using LoopPassModelT =      detail::PassModel&lt;Loop, PassT, PreservedAnalyses, LoopAnalysisManager,                        LoopStandardAnalysisResults &amp;, LPMUpdater &amp;&gt;;  IsLoopNestPass.push_back(false);  // Do not use make_unique or emplace_back, they cause too many template  // instantiations, causing terrible compile times.  LoopPasses.push_back(std::unique_ptr&lt;LoopPassConceptT&gt;(      new LoopPassModelT(std::forward&lt;PassT&gt;(Pass))));&#125;template &lt;typename PassT&gt;LLVM_ATTRIBUTE_MINSIZE    std::enable_if_t&lt;!is_detected&lt;HasRunOnLoopT, PassT&gt;::value&gt;    addPass(PassT &amp;&amp;Pass) &#123;  using LoopNestPassModelT =      detail::PassModel&lt;LoopNest, PassT, PreservedAnalyses,                        LoopAnalysisManager, LoopStandardAnalysisResults &amp;,                        LPMUpdater &amp;&gt;;  IsLoopNestPass.push_back(true);  // Do not use make_unique or emplace_back, they cause too many template  // instantiations, causing terrible compile times.  LoopNestPasses.push_back(std::unique_ptr&lt;LoopNestPassConceptT&gt;(      new LoopNestPassModelT(std::forward&lt;PassT&gt;(Pass))));&#125;\n\n// Specializations of `addPass` for `RepeatedPass`. These are necessary since// `RepeatedPass` has a templated `run` method that will result in incorrect// detection of `HasRunOnLoopT`.template &lt;typename PassT&gt;LLVM_ATTRIBUTE_MINSIZE    std::enable_if_t&lt;is_detected&lt;HasRunOnLoopT, PassT&gt;::value&gt;    addPass(RepeatedPass&lt;PassT&gt; &amp;&amp;Pass) &#123;  using RepeatedLoopPassModelT =      detail::PassModel&lt;Loop, RepeatedPass&lt;PassT&gt;, PreservedAnalyses,                        LoopAnalysisManager, LoopStandardAnalysisResults &amp;,                        LPMUpdater &amp;&gt;;  IsLoopNestPass.push_back(false);  // Do not use make_unique or emplace_back, they cause too many template  // instantiations, causing terrible compile times.  LoopPasses.push_back(std::unique_ptr&lt;LoopPassConceptT&gt;(      new RepeatedLoopPassModelT(std::move(Pass))));&#125;template &lt;typename PassT&gt;LLVM_ATTRIBUTE_MINSIZE    std::enable_if_t&lt;!is_detected&lt;HasRunOnLoopT, PassT&gt;::value&gt;    addPass(RepeatedPass&lt;PassT&gt; &amp;&amp;Pass) &#123;  using RepeatedLoopNestPassModelT =      detail::PassModel&lt;LoopNest, RepeatedPass&lt;PassT&gt;, PreservedAnalyses,                        LoopAnalysisManager, LoopStandardAnalysisResults &amp;,                        LPMUpdater &amp;&gt;;  IsLoopNestPass.push_back(true);  // Do not use make_unique or emplace_back, they cause too many template  // instantiations, causing terrible compile times.  LoopNestPasses.push_back(std::unique_ptr&lt;LoopNestPassConceptT&gt;(      new RepeatedLoopNestPassModelT(std::move(Pass))));&#125;\n\nrun/// Explicitly specialize the pass manager&#x27;s run method to handle loop nest/// structure updates.PreservedAnalysesPassManager&lt;Loop, LoopAnalysisManager, LoopStandardAnalysisResults &amp;,            LPMUpdater &amp;&gt;::run(Loop &amp;L, LoopAnalysisManager &amp;AM,                               LoopStandardAnalysisResults &amp;AR, LPMUpdater &amp;U) &#123;  // Runs loop-nest passes only when the current loop is a top-level one.  PreservedAnalyses PA = (L.isOutermost() &amp;&amp; !LoopNestPasses.empty())                             ? runWithLoopNestPasses(L, AM, AR, U)                             : runWithoutLoopNestPasses(L, AM, AR, U);  // Invalidation for the current loop should be handled above, and other loop  // analysis results shouldn&#x27;t be impacted by runs over this loop. Therefore,  // the remaining analysis results in the AnalysisManager are preserved. We  // mark this with a set so that we don&#x27;t need to inspect each one  // individually.  PA.preserveSet&lt;AllAnalysesOn&lt;Loop&gt;&gt;();  return PA;&#125;/// Run either a loop pass or a loop-nest pass. Returns `None` if/// PassInstrumentation&#x27;s BeforePass returns false. Otherwise, returns the/// preserved analyses of the pass.template &lt;typename IRUnitT, typename PassT&gt;Optional&lt;PreservedAnalyses&gt;runSinglePass(IRUnitT &amp;IR, PassT &amp;Pass, LoopAnalysisManager &amp;AM,              LoopStandardAnalysisResults &amp;AR, LPMUpdater &amp;U,              PassInstrumentation &amp;PI);PreservedAnalyses runWithLoopNestPasses(Loop &amp;L, LoopAnalysisManager &amp;AM,                                        LoopStandardAnalysisResults &amp;AR,                                        LPMUpdater &amp;U);PreservedAnalyses runWithoutLoopNestPasses(Loop &amp;L, LoopAnalysisManager &amp;AM,                                           LoopStandardAnalysisResults &amp;AR,                                           LPMUpdater &amp;U);\n\nrunSinglePass\ntemplate &lt;typename IRUnitT, typename PassT&gt;Optional&lt;PreservedAnalyses&gt; LoopPassManager::runSinglePass(    IRUnitT &amp;IR, PassT &amp;Pass, LoopAnalysisManager &amp;AM,    LoopStandardAnalysisResults &amp;AR, LPMUpdater &amp;U, PassInstrumentation &amp;PI) &#123;  // Get the loop in case of Loop pass and outermost loop in case of LoopNest  // pass which is to be passed to BeforePass and AfterPass call backs.  const Loop &amp;L = getLoopFromIR(IR);  // Check the PassInstrumentation&#x27;s BeforePass callbacks before running the  // pass, skip its execution completely if asked to (callback returns false).  if (!PI.runBeforePass&lt;Loop&gt;(*Pass, L))    return None;  PreservedAnalyses PA;  &#123;    TimeTraceScope TimeScope(Pass-&gt;name(), IR.getName());    PA = Pass-&gt;run(IR, AM, AR, U);  &#125;  // do not pass deleted Loop into the instrumentation  if (U.skipCurrentLoop())    PI.runAfterPassInvalidated&lt;IRUnitT&gt;(*Pass, PA);  else    PI.runAfterPass&lt;Loop&gt;(*Pass, L, PA);  return PA;&#125;\n\n关系大概是这个样子的，这里就不贴其他的具体实现了，里面关于Analysis以及各种处理本质上都是类似的\nflowchart LR  run --&gt; runWithLoopNestPasses --&gt; runSinglePass  run --&gt; runWithOutLoopNestPasses --&gt; runSinglePass\n\n别名最后也是使用了一个别名\ntypedef PassManager&lt;Loop, LoopAnalysisManager, LoopStandardAnalysisResults &amp;,                    LPMUpdater &amp;&gt;    LoopPassManager;\n\n继承include/llvm/CodeGen/MachinePassManager.h\n/// MachineFunctionPassManager adds/removes below features to/from the base/// PassManager template instantiation.////// - Support passes that implement doInitialization/doFinalization. This is for///   machine function passes to work on module level constructs. One such pass///   is AsmPrinter./// .../// - The base class `run` method is replaced by an alternative `run` method.///   See details below.////// - Support codegening in the SCC order. Users include interprocedural///   register allocation (IPRA).class MachineFunctionPassManager    : public PassManager&lt;MachineFunction, MachineFunctionAnalysisManager&gt; &#123;  using Base = PassManager&lt;MachineFunction, MachineFunctionAnalysisManager&gt;;  ...&#125;\n\nMachineFunctionPassManager属于codegen的部分，而codegen的部分目前还未完全迁移到新的Pass架构中，因此为了兼容旧部分的内容做了一些特殊处理\n\naddPass在旧的Pass中有doInitialization以及doFinalization的部分，因此在addPass的时候同时会将init和final的Pass注册进去\ntemplate &lt;typename PassT&gt; void addPass(PassT &amp;&amp;Pass) &#123;  Base::addPass(std::forward&lt;PassT&gt;(Pass));  PassConceptT *P = Passes.back().get();  addDoInitialization&lt;PassT&gt;(P);  addDoFinalization&lt;PassT&gt;(P);  // Add machine module pass.  addRunOnModule&lt;PassT&gt;(P);&#125;\n\n关于addDoInitialization的处理是这样的，addDoFinalization以及addRunOnModule的函数也是类似的做法，只是更换了detected的条件，不再过多赘述。\ntemplate &lt;typename PassT&gt;  std::enable_if_t&lt;!is_detected&lt;has_init_t, PassT&gt;::value&gt;  addDoInitialization(PassConceptT *Pass) &#123;&#125;  template &lt;typename PassT&gt;  std::enable_if_t&lt;is_detected&lt;has_init_t, PassT&gt;::value&gt;  addDoInitialization(PassConceptT *Pass) &#123;    using PassModelT =        detail::PassModel&lt;MachineFunction, PassT, PreservedAnalyses,                          MachineFunctionAnalysisManager&gt;;    auto *P = static_cast&lt;PassModelT *&gt;(Pass);    InitializationFuncs.emplace_back(        [=](Module &amp;M, MachineFunctionAnalysisManager &amp;MFAM) &#123;          return P-&gt;Pass.doInitialization(M, MFAM);        &#125;);  &#125;\n\nrun之后在run的前后执行（这里省略绝大部分的细节），addDoInitialization以及addDoFinalization的部分在新的Pass架构中我觉得应当是要转换为callback的形式，就像之前的runBeforePass一样\nError MachineFunctionPassManager::run(Module &amp;M,                                      MachineFunctionAnalysisManager &amp;MFAM) &#123;\t...\t// Add a PIC to verify machine functions.  if (VerifyMachineFunction) &#123;    PassInstrumentation PI = MFAM.getResult&lt;PassInstrumentationAnalysis&gt;(M);    // No need to pop this callback later since MIR pipeline is flat which means    // current pipeline is the top-level pipeline. Callbacks are not used after    // current pipeline.    PI.pushBeforeNonSkippedPassCallback([&amp;MFAM](StringRef PassID, Any IR) &#123;\t\t\t...    &#125;);  &#125;  for (auto &amp;F : InitializationFuncs) &#123;    if (auto Err = F(M, MFAM))      return Err;  &#125;  do &#123;    // Run machine module passes    ...  &#125; while (true);  for (auto &amp;F : FinalizationFuncs) &#123;    if (auto Err = F(M, MFAM))      return Err;  &#125;  return Error::success();&#125;\n\n针对SCC特化了run的PassManager// Explicit specialization and instantiation declarations for the pass manager.// See the comments on the definition of the specialization for details on how// it differs from the primary template.template &lt;&gt;PreservedAnalysesPassManager&lt;LazyCallGraph::SCC, CGSCCAnalysisManager, LazyCallGraph &amp;,            CGSCCUpdateResult &amp;&gt;::run(LazyCallGraph::SCC &amp;InitialC,                                      CGSCCAnalysisManager &amp;AM,                                      LazyCallGraph &amp;G, CGSCCUpdateResult &amp;UR);extern template class PassManager&lt;LazyCallGraph::SCC, CGSCCAnalysisManager,                                  LazyCallGraph &amp;, CGSCCUpdateResult &amp;&gt;;/// The CGSCC pass manager.////// See the documentation for the PassManager template for details. It runs/// a sequence of SCC passes over each SCC that the manager is run over. This/// type serves as a convenient way to refer to this construct.using CGSCCPassManager =    PassManager&lt;LazyCallGraph::SCC, CGSCCAnalysisManager, LazyCallGraph &amp;,                CGSCCUpdateResult &amp;&gt;;\n\nSCC的PassManager只是特化了run的部分。在原来PassManager的基础上加了一些SCC相关的处理，这里出现了proxy这个东西，先忽视它，我们之后再介绍\n/// Explicitly specialize the pass manager run method to handle call graph/// updates.template &lt;&gt;PreservedAnalysesPassManager&lt;LazyCallGraph::SCC, CGSCCAnalysisManager, LazyCallGraph &amp;,            CGSCCUpdateResult &amp;&gt;::run(LazyCallGraph::SCC &amp;InitialC,                                      CGSCCAnalysisManager &amp;AM,                                      LazyCallGraph &amp;G, CGSCCUpdateResult &amp;UR) &#123;  // Request PassInstrumentation from analysis manager, will use it to run  // instrumenting callbacks for the passes later.  PassInstrumentation PI =      AM.getResult&lt;PassInstrumentationAnalysis&gt;(InitialC, G);  PreservedAnalyses PA = PreservedAnalyses::all();  // The SCC may be refined while we are running passes over it, so set up  // a pointer that we can update.  LazyCallGraph::SCC *C = &amp;InitialC;  // Get Function analysis manager from its proxy.  FunctionAnalysisManager &amp;FAM =      AM.getCachedResult&lt;FunctionAnalysisManagerCGSCCProxy&gt;(*C)-&gt;getManager();  for (auto &amp;Pass : Passes) &#123;    // Check the PassInstrumentation&#x27;s BeforePass callbacks before running the    // pass, skip its execution completely if asked to (callback returns false).    if (!PI.runBeforePass(*Pass, *C))      continue;    PreservedAnalyses PassPA;    &#123;      TimeTraceScope TimeScope(Pass-&gt;name());      PassPA = Pass-&gt;run(*C, AM, G, UR);    &#125;    if (UR.InvalidatedSCCs.count(C))      PI.runAfterPassInvalidated&lt;LazyCallGraph::SCC&gt;(*Pass, PassPA);    else      PI.runAfterPass&lt;LazyCallGraph::SCC&gt;(*Pass, *C, PassPA);    // Update the SCC if necessary.    C = UR.UpdatedC ? UR.UpdatedC : C;    if (UR.UpdatedC) &#123;      // If C is updated, also create a proxy and update FAM inside the result.      auto *ResultFAMCP =          &amp;AM.getResult&lt;FunctionAnalysisManagerCGSCCProxy&gt;(*C, G);      ResultFAMCP-&gt;updateFAM(FAM);    &#125;    // If the CGSCC pass wasn&#x27;t able to provide a valid updated SCC, the    // current SCC may simply need to be skipped if invalid.    if (UR.InvalidatedSCCs.count(C)) &#123;      LLVM_DEBUG(dbgs() &lt;&lt; &quot;Skipping invalidated root or island SCC!\\n&quot;);      break;    &#125;    // Check that we didn&#x27;t miss any update scenario.    assert(C-&gt;begin() != C-&gt;end() &amp;&amp; &quot;Cannot have an empty SCC!&quot;);    // Update the analysis manager as each pass runs and potentially    // invalidates analyses.    AM.invalidate(*C, PassPA);    // Finally, we intersect the final preserved analyses to compute the    // aggregate preserved set for this pass manager.    PA.intersect(std::move(PassPA));  &#125;  // Before we mark all of *this* SCC&#x27;s analyses as preserved below, intersect  // this with the cross-SCC preserved analysis set. This is used to allow  // CGSCC passes to mutate ancestor SCCs and still trigger proper invalidation  // for them.  UR.CrossSCCPA.intersect(PA);  // Invalidation was handled after each pass in the above loop for the current  // SCC. Therefore, the remaining analysis results in the AnalysisManager are  // preserved. We mark this with a set so that we don&#x27;t need to inspect each  // one individually.  PA.preserveSet&lt;AllAnalysesOn&lt;LazyCallGraph::SCC&gt;&gt;();  return PA;&#125;\n\n旧的PassManager体系最后再简单讲一下我了解的旧PassManager的一些做法，不会涉及太多细节\n核心实现在PassManagerImpl中\nlib/IR/LegacyPassManager.cpp\n/// PassManagerImpl manages MPPassManagersclass PassManagerImpl : public Pass,                        public PMDataManager,                        public PMTopLevelManager &#123;  virtual void anchor();public:  static char ID;  explicit PassManagerImpl()      : Pass(PT_PassManager, ID), PMTopLevelManager(new MPPassManager()) &#123;&#125;  /// \\copydoc PassManager::add()  void add(Pass *P) &#123;    schedulePass(P);  &#125;  /// createPrinterPass - Get a module printer pass.  Pass *createPrinterPass(raw_ostream &amp;O,                          const std::string &amp;Banner) const override &#123;    return createPrintModulePass(O, Banner);  &#125;  /// run - Execute all of the passes scheduled for execution.  Keep track of  /// whether any of the passes modifies the module, and if so, return true.  bool run(Module &amp;M);  using llvm::Pass::doInitialization;  using llvm::Pass::doFinalization;\t...&#125;\n\n一个非常大的不同是LegacyPassManager（以下简称LegacyPM）每次添加Pass的时候需要进行一次schedule。LegacyPass中在Analysis内部保存Analysis的结果，而在schedule中管理Pass的顺序以及不再需要的Analysis的释放。\n然后我们来看一下run\n/// run - Execute all of the passes scheduled for execution.  Keep track of/// whether any of the passes modifies the module, and if so, return true.bool PassManagerImpl::run(Module &amp;M) &#123;  bool Changed = false;  dumpArguments();  dumpPasses();  for (ImmutablePass *ImPass : getImmutablePasses())    Changed |= ImPass-&gt;doInitialization(M);  initializeAllAnalysisInfo();  for (unsigned Index = 0; Index &lt; getNumContainedManagers(); ++Index) &#123;    Changed |= getContainedManager(Index)-&gt;runOnModule(M);    M.getContext().yield();  &#125;  for (ImmutablePass *ImPass : getImmutablePasses())    Changed |= ImPass-&gt;doFinalization(M);  return Changed;&#125;\n\nrun的前后会执行doInitialization和doFinalization，这两个函数名是不是很眼熟？就是我们上面提到MachinePassManager中提及的\n除了针对Module的PassManager还有一个针对Function的FunctionPassManager。对于FunctionPassManager来说也是需要每次addPass的时候进行schedule\nbool FunctionPassManagerImpl::run(Function &amp;F) &#123;\tbool Changed = false;\t\tinitializeAllAnalysisInfo();\tfor (unsigned Index = 0; Index &lt; getNumContainedManagers(); ++Index) &#123;\t  Changed |= getContainedManager(Index)-&gt;runOnFunction(F);\t  F.getContext().yield();\t&#125;\t\tfor (unsigned Index = 0; Index &lt; getNumContainedManagers(); ++Index)\t  getContainedManager(Index)-&gt;cleanup();\t\twasRun = true;\treturn Changed;&#125;\n","categories":["Compiler"],"tags":["LLVM","Pass"]},{"title":"LLVM Pass 其二：Analysis与AnalysisManager","url":"/2022/07/03/llvm-pass/llvm-pass-2/","content":"\n来自究极怪兽之上的召唤，将一切全部抹消的光之龙！现身吧！青眼光龙！ \n\n在第一期的时候我们就提到过，新的Pass与LegacyPass的其中一个不同在于将Analysis单独分离了出来，那么本期我们从一个Analysis的写法开始写起。\n实现一个Analysis/// Analysis pass which computes a \\c DominatorTree.class DominatorTreeAnalysis : public AnalysisInfoMixin&lt;DominatorTreeAnalysis&gt; &#123;  friend AnalysisInfoMixin&lt;DominatorTreeAnalysis&gt;;  static AnalysisKey Key;public:  /// Provide the result typedef for this analysis pass.  using Result = DominatorTree;  /// Run the analysis pass over a function and produce a dominator tree.  DominatorTree run(Function &amp;F, FunctionAnalysisManager &amp;);&#125;;\n\n和Pass相比有这么几处不同\n\n直接继承的是AnalysisInfoMixin而不是PassInfoMixin\nrun返回的不是一个Preserved Analyses而是一个对应的Result类型\n声明了一个static的AnalysisKey\n\n读完后面的内容或许就能理解为什么会有这样的不同了\nAnalysis本身相关的类型先来回顾一下前面两期在讲普通Pass相关的时候我们提到了这么几样东西\n\nPassInfoMixin\nPassConcept\nPassModel\n\n这些东西和Pass本身的关联如下\n\nPass类自身继承自PassInfoMixin（PassInfoMixin保存了一些获取信息的接口）\nPassConcept定义了Pass类应有的行为\nPassManager实际直接保存与执行的是PassConcept\nPassModel是满足了PassConcept的一个类型\n在PassManager中实际添加Pass的时候使用Pass类创建一个保存了这个Pass类的PassModel\n\n而在Analysis中这些东西也都是相同的，因此代码只会展示关键部分。Analysis相关的类有这么几个部分\n\nAnalysisInfoMixin\nAnalysisPass[Concept | Model]\nAnalysisResult[Concept | Model]\n\nAnalysisInfoMixintemplate &lt;typename DerivedT&gt;struct AnalysisInfoMixin : PassInfoMixin&lt;DerivedT&gt; &#123;  static AnalysisKey *ID() &#123;    static_assert(std::is_base_of&lt;AnalysisInfoMixin, DerivedT&gt;::value,                  &quot;Must pass the derived type as the template argument!&quot;);    return &amp;DerivedT::Key;  &#125;&#125;;\n\n虽然AnalysisInfoMixin继承自PassInfoMixin，但是实际上一个Analysis并没有实现PassConcept中的接口，而每个AnalysisPass中也没有实现PassConcept中的接口，因此Analysis并不是一个可以被PassManager执行的Pass（但是有自己的AnalysisManager）\nAnalysis增加了一个获取ID的功能，内部的实现是获取子类的key，也就是上面Analysis实现的时候声明的。后面再对这个Key进行展开讲解\nstatic AnalysisKey Key;\n\nAnalysisPassAnalysisPassConcepttemplate &lt;typename IRUnitT, typename PreservedAnalysesT, typename InvalidatorT,          typename... ExtraArgTs&gt;struct AnalysisPassConcept &#123;  virtual ~AnalysisPassConcept() = default;  virtual std::unique_ptr&lt;      AnalysisResultConcept&lt;IRUnitT, PreservedAnalysesT, InvalidatorT&gt;&gt;  run(IRUnitT &amp;IR, AnalysisManager&lt;IRUnitT, ExtraArgTs...&gt; &amp;AM,      ExtraArgTs... ExtraArgs) = 0;  virtual StringRef name() const = 0;&#125;;\n\nrun的时候返回的是一个AnalysisResultConcept\nAnalysis的模板参数出现一个InvalidatorT\nAnalysisPassModeltemplate &lt;typename IRUnitT, typename PassT, typename PreservedAnalysesT,          typename InvalidatorT, typename... ExtraArgTs&gt;struct AnalysisPassModel : AnalysisPassConcept&lt;IRUnitT, PreservedAnalysesT,                                               InvalidatorT, ExtraArgTs...&gt; &#123;  ...  using ResultModelT =      AnalysisResultModel&lt;IRUnitT, PassT, typename PassT::Result,                          PreservedAnalysesT, InvalidatorT&gt;;  std::unique_ptr&lt;      AnalysisResultConcept&lt;IRUnitT, PreservedAnalysesT, InvalidatorT&gt;&gt;  run(IRUnitT &amp;IR, AnalysisManager&lt;IRUnitT, ExtraArgTs...&gt; &amp;AM,      ExtraArgTs... ExtraArgs) override &#123;    return std::make_unique&lt;ResultModelT&gt;(        Pass.run(IR, AM, std::forward&lt;ExtraArgTs&gt;(ExtraArgs)...));  &#125;\n\n没什么可讲的，简单调用一下保存的Analysis\nAnalysisResultAnalysisResultConcepttemplate &lt;typename IRUnitT, typename PreservedAnalysesT, typename InvalidatorT&gt;struct AnalysisResultConcept &#123;  virtual ~AnalysisResultConcept() = default;\t/// Method to try and mark a result as invalid.  ///  /// When the outer analysis manager detects a change in some underlying  /// unit of the IR, it will call this method on all of the results cached.  ///  /// \\p PA is a set of preserved analyses which can be used to avoid  /// invalidation because the pass which changed the underlying IR took care  /// to update or preserve the analysis result in some way.  ///  /// \\p Inv is typically a \\c AnalysisManager::Invalidator object that can be  /// used by a particular analysis result to discover if other analyses  /// results are also invalidated in the event that this result depends on  /// them. See the documentation in the \\c AnalysisManager for more details.  ///  /// \\returns true if the result is indeed invalid (the default).  virtual bool invalidate(IRUnitT &amp;IR, const PreservedAnalysesT &amp;PA,                          InvalidatorT &amp;Inv) = 0;&#125;;\n\nAnalysisResultModel/// Wrapper to model the analysis result concept.////// By default, this will implement the invalidate method with a trivial/// implementation so that the actual analysis result doesn&#x27;t need to provide/// an invalidation handler. It is only selected when the invalidation handler/// is not part of the ResultT&#x27;s interface.template &lt;typename IRUnitT, typename PassT, typename ResultT,          typename PreservedAnalysesT, typename InvalidatorT,          bool HasInvalidateHandler =              ResultHasInvalidateMethod&lt;IRUnitT, ResultT&gt;::Value&gt;struct AnalysisResultModel;\n\n这里实际会根据是否存在invalidator而产生不同的特化，我们在后面讲到invalidate的时候再细说\nAnalysisManager先来看一下声明和成员\n/// A container for analyses that lazily runs them and caches their/// results.////// This class can manage analyses for any IR unit where the address of the IR/// unit sufficies as its identity.template &lt;typename IRUnitT, typename... ExtraArgTs&gt; class AnalysisManager &#123;  ...&#125;\n\n注意看声明中的类型，这里和PassManager不同的是没有继承PassInfoMixin，因此AnalysisManager并不是一个Pass\n\n添加Analysistemplate &lt;typename PassBuilderT&gt;bool registerPass(PassBuilderT &amp;&amp;PassBuilder) &#123;  using PassT = decltype(PassBuilder());  using PassModelT =      detail::AnalysisPassModel&lt;IRUnitT, PassT, PreservedAnalyses,                                Invalidator, ExtraArgTs...&gt;;  auto &amp;PassPtr = AnalysisPasses[PassT::ID()];  if (PassPtr)    // Already registered this pass type!    return false;  // Construct a new model around the instance returned by the builder.  PassPtr.reset(new PassModelT(PassBuilder()));  return true;&#125;\n\n和普通Pass不同之处有两点\n\nAnalysis的Pass只允许存在一个。因为Analysis本身并不需要多次add进来，而是通过AnalysisManager统一管理多次调用的情况\nAnalysis在添加的时候是使用一个Builder来构建的。因为一个Analysis如果存在的话则不会再进行构建，这里我想也是为了性能考虑\n\n外部从AnalysisManager获取信息至于如何从AnalysisManager获取信息，通过已有Pass的使用方式可以看到是通过getResult来获取结果的，比如说这里\nPreservedAnalyses PromotePass::run(Function &amp;F, FunctionAnalysisManager &amp;AM) &#123;  auto &amp;DT = AM.getResult&lt;DominatorTreeAnalysis&gt;(F);  auto &amp;AC = AM.getResult&lt;AssumptionAnalysis&gt;(F);  if (!promoteMemoryToRegister(F, DT, AC))    return PreservedAnalyses::all();  PreservedAnalyses PA;  PA.preserveSet&lt;CFGAnalyses&gt;();  return PA;&#125;\n\n那么我们从getResult作为起点来讲述AnalysisManager\ngetResult主要流程先放一下整个流程的代码，之后通过选择片段讲解\ntemplate &lt;typename PassT&gt;typename PassT::Result &amp;getResult(IRUnitT &amp;IR, ExtraArgTs... ExtraArgs) &#123;  assert(AnalysisPasses.count(PassT::ID()) &amp;&amp;         &quot;This analysis pass was not registered prior to being queried&quot;);  ResultConceptT &amp;ResultConcept =      getResultImpl(PassT::ID(), IR, ExtraArgs...);  using ResultModelT =      detail::AnalysisResultModel&lt;IRUnitT, PassT, typename PassT::Result,                                  PreservedAnalyses, Invalidator&gt;;  return static_cast&lt;ResultModelT &amp;&gt;(ResultConcept).Result;&#125;template &lt;typename IRUnitT, typename... ExtraArgTs&gt;inline typename AnalysisManager&lt;IRUnitT, ExtraArgTs...&gt;::ResultConceptT &amp;AnalysisManager&lt;IRUnitT, ExtraArgTs...&gt;::getResultImpl(    AnalysisKey *ID, IRUnitT &amp;IR, ExtraArgTs... ExtraArgs) &#123;  typename AnalysisResultMapT::iterator RI;  bool Inserted;  std::tie(RI, Inserted) = AnalysisResults.insert(std::make_pair(      std::make_pair(ID, &amp;IR), typename AnalysisResultListT::iterator()));  // If we don&#x27;t have a cached result for this function, look up the pass and  // run it to produce a result, which we then add to the cache.  if (Inserted) &#123;    auto &amp;P = this-&gt;lookUpPass(ID);    PassInstrumentation PI;    if (ID != PassInstrumentationAnalysis::ID()) &#123;      PI = getResult&lt;PassInstrumentationAnalysis&gt;(IR, ExtraArgs...);      PI.runBeforeAnalysis(P, IR);    &#125;    AnalysisResultListT &amp;ResultList = AnalysisResultLists[&amp;IR];    ResultList.emplace_back(ID, P.run(IR, *this, ExtraArgs...));    PI.runAfterAnalysis(P, IR);    // P.run may have inserted elements into AnalysisResults and invalidated    // RI.    RI = AnalysisResults.find(&#123;ID, &amp;IR&#125;);    assert(RI != AnalysisResults.end() &amp;&amp; &quot;we just inserted it!&quot;);    RI-&gt;second = std::prev(ResultList.end());  &#125;  return *RI-&gt;second-&gt;second;&#125;\n\ngetResulttemplate &lt;typename PassT&gt;typename PassT::Result &amp;getResult(IRUnitT &amp;IR, ExtraArgTs... ExtraArgs) &#123;  assert(AnalysisPasses.count(PassT::ID()) &amp;&amp;         &quot;This analysis pass was not registered prior to being queried&quot;);  ResultConceptT &amp;ResultConcept =      getResultImpl(PassT::ID(), IR, ExtraArgs...);  using ResultModelT =      detail::AnalysisResultModel&lt;IRUnitT, PassT, typename PassT::Result,                                  PreservedAnalyses, Invalidator&gt;;  return static_cast&lt;ResultModelT &amp;&gt;(ResultConcept).Result;&#125;\n\n这里通过PassT::Result的方式来获取到在Analysis中声明的Result的别名\n之后就是通过getResultImpl中取出一个ResultConcept再转成ResultModel取出具体的Result\ngetResultImplimpl逻辑首先尝试将这个IR insert到ResultMap中\ntypename AnalysisResultMapT::iterator RI;bool Inserted;std::tie(RI, Inserted) = AnalysisResults.insert(std::make_pair(    std::make_pair(ID, &amp;IR), typename AnalysisResultListT::iterator()));\n\n而这个AnalysisResultMapT是这样的\n/// Map type from a pair of analysis ID and IRUnitT pointer to an/// iterator into a particular result list (which is where the actual analysis/// result is stored).using AnalysisResultMapT =    DenseMap&lt;std::pair&lt;AnalysisKey *, IRUnitT *&gt;,             typename AnalysisResultListT::iterator&gt;;\n\nkey → std::make_pair(ID, &amp;IR)\nvalue → typename AnalysisResultListT::iterator()\n也就是说通过一对(AnalysisKey *, IRUnitT *)来判断result是否存在\n已经存在则直接返回值，不存在则表示没有cache，之后开始跑Pass。\nPassInstrumentation PI;if (ID != PassInstrumentationAnalysis::ID()) &#123;  PI = getResult&lt;PassInstrumentationAnalysis&gt;(IR, ExtraArgs...);  PI.runBeforeAnalysis(P, IR);&#125;AnalysisResultListT &amp;ResultList = AnalysisResultLists[&amp;IR];ResultList.emplace_back(ID, P.run(IR, *this, ExtraArgs...));PI.runAfterAnalysis(P, IR);\n\n这部分的代码可以看到实际跑pass的结果是存到了ResultList中，但是前面看到判断是否存在是依靠AnalysisResult实现的，那么我们要理一下将这两者关联起来的途径。\nAnalysisResultLists对于一个AnalysisResultLists来说，通过一个IR来索引，找到这个IR所执行的所有PassID以及Pass对应的结果，也就是说通过一个IR关联到其所有跑的PassID，而每个PassID又和一个结果联系起来。\n换个说法就是一个IRUnit和一个PassID实际上是唯一标识一组Result的。这里不标明pair的first、second以及end了，知道是pair就够了\n（感谢rami3l推荐的mermaid，画图真方便）\nflowchart LR  AnalysisResultList -- key --&gt; IRUnit1 -- value --&gt; Pair11 --&gt; ID1 &amp; Result1  IRUnit1 --&gt; Pair12 --&gt; ID2 &amp; Result2  IRUnit1 --&gt; ....  AnalysisResultList --&gt; IRUnit2 --&gt; Pair21 --&gt; ID1 &amp; Result3  AnalysisResultList --&gt; ...  AnalysisResultList --&gt; IRUnitN --&gt; PairNM --&gt; IDN &amp; ResultX\n\nAnalysisResult上面也提到了AnalysisResultList中实际上是通过一个IRUnit和一个PassID来确定一个唯一的Result的。AnalysisResult在上面也看到了是一个IRUnit和PassID的pair作为key的Map，画成图是这样的。pair这里不知道怎么画了，姑且用这样的形式\n而作为值的iter本质是指向了AnalysisResultList中结果所保存的PassID与Result的pair\nflowchart LR\tAnalysisResult -- key --&gt; Pair1Start -- first --&gt; ID1 --&gt; Pair1End\t\t\t\t\t\t\t\t\t\t\t\t\t  Pair1Start -- second --&gt; ID1IRUnit1 --&gt; Pair1End \tPair1End -- value --&gt; Iter1\tAnalysisResult -- key --&gt; Pair2Start -- first --&gt; ID2 --&gt; Pair2End\t\t\t\t\t\t\t\t\t\t\t\t\t  Pair2Start -- second --&gt; ID2IRUnit2 --&gt; Pair2End \tPair2End -- value --&gt; Iter2\tAnalysisResult --&gt; ...\tAnalysisResult -- key --&gt; PairNStart -- first --&gt; IDN --&gt; PairNEnd\t\t\t\t\t\t\t\t\t\t\t\t\t  PairNStart -- second --&gt; IDNIRUnitN --&gt; PairNEnd \tPairNEnd -- value --&gt; IterN\n\n关联那么我们把这两个部分串联起来看\nflowchart LR\tAnalysisResult -- key --&gt; Pair1Start -- first --&gt; ID1 --&gt; Pair1End\t\t\t\t\t\t\t\t\t\t\t\t\t  Pair1Start -- second --&gt; ID1IRUnit1 --&gt; Pair1End \tPair1End -- value --&gt; Iter1  AnalysisResultList -- key --&gt; IRUnit1 -- value --&gt; Pair11 --&gt; ID1 &amp; Result1  IRUnit1 --&gt; Pair12 --&gt; ID2 &amp; Result2    Iter1 --&gt; Result1\n\nAnalysisKey上面的查询过程中一直提到一个ID，而这个ID正是上面提及过的AnalysisInfoMixin所携带的ID函数所获取的。\n类型定义是这样的\nstruct alignas(8) AnalysisKey &#123;&#125;;\n\n还记得每个Analysis中会声明一个静态的id变量么，C++中空对象依然需要保留1字节的空间来标识地址，因此使用了这种方式区分不同的Analysis\n总结一个Analysis的结果是在Pass中通过AnalysisManager的getResult实例方法获取的\n只有在实际进入这个函数的时候才会得到结果(lazily runs)，而每次进入到getResult的时候会根据一个Analysis ID以及一个IR来判断是否有结果的cache，没有cache这个时候才会进行分析得到结果(caches their results)\nAnalysisResultList是IR为Key，Analysis的ID与结果为值的Map\nAnalysisResults保存的则是一个IR + Analysis ID为key，结果为指向AnalysisResultList中某个结果的迭代器\nAnalysis Cache那么问题来了，既然是类似cache的机制，cache失效是怎么判断的呢？\n我们回看一下PassManger中执行完Pass后的代码\nfor (unsigned Idx = 0, Size = Passes.size(); Idx != Size; ++Idx) &#123;    ...    PI.runAfterPass&lt;IRUnitT&gt;(*P, IR, PassPA);    // Update the analysis manager as each pass runs and potentially    // invalidates analyses.    AM.invalidate(IR, PassPA);    // Finally, intersect the preserved analyses to compute the aggregate    // preserved set for this pass manager.    PA.intersect(std::move(PassPA));  &#125;\n\n这里提到了AM.invalidate，那么我们开始看一下invalidate的整个流程。不过在这之前我们先大概了解一下PreservedAnalyses\nPreservedAnalyses\n大体看一下成员分为这么几类\n\n实际保存的preserve信息\n基本的preserve相关的接口\nabandon以及intersect\nPreservedAnalysisChecker\n\n有这么三个成员变量\nclass PreservedAnalyses &#123;private:\t/// A special key used to indicate all analyses.  static AnalysisSetKey AllAnalysesKey;  /// The IDs of analyses and analysis sets that are preserved.  SmallPtrSet&lt;void *, 2&gt; PreservedIDs;  /// The IDs of explicitly not-preserved analyses.  ///  /// If an analysis in this set is covered by a set in `PreservedIDs`, we  /// consider it not-preserved. That is, `NotPreservedAnalysisIDs` always  /// &quot;wins&quot; over analysis sets in `PreservedIDs`.  ///  /// Also, a given ID should never occur both here and in `PreservedIDs`.  SmallPtrSet&lt;AnalysisKey *, 2&gt; NotPreservedAnalysisIDs;&#125;\n\n看名字就能理解其用途，一个Set保存了Preserved的ID，另一个Set保存NotPreserved的ID。要注意的是PreserveIDs里面的是void而不是AnalysisKey，因为被preserved的不仅可以是单个Analysis，还可以AnalysisSetKey。\nAnalysisSetKeystruct alignas(8) AnalysisKey &#123;&#125;;struct alignas(8) AnalysisSetKey &#123;&#125;;\n\nAnalysisSetKey是一个代表一个IRUnit类型所有Analysis的。比如说IRUnit的类型是一个Function，那么就会有一个Function的AnalysisSetKey来表示preserve了所有Function相关的Pass，避免了对每个FunctionAnalysis进行比较判断\n每个AnalysisSetKey也是像AnalysisKey有一个静态的实例。\n首先是AllAnalysesOn这个类保存了Module和Function的AnalysisSetKey。AllAnalysesOn::ID就是获取表示对应IRUnit类型所有Analysis的AnalysisSetKey\n/// This templated class represents &quot;all analyses that operate over \\&lt;a/// particular IR unit\\&gt;&quot; (e.g. a Function or a Module) in instances of/// PreservedAnalysis.////// This lets a transformation say e.g. &quot;I preserved all function analyses&quot;.////// Note that you must provide an explicit instantiation declaration and/// definition for this template in order to get the correct behavior on/// Windows. Otherwise, the address of SetKey will not be stable.template &lt;typename IRUnitT&gt; class AllAnalysesOn &#123;public:  static AnalysisSetKey *ID() &#123; return &amp;SetKey; &#125;private:  static AnalysisSetKey SetKey;&#125;;template &lt;typename IRUnitT&gt; AnalysisSetKey AllAnalysesOn&lt;IRUnitT&gt;::SetKey;extern template class AllAnalysesOn&lt;Module&gt;;extern template class AllAnalysesOn&lt;Function&gt;;\n\n除此之外，在PreservedAnalyses中有一个表示保存了所有Analysis的key。注意这里的是private的，通过public的all来返回\nclass PreservedAnalyses &#123;public:  ...\tstatic PreservedAnalyses all() &#123;    PreservedAnalyses PA;    PA.PreservedIDs.insert(&amp;AllAnalysesKey);    return PA;  &#125;private:  /// A special key used to indicate all analyses.  static AnalysisSetKey AllAnalysesKey;&#125;\n\nCFGAnalyses还有自己的一个AnalysisSetKey\nclass CFGAnalyses &#123;public:  static AnalysisSetKey *ID() &#123; return &amp;SetKey; &#125;private:  static AnalysisSetKey SetKey;&#125;;\n\npreserve的相关接口class PreservedAnalyses &#123;public:\t/// Convenience factory function for the empty preserved set.  static PreservedAnalyses none() &#123; return PreservedAnalyses(); &#125;  /// Construct a special preserved set that preserves all passes.  static PreservedAnalyses all() &#123;    PreservedAnalyses PA;    PA.PreservedIDs.insert(&amp;AllAnalysesKey);    return PA;  &#125;  /// Construct a preserved analyses object with a single preserved set.  template &lt;typename AnalysisSetT&gt;  static PreservedAnalyses allInSet() &#123;    PreservedAnalyses PA;    PA.preserveSet&lt;AnalysisSetT&gt;();    return PA;  &#125;  /// Mark an analysis as preserved.  template &lt;typename AnalysisT&gt; void preserve() &#123; preserve(AnalysisT::ID()); &#125;  /// Given an analysis&#x27;s ID, mark the analysis as preserved, adding it  /// to the set.  void preserve(AnalysisKey *ID) &#123;    // Clear this ID from the explicit not-preserved set if present.    NotPreservedAnalysisIDs.erase(ID);    // If we&#x27;re not already preserving all analyses (other than those in    // NotPreservedAnalysisIDs).    if (!areAllPreserved())      PreservedIDs.insert(ID);  &#125;  /// Mark an analysis set as preserved.  template &lt;typename AnalysisSetT&gt; void preserveSet() &#123;    preserveSet(AnalysisSetT::ID());  &#125;  /// Mark an analysis set as preserved using its ID.  void preserveSet(AnalysisSetKey *ID) &#123;    // If we&#x27;re not already in the saturated &#x27;all&#x27; state, add this set.    if (!areAllPreserved())      PreservedIDs.insert(ID);  &#125;  ...&#125;\n\n一些比较基础的preserve接口，和Set相关的只需要操作PreservedIDs就可以，如果是非Set的Key则需要再操作NotPreservedAnalysisIDs\nabandon/// Mark an analysis as abandoned.////// An abandoned analysis is not preserved, even if it is nominally covered/// by some other set or was previously explicitly marked as preserved.////// Note that you can only abandon a specific analysis, not a *set* of/// analyses.template &lt;typename AnalysisT&gt; void abandon() &#123; abandon(AnalysisT::ID()); &#125;/// Mark an analysis as abandoned using its ID.////// An abandoned analysis is not preserved, even if it is nominally covered/// by some other set or was previously explicitly marked as preserved.////// Note that you can only abandon a specific analysis, not a *set* of/// analyses.void abandon(AnalysisKey *ID) &#123;  PreservedIDs.erase(ID);  NotPreservedAnalysisIDs.insert(ID);&#125;\n\n这个就是简单的设置某个Analysis为NotPreserved\nintersect/// Intersect this set with another in place.  ///  /// This is a mutating operation on this preserved set, removing all  /// preserved passes which are not also preserved in the argument.  void intersect(const PreservedAnalyses &amp;Arg) &#123;    if (Arg.areAllPreserved())      return;    if (areAllPreserved()) &#123;      *this = Arg;      return;    &#125;    // The intersection requires the *union* of the explicitly not-preserved    // IDs and the *intersection* of the preserved IDs.    for (auto ID : Arg.NotPreservedAnalysisIDs) &#123;      PreservedIDs.erase(ID);      NotPreservedAnalysisIDs.insert(ID);    &#125;    for (auto ID : PreservedIDs)      if (!Arg.PreservedIDs.count(ID))        PreservedIDs.erase(ID);  &#125;  /// Intersect this set with a temporary other set in place.  ///  /// This is a mutating operation on this preserved set, removing all  /// preserved passes which are not also preserved in the argument.  void intersect(PreservedAnalyses &amp;&amp;Arg) &#123;    if (Arg.areAllPreserved())      return;    if (areAllPreserved()) &#123;      *this = std::move(Arg);      return;    &#125;    // The intersection requires the *union* of the explicitly not-preserved    // IDs and the *intersection* of the preserved IDs.    for (auto ID : Arg.NotPreservedAnalysisIDs) &#123;      PreservedIDs.erase(ID);      NotPreservedAnalysisIDs.insert(ID);    &#125;    for (auto ID : PreservedIDs)      if (!Arg.PreservedIDs.count(ID))        PreservedIDs.erase(ID);  &#125;\n\ninvalidate声明\n/// Invalidate cached analyses for an IR unit.////// Walk through all of the analyses pertaining to this unit of IR and/// invalidate them, unless they are preserved by the PreservedAnalyses set.void invalidate(IRUnitT &amp;IR, const PreservedAnalyses &amp;PA);\n\n实现的完整代码\ntemplate &lt;typename IRUnitT, typename... ExtraArgTs&gt;inline void AnalysisManager&lt;IRUnitT, ExtraArgTs...&gt;::invalidate(    IRUnitT &amp;IR, const PreservedAnalyses &amp;PA) &#123;  // We&#x27;re done if all analyses on this IR unit are preserved.  if (PA.allAnalysesInSetPreserved&lt;AllAnalysesOn&lt;IRUnitT&gt;&gt;())    return;  // Track whether each analysis&#x27;s result is invalidated in  // IsResultInvalidated.  SmallDenseMap&lt;AnalysisKey *, bool, 8&gt; IsResultInvalidated;  Invalidator Inv(IsResultInvalidated, AnalysisResults);  AnalysisResultListT &amp;ResultsList = AnalysisResultLists[&amp;IR];  for (auto &amp;AnalysisResultPair : ResultsList) &#123;    // This is basically the same thing as Invalidator::invalidate, but we    // can&#x27;t call it here because we&#x27;re operating on the type-erased result.    // Moreover if we instead called invalidate() directly, it would do an    // unnecessary look up in ResultsList.    AnalysisKey *ID = AnalysisResultPair.first;    auto &amp;Result = *AnalysisResultPair.second;    auto IMapI = IsResultInvalidated.find(ID);    if (IMapI != IsResultInvalidated.end())      // This result was already handled via the Invalidator.      continue;    // Try to invalidate the result, giving it the Invalidator so it can    // recursively query for any dependencies it has and record the result.    // Note that we cannot reuse &#x27;IMapI&#x27; here or pre-insert the ID, as    // Result.invalidate may insert things into the map, invalidating our    // iterator.    bool Inserted =        IsResultInvalidated.insert(&#123;ID, Result.invalidate(IR, PA, Inv)&#125;).second;    (void)Inserted;    assert(Inserted &amp;&amp; &quot;Should never have already inserted this ID, likely &quot;                       &quot;indicates a cycle!&quot;);  &#125;  // Now erase the results that were marked above as invalidated.  if (!IsResultInvalidated.empty()) &#123;    for (auto I = ResultsList.begin(), E = ResultsList.end(); I != E;) &#123;      AnalysisKey *ID = I-&gt;first;      if (!IsResultInvalidated.lookup(ID)) &#123;        ++I;        continue;      &#125;      if (auto *PI = getCachedResult&lt;PassInstrumentationAnalysis&gt;(IR))        PI-&gt;runAnalysisInvalidated(this-&gt;lookUpPass(ID), IR);      I = ResultsList.erase(I);      AnalysisResults.erase(&#123;ID, &amp;IR&#125;);    &#125;  &#125;  if (ResultsList.empty())    AnalysisResultLists.erase(&amp;IR);&#125;\n\nIsAllPreserved首先是判断是否这个set是被preserved的\n// We&#x27;re done if all analyses on this IR unit are preserved.if (PA.allAnalysesInSetPreserved&lt;AllAnalysesOn&lt;IRUnitT&gt;&gt;())  return;\n\n这里通过了一种AnalysisSetKey的方式来标识是否preserved了某个IRUnit的所有Analysis。\ntemplate &lt;typename AnalysisSetT&gt; bool allAnalysesInSetPreserved() const &#123;  return allAnalysesInSetPreserved(AnalysisSetT::ID());&#125;/// Directly test whether a set of analyses is preserved.////// This is only true when no analyses have been explicitly abandoned.bool allAnalysesInSetPreserved(AnalysisSetKey *SetID) const &#123;  return NotPreservedAnalysisIDs.empty() &amp;&amp;         (PreservedIDs.count(&amp;AllAnalysesKey) || PreservedIDs.count(SetID));&#125;\n\n这里与其叫count不如叫find，查找是否存在对应的Key\n遍历所有Result执行invalidateSmallDenseMap&lt;AnalysisKey *, bool, 8&gt; IsResultInvalidated;Invalidator Inv(IsResultInvalidated, AnalysisResults);AnalysisResultListT &amp;ResultsList = AnalysisResultLists[&amp;IR];for (auto &amp;AnalysisResultPair : ResultsList) &#123;  AnalysisKey *ID = AnalysisResultPair.first;  auto &amp;Result = *AnalysisResultPair.second;  auto IMapI = IsResultInvalidated.find(ID);  if (IMapI != IsResultInvalidated.end())    continue;  bool Inserted =      IsResultInvalidated.insert(&#123;ID, Result.invalidate(IR, PA, Inv)&#125;).second;  (void)Inserted;  assert(Inserted &amp;&amp; &quot;Should never have already inserted this ID, likely &quot;                     &quot;indicates a cycle!&quot;);&#125;\n\n回想一下getResultImpl中将pass的结果存到了AnalysisResults中，前面的思路都捋清了这里也就很简单了\n通过IsResultInvalidated记录处理过的Analysis\n先找到所有这个IR关联的analysis以及result的组合，遍历每一个Result然后调用Result.invalidate，将验证结果塞入到IsResultInvalidated\n删除无效cache// Now erase the results that were marked above as invalidated.if (!IsResultInvalidated.empty()) &#123;  for (auto I = ResultsList.begin(), E = ResultsList.end(); I != E;) &#123;    AnalysisKey *ID = I-&gt;first;    if (!IsResultInvalidated.lookup(ID)) &#123;      ++I;      continue;    &#125;    if (auto *PI = getCachedResult&lt;PassInstrumentationAnalysis&gt;(IR))      PI-&gt;runAnalysisInvalidated(this-&gt;lookUpPass(ID), IR);    I = ResultsList.erase(I);    AnalysisResults.erase(&#123;ID, &amp;IR&#125;);  &#125;&#125;if (ResultsList.empty())  AnalysisResultLists.erase(&amp;IR);\n\n最后则是简单的遍历所有的Result，根据IsResultInvalidated判断，如果是invalid则要从ResultList和AnalysisResults中删除\n如果这个IR的所有Analysis结果都删掉了，那么就直接清除掉在ResultList中的这个IR相关的条目\n这里的getCachedResult逻辑也很简单，就是取出保存的结果，这里不赘述了\nAnalysisResultModelinvalidate的过程中最关键的步骤在于Result.invalidate，而一个Result又是一个AnalysisResultModel\n前面只看过了这个类的声明，我们在这里看一下HasInvalidateHandler为True和False的实现（省略了一些构造函数和相同的部分）\n/// Specialization of \\c AnalysisResultModel which delegates invalidate/// handling to \\c ResultT.template &lt;typename IRUnitT, typename PassT, typename ResultT,          typename PreservedAnalysesT, typename InvalidatorT&gt;struct AnalysisResultModel&lt;IRUnitT, PassT, ResultT, PreservedAnalysesT,                           InvalidatorT, true&gt;    : AnalysisResultConcept&lt;IRUnitT, PreservedAnalysesT, InvalidatorT&gt; &#123;  explicit AnalysisResultModel(ResultT Result) : Result(std::move(Result)) &#123;&#125;  ...  /// The model delegates to the \\c ResultT method.  bool invalidate(IRUnitT &amp;IR, const PreservedAnalysesT &amp;PA,                  InvalidatorT &amp;Inv) override &#123;    return Result.invalidate(IR, PA, Inv);  &#125;  ResultT Result;&#125;;\n\n而为false的时候只有invalidate的内部实现是不同的\nbool invalidate(IRUnitT &amp;, const PreservedAnalysesT &amp;PA,                InvalidatorT &amp;) override &#123;  auto PAC = PA.template getChecker&lt;PassT&gt;();  return !PAC.preserved() &amp;&amp;         !PAC.template preservedSet&lt;AllAnalysesOn&lt;IRUnitT&gt;&gt;();&#125;\n\n关于这个参数有这样一段注释\n\nBy default, this will implement the invalidate method with a trivial implementation so that the actual analysis result doesn’t need to provide an invalidation handler. It is only selected when the invalidation handler is not part of the ResultT’s interface.\n\n大意是LLVM中实现了一个默认的invalidate method，只有result不包含invalidate接口的时候才会被使用\n那么我们先来从getChecker开始理解LLVM中默认的trivial invalidate过程\ngetCheckerclass PreservedAnalyses &#123;public:\t\t/// Build a checker for this `PreservedAnalyses` and the specified analysis  /// type.  ///  /// You can use the returned object to query whether an analysis was  /// preserved. See the example in the comment on `PreservedAnalysis`.  template &lt;typename AnalysisT&gt; PreservedAnalysisChecker getChecker() const &#123;    return PreservedAnalysisChecker(*this, AnalysisT::ID());  &#125;  /// Build a checker for this `PreservedAnalyses` and the specified analysis  /// ID.  ///  /// You can use the returned object to query whether an analysis was  /// preserved. See the example in the comment on `PreservedAnalysis`.  PreservedAnalysisChecker getChecker(AnalysisKey *ID) const &#123;    return PreservedAnalysisChecker(*this, ID);  &#125;&#125;\n\nPreservedAnalysisCheckerclass PreservedAnalysisChecker &#123;  friend class PreservedAnalyses;  /// A PreservedAnalysisChecker is tied to a particular Analysis because  /// `preserved()` and `preservedSet()` both return false if the Analysis  /// was abandoned.  PreservedAnalysisChecker(const PreservedAnalyses &amp;PA, AnalysisKey *ID)      : PA(PA), ID(ID), IsAbandoned(PA.NotPreservedAnalysisIDs.count(ID)) &#123;&#125;\t/// Returns true if the checker&#x27;s analysis was not abandoned and either  ///  - the analysis is explicitly preserved or  ///  - all analyses are preserved.  bool preserved() &#123;    return !IsAbandoned &amp;&amp; (PA.PreservedIDs.count(&amp;AllAnalysesKey) ||                            PA.PreservedIDs.count(ID));  &#125;\t/// Returns true if the checker&#x27;s analysis was not abandoned and either  ///  - \\p AnalysisSetT is explicitly preserved or  ///  - all analyses are preserved.  template &lt;typename AnalysisSetT&gt; bool preservedSet() &#123;    AnalysisSetKey *SetID = AnalysisSetT::ID();    return !IsAbandoned &amp;&amp; (PA.PreservedIDs.count(&amp;AllAnalysesKey) ||                            PA.PreservedIDs.count(SetID));  &#125;&#125;\n\n这里的逻辑也是比较简单。\n回顾invalidate流程我们来回头捋一下invalidate的调用栈以及整个逻辑\nflowchart LR  PassManager::run --&gt; AnalysisManager::invalidate\tAnalysisManager::invalidate --&gt; AnalysisResultModel::invalidate   AnalysisResultModel::invalidate --&gt; HasInvalidateHandlerFalse  HasInvalidateHandlerFalse --&gt; getChecker --&gt; PreservedAnalysisChecker\tPreservedAnalysisChecker --&gt; preserved\tPreservedAnalysisChecker --&gt; preservedSet\n\n一个Pass返回的PreservedAnalyses用于检查导致哪些Analysis失效了，而实际进行检查的则是对应的Result中的handler或者是LLVM默认的PreservedAnalysisChecker\n自定义的handler我们来看几个例子\n/// Analysis pass which computes a \\c DominatorTree.class DominatorTreeAnalysis : public AnalysisInfoMixin&lt;DominatorTreeAnalysis&gt; &#123;  ...  /// Provide the result typedef for this analysis pass.  using Result = DominatorTree;  ...&#125;class DominatorTree : public DominatorTreeBase&lt;BasicBlock, false&gt; &#123;  /// Handle invalidation explicitly.  bool invalidate(Function &amp;F, const PreservedAnalyses &amp;PA,                  FunctionAnalysisManager::Invalidator &amp;);&#125;bool DominatorTree::invalidate(Function &amp;F, const PreservedAnalyses &amp;PA,                               FunctionAnalysisManager::Invalidator &amp;) &#123;  // Check whether the analysis, all analyses on functions, or the function&#x27;s  // CFG have been preserved.  auto PAC = PA.getChecker&lt;DominatorTreeAnalysis&gt;();  return !(PAC.preserved() || PAC.preservedSet&lt;AllAnalysesOn&lt;Function&gt;&gt;() ||           PAC.preservedSet&lt;CFGAnalyses&gt;());&#125;\n\nclass CallGraphAnalysis : public AnalysisInfoMixin&lt;CallGraphAnalysis&gt; &#123;  ...  using Result = CallGraph;&#125;bool CallGraph::invalidate(Module &amp;, const PreservedAnalyses &amp;PA,                           ModuleAnalysisManager::Invalidator &amp;) &#123;  // Check whether the analysis, all analyses on functions, or the function&#x27;s  // CFG have been preserved.  auto PAC = PA.getChecker&lt;CallGraphAnalysis&gt;();  return !(PAC.preserved() || PAC.preservedSet&lt;AllAnalysesOn&lt;Module&gt;&gt;() ||           PAC.preservedSet&lt;CFGAnalyses&gt;());&#125;\n\n自定义invalidate的基本上都是利用了PreservedAnalysisChecker，加了一些特殊Set的检查，目前没看到有什么特别复杂的实现\n","categories":["Compiler"],"tags":["LLVM","Pass","Analysis"]},{"title":"LLVM Pass 其三：PassBuilder","url":"/2022/07/10/llvm-pass/llvm-pass-3/","content":"LLVM Pass 其三：PassBuilder\n出来吧，罪青眼白龙！（为什么这张卡台词这么简单 \n\n在前面几期中我们讲了新Pass，PassManager，Analysis是怎么样的，这期我们来讲一下PassBuilder以及实际许多Pass是如何组织起来的。\nPassBuilder相关的源文件有这几个\ninclude/llvm/Passes/PassBuilder.h\nlib/Passes/PassBuilder.cpp\nlib/Passes/PassBuilderPipelines.cpp\nPassBuilder结构/// This class provides access to building LLVM&#x27;s passes.////// Its members provide the baseline state available to passes during their/// construction. The \\c PassRegistry.def file specifies how to construct all/// of the built-in passes, and those may reference these members during/// construction.class PassBuilder &#123;  TargetMachine *TM;  PipelineTuningOptions PTO;  Optional&lt;PGOOptions&gt; PGOOpt;  PassInstrumentationCallbacks *PIC;  ...&#125;\n\n注意这里有一个TargetMachine\n\n\n可以看到由这么几类成员构成\n\n存放基本信息的成员，包括TargetMachine以及各种保存的callback等\nregisterXXXAnalysis / registerXXXCallback\nbuildXXXpipeline\nparseXXXPass / parseXXXPasePipeline\n\nPassBuilder的使用我们从PassBuilder的使用开始理顺里面的流程。PassBuilder有两处主要的使用位置，一处是在lto中调用，另一处是这次主要讲解的LLVMRunPasses\n这个函数对应的头文件是include/llvm-c/Transforms/PassBuilder.h\n而LLVMRunPasses的实现在lib/Passes/PassBuilderBindings.cpp\nLLVMErrorRef LLVMRunPasses(LLVMModuleRef M, const char *Passes,                           LLVMTargetMachineRef TM,                           LLVMPassBuilderOptionsRef Options) &#123;  TargetMachine *Machine = unwrap(TM);  LLVMPassBuilderOptions *PassOpts = unwrap(Options);  bool Debug = PassOpts-&gt;DebugLogging;  bool VerifyEach = PassOpts-&gt;VerifyEach;  Module *Mod = unwrap(M);  PassInstrumentationCallbacks PIC;  PassBuilder PB(Machine, PassOpts-&gt;PTO, None, &amp;PIC);  LoopAnalysisManager LAM;  FunctionAnalysisManager FAM;  CGSCCAnalysisManager CGAM;  ModuleAnalysisManager MAM;  PB.registerLoopAnalyses(LAM);  PB.registerFunctionAnalyses(FAM);  PB.registerCGSCCAnalyses(CGAM);  PB.registerModuleAnalyses(MAM);  PB.crossRegisterProxies(LAM, FAM, CGAM, MAM);  StandardInstrumentations SI(Debug, VerifyEach);  SI.registerCallbacks(PIC, &amp;FAM);  ModulePassManager MPM;  if (VerifyEach) &#123;    MPM.addPass(VerifierPass());  &#125;  if (auto Err = PB.parsePassPipeline(MPM, Passes)) &#123;    return wrap(std::move(Err));  &#125;  MPM.run(*Mod, MAM);  return LLVMErrorSuccess;&#125;\n\n这里的逻辑非常清晰\n\n先对每一种Analysis注册，之后注册Proxies\n注册callback\nparsePassPieline开始添加Pass到MPM中\n\n接下来我们对这三部分操作逐一讲解\n注册Analyses首先我们回顾一下之前讲过的Pass注册方式。LLVM内部的Pass注册需要在PassRegistry.def中以宏的方式写下，之后在include这个文件的前面定义这些宏，之后再include这个文件完成整个流程\nregisterXXXAnalysesvoid PassBuilder::registerModuleAnalyses(ModuleAnalysisManager &amp;MAM) &#123;#define MODULE_ANALYSIS(NAME, CREATE_PASS)                                     \\  MAM.registerPass([&amp;] &#123; return CREATE_PASS; &#125;);#include &quot;PassRegistry.def&quot;  for (auto &amp;C : ModuleAnalysisRegistrationCallbacks)    C(MAM);&#125;\n\n这里简单的注册一遍Analysis之后执行一下ModuleAnalysisRegistrationCallbacks\n除了Module，Function，Loop之类的实现基本上一致，这里不再重复贴代码了\ncrossRegisterProxiesvoid PassBuilder::crossRegisterProxies(LoopAnalysisManager &amp;LAM,                                       FunctionAnalysisManager &amp;FAM,                                       CGSCCAnalysisManager &amp;CGAM,                                       ModuleAnalysisManager &amp;MAM) &#123;  MAM.registerPass([&amp;] &#123; return FunctionAnalysisManagerModuleProxy(FAM); &#125;);  MAM.registerPass([&amp;] &#123; return CGSCCAnalysisManagerModuleProxy(CGAM); &#125;);  CGAM.registerPass([&amp;] &#123; return ModuleAnalysisManagerCGSCCProxy(MAM); &#125;);  FAM.registerPass([&amp;] &#123; return CGSCCAnalysisManagerFunctionProxy(CGAM); &#125;);  FAM.registerPass([&amp;] &#123; return ModuleAnalysisManagerFunctionProxy(MAM); &#125;);  FAM.registerPass([&amp;] &#123; return LoopAnalysisManagerFunctionProxy(LAM); &#125;);  LAM.registerPass([&amp;] &#123; return FunctionAnalysisManagerLoopProxy(FAM); &#125;);&#125;\n\n这里是给各种的AnalysisManager注册了一个XXXXAnalysisManagerXXXProxy，而这些类型本质上是一个给proxy指定了部分模板参数的别名。比如说FunctionAnalysisManagerModuleProxy这个类型\nusing FunctionAnalysisManagerModuleProxy =    InnerAnalysisManagerProxy&lt;FunctionAnalysisManager, Module&gt;;\n\n和普通Pass使用adaptor不同的是一个Function的Manager注册了到Module的Proxy，而Module也注册了一个到Function的Proxy。注意这里的是Outer，而不再是Inner了\nusing ModuleAnalysisManagerFunctionProxy =    OuterAnalysisManagerProxy&lt;ModuleAnalysisManager, Function&gt;;\n\nInnerAnalysisManagerProxy\n对于Proxy来说功能也是类似于adaptor，用于在不同范围的IRUnit之间转换处理。Inner和adaptor一样，将一个小范围的pass的应用在大的范围上（Function的analysis应用到整个Module上）\ntemplate &lt;typename AnalysisManagerT, typename IRUnitT, typename... ExtraArgTs&gt;class InnerAnalysisManagerProxy    : public AnalysisInfoMixin&lt;          InnerAnalysisManagerProxy&lt;AnalysisManagerT, IRUnitT&gt;&gt; &#123;public:  class Result &#123;&#125;&#125;\n\n从上面addPass的行为以及类型声明可以看到Proxy也是一个Analysis，对于一个Analysis最主要的就是run以及Result里的行为了。\n这里run的逻辑就是将InnerAM塞到InnerAnalysisManagerProxy::Result中返回\nResult run(IRUnitT &amp;IR, AnalysisManager&lt;IRUnitT, ExtraArgTs...&gt; &amp;AM,           ExtraArgTs...) &#123;  return Result(*InnerAM);&#125;\n\nResultclass Result &#123;public:  explicit Result(AnalysisManagerT &amp;InnerAM) : InnerAM(&amp;InnerAM) &#123;&#125;  ...\tAnalysisManagerT &amp;getManager() &#123; return *InnerAM; &#125;  ...\tbool invalidate(    IRUnitT &amp;IR, const PreservedAnalyses &amp;PA,    typename AnalysisManager&lt;IRUnitT, ExtraArgTs...&gt;::Invalidator &amp;Inv);private:  AnalysisManagerT *InnerAM;&#125;;\n\n这里的Result并不是一个具体的什么值，而是一个AnalysisManagerT的包装，这样做避免了每个AnalysisManager中塞入不必要的invalidate。\n在实际使用的时候都是要先获取proxy的result再从中getManager，最后从AnalysisManager中获取某个具体的Analysis\nLazyCallGraph run(Module &amp;M, ModuleAnalysisManager &amp;AM) &#123;    FunctionAnalysisManager &amp;FAM =        AM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();    auto GetTLI = [&amp;FAM](Function &amp;F) -&gt; TargetLibraryInfo &amp; &#123;      return FAM.getResult&lt;TargetLibraryAnalysis&gt;(F);    &#125;;    return LazyCallGraph(M, GetTLI);  &#125;\n\ninvalidate对于一个Result来说invalidate的行为是最关键的。Result类内部本身并没有定义invalidate的行为，但是通过各种偏特化的形式定义不同IRUnit类型对应的invalidate方式\n\n复杂的invalidate逻辑（已删去所有注释），这不是本期重点因此不赘述，整体逻辑应当和上一期的invalidate一致，如果要理顺这些可以看上一期作为参考\ntemplate &lt;&gt;bool FunctionAnalysisManagerModuleProxy::Result::invalidate(    Module &amp;M, const PreservedAnalyses &amp;PA,    ModuleAnalysisManager::Invalidator &amp;Inv) &#123;  if (PA.areAllPreserved())    return false; // This is still a valid proxy.  auto PAC = PA.getChecker&lt;FunctionAnalysisManagerModuleProxy&gt;();  if (!PAC.preserved() &amp;&amp; !PAC.preservedSet&lt;AllAnalysesOn&lt;Module&gt;&gt;()) &#123;    InnerAM-&gt;clear();    return true;  &#125;  bool AreFunctionAnalysesPreserved =      PA.allAnalysesInSetPreserved&lt;AllAnalysesOn&lt;Function&gt;&gt;();  for (Function &amp;F : M) &#123;    Optional&lt;PreservedAnalyses&gt; FunctionPA;    if (auto *OuterProxy =            InnerAM-&gt;getCachedResult&lt;ModuleAnalysisManagerFunctionProxy&gt;(F))      for (const auto &amp;OuterInvalidationPair :           OuterProxy-&gt;getOuterInvalidations()) &#123;        AnalysisKey *OuterAnalysisID = OuterInvalidationPair.first;        const auto &amp;InnerAnalysisIDs = OuterInvalidationPair.second;        if (Inv.invalidate(OuterAnalysisID, M, PA)) &#123;          if (!FunctionPA)            FunctionPA = PA;          for (AnalysisKey *InnerAnalysisID : InnerAnalysisIDs)            FunctionPA-&gt;abandon(InnerAnalysisID);        &#125;      &#125;    if (FunctionPA) &#123;      InnerAM-&gt;invalidate(F, *FunctionPA);      continue;    &#125;    if (!AreFunctionAnalysesPreserved)      InnerAM-&gt;invalidate(F, PA);  &#125;  return false;&#125;\n\nOuterAnalysisManagerProxy这个与上面提到的InnerAnalysisManagerProxy相反。将一个大范围的Analysis应用到一个小范围的IRUnit上。比如说这个\nusing ModuleAnalysisManagerFunctionProxy =    OuterAnalysisManagerProxy&lt;ModuleAnalysisManager, Function&gt;;\n\n除了Result之外的逻辑和InnerAnalysisManagerProxy基本上一致，但是Proxy保存的则是一个const AnalysisManagerT，也就是说是一个只读的包装。Inner的Result是用来存放一个AnalysisManager，而Outer的Result则和外层的Manager一样保存的是一个const AnalysisManagerT，也就是说是一个只读的包装。\nclass Result &#123;  public:    explicit Result(const AnalysisManagerT &amp;OuterAM) : OuterAM(&amp;OuterAM) &#123;&#125;    /// Get a cached analysis. If the analysis can be invalidated, this will    /// assert.    template &lt;typename PassT, typename IRUnitTParam&gt;    typename PassT::Result *getCachedResult(IRUnitTParam &amp;IR) const &#123;      typename PassT::Result *Res =          OuterAM-&gt;template getCachedResult&lt;PassT&gt;(IR);      if (Res)        OuterAM-&gt;template verifyNotInvalidated&lt;PassT&gt;(IR, Res);      return Res;    &#125;    /// Method provided for unit testing, not intended for general use.    template &lt;typename PassT, typename IRUnitTParam&gt;    bool cachedResultExists(IRUnitTParam &amp;IR) const &#123;      typename PassT::Result *Res =          OuterAM-&gt;template getCachedResult&lt;PassT&gt;(IR);      return Res != nullptr;    &#125;    /// When invalidation occurs, remove any registered invalidation events.    bool invalidate(        IRUnitT &amp;IRUnit, const PreservedAnalyses &amp;PA,        typename AnalysisManager&lt;IRUnitT, ExtraArgTs...&gt;::Invalidator &amp;Inv) &#123;      // Loop over the set of registered outer invalidation mappings and if any      // of them map to an analysis that is now invalid, clear it out.      SmallVector&lt;AnalysisKey *, 4&gt; DeadKeys;      for (auto &amp;KeyValuePair : OuterAnalysisInvalidationMap) &#123;        AnalysisKey *OuterID = KeyValuePair.first;        auto &amp;InnerIDs = KeyValuePair.second;        llvm::erase_if(InnerIDs, [&amp;](AnalysisKey *InnerID) &#123;          return Inv.invalidate(InnerID, IRUnit, PA);        &#125;);        if (InnerIDs.empty())          DeadKeys.push_back(OuterID);      &#125;      for (auto OuterID : DeadKeys)        OuterAnalysisInvalidationMap.erase(OuterID);      // The proxy itself remains valid regardless of anything else.      return false;    &#125;    /// Register a deferred invalidation event for when the outer analysis    /// manager processes its invalidations.    template &lt;typename OuterAnalysisT, typename InvalidatedAnalysisT&gt;    void registerOuterAnalysisInvalidation() &#123;      AnalysisKey *OuterID = OuterAnalysisT::ID();      AnalysisKey *InvalidatedID = InvalidatedAnalysisT::ID();      auto &amp;InvalidatedIDList = OuterAnalysisInvalidationMap[OuterID];      // Note, this is a linear scan. If we end up with large numbers of      // analyses that all trigger invalidation on the same outer analysis,      // this entire system should be changed to some other deterministic      // data structure such as a `SetVector` of a pair of pointers.      if (!llvm::is_contained(InvalidatedIDList, InvalidatedID))        InvalidatedIDList.push_back(InvalidatedID);    &#125;    /// Access the map from outer analyses to deferred invalidation requiring    /// analyses.    const SmallDenseMap&lt;AnalysisKey *, TinyPtrVector&lt;AnalysisKey *&gt;, 2&gt; &amp;    getOuterInvalidations() const &#123;      return OuterAnalysisInvalidationMap;    &#125;  private:    const AnalysisManagerT *OuterAM;    /// A map from an outer analysis ID to the set of this IR-unit&#x27;s analyses    /// which need to be invalidated.    SmallDenseMap&lt;AnalysisKey *, TinyPtrVector&lt;AnalysisKey *&gt;, 2&gt;        OuterAnalysisInvalidationMap;  &#125;;  OuterAnalysisManagerProxy(const AnalysisManagerT &amp;OuterAM)      : OuterAM(&amp;OuterAM) &#123;&#125;  /// Run the analysis pass and create our proxy result object.  /// Nothing to see here, it just forwards the \\c OuterAM reference into the  /// result.  Result run(IRUnitT &amp;, AnalysisManager&lt;IRUnitT, ExtraArgTs...&gt; &amp;,             ExtraArgTs...) &#123;    return Result(*OuterAM);  &#125;\n\n需要注意这里的设计是不能修改OuterAM的因此只能获取cached的result，并且有一套自己的analysis Invalidation机制，这里就不展开讲解了。\n我们来实际看一下使用的场合。目前实际有效的getResult的场合只搜到了这一处\ntemplate &lt;typename AnalysisT&gt;static void getModuleAAResultImpl(Function &amp;F, FunctionAnalysisManager &amp;AM,                                  AAResults &amp;AAResults) &#123;  auto &amp;MAMProxy = AM.getResult&lt;ModuleAnalysisManagerFunctionProxy&gt;(F);  if (auto *R =          MAMProxy.template getCachedResult&lt;AnalysisT&gt;(*F.getParent())) &#123;    AAResults.addAAResult(*R);    MAMProxy        .template registerOuterAnalysisInvalidation&lt;AnalysisT, AAManager&gt;();  &#125;&#125;\n\n这里我觉得是分析需要在Function内部做，但是全局变量的存在使得Function仍然需要一个全局范围内的别名分析\nAnalysisManager结构flowchart TD\t\tFAM(FunctionAnalysisManager)\t\tLAM(LoopAnalysisManager)\t\tCGAM(CGSCCAnalysisManager)\t\tMAM(ModuleAnalysisManager)\t\tFAMP(FunctionAnalysisManagerModuleProxy)    CGAMP(CGSCCAnalysisManagerModuleProxy)    CGAFP(CGSCCAnalysisManagerFunctionProxy)    MCGAP(ModuleAnalysisManagerCGSCCProxy)\t\tMAFP(ModuleAnalysisManagerFunctionProxy)\t\tLAFP(LoopAnalysisManagerFunctionProxy)\t\tFLAP(FunctionAnalysisManagerLoopProxy)    MAM --&gt;  FAMP --&gt; FAM\t\tMAM --&gt; CGAMP --&gt; CGAM    CGAM --&gt; MCGAP --&gt; MAM\t\tFAM --&gt; CGAFP --&gt; CGAM\t\tFAM --&gt; MAFP --&gt; MAM\t\tFAM --&gt; LAFP --&gt; LAM\t\tLAM --&gt; FLAP --&gt; FAM\n\n感觉画出来的图非常奇怪…\n至此Analysis的部分就已经处理结束了\nCallbacks and InstrumentationAnalysis之后则是添加各种callback。而这里则是通过StandardInstrumentations来注册callback到PIC（PassInstrumentCallbacks）中\nPassInstrumentationCallbacks PIC;PassBuilder PB(Machine, PassOpts-&gt;PTO, None, &amp;PIC);StandardInstrumentations SI(Debug, VerifyEach);SI.registerCallbacks(PIC, &amp;FAM);\n\n类定义include/llvm/IR/PassInstrumentation.h\n先不说StandardInstrumentations，和PassInstrument相关的有这么两个类\n\n\n两个类的关系也非常简单，PassInstrumentation中保存了一个实际持有各种callback的PassInstrumentationCallbacks对象。里面保存的各种callbacks的作用从成员名就能看出，这里不再赘述细节\n使用而获取PassInstrumentation则是通过PassInstrumentationAnalysis这个analysis获取的\nclass PassInstrumentationAnalysis    : public AnalysisInfoMixin&lt;PassInstrumentationAnalysis&gt; &#123;  friend AnalysisInfoMixin&lt;PassInstrumentationAnalysis&gt;;  static AnalysisKey Key;  PassInstrumentationCallbacks *Callbacks;public:  /// PassInstrumentationCallbacks object is shared, owned by something else,  /// not this analysis.  PassInstrumentationAnalysis(PassInstrumentationCallbacks *Callbacks = nullptr)      : Callbacks(Callbacks) &#123;&#125;  using Result = PassInstrumentation;  template &lt;typename IRUnitT, typename AnalysisManagerT, typename... ExtraArgTs&gt;  Result run(IRUnitT &amp;, AnalysisManagerT &amp;, ExtraArgTs &amp;&amp;...) &#123;    return PassInstrumentation(Callbacks);  &#125;&#125;;\n\n比如说我们之前讲过的PassManager中的代码（删掉了许多无关的代码）\nPreservedAnalyses run(IRUnitT &amp;IR, AnalysisManagerT &amp;AM,                        ExtraArgTs... ExtraArgs) &#123;    PassInstrumentation PI =        detail::getAnalysisResult&lt;PassInstrumentationAnalysis&gt;(            AM, IR, std::tuple&lt;ExtraArgTs...&gt;(ExtraArgs...));    for (unsigned Idx = 0, Size = Passes.size(); Idx != Size; ++Idx) &#123;      if (!PI.runBeforePass&lt;IRUnitT&gt;(*P, IR))        continue;          PreservedAnalyses PassPA;      &#123;        TimeTraceScope TimeScope(P-&gt;name(), IR.getName());        PassPA = P-&gt;run(IR, AM, ExtraArgs...);      &#125;      // Call onto PassInstrumentation&#x27;s AfterPass callbacks immediately after      // running the pass.      PI.runAfterPass&lt;IRUnitT&gt;(*P, IR, PassPA);    &#125;  &#125;\n\nStandardInstrumentationsStandardInstrumentations里面提供了注册standard pass instrumentations的接口\nclass StandardInstrumentations &#123;  PrintIRInstrumentation PrintIR;  PrintPassInstrumentation PrintPass;  TimePassesHandler TimePasses;  OptNoneInstrumentation OptNone;  OptBisectInstrumentation OptBisect;  PreservedCFGCheckerInstrumentation PreservedCFGChecker;  IRChangedPrinter PrintChangedIR;  PseudoProbeVerifier PseudoProbeVerification;  InLineChangePrinter PrintChangedDiff;  DotCfgChangeReporter WebsiteChangeReporter;  VerifyInstrumentation Verify;  bool VerifyEach;public:  StandardInstrumentations(bool DebugLogging, bool VerifyEach = false,                           PrintPassOptions PrintPassOpts = PrintPassOptions());  // Register all the standard instrumentation callbacks. If \\p FAM is nullptr  // then PreservedCFGChecker is not enabled.  void registerCallbacks(PassInstrumentationCallbacks &amp;PIC,                         FunctionAnalysisManager *FAM = nullptr);  TimePassesHandler &amp;getTimePasses() &#123; return TimePasses; &#125;&#125;;\n\n提供了一些基本的Instrumentation，通过StandardInstrumentations::registerCallbacks来将这些callback注册到PIC中\nStandardInstrumentations::StandardInstrumentations(    bool DebugLogging, bool VerifyEach, PrintPassOptions PrintPassOpts)    : PrintPass(DebugLogging, PrintPassOpts), OptNone(DebugLogging),      PrintChangedIR(PrintChanged == ChangePrinter::PrintChangedVerbose),      PrintChangedDiff(          PrintChanged == ChangePrinter::PrintChangedDiffVerbose ||              PrintChanged == ChangePrinter::PrintChangedColourDiffVerbose,          PrintChanged == ChangePrinter::PrintChangedColourDiffVerbose ||              PrintChanged == ChangePrinter::PrintChangedColourDiffQuiet),      WebsiteChangeReporter(PrintChanged ==                            ChangePrinter::PrintChangedDotCfgVerbose),      Verify(DebugLogging), VerifyEach(VerifyEach) &#123;&#125;void StandardInstrumentations::registerCallbacks(    PassInstrumentationCallbacks &amp;PIC, FunctionAnalysisManager *FAM) &#123;  PrintIR.registerCallbacks(PIC);  PrintPass.registerCallbacks(PIC);  TimePasses.registerCallbacks(PIC);  OptNone.registerCallbacks(PIC);  OptBisect.registerCallbacks(PIC);  if (FAM)    PreservedCFGChecker.registerCallbacks(PIC, *FAM);  PrintChangedIR.registerCallbacks(PIC);  PseudoProbeVerification.registerCallbacks(PIC);  if (VerifyEach)    Verify.registerCallbacks(PIC);  PrintChangedDiff.registerCallbacks(PIC);  WebsiteChangeReporter.registerCallbacks(PIC);&#125;\n\n我们来看其中一个的实现（比较长，故省略了一部分，基本上都是在register各种callback\n// Debug logging for transformation and analysis passes.class PrintPassInstrumentation &#123;  raw_ostream &amp;print();public:  PrintPassInstrumentation(bool Enabled, PrintPassOptions Opts)      : Enabled(Enabled), Opts(Opts) &#123;&#125;  void registerCallbacks(PassInstrumentationCallbacks &amp;PIC);private:  bool Enabled;  PrintPassOptions Opts;  int Indent = 0;&#125;;raw_ostream &amp;PrintPassInstrumentation::print() &#123;  if (Opts.Indent) &#123;    assert(Indent &gt;= 0);    dbgs().indent(Indent);  &#125;  return dbgs();&#125;void PrintPassInstrumentation::registerCallbacks(    PassInstrumentationCallbacks &amp;PIC) &#123;  if (!Enabled)    return;  std::vector&lt;StringRef&gt; SpecialPasses;  if (!Opts.Verbose) &#123;    SpecialPasses.emplace_back(&quot;PassManager&quot;);    SpecialPasses.emplace_back(&quot;PassAdaptor&quot;);  &#125;   ...  if (!Opts.SkipAnalyses) &#123;    PIC.registerAnalysisInvalidatedCallback([this](StringRef PassID, Any IR) &#123;      print() &lt;&lt; &quot;Invalidating analysis: &quot; &lt;&lt; PassID &lt;&lt; &quot; on &quot; &lt;&lt; getIRName(IR)              &lt;&lt; &quot;\\n&quot;;    &#125;);    PIC.registerAnalysesClearedCallback([this](StringRef IRName) &#123;      print() &lt;&lt; &quot;Clearing all analysis results for: &quot; &lt;&lt; IRName &lt;&lt; &quot;\\n&quot;;    &#125;);  &#125;&#125;\n\n简单的注册了各个阶段的callback\nParsePipeline在Analysis和callbacks都处理好以后开始执行parsePassPipeline。\nif (auto Err = PB.parsePassPipeline(MPM, Passes)) &#123;  return wrap(std::move(Err));&#125;\n\nparsePassPipelinePassBuilder的成员函数和ParsePipeline相关的有两类，一个是ParseXXXPassPipeline，另一个是ParseXXXPass\n这里我们就先不关心pipeline里面是怎样的形式以及parser的过程了，重点在于通过看这个pipeline了解整个PassManager的构建过程。从parsePassPipeline开始\nError PassBuilder::parsePassPipeline(ModulePassManager &amp;MPM,                                     StringRef PipelineText) &#123;  auto Pipeline = parsePipelineText(PipelineText);  if (!Pipeline || Pipeline-&gt;empty())    return make_error&lt;StringError&gt;(        formatv(&quot;invalid pipeline &#x27;&#123;0&#125;&#x27;&quot;, PipelineText).str(),        inconvertibleErrorCode());  ...  if (auto Err = parseModulePassPipeline(MPM, *Pipeline))    return Err;  return Error::success();&#125;\n\nparseModulePassPipeline关于parseModulePassPipeline\nError PassBuilder::parseModulePassPipeline(ModulePassManager &amp;MPM,                                           ArrayRef&lt;PipelineElement&gt; Pipeline) &#123;  for (const auto &amp;Element : Pipeline) &#123;    if (auto Err = parseModulePass(MPM, Element))      return Err;  &#125;  return Error::success();&#125;\n\nError PassBuilder::parseModulePass(ModulePassManager &amp;MPM,                                   const PipelineElement &amp;E) &#123;  auto &amp;Name = E.Name;  auto &amp;InnerPipeline = E.InnerPipeline;  // First handle complex passes like the pass managers which carry pipelines.  if (!InnerPipeline.empty()) &#123;    if (Name == &quot;module&quot;) &#123;      ModulePassManager NestedMPM;      if (auto Err = parseModulePassPipeline(NestedMPM, InnerPipeline))        return Err;      MPM.addPass(std::move(NestedMPM));      return Error::success();    &#125;    if (Name == &quot;cgscc&quot;) &#123;      ...    &#125;    if (Name == &quot;function&quot; || Name == &quot;function&lt;eager-inv&gt;&quot;) &#123;      FunctionPassManager FPM;      if (auto Err = parseFunctionPassPipeline(FPM, InnerPipeline))        return Err;      MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM),                                                    Name != &quot;function&quot;));      return Error::success();    &#125;    if (auto Count = parseRepeatPassName(Name)) &#123;      ...    &#125;    for (auto &amp;C : ModulePipelineParsingCallbacks)      if (C(Name, MPM, InnerPipeline))        return Error::success();    // Normal passes can&#x27;t have pipelines.    return make_error&lt;StringError&gt;(        formatv(&quot;invalid use of &#x27;&#123;0&#125;&#x27; pass as module pipeline&quot;, Name).str(),        inconvertibleErrorCode());    ;  &#125;  // Manually handle aliases for pre-configured pipeline fragments.  if (startsWithDefaultPipelineAliasPrefix(Name)) &#123;    SmallVector&lt;StringRef, 3&gt; Matches;    if (!DefaultAliasRegex.match(Name, &amp;Matches))      return make_error&lt;StringError&gt;(          formatv(&quot;unknown default pipeline alias &#x27;&#123;0&#125;&#x27;&quot;, Name).str(),          inconvertibleErrorCode());    assert(Matches.size() == 3 &amp;&amp; &quot;Must capture two matched strings!&quot;);    OptimizationLevel L = StringSwitch&lt;OptimizationLevel&gt;(Matches[2])                              .Case(&quot;O0&quot;, OptimizationLevel::O0)                              .Case(&quot;O1&quot;, OptimizationLevel::O1)                              .Case(&quot;O2&quot;, OptimizationLevel::O2)                              .Case(&quot;O3&quot;, OptimizationLevel::O3)                              .Case(&quot;Os&quot;, OptimizationLevel::Os)                              .Case(&quot;Oz&quot;, OptimizationLevel::Oz);    if (L == OptimizationLevel::O0 &amp;&amp; Matches[1] != &quot;thinlto&quot; &amp;&amp;        Matches[1] != &quot;lto&quot;) &#123;      MPM.addPass(buildO0DefaultPipeline(L, Matches[1] == &quot;thinlto-pre-link&quot; ||                                                Matches[1] == &quot;lto-pre-link&quot;));      return Error::success();    &#125;    // This is consistent with old pass manager invoked via opt, but    // inconsistent with clang. Clang doesn&#x27;t enable loop vectorization    // but does enable slp vectorization at Oz.    PTO.LoopVectorization =        L.getSpeedupLevel() &gt; 1 &amp;&amp; L != OptimizationLevel::Oz;    PTO.SLPVectorization =        L.getSpeedupLevel() &gt; 1 &amp;&amp; L != OptimizationLevel::Oz;    if (Matches[1] == &quot;default&quot;) &#123;      MPM.addPass(buildPerModuleDefaultPipeline(L));    &#125; else if (Matches[1] == &quot;thinlto-pre-link&quot;) &#123;      ...\t\t&#125;    return Error::success();  &#125;  // Finally expand the basic registered passes from the .inc file.#define MODULE_PASS(NAME, CREATE_PASS)                                         \\  if (Name == NAME) &#123;                                                          \\    MPM.addPass(CREATE_PASS);                                                  \\    return Error::success();                                                   \\  &#125;...                                 #include &quot;PassRegistry.def&quot;  for (auto &amp;C : ModulePipelineParsingCallbacks)    if (C(Name, MPM, InnerPipeline))      return Error::success();  return make_error&lt;StringError&gt;(      formatv(&quot;unknown module pass &#x27;&#123;0&#125;&#x27;&quot;, Name).str(),      inconvertibleErrorCode());&#125;\n\n由于函数实在太长了，省略掉了大部分。\n\npipeline非空的情况下继续parseXXXPipeline。通过parseModulePipeline调用parseModulePass我们可以猜到每个parseXXPipeline都会调用对应的parseXXParse\n根据优化等级以及一些lto选项添加一些buildXXXDefaultPipeline‘\n展开PassRegistry中的定义\n\n在详细展开这些之前我们先来讲解一下上面出现的各种createXXAdaptor\nAdaptor各种adaptor被用于将IRUnit范围更小的Pass应用到更大的IRUnit上，比如说这里的Function的范围比一个Module要小\ntemplate &lt;typename FunctionPassT&gt;ModuleToFunctionPassAdaptorcreateModuleToFunctionPassAdaptor(FunctionPassT &amp;&amp;Pass,                                  bool EagerlyInvalidate = false) &#123;  using PassModelT =      detail::PassModel&lt;Function, FunctionPassT, PreservedAnalyses,                        FunctionAnalysisManager&gt;;  // Do not use make_unique, it causes too many template instantiations,  // causing terrible compile times.  return ModuleToFunctionPassAdaptor(      std::unique_ptr&lt;ModuleToFunctionPassAdaptor::PassConceptT&gt;(          new PassModelT(std::forward&lt;FunctionPassT&gt;(Pass))),      EagerlyInvalidate);&#125;\n\nclass ModuleToFunctionPassAdaptor    : public PassInfoMixin&lt;ModuleToFunctionPassAdaptor&gt; &#123;public:  ...  PreservedAnalyses run(Module &amp;M, ModuleAnalysisManager &amp;AM);  static bool isRequired() &#123; return true; &#125;private:  std::unique_ptr&lt;PassConceptT&gt; Pass;  bool EagerlyInvalidate;&#125;;\n\n这里和一个常规Pass都差不多，主要是run有比较大的区别\nPreservedAnalyses ModuleToFunctionPassAdaptor::run(Module &amp;M,                                                   ModuleAnalysisManager &amp;AM) &#123;  FunctionAnalysisManager &amp;FAM =      AM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();  PassInstrumentation PI = AM.getResult&lt;PassInstrumentationAnalysis&gt;(M);  PreservedAnalyses PA = PreservedAnalyses::all();  for (Function &amp;F : M) &#123;    if (F.isDeclaration())      continue; execution completely if asked to (callback returns    // false).    if (!PI.runBeforePass&lt;Function&gt;(*Pass, F))      continue;    PreservedAnalyses PassPA;    &#123;      TimeTraceScope TimeScope(Pass-&gt;name(), F.getName());      PassPA = Pass-&gt;run(F, FAM);    &#125;    PI.runAfterPass(*Pass, F, PassPA);    FAM.invalidate(F, EagerlyInvalidate ? PreservedAnalyses::none() : PassPA);    PA.intersect(std::move(PassPA));  &#125;  PA.preserveSet&lt;AllAnalysesOn&lt;Function&gt;&gt;();  PA.preserve&lt;FunctionAnalysisManagerModuleProxy&gt;();  return PA;&#125;\n\n首先是获取AnalysisManager（AM）这里的AM也是通过上面所讲过的Proxy获取的。由于是Function范围的Pass应用到Module的范围上，很自然要遍历大的IR中的所有Function。大体逻辑有点类似于一个PassManager。\nparseModulePass与更小范围的IR的parseXXPassPipeline根据上面的内容所说，parsePassPipeline会进入到parseModulePipeline中。而在parseModulePass中有这样的处理代码，也就是说可能会嵌套Module，也可能去处理IRUnit范围更小的相关Pass，并通过adaptor来加入到ModulePassManager中。其他的parseXXXPass也是有类似的处理\nif (Name == &quot;module&quot;) &#123;    ModulePassManager NestedMPM;    if (auto Err = parseModulePassPipeline(NestedMPM, InnerPipeline))      return Err;    MPM.addPass(std::move(NestedMPM));    return Error::success();  &#125;  if (Name == &quot;cgscc&quot;) &#123;    CGSCCPassManager CGPM;    if (auto Err = parseCGSCCPassPipeline(CGPM, InnerPipeline))      return Err;    MPM.addPass(createModuleToPostOrderCGSCCPassAdaptor(std::move(CGPM)));    return Error::success();  &#125;  if (Name == &quot;function&quot; || Name == &quot;function&lt;eager-inv&gt;&quot;) &#123;    FunctionPassManager FPM;    if (auto Err = parseFunctionPassPipeline(FPM, InnerPipeline))      return Err;    MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM),                                                  Name != &quot;function&quot;));    return Error::success();  &#125;  if (auto Count = parseRepeatPassName(Name)) &#123;    ModulePassManager NestedMPM;    if (auto Err = parseModulePassPipeline(NestedMPM, InnerPipeline))      return Err;    MPM.addPass(createRepeatedPass(*Count, std::move(NestedMPM)));    return Error::success();  &#125;\n\nBuildXXPipeline相关的逻辑也很简单，就是在这个函数中按照顺序和各种选项添加Pass，返回了一个构建好的ModulePassManager。还记得吗，一个PassManager（PM）添加Pass时可以传另一个PM，此时的行为是直接将传入PM的Pass添加到被添加的PM的Pass列表中。\n我们来看一下buildO0DefaultPipeline就好了，这里面不需要根据pipeline的text判断是否添加Pass，用一个非常不严谨的说法是这里面添加的逻辑和你是否指定了里面的Pass没有关系，不像之前的函数都是要先parse pipeline text之后根据parse得到的结果判断某个Pass是否要被添加\n这部分的实现都在PassBuilderPipelines.cpp中\nModulePassManager PassBuilder::buildO0DefaultPipeline(OptimizationLevel Level,                                                      bool LTOPreLink) &#123;  assert(Level == OptimizationLevel::O0 &amp;&amp;         &quot;buildO0DefaultPipeline should only be used with O0&quot;);  ModulePassManager MPM;  ...  // Build a minimal pipeline based on the semantics required by LLVM,  // which is just that always inlining occurs. Further, disable generating  // lifetime intrinsics to avoid enabling further optimizations during  // code generation.  MPM.addPass(AlwaysInlinerPass(      /*InsertLifetimeIntrinsics=*/false));  if (PTO.MergeFunctions)    MPM.addPass(MergeFunctionsPass());  if (EnableMatrix)    MPM.addPass(        createModuleToFunctionPassAdaptor(LowerMatrixIntrinsicsPass(true)));  if (!CGSCCOptimizerLateEPCallbacks.empty()) &#123;    CGSCCPassManager CGPM;    for (auto &amp;C : CGSCCOptimizerLateEPCallbacks)      C(CGPM, Level);    if (!CGPM.isEmpty())      MPM.addPass(createModuleToPostOrderCGSCCPassAdaptor(std::move(CGPM)));  &#125;  ...  ModulePassManager CoroPM;  CoroPM.addPass(createModuleToFunctionPassAdaptor(CoroEarlyPass()));  CGSCCPassManager CGPM;  CGPM.addPass(CoroSplitPass());  ...  if (LTOPreLink)    addRequiredLTOPreLinkPasses(MPM);  MPM.addPass(createModuleToFunctionPassAdaptor(AnnotationRemarksPass()));  return MPM;&#125;\n\n展开Registry展开PassRegistry中的定义，有这么几类\n直接添加ModulePass#define MODULE_PASS(NAME, CREATE_PASS)                                         \\  if (Name == NAME) &#123;                                                          \\    MPM.addPass(CREATE_PASS);                                                  \\    return Error::success();                                                   \\  &#125;\n\n有的还需要传入参数构造Pass\n#define MODULE_PASS_WITH_PARAMS(NAME, CLASS, CREATE_PASS, PARSER, PARAMS)      \\  if (checkParametrizedPassName(Name, NAME)) &#123;                                 \\    auto Params = parsePassParameters(PARSER, Name, NAME);                     \\    if (!Params)                                                               \\      return Params.takeError();                                               \\    MPM.addPass(CREATE_PASS(Params.get()));                                    \\    return Error::success();                                                   \\  &#125;\n\n通过adaptor的形式传入PassManager#define FUNCTION_PASS(NAME, CREATE_PASS)                                       \\  if (Name == NAME) &#123;                                                          \\    MPM.addPass(createModuleToFunctionPassAdaptor(CREATE_PASS));               \\    return Error::success();                                                   \\  &#125;\n\n不仅是一层，甚至会有多层Adaptor\n#define LOOP_PASS(NAME, CREATE_PASS)                                           \\  if (Name == NAME) &#123;                                                          \\    MPM.addPass(createModuleToFunctionPassAdaptor(                             \\        createFunctionToLoopPassAdaptor(CREATE_PASS, false, false)));          \\    return Error::success();                                                   \\  &#125;\n\nAnalysisPass#define MODULE_ANALYSIS(NAME, CREATE_PASS)                                     \\  if (Name == &quot;require&lt;&quot; NAME &quot;&gt;&quot;) &#123;                                           \\    MPM.addPass(                                                               \\        RequireAnalysisPass&lt;                                                   \\            std::remove_reference&lt;decltype(CREATE_PASS)&gt;::type, Module&gt;());    \\    return Error::success();                                                   \\  &#125;                                                                            \\  if (Name == &quot;invalidate&lt;&quot; NAME &quot;&gt;&quot;) &#123;                                        \\    MPM.addPass(InvalidateAnalysisPass&lt;                                        \\                std::remove_reference&lt;decltype(CREATE_PASS)&gt;::type&gt;());        \\    return Error::success();                                                   \\  &#125;\n\nPassManager中Pass的结构实际还有CGSCC以及Loop之类的Pass，这里就挑出三个有代表性的结构展示关系了\n一个是顶级的ModulePass，一个是一层adaptor，另一个是多层adaptor\nflowchart TD    R(ModulePassManager)    R--&gt;MP(ModulePass)    R--&gt;FP(ModuleToFunctionPassAdaptor)    FP--&gt;FPS(FunctionPass)    R--&gt;FPTemp(ModuleToFunctionPassAdaptor)    FPTemp--&gt;LPP(FunctionToLoopPassAdator)    LPP--&gt;LPPS(LoopPass)\n\n用户自定义添加Pass的方式最后介绍一下讲解一下如何添加自己的Pass到LLVM中。在llvm官方的仓库里example目录中有这么一段代码\nexamples/Bye/Bye.cpp\n/* New PM Registration */llvm::PassPluginLibraryInfo getByePluginInfo() &#123;  return &#123;LLVM_PLUGIN_API_VERSION, &quot;Bye&quot;, LLVM_VERSION_STRING,          [](PassBuilder &amp;PB) &#123;            PB.registerVectorizerStartEPCallback(                [](llvm::FunctionPassManager &amp;PM, OptimizationLevel Level) &#123;                  PM.addPass(Bye());                &#125;);            PB.registerPipelineParsingCallback(                [](StringRef Name, llvm::FunctionPassManager &amp;PM,                   ArrayRef&lt;llvm::PassBuilder::PipelineElement&gt;) &#123;                  if (Name == &quot;goodbye&quot;) &#123;                    PM.addPass(Bye());                    return true;                  &#125;                  return false;                &#125;);          &#125;&#125;;&#125;#ifndef LLVM_BYE_LINK_INTO_TOOLSextern &quot;C&quot; LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfollvmGetPassPluginInfo() &#123;  return getByePluginInfo();&#125;#endifstruct PassPluginLibraryInfo &#123;  /// The API version understood by this plugin, usually \\c  /// LLVM_PLUGIN_API_VERSION  uint32_t APIVersion;  /// A meaningful name of the plugin.  const char *PluginName;  /// The version of the plugin.  const char *PluginVersion;  /// The callback for registering plugin passes with a \\c PassBuilder  /// instance  void (*RegisterPassBuilderCallbacks)(PassBuilder &amp;);&#125;;\n\n在这里我们先不考虑PassPlugin相关的具体细节。通过这种插件的方式可以给LLVM添加一些自己实现的Pass，可以看到有一个传入PassBuilder的lambda，之后通过注册各种callback来实现。LLVM也一定有某种机制找到对应的Plugin之后调用其callback\n除此之外上面提及过的PassBuilder的构造函数有这么一段代码\nPassBuilder::PassBuilder(TargetMachine *TM, PipelineTuningOptions PTO,                         Optional&lt;PGOOptions&gt; PGOOpt,                         PassInstrumentationCallbacks *PIC)    : TM(TM), PTO(PTO), PGOOpt(PGOOpt), PIC(PIC) &#123;  if (TM)    TM-&gt;registerPassBuilderCallbacks(*this);  ...&#125;\n\n也就是说如果你是调用LLVM进行生成代码而不是给llvm添加一个自己的Pass的话应该在自己继承的TargetMachine中实现registerPassBuilderCallbacks方法，而在这个方法中也应当是通过传入的PassBuilder添加各种callback的形式\n","categories":["Compiler"],"tags":["LLVM","Pass","PassBuilder"]},{"title":"LLVM Pass 其零：新的Pass机制","url":"/2022/06/19/llvm-pass/llvm-pass-0/","content":"\n以高攻击力著称的传说之龙。任何编程语言和目标平台都能被粉碎，其破坏力不可估量 \n\n在目前的LLVM中存在两套Pass相关的机制，一套是基本上已经过时的被称为LegacyPass的机制（codegen的部分还没有迁移完毕），另一套则是现在主要使用的Pass机制\n这个系列会讲解新Pass结构的各个方面（重点在于新的Pass结构），PassManager以及与Pass的联系、Pass相关基础设施，旧架构设计上的问题以及在新架构的解决方案等内容，而第一篇则是着重于Pass本身。这个系列有些一笔带过的内容通常都会在后续文章提及，后面不再赘述。\n本文从以下几个点来对比分析这两类的不同并且着重看一下新的机制的实现\n\nPass的类结构是怎样的\nPass的编写方式\nPass的注册方式（这里只提及LLVM本身的Pass）\nPass元信息的获取方式\n\n结构类型关系链在LegacyPass中通过类型严格区分了module pass，function pass等。通过这张图可以看到Pass的继承链。（这里图片太长我只截取部分\n\n来源：https://llvm.org/doxygen/classllvm_1_1Pass.html\nLegacyPass中就是非常普通的继承链，从这个角度上来说没什么可讲的\n而在新Pass中每个Pass都是一个满足了PassConcept的东西。而PassConcept的要求是和PassInfoMixin相关联起来的，也就是说继承了PassInfoMixin的类算是Pass。虽然说是mixin，但是C++语法层面没有这样的特性，因此通过特殊的技巧来实现这样的语义。\n关于Pass的实现方式有这样一段注释，大意是说继承是非常不好的，因此采用了这种concept-based polymorphism方式。在这里不具体讲解相关细节了，有兴趣可以点进注释中提到的链接看下\n/// Note that the implementations of the pass managers use concept-based/// polymorphism as outlined in the &quot;Value Semantics and Concept-based/// Polymorphism&quot; talk (or its abbreviated sibling &quot;Inheritance Is The Base/// Class of Evil&quot;) by Sean Parent:/// * http://github.com/sean-parent/sean-parent.github.com/wiki/Papers-and-Presentations/// * http://www.youtube.com/watch?v=_BpMYeUFXv8/// * http://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil\n\n我对这个概念没什么了解，按照我目前从代码中看到的，用我的话来说更像是一种编译期间执行的动态类型，只要有满足PassConcept接口的东西就可以成为Pass。在后续的内容中会提到各种各样的满足PassConcept的类，目前先说基本的Pass。\ninclude/llvm/IR/PassManagerInternal.h\ntemplate &lt;typename IRUnitT, typename AnalysisManagerT, typename... ExtraArgTs&gt;struct PassConcept &#123;  virtual ~PassConcept() = default;  virtual PreservedAnalyses run(IRUnitT &amp;IR, AnalysisManagerT &amp;AM,                                ExtraArgTs... ExtraArgs) = 0;  virtual void  printPipeline(raw_ostream &amp;OS,                function_ref&lt;StringRef(StringRef)&gt; MapClassName2PassName) = 0;  virtual StringRef name() const = 0;\t/// Polymorphic method to to let a pass optionally exempted from skipping by  /// PassInstrumentation.  /// To opt-in, pass should implement `static bool isRequired()`. It&#x27;s no-op  /// to have `isRequired` always return false since that is the default.  virtual bool isRequired() const = 0;&#125;;\n\n注意isRequired是可选的，不实现则会是默认false，处理这里则是在PassModel中\n大概了解一下Concept有什么接口之后我们来看Mixin\n\n图为各种继承了PassInfoMixin的Pass\n对于PassInfoMixin来说只有name以及printPipeline的部分，而我们编写的Pass是要补全run的部分。那么我们来看一下PassInfoMixin的声明部分，实际上利用CRTP的机制来获取PassInfoMixin的子类信息并且返回，同样做到了多态的效果\ninclude/llvm/IR/PassManager.h\n/// A CRTP mix-in to automatically provide informational APIs needed for/// passes.////// This provides some boilerplate for types that are passes.template &lt;typename DerivedT&gt; struct PassInfoMixin &#123;  /// Gets the name of the pass we are mixed into.  static StringRef name() &#123;    static_assert(std::is_base_of&lt;PassInfoMixin, DerivedT&gt;::value,                  &quot;Must pass the derived type as the template argument!&quot;);    StringRef Name = getTypeName&lt;DerivedT&gt;();    Name.consume_front(&quot;llvm::&quot;);    return Name;  &#125;  void printPipeline(raw_ostream &amp;OS,                     function_ref&lt;StringRef(StringRef)&gt; MapClassName2PassName) &#123;    StringRef ClassName = DerivedT::name();    auto PassName = MapClassName2PassName(ClassName);    OS &lt;&lt; PassName;  &#125;&#125;;\n\n区分Analysis对于LegacyPass来说要注意的是对于LegacyPass来说不论是Analysis还是Transform都是一个Pass，只是Analysis是一种ImmutablePass，在注册的时候也会需要这个信息。\n但是对于新Pass来说Analysis就是Analysis，并不是一种Pass。比如我们来看一个Analysis的签名\ninclude/llvm/Analysis/AssumptionCache.h\nclass AssumptionAnalysis : public AnalysisInfoMixin&lt;AssumptionAnalysis&gt; &#123;  friend AnalysisInfoMixin&lt;AssumptionAnalysis&gt;;  static AnalysisKey Key;public:  using Result = AssumptionCache;  AssumptionCache run(Function &amp;F, FunctionAnalysisManager &amp;);&#125;;\n\n很明显这个run的返回结果是不满足PassConcept的，Analysis有自己的一套AnalysisConcept\n编写lib/Transforms/Scalar/FlattenCFGPass.cpp\nstruct FlattenCFGLegacyPass : public FunctionPass &#123;  static char ID; // Pass identification, replacement for typeidpublic:  FlattenCFGLegacyPass() : FunctionPass(ID) &#123;    initializeFlattenCFGLegacyPassPass(*PassRegistry::getPassRegistry());  &#125;  bool runOnFunction(Function &amp;F) override;  void getAnalysisUsage(AnalysisUsage &amp;AU) const override &#123;    AU.addRequired&lt;AAResultsWrapperPass&gt;();  &#125;private:  AliasAnalysis *AA;&#125;;bool FlattenCFGLegacyPass::runOnFunction(Function &amp;F) &#123;  AA = &amp;getAnalysis&lt;AAResultsWrapperPass&gt;().getAAResults();  bool EverChanged = false;  // iterativelyFlattenCFG can make some blocks dead.  while (iterativelyFlattenCFG(F, AA)) &#123;    removeUnreachableBlocks(F);    EverChanged = true;  &#125;  return EverChanged;&#125;\n\nstruct FlattenCFGPass : PassInfoMixin&lt;FlattenCFGPass&gt; &#123;  PreservedAnalyses run(Function &amp;F, FunctionAnalysisManager &amp;AM);&#125;;PreservedAnalyses FlattenCFGPass::run(Function &amp;F,                                      FunctionAnalysisManager &amp;AM) &#123;  bool EverChanged = false;  AliasAnalysis *AA = &amp;AM.getResult&lt;AAManager&gt;(F);  // iterativelyFlattenCFG can make some blocks dead.  while (iterativelyFlattenCFG(F, AA)) &#123;    removeUnreachableBlocks(F);    EverChanged = true;  &#125;  return EverChanged ? PreservedAnalyses::none() : PreservedAnalyses::all();&#125;\n\n复杂的LegacyPass对比代码可以看到LegacyPass非常麻烦\n\n添加initializeXXXPass\n声明一个PassID\n用到的analysis还需要手动addRequired\n\n而新的Pass则不需要关心那么多其他的事情，只需要专注于编写实现就可以了\nrun这里可以看到两者run的参数是有区别的，对于新的Pass来说还需要传递一个AnalysisManager\n而run中传进来的类型（被称为IRUnitT）以及AnalysisManager的类型共同体现了这个Pass是作用范围是什么（是一个Function又或是一个Module等等）\n对于返回的结果两者也不相同。LegacyPass返回的是 是否修改的bool值，对于新的Pass返回的是这个Pass不会影响到哪些Analysis\n注册LegacyPass的注册方式是在一个全局的Registry变量中add每一个Pass的info\nlib/Transforms/Scalar/FlattenCFGPass.cpp\nchar FlattenCFGLegacyPass::ID = 0;INITIALIZE_PASS_BEGIN(FlattenCFGLegacyPass, &quot;flattencfg&quot;, &quot;Flatten the CFG&quot;,                      false, false)INITIALIZE_PASS_DEPENDENCY(AAResultsWrapperPass)INITIALIZE_PASS_END(FlattenCFGLegacyPass, &quot;flattencfg&quot;, &quot;Flatten the CFG&quot;,                    false, false)#define INITIALIZE_PASS_BEGIN(passName, arg, name, cfg, analysis)              \\  static void *initialize##passName##PassOnce(PassRegistry &amp;Registry) &#123;#define INITIALIZE_PASS_DEPENDENCY(depName) initialize##depName##Pass(Registry);#define INITIALIZE_AG_DEPENDENCY(depName)                                      \\  initialize##depName##AnalysisGroup(Registry);\n\n展开宏是这个样子的，看到这个initialize函数是不是有点眼熟？这就是刚才在构造函数中实际调用的\nstatic void *initializeFlattenCFGLegacyPassPassOnce(PassRegistry &amp;Registry) &#123;  initializeAAResultsWrapperPassPass(Registry);  PassInfo *PI =      new PassInfo(&quot;Flatten the CFG&quot;, &quot;flattencfg&quot;, &amp;FlattenCFGLegacyPass::ID,                   PassInfo::NormalCtor_t(callDefaultCtor&lt;FlattenCFGLegacyPass&gt;),                   false, false);  Registry.registerPass(*PI, true);  return PI;&#125;static llvm::once_flag InitializeFlattenCFGLegacyPassPassFlag;void llvm::initializeFlattenCFGLegacyPassPass(PassRegistry &amp;Registry) &#123;  llvm::call_once(InitializeFlattenCFGLegacyPassPassFlag,                  initializeFlattenCFGLegacyPassPassOnce, std::ref(Registry));&#125;\n\n宏的最后两个bool参数分别是 是否为CFGPass和AnalysisPass\n新的则是在lib/Passes/PassRegistry.def中使用这样的方式注册\nFUNCTION_PASS(&quot;flattencfg&quot;, FlattenCFGPass())\n\n对于新的Pass来说不需要再添加选项区分是否为Analysis，而是通过采用了不同名称的宏来实现，比如说有这样一个用于注册Analysis的宏\n#define FUNCTION_ANALYSIS(NAME, CREATE_PASS)\n\n而宏的具体实现则是根据使用的上下文来实现。通过先define这个宏的具体实现再include这个def文件完成各种流程（我并不知道这个做法叫什么..）\n在lib/Passes/PassBuilder.cpp中有这样一段代码\nError PassBuilder::parseFunctionPass(FunctionPassManager &amp;FPM,                                     const PipelineElement &amp;E) &#123;  ...// Now expand the basic registered passes from the .inc file.#define FUNCTION_PASS(NAME, CREATE_PASS)                                       \\  if (Name == NAME) &#123;                                                          \\    FPM.addPass(CREATE_PASS);                                                  \\    return Error::success();                                                   \\  &#125;  ...&#125;\n\n同时这个宏还会被用于一些其他的地方，比如说打印Pass名字\nvoid PassBuilder::printPassNames(raw_ostream &amp;OS) &#123;  ...\tOS &lt;&lt; &quot;Function passes:\\n&quot;;\t#define FUNCTION_PASS(NAME, CREATE_PASS) printPassName(NAME, OS);\t#include &quot;PassRegistry.def&quot;  ...&#125;\n\n元信息identifier对于LegacyPass来说通过声明的静态成员变量来区分。上面的编写Pass的时候添加静态成员变量ID，之后在注册的宏内构建了PassInfo并且将整个ID传进去\n对于新的Pass我觉得是根据name来区分的。因为name是通过获取Pass的TypeName得到的。这一点对于Analysis也一样\ntemplate &lt;typename DerivedT&gt; struct PassInfoMixin &#123;  /// Gets the name of the pass we are mixed into.  static StringRef name() &#123;    static_assert(std::is_base_of&lt;PassInfoMixin, DerivedT&gt;::value,                  &quot;Must pass the derived type as the template argument!&quot;);    StringRef Name = getTypeName&lt;DerivedT&gt;();    Name.consume_front(&quot;llvm::&quot;);    return Name;  &#125;  ...&#125;\n\n获取对于LegacyPass来说PassInfo基本上都在PassInfo中了，而上面也提到注册的时候会将PassInfo塞到一个全局的Registry对象中，获取的话通过Registry对象的getPassInfo方法传入Id或者注册的时候填写的arg来获取到对应的PassInfo实例。\ninclude/llvm/PassInfo.h\nclass PassInfo &#123;public:  using NormalCtor_t = Pass* (*)();private:  StringRef PassName;     // Nice name for Pass  StringRef PassArgument; // Command Line argument to run this pass  const void *PassID;  const bool IsCFGOnlyPass = false;      // Pass only looks at the CFG.  const bool IsAnalysis;                 // True if an analysis pass.  const bool IsAnalysisGroup;            // True if an analysis group.  std::vector&lt;const PassInfo *&gt; ItfImpl; // Interfaces implemented by this pass  NormalCtor_t NormalCtor = nullptr;  ...&#125;\n\n在Registry获取PassInfo的里有这样的代码\ninclude/llvm/PassRegistry.h\nconst PassInfo *PassRegistry::getPassInfo(const void *TI) const &#123;  sys::SmartScopedReader&lt;true&gt; Guard(Lock);  return PassInfoMap.lookup(TI);&#125;/// PassInfoMap - Keep track of the PassInfo object for each registered pass.using MapType = DenseMap&lt;const void *, const PassInfo *&gt;;MapType PassInfoMap;\n\n对于新的Pass来说原本的PassInfo中绝大部分信息都已经不再需要了，比如说是否为Analysis，是否为CFGOnly，ID等。PassInfo中有一个叫NormalCtor的成员，LegacyPass是通过PassInfo创建的因此需要保存构造Pass的方法，但新Pass这里采用了其他的做法，因此这个成员也是不需要的。\n唯一需要的就是name信息。由于Transform Pass和Analysis都是由ID区分的，在PassBuilder中也有isAnalysisPassName这样根据ID来帮助我们判断是什么的函数\n简单区分由于同时存在两套机制，我在初次接触的时候也感到很困惑，之前想要获取新Pass元信息的时候还在尝试LegacyPass的方法\n在对整个结构不了解的时候想要区分一个Pass相关的内容是旧的还是新的可以通过这么两个思路\n\n通过所使用的类的声明位置，LegacyPass的基础设施相关头文件目前都放到了include/llvm的路径下，而新Pass的基础设施则是分散在include/llvm/IR/ 和include/llvm/Passes/下\nLegacyPass的名字都改为了XXXLegacyPass\n\n","categories":["Compiler"],"tags":["LLVM","Pass"]},{"title":"Rc-lang开发周记2 VM相关","url":"/2022/01/02/rc-lang-dev/rc-lang-dev-2/","content":"本周主要先对tac的函数进行了简单的测试，以确保能够正确运行我的vm demo，修正了function的一些问题，之后就是处理对vm指令的生成，处理了一下符号相关的信息，还做了一点函数的相关的以及生成C++的解析代码（都没做完，还是下周吧\n本周vm的代码都在ir/vm中，translator用于转换，inst是指令定义，vm.rb是入口\nFunction转换这是我目前的Function的ast定义\nclass Function    attr_reader :name, :args, :stmtsend\n\n在修改function生成代码的时候发现了一个问题，因为我有默认最后一个值直接返回的设计，所以或许应该在高层添加一个将stmt显式抽出\nreturn的操作。这个步骤现在看来大概分为简单两步\n\n消除不可达代码，比如说一个return后面还有好几个值\n消除后就可以放心将最后一个语句的结果转换为一个返回值了\n\n但是第二步实际实现的时候可能没有这么简单，这里就暂提个思路，以后再回头看这个设计是否有需要\n无意义的tac to vm inst之后做了一些将tac转到vm指令。在做这个的过程我才意识到其实不需要转成tac，对于tac和vm指令的表达力应该是同等级的，都比较偏向于中层IR。查看了一下其他语言的做法，Ruby和Java都是从AST转到了字节码\n深入理解Java虚拟机310页：\n\n字节码生成阶段不仅仅是把前面各个步骤所生成的信息（语法树、符号表）转换成字节码写到磁盘中，编译器还进行了少量的代码添加和转换工作\n\nRuby原理剖析36页：\n\n在解析完 词条生成AST之后，Ruby1.9和Ruby2.0继续把代码编译成一系列的底层指令，叫做YARV指令\n\n这里的YARV是Ruby的字节码解释器，而YARV指令自然就是对应的字节码。而Ruby1.9之前是直接解释执行ast的，甚至不会考虑到tac这样的东西\n为什么不需要先转成tac优化后再到vm指令关于这一点，我询问了朋友，最后的结论大概有以下两点。如果读者对这方面很了解希望能科普一下\n\n转成tac做优化以后，尤其是部分针对全局的优化会以及其他的变换会剔除掉一些JIT时所需要的信息。\n关于这点我问了很久，我觉得还要尽可能地多做优化再到jit，应该要通过控制不做哪些优化来避免剔除所需信息。因为我对这几个层面所能做的优化了解不深，不知道所能做的优化有哪些差异，也没法举出例子或者说明收益\n后续我又了解了一些信息，发现jit中还有一个名叫的deoptimize技术，这个出现在multi tiered jit中。关于这个的内容在我另一篇博客中\n\n如果直接显式执行的是源码而不是字节码，先转成tac做处理再到vm指令会影响到了启动时间\nRuby是在内部对源码解析之后再由vm来执行。Java可能给大多数人的印象是必须要先编译到字节码，然后再单独加载执行字节码，但调查发现Java9开始可以通过jshell来直接执行。将这个过程封装到一起实际上也不麻烦，只是不需要你显式操作罢了\n\n\n所以经过了这些结论，前面做的tac到vm指令的就白费了，只能重新写一套从ast生成vm指令代码。生成tac这个过程并没有白费，编写的过程中让我有对这个东西有了更深的理解，以及后续可能会用tac实现优化算法。\nVM简介至于VM的实现，很自然的就会选择栈式VM。以学习为目的肯定要做寄存器分配，但是因为后续想做jit，所以寄存器分配就留到那个时候再做，或者说可以再从tac做成aot，反正目前还是以实现学习为目的。\n搞一个VM本质是什么？我觉得本质是对运行时的环境进行处理。那么我们首先要来谈及这个环境都有哪些部分\n我觉得简单可以分为以下两种\n\n数据（代码与计算的数据）\n当前状态（寄存器与栈帧）\n\n数据数据牵扯到的问题有很多，比如说数据排布、对象布局、地址分配等等。这也是我第一次动手做这些，这里就先从最简单的只有int32做起。如果后面做完善了可以再单独出一期把这些东西串起来（咕咕咕咕咕咕\n当前状态寄存器寄存器就从目前来说，我们需要一个pc寄存器来表明当前执行到哪条语句了。至于vm那边的实现目前使用一个数组保存，pc保存下数组索引就好\n栈帧栈帧根据不同的需求内容也各不相同\n我们来看一下龙书中提到的常见栈帧成员（不论什么书其实大都差不多\n\n局部变量\n临时变量的位置（牵扯到临时变量？\n机器状态（保存的特殊寄存器值，这个和调用约定也有一定关联。调用约定决定了哪些寄存器是需要保存的，哪些是不需要保存的，关于调用约定更多详情还请自行查询\nrbp指针（用于管理访问链\n指向调用者的地址\n返回值（我选择统一放到一个寄存器中）\n实参\n\n要注意的是书中提到的基本上是针对非VM的栈帧，VM的栈帧可以根据需求做出不一样的设计，比如说Ruby中采用了双栈的设计，一个调用栈用于管理调用链，一个计算栈用于存放各种变量与计算，而对于非VM栈帧絕大多说都是一个栈（我没听说过有使用双栈的，但是说不定也存在呢）通过栈中保存的rbp寄存器中的值来处理访问链\n就目前从头开始实现而言，我们需要什么再加什么就好了，后续每个东西怎么加，为什么加我都会有一定说明。\nVM指令转换计算赋值先从普通的运算赋值做起。这里其实有点问题，我还没有处理好单独的语句，所以都放到了一个函数里（写完这篇就去改），以及对于函数定义该如何处理我也没想好。\ndef foo  a = 3 * 2end\n\n在Ruby的虚拟机中扫描到类似的函数定义则是会产生一行调用 definemethod :foo, foo\n而foo本身的内容则是\n== disasm: #&lt;ISeq:f@&lt;compiled&gt;:1 (1,0)-(3,3)&gt; (catch: FALSE)local table (size: 1, argc: 0 [opts: 0, rest: -1, post: 0, block: -1, kw: -1@-1, kwrest: -1])[ 1] a@00000 putobject                              3                         (   2)[LiCa]0002 putobject                              20004 opt_mult                               &lt;calldata!mid:*, argc:1, ARGS_SIMPLE&gt;0006 dup0007 setlocal_WC_0                          a@00009 leave                                                            (   3)[Re]\n\n这里出现了一个点，由于函数体中是一个assign，值会pop走，但是这个assign又是作为一个返回值，因此ruby中对结果调用了dup，创建一个重复的值用于返回。在写博客的时候看到Ruby指令的结果刚意识到这个问题，不过这个是属于关于函数体与函数调用相关的内容，这里目前暂不修改。\n作为参考，进行编写测试。\ncontext &#x27;assign&#x27; do  it &#x27;normal expr&#x27; do    s = &lt;&lt;SRCdef fooa = 1 * 2endSRC    inst = get_vm_inst(s)    expect(inst).to eq [Rc::VM::Push.new(1), Push.new(2), Mul.new, SetLocal.new(0), Return.new]  endend\n\n对于一个普通的a = 1 * 2，我们期望的行为是将两个参数push到栈上，之后进行mul操作，最后设置本地变量的值\n乘法操作class Binary # Rc::AST::Binary  attr_reader :op, :lhs, :rhsenddef on_binary(node)  [    push(visit(node.lhs)),    push(visit(node.rhs)),    translate_op(node.op),  ]end\n\n操作数的处理指令操作数目前分了两种，一种是直接可以保存值的，一种是引用某个名字\nmodule VMInstOperand  class Value &lt; Struct.new(:value)  end  # Ref a exist var  class Ref &lt; Struct.new(:ref)  end  def push(node)    if node.is_a? Value      Push.new(node.value)    elsif node.is_a? Ref      GetLocal.new(node.ref)    else      raise &quot;Unsupported node type #&#123;node.class&#125;&quot;    end  endend# 下面两个都是visit结点的函数def on_number_constant(node)  Value.new node.val.to_iend# Get or Set, so need return a iddef on_identifier(node)  Ref.new cur_fun_env[node.name].idend\n\n这么设计的原因是\n\n针对一个简单的数值我们可以直接将值push到栈上\n针对一个名字我们需要去符号表中找到这个名字所在的位置，再将对应的值push到栈上\n\n同时也有不同的“push操作”\n\n针对简单的值直接push\n针对名字我们通过GetLocal来获取（对于vm那边的实现，需要根据局部变量的基址和偏移量以及类型找到对应的值再放上去，但是类型目前不考虑，统一int32）\n\n这里暂时不考虑访问外部作用域的问题，这会涉及到符号表的访问以及栈的修改两部分内容。\n针对这样的设计，我们需要开始增加栈的功能了\n\n简单数值的运算，我们需要能将值放上去，再进行运算取出或者留在栈里（这些临时变量）\n\n因此就有了如下最最最简单的栈\n----------  临时变量----------\n\n\n我们需要留有局部变量的位置，能够在里面存取数据。临时变量是会随着当前函数结束而销毁，因此我们需要添加临时变量的位置在栈上，栈回退的时候也会直接销毁掉\n由于1需要反复修改栈指针的操作需要所以放在当前栈帧的最顶端比较合适\n\n\n因此就有了如下最最简单的栈\n----------  临时变量----------  局部变量----------\n\nop处理这个没什么好说的，简单从op字符串转换到不同类型的运算指令\ndef translate_op(op)    case op.op    in &#x27;+&#x27;      Add.new# ...以下省略\n\n符号表就之前的代码而言，符号表信息之类的记录的并不够。在实际考虑栈帧以及执行之前我对符号表的认识仅仅停留在作为解释器的env以及他的功能的“概念”上。由于是之前写过的，就直接拿来用了，没有 再来认真反思设计以及其他的问题，回头再重新设计吧，先能用就行\n考虑局部变量如何保存这个问题，引出了我对符号表更多的实际理解，所以还是要自己动手做才能更有助于理解，只是看一些理论讲还是不够，至少对我而言是这样的\n关于扫描分析的代码在analysis/global_env中\n符号表相关的定义在lib/env中\n全局表class GlobalEnv &lt; Struct.new(:define_env, :const_table, :fun_env)end\n\n全局表目前保存三个东西\n\n各种定义（类定义、函数定义等），这个设计是比较早的时候写的，可能并不合适，后续再好好想一下该怎么做\n常量表\n函数的符号表，根据函数名找到对应函数的符号表\n\n条目针对生成VM指令的阶段，需要知道一个临时变量的位置，因此有了这样的一个东西作为符号表的条目。\nclass EnvItemInfo &lt; Struct.new(:id, :type)end\n\nid的话在一个函数中是自增的，用于GetLocal和SetLocal中计算具体的offset（这个设计对于后续可能不够用，先这样）。类型肯定也是需要的，但是目前并没有考虑类型的问题，就留了这么一个坑在这里\n函数def on_function(node)  @define_env.define_symbol(node.name, node)  @cur_fun_sym = Env.new  @cur_fun_var_id = 0  @cur_fun_sym.merge(node.args.map&#123; |arg| [arg, EnvItemInfo.new(cur_fun_var_id, &#x27;&#x27;)]&#125;.to_h)  visit(node.stmts)  @fun_env[node.name] = @cur_fun_symend\n\n\n将函数名字关联到结点\n从每个函数开始分析时初始化各参数的状态\n将参数merge进当前函数的符号表中\n访问函数体\n将函数名关联到对应的符号表\n\n最后今天写的太久有点写不下去了，所以到后面内容比较潦草，还请见谅。（目前以保证更新频率为主）有疑惑的地方可以联系我\n","categories":["Compiler","VM"],"tags":["Rc-lang"]},{"title":"Rc-lang开发周记0 基本块与if重排","url":"/2021/12/19/rc-lang-dev/rc-lang-dev-0/","content":"目前的工作重心在于将ast转换为tac指令。\n由于ast的if转成的中间表示的条件跳转是带有两个分支的，因此需要对if后面所跳转到的位置进行重排。\n基本块与重排相关的代码目前在ir/cfg.rb中，ast到tac的代码目前在ir/tac/tac.rb中\n而跳转指令实质上是从一个基本块（BasicBlock）跳转到另一个基本块，因此我们需要先将tac（三地址码）转换成由基本块构成的形式\n基本块核心性质\n每个基本块是从一个label开始（单一入口点）\n每个基本块是由一个跳转结束（单一结束点）\n\n每一个基本块是独立的，因为由跳转结束，所以不管怎么更换基本块的位置最后都不会影执行顺序的正确性\n案例def f(cond, a, b)  n = a + b  if cond    n * 2  else    n + 2  endend\n\n比如这段代码，就会存在三个基本块\n\nmain开始到if的条件跳转\ntrue的部分是一个基本块\nfalse的部分是一个基本块\n\n2和3：在生成if代码的时候会给true和false的分支各自添加一个label作为跳转目标，而每个分支结束都会跳转到最后结束的分支\n用途能够表示程序的控制流。\n目前用于重排if指令，后续代码的优化分析会经常用到。最经典的就是ssa(Static Single Assign)相关操作，需要对控制流进行分析，而转换为cfg的形式本质上只需要对cfg分析就可以了\n构造算法构造算法很简单。从头到尾进行一遍搜索，找到一个label就开始一个基本块，而到了一个跳转就结束一个基本块。\n但是存在两种特殊情况\n\n当前是label的情况下前一条指令不是jump的话需要手动添加一个jump跳转到当前的label\n当前是jump的情况下如果下一个不是label则需要将下一个指令设置为label\n\n上核心代码（这里省掉了检查第一个label的代码\ntac_list.each_with_index do |cur_tac, index|  if cur_tac.is_a? TAC::Label    # prev is not a jump, maybe need push a jump to this label    # but when first, not need process    valid_do(tac_list, index - 1) do |prev_tac|      unless prev_tac.is_a? TAC::Jump        blocks.last.push TAC::DirectJump.new(cur_tac)      end    end    blocks.push BasicBlock.new(cur_tac)  elsif cur_tac.is_a? TAC::Jump    # next is not a label, need create a block and push a label to next block    blocks.last.push cur_tac    valid_do(tac_list, index + 1) do |next_tac|      unless next_tac.is_a? TAC::Label        blocks.push BasicBlock.new(&quot;TmpLabel#&#123;tmp_label_count&#125;&quot;)        # push a label      end    end  else    blocks.last.push cur_tac  endend\n\n目前这里的tac采用的是数组而不是链式结构，所以查看前一个以及插入结点略微麻烦（第一次写，所以一开始写的时候没有想到那么多，后续可以考虑换成链式结构方便插入与查找前驱后继）\n重排if重排的过程分为三步\n\n找到所有的路线\n路线排序\n\n找到所有路线这里也是采用相对比较简单粗暴的算法\n类似于dfs的形式，将所有的基本块放入一个队列中，从第一个未标记的开始深度优先遍历，和dfs一样需要标记中途遍历过的结点，但是并不恢复标记。一条路走完后会从队列取出下一个未走过的点作为新的路线的起点。\n从当前的块选择下一个到达块的时候优先选择false分支， ****为了后续转到vm指令的时候不需要考虑CondJump false的情况，false直接顺着走就可以了，方便后面的排序\n上代码\ndef search_all_branches(cfg)  blocks = cfg.blocks  tag = Tag.new  q = blocks  roads = []  # dfs that traverse all nodes  until q.empty?    roads.push search_single_road(q, tag)  end  roads.reduce([]) do |sum, road|    sum + road.blocks  endenddef search_single_road(q, tag)    t = Road.new    b = q.shift    until tag.has_marked(b)      tag.mark(b)      t.append(b)      # find last(false branch)      first_next_b = b.all_next.reverse.find &#123; |next_b| not tag.has_marked(next_b) &#125;      if first_next_b.nil?        break      else        b = first_next_b      end    end    tend\n\n排序这里有三种情况\n\nCondJump后面接着的是false的块，则不需要做任何事情\n后面接的是true块，则需要调换顺序，而条件需要设置为相反的\n后面的块和这个CondJump没有关联，那么需要将这个CondJump(cond, label_true, label_false)转换为一个CondJump(cond, label_true, label_false‘)，之后在后面添加一个label_false’以及直接到label_false的跳转指令\n\nCondJump(cond, label_true, label_false) →\nCondJump(cond, label_true, label_false‘) + label_false’ + Jump(label_false)\n我这里是通过判断块的第一个label来判断是不是对应的块。代码写的比较粗糙\ndef reorder_branches_impl(tac_list)  tac_list.each_with_index do |tac, index|    if tac.is_a? TAC::CondJump      next_tac = tac_list[index + 1]      if next_tac == tac.false_addr        # is ok      elsif next_tac == tac.true_addr\t\t\t\tset_not_cond(tac_list, index)        next_false_tac = tac_list[index + 2]        tac_list[index + 1], tac_list[index + 2] = next_false_tac, next_tac      else        old_false_branch = tac.false_addr        new_false_branch = TAC::Label.new(&quot;#&#123;tac.false_addr.name&#125;f&#x27;&quot;)        tac.false_addr = new_false_branch        tac_list.insert(index + 1, new_false_branch)        tac_list.insert(index + 2, TAC::DirectJump.new(old_false_branch))      end    end  endend\n\n可以看到这里也是由于使用数组来保存导致插入新指令比较麻烦（下次一定修改为链式，咕咕咕）\n关于更详细的案例可以看对应的测试代码。重排if的测试代码在spec/ir/tac_spec.rb中\n参考资料现代编译原理C语言描述 第七章、第八章\n","categories":["Compiler"],"tags":["Rc-lang"]},{"title":"Rc-lang开发周记3 生成C++代码","url":"/2022/01/09/rc-lang-dev/rc-lang-dev-3/","content":"由于元旦第二天开始状态奇差，本周并没有增加太多内容，周记的内容也会相对少一些。以及本周的内容主要在于生成C++的代码，更多的是Ruby的元编程技巧。\n指令定义每个指令有一个InstType的枚举字段来标明类型\n所有指令继承自一个VMInst类\nstruct VMInst &#123;    InstType type;protected:    VMInst(InstType t) : type(t) &#123;&#125;;&#125;;struct Addr : VMInst &#123;public:    Addr(int offset, string seg) : VMInst(InstType::Addr), _offset(offset), _seg(seg) &#123;&#125;private:    int _offset;    string _seg;&#125;;\n\nC++解析最主要的问题是要如何让C++解析这边生成的东西。我目前就选用了最简单粗暴的方法，直接生成字符串，用空格分离参数，用换行分离指令\n获取所有指令信息获取有哪些指令我将所有的指令都放到了Rc::VM::Inst中，通过获取这个module的所有constant，判断哪些是Class\ndef get_classes(mod)\tmod.constants.map&#123;|c| mod.const_get(c)&#125;.select&#123;|c| c.is_a? Class&#125;.sort_by&#123; |klass| klass.to_s &#125;endclasses = get_classes(Rc::VM::Inst)\n\n通过这个代码能够获取到Inst这个模块中的所有指令\n\n获取每个指令里面是怎么样的\n\n由于ruby并没有定义成员类型的东西，因此我选择自己造一个指定成员类型的东西\n有两种实现\n实现方式TypeStruct第一种是将Struct给包装一层，我给其命名为TypeStruct\n使用方式\nclass CondJump &lt; TypeStruct.new(:cond, :addr =&gt; :int)  def to_s    &quot;CondJump #&#123;cond&#125; #&#123;addr&#125;&quot;  endend\n\n类似于常规的Struct的使用方式，但是输入变成了可以是一个hash\n实现\n\n实现的一个要点在于new返回的东西需要是一个class。那么我们需要知道Ruby中new是怎么运作的\n常规的对象来说，new中会做三件事。class MemberMap  def initialize(type_defines)    @type_defines = type_defines  end  def generate(c = “\\n”, &amp;f)    @type_defines.generate(c, &amp;f)  end  def keys    @type_defines.map { |td| td.name }  endend通过allocate分配空间，send initialize方法进行构造对象，最后将obj返回。而在这里只要修改返回的内容即可\n\n另一个要点在于需要给返回的class添加一些实例方法\n这里我们需要先理解常规的Struct.new做了什么，在我的理解本质上是返回了一个通过动态添加定义的匿名class，那么我们需要的是给这个匿名class添加一些方法来定义\n那么我们很自然的就会想到将所有传给new的参数转换为每一个成员以及与之相应的类型定义，之后再对其中每一对“成员名⇒类型”定义对应的获取类型的方法\n\n保存一个type_map，用于后面获取信息使用\n\n\n来看一下代码\ndef args_to_hash(*args)  args.reduce(&#123;&#125;) do |sum, arg|    sum.merge(      if arg.is_a? Hash        arg      else        &#123; arg =&gt; :str &#125;      end)  endendclass TypeStruct  include TypeCheck  def self.new(*args, &amp;block)    # if don&#x27;t have allocate, will be nil class    obj = allocate    # initialize is a private method    # initialize must be send instead of direct call    obj.send(:initialize, *args, &amp;block)  end  def initialize(*args)    args = args_to_hash(*args)    Struct.new(*args.keys).tap do |klass|      args.each do |attr, type|        check(type)        # per class Struct is different        klass.define_method &quot;#&#123;attr&#125;_t&quot; do          type        end      end\t  klass.define_method &quot;type_map&quot; do        args      end    end  endend\n\n还有一个点是需要在这里检查type的合法性，这里想过生成类的，但是最后想或许现在没必要，还是先用符号吧。检查相关的代码如下\nmodule TypeCheck  VALID_TYPE = &#123;:int =&gt; :int, :str =&gt; :string&#125;  def invalid?(type)    VALID_TYPE.keys.include? type  end  def check(type)    unless invalid? type      raise &quot;invalid type #&#123;type&#125;, only supported #&#123;VALID_TYPE.map(&amp;:to_s).join(&#x27;,&#x27;)&#125;&quot;    end  end  module_function :check, :invalid?end\n\nattr_type第二种是增加了一个像attr_reader一样叫做attr_type的东西，但是这个要依赖于常规的Struct，我还是想要常规Struct内部的东西来避免重复代码。虽然有办法不依赖Struct，但是那样需要在这个attr_type里面引入更多不属于这个函数的功能，于是还是放弃吧\n使用示例\nclass Push &lt; Struct.new(:value)  attr_type :value =&gt; :int  def to_s    &quot;Push #&#123;value&#125;&quot;  endend\n\n实现\n实现的核心原理还是参数转到hash再对每一对值define_method，只是这次我们要直接hack Module。attr_reader等函数也是采用的类似的做法\ntype_map的处置有一些不同，type_map需要将成员初始化，所有成员默认str类型，接着需要不断的merge新的参数，这个时候会将type_map中在args出现过的key所关联的值更新，这么解释可能比较复杂，看代码更直接一些\n&#123;:a =&gt; 1&#125;.merge(&#123;:a =&gt; 2&#125;)=&gt; &#123;:a=&gt;2&#125;\n\nclass Module  def attr_type(*args)    args = args_to_hash(*args)    args.map do |attr, type|      TypeCheck::check(type)      define_method &quot;#&#123;attr&#125;_t&quot; do        type      end    end\t@type_map ||= self.members.reduce(&#123;&#125;) &#123;|mem| &#123;mem =&gt; :str&#125;&#125;    @type_map.merge!(args)  endend\n\n二者的选择最后的结果嘛…ide分析不出来，不想看到各种报错的红线。遇到需要手动new的时候只能改成第二种了\n\n在获取成员的时候也用了很脏的做法，没找到什么在不new的情况下获取成员的好方法，因此也只有先new再从里面找。\n生成以前没做的坑这里其实做一个dsl来描述然后生成是最好的。在好久之前了解rv的时候我甚至一度想开一个坑，用一个dsl来描述一个isa，之后生成对应的C++的读写代码。最后也是咕咕咕了，后续有时间可以做一下，还是挺有意思的。\n这是一个描述load store的例子。当时做的时候没想到，现在一想其实也可以直接用Struct来描述，采用和我上面一致的方案\nISA.define :LOAD do  field :rd, 5  field :funct3, 3  field :rs1, 5  field :imm, 12endISA::define :STORE do  field :offset_4_0, 5  field :width, 3  field :base, 5  field :src, 5  field :offset, 5end\n\n这是一个只做了外观没有做内部实现的例子，属实有点问题，正经人谁会搞出这玩意\nnamespace :Suica do  namespace :T do    struct :F do      auto :a1      auto :a2, 1      void :f2, [&#x27;a&#x27;, &#x27;b&#x27;] do      end    end  endend\n\n生成的实现有点扯远了，我们来看一下实际生成C++代码的部分。\n我们需要生成如下几步\n\n获取所有指令信息\ninclude头文件，名称空间等内容\nInstType的enum定义\n所有指令类的定义\n解析输入的部分\n\n每个部分生成一个源码字符串，最后将这些拼接为一个长的字符串就好了\n捋清这个流程以后就简单贴一下部分代码好了，源码中&lt;&lt;SRC的部分是一个字符串块的开始，SRC是结束，中间的任何字符都会保留，除了#{expr}，这个是将expr to_s以后再嵌入进去\n帮助方法这是我自己加给Array的辅助函数，因为经常会有需要遍历array的所有对象做一套统一的操作最后再join连接的情况\nclass Array  def generate(c = &quot;\\n&quot;, &amp;f)    map &#123;|a| f[a] &#125;.join(c)  end  def pure_generate(&amp;f)    map &#123; |a| a.demodulize_class &#125;.generate(&amp;f)  endend\n\ndemodulize_class的话就是简单的将类名去除了module前缀\n获取所有指令信息虽然上面提过，这里再放一下代码\ndef get_classes(mod)      mod.constants.map&#123;|c| mod.const_get(c)&#125;.select&#123;|c| c.is_a? Class&#125;.sort_by&#123; |klass| klass.to_s &#125;end\n\n头文件def gen_header_namespace  &lt;&lt;SRC#include &lt;string&gt;#include &lt;vector&gt;#include &lt;memory&gt;#pragma onceusing std::string;SRCend\n\nInstType的enum定义def gen_enum_inst_type(classes)  &lt;&lt;SRCenum class InstType &#123;#&#123;classes.pure_generate &#123;|c| &quot;#&#123;c&#125;,&quot;&#125;&#125;&#125;;SRCend\n\n生成的样子\nenum class InstType &#123;Add,Label,SetLocal,&#125;;\n\n指令类定义def gen_class_define(klass)  class_name = klass.demodulize_class  member_map = klass.get_member_map  params = member_map.generate(&#x27;, &#x27;) &#123;|td| gen_class_member(td)&#125;  init_member = &quot;#&#123;member_map.keys.generate(&#x27;, &#x27;) &#123;|name| &quot;_#&#123;name&#125;(#&#123;name&#125;)&quot;&#125;&#125;&quot;  init_member = &quot;, #&#123;init_member&#125;&quot; unless init_member.empty?  init_inst = &quot;VMInst(InstType::#&#123;class_name&#125;)&quot;  &lt;&lt;SRCstruct #&#123;class_name&#125; : VMInst&#123;public:  #&#123;class_name&#125;(#&#123;params&#125;):#&#123;init_inst&#125;#&#123;init_member&#125; &#123;&#125;private:#&#123;member_map.generate &#123;|mem_ty| &quot;#&#123;gen_class_member(mem_ty, &#x27;_&#x27;)&#125;;&quot;&#125;&#125;&#125;;SRCend\n\n这里可能有一些需要提一下的东西，比如说有一个get_member_map\nclass Class  def get_member_map    instance = self.new    # need keep same order    MemberMap.new(instance.try(:type_map).or_else&#123;[]&#125;.map do |name, type|      TypeDefine.new(name, type)    end)  endend\n\n为了保持顺序，我选择了用数组来存放。指令最多无外乎一两百条，对于这个数据量不需要太去关心什么高效算法。\n为了有更多的类型信息来帮助写易读和更可用的代码，一个名称类型对也转转换为了一个类型\nclass TypeDefine &lt; Struct.new(:name, :type)end\n\n而MemberMap是一层包装，内部用typedefine的array存储，但也是可以像hash一样取出所有的key\nclass MemberMap  def initialize(type_defines)    @type_defines = type_defines  end  def generate(c = &quot;\\n&quot;, &amp;f)    @type_defines.generate(c, &amp;f)  end  def keys    @type_defines.map &#123; |td| td.name &#125;  endend\n\n生成的样子\nstruct Label : VMInst&#123;public:  Label(string name):VMInst(InstType::Label), _name(name) &#123;&#125;private:string _name;&#125;;\n\n解析代码def gen_all_parser(classes)  &lt;&lt;SRCstd::unique_ptr&lt;VMInst&gt; get_inst(const std::vector&lt;std::string&gt; &amp;list)&#123;#&#123;classes.generate &#123;|x| gen_parser(x)&#125;&#125;throw std::runtime_error(&quot;Unknown inst type&quot; + list[0]);&#125;SRCend\n\n生成的样子（这里只放一个示例\nstd::unique_ptr&lt;VMInst&gt; get_inst(const std::vector&lt;std::string&gt; &amp;list) &#123;\t    if (list[0] == &quot;Addr&quot;)\t\t        return std::make_unique&lt;Addr&gt;(std::stoi(list[1]), list[2]);&#125;\n\nC++代码格式这里应该提一下，这种生成方式代码格式一定会乱七八糟，所以还应该调用一下clang-format处理一下。但是VM那边的clang-format之类的许多东西还没有加好，之后再做一下吧\n最后感谢你能看到这里，我再闲谈几句没什么关联的\n这个系列我已经到了四篇，也就是一个月。持续做了这么几次已经可以确定只要不出意外自己就能连载下去，于是之后都会在推特推送我的更新（本周的就先算了，ruby本身所占比例有点大）RealAkemiHomura’ Twitter\n如果对我的日常有兴趣可以点个关注，如果并不在意这个只想看后续的文章，那么可以通过rss订阅，或者每周一查看我的文章，更新一定是在周末\n前面也提到元旦状态差，这些天甚至几次觉得这个系列过于玩具没有意义，想要断更、项目不想做下去了。但我最后还是决定继续更新，不为别的，只因为我还想接着做这个项目，哪怕内容如此简陋，只是一个过于简单的玩具，但我确实从中收获了知识和乐趣\n","categories":["Ruby"],"tags":["Rc-lang","元编程"]},{"title":"Rc-lang开发周记1 中间代码表示","url":"/2021/12/26/rc-lang-dev/rc-lang-dev-1/","content":"本周前面的时间主要选择了重新整理项目结构以及修正了自己滥用require_relative的问题，后面的话则是开始对ast to tac进行测试，尝试通过TDD的方式在开发效率和质量确保找到一个平衡点。\n比起测试，更主要的目的是重新回顾自己tac的设计决策，前面写的时候更多是一时兴起，完全不顾结构与正确性就往下写，比起急急忙忙往后赶进度还是应该将当前的内容做好才行。\n当前的项目结构.github # CI 尽管代码不多，但是依然要依靠单元测试和CI保证每次修改的正确性analysis # 代码分析的内容，目前并没有做过多的内容interface # 编译器、解释器和REPL的入口compiler # compiler的实现interpreter # 解释执行的实现ir # 多级ir的实现，ast, tac, vm指令lib # 编译器相关的一些简单的库，比如env, log或者错误处理之类parserspec # 专门用于测试\n\n解释执行实现的部分由于其他内容快速修改，暂无法顾及，因此暂时无法正常工作\nRc-lang的多层IR结构\n高层IR：AST\n中层IR：四元式\n底层IR：VM指令\n\n本周内容主要以中层IR为主\n中间代码表示IR主要分为两类\n\n线性IR\n图IR\n\n要注意的是树IR也是一种DAG图，因此也属于图IR，而高层的AST也是属于图IR\n选择IR的时候最主要的一点是我们要用它来做什么、需要什么信息，我想也没有什么绝对的设计正确，只要提供了所需信息，方便后续测试就足够了。在这里对比一下常见的IR实现（以线性IR为主）\n线性IR的概念三地址码是指 指令右侧只能有一个运算，不允许出现组合的形式\na2 = (b + c) * 4需要被翻译为a1 = b + ca2 = a1 * 4\n\n龙书中选择了线性IR的方式，使用了传统的三地址码。而虎书采用了树形IR（最后会简单提及）\n四元式具有四个字段，类似于 op arg1 arg2 result的形式，但是存在一些特例\n\nop仅需要一个参数\nparam的运算不使用args2和result（这里的param是龙书中用于传递函数参数的指令，龙书针对每一个参数产生一个param，仅传递参数也不需要返回值）\n转移指令将跳转地址放入result\n\n这些特例是针对虎书中的指令，实际可以根据需求进行一些变动\n定义这是我的四元式定义 在文件ir/tac/quad.rb中\nclass Quad  attr_accessor :op, :result, :lhs, :rhs  def initialize(op, result, lhs, rhs)    @op, @result, @lhs, @rhs = op, result, lhs, rhs  end  def to_s    &quot;#&#123;@result&#125; = #&#123;@lhs&#125; #&#123;@op&#125; #&#123;@rhs&#125;&quot;  end  def ==(other)    @op == other.op &amp;&amp; @result == other.result &amp;&amp; @lhs == other.lhs &amp;&amp; @rhs == other.rhs  endend\n\n以及我个人觉得没必要全都严格按照这种方式来，还是以自己的需求为准。按照常规的四元式op可以是各种类型的\n比如说我实现的Assign和Call（其他的op目前还没有修改以及做更多测试，本周先介绍这两个最基本的）\n通过类型来获取更多的信息，而不是仅仅通过字符串判别。还可以做到像call一样设置一个别名，能够显得更加直观\nclass Assign &lt; Quad  def initialize(result, lhs)    @op = &#x27;assign&#x27;    @result = result    @lhs = lhs    @rhs = EmptyValue.new  endend\n\nclass Call &lt; Quad  def initialize(result, target, args)    @op = &#x27;call&#x27;    @result = result    @lhs = target    @rhs = args  end  def target    @lhs  end  def args    @rhs  endend\n\nAssign没什么可说的。但是Call比较特殊\nargs并不是只有一个地址，所以Call并不算严格意义上的四元式。上面也提及过龙书中的Call的参数是通过一个param指令传递的，然后单独调用一个call。但就我目前来说这样做比较方便，等到后续做其他功能发现这么做的坏处的时候再修改也不晚\n转换实现\n转换代码在ir/tac/translator.rb中\nclass Assign # Rc::AST::Assign  attr_reader :var_obj, :expr  def initialize(var_obj, expr)    @var_obj, @expr = var_obj, expr  endenddef on_assign(node)  name = visit(node.var_obj)  expr = visit(node.expr)  Assign.new(name, expr).tap &#123; |assign| @tac_list.push assign &#125;end\n\n转换ast::assign的时候会将原来的名字作为tac::assign一个目标地址（尽管设计上留有了这个空间，但是目前先不考虑成员变量这种复杂的情况），然后再将表达式返回的内容设置为assign的operand。因此我们需要看一下expr的转换\nclass Expr # Rc::AST::Expr\tattr_reader :exprend# Rc::AST::Expr -&gt; Operanddef on_expr(node)  expr = visit(node.expr)  if expr.is_a? Operand    expr  elsif expr.is_a? Quad    expr.result  else    raise &#x27;unknown expr type&#x27;  endend\n\n存在两种情况\n\n转换为一个operand（比如说常量的情况）\n\n转换为了一个quad\n比如说c = a * b，a * b 会先存到一个临时变量再赋值。关于这个，龙书6.1.1中提到了这样的内容\n\n为什么我们需要复制指令？通常，每个子表达式都会有一个它自己的新临时变量来存放运算结果。只有处理赋值运算符=时，我们才知道将把整个表达式的结果赋到哪里，一个代码优化过程将会发现可以发生替换\n\n我没完全理解，也许只有做优化的时候才会明白，就先沿用这样的设计了\n\n\nquad的时候需要返回对应的临时变量，因为返回值会直接用于assign的operand\n测试\n然后我们再来看一下测试代码 spec/ir/tac_spec.rb\ncontext &#x27;assign&#x27; do  it &#x27;succeed&#x27; do    s = &lt;&lt;SRCdef f1\ta = 1\tb = 2\tc = a * bendSRC    tac = get_tac(s)    list = tac.first_fun_tac_list    expect(list[1]).to eq Assign.new(Name.new(&#x27;a&#x27;), Number.new(1))    expect(list[2]).to eq Assign.new(Name.new(&#x27;b&#x27;), Number.new(2))    expect(list[3]).to eq Quad.new(&#x27;*&#x27;, TempName.new(&#x27;0&#x27;), Name.new(&#x27;a&#x27;), Name.new(&#x27;b&#x27;))    expect(list[4]).to eq Assign.new(Name.new(&#x27;c&#x27;), TempName.new(&#x27;0&#x27;))  endend\n\n可以看到有简单的assign, 还有一个表达式的运算。\n表达式的运算转换为了一个quad，并且保存在了临时变量中，最后再将这个临时变量assign给c\n线性IR的存储方式对于线性IR来说，保存的方式也是一个比较重要的实现决策，很大程度会影响到后续各种操作。\n而实际实现无外乎数组和链表两种保存方式，在上周做重排if的时候也能看到数组的方式插入删除比较麻烦，而且效率会比较低。数组插入删除的方式也有对应的优化实现，但是对于其他优点目前没什么了解，后续做到优化的时候可能会需要考虑到这些实现方式的差别。\n我当前所有指令都保存在了一个数组，所以上面的四元式并没有指向前后的指令。之所以这么选择是因为当时没考虑太多，很自然的会想到一组指令会存到一个数组中。不过需要时在ast全部转为tac以后再做一下转换即可，需要做其他优化时再添加。当前目的是直接生成下一步的指令，所以现在这样就够了。\n名称与地址对于线性ir来说名称和地址是非常重要的事情。名称与地址是对应了三地址码的操作数，可以是常数，可以是一个地址，也可以是一个名字（间接索引到地址）\n所以有了一个operand的定义，在文件ir/tac/operand.rb中\nclass Operandend\n\n1.名字通过名字确定一个地址，实际实现可以通过符号表来索引到对应地址。\nclass Name &lt; Operand  attr_accessor :name  def initialize(name)    @name = name  end  def to_s    @name.gsub(/:/, &#x27;&#x27;)  end  def ==(other)    @name == other.name  endendclass TempName &lt; Nameend\n\n2.常量如果是数字类型的常量可以直接放入，这也符合CPU指令的行为。（bool本质也是数字）\n如果是字符串常量则需要记录到全局的一个表中，本质上我们还是使用字符串的地址。这个表里的东西在后续转vm指令和运行时会放入常量段，由于不会牵扯到改变，因此目前这里采用了一个普通的列表，通过索引来获取地址的方式。这里或许会牵扯到优化的问题，我觉得关于字符串常量这种优化可以放到转入这一步之前，如果遇到其他场合再做修改。\n两种常量的定义\nclass Number &lt; Operand      attr_accessor :num      def initialize(num)            @num = num      end      def to_s            @num.to_s      end      def ==(other)            @num == other.num     endend\n\nclass Memory &lt; Operand  attr_reader :addr  def initialize(addr)    @addr = addr  end  def ==(other)    @addr == other.addr  endend\n\n常量的转换\ndef on_bool_constant(node)  Number.new(node.val.to_i)enddef on_number_constant(node)  Number.new(node.val.to_i)enddef on_string_constant(node)  Memory.new(@const_table.add(node.val))end\n\n在这里涉及到一个const_table的问题。字符串会放在常量区，因此我选择在这里转换为一个地址。关于Memory或许需要选择段的问题，但是目前还没有遇到需要区分的情况，后续添加其他类型的常量再考虑吧，因此也是先这样。\nclass Memory &lt; Operand  attr_reader :addr  def initialize(addr)    @addr = addr  end  def ==(other)    @addr == other.addr  endend\n\n常量表\nclass ConstTable  attr_reader :list  def initialize    @list = []  end  def add(constant)    i = @list.index(constant)\t\ti.or_else do      @list.push constant      @list.size - 1    end  end  private def method_missing(symbol, *args)    @list.method(symbol).try &#123; |x| x.call(*args) &#125;  end  def ==(other)\tlist == @other.list  endend\n\n目前选择了这样简单的形式。没有用Set的原因是难以添加一个成员以后再返回对应的索引，可以作为后续优化的一个点。\nor_else是一个hack, nil的情况会返回block中的代码\n3.临时变量临时变量会出现在各种表达式中，前面转换的实现中也能看到相关内容。这里不多赘述\n其他IR形式这里对于SSA(Static Single Assign)就暂不提及了，SSA更多的是用于优化方面，目前的目标是生成VM指令并且能在VM上运行，做到SSA的时候会讲的\n其他的形式在这里大概一提，不讲过多细节（写不完了）\n三元式具有三个字段，类似于op arg1 arg2的形式。和四元式不同，不会显式保存返回结果，而是将每个结果存入列表中，因此三元式对结果的引用也是依靠于位置。很明显，这样就会导致如果添加或者减少指令则会变得很麻烦，因此引入间接三元式（在这里不赘述了，有兴趣自行搜索）\n由于实现比较麻烦，所以我还是选择使用常规四元式\n图IR虎书采用了树形IR\n由于我目前选择了线性的方式，暂无这方面的代码，姑且还是提一下虎书中的实现并且贴一下图\n其实也比较接近于tac，只是结构变成了树状，同样会有各种常数，内存操作，调用等等，因为中层IR本质上都是要将AST转换为接近于机器表示，所以不管什么样子最终都是要接近于机器指令。不同的存储方式区别只是做优化的时候不同\n\n\n最后tac指令以及对应的operand过于繁琐，测试代码也有待改进，对于Ruby来说这些都可以利用元编程来精简代码，而且可以疯狂造dsl。只是每天的开发时间实在不多，还是以能做出来为最高优先级。\n写了足足快俩小时，有点写的不耐烦了（有点时间焦虑，先以能写完为目标吧…）。写的过程中我会强迫自己反思和改进，上周写的时候最后还发现了一个bug，也算是不亏，下周也会更（在新建文件了，咕咕咕\n参考https://www.zhihu.com/question/33518780/answer/56731699\n编译原理 第六章\n现代编译原理 第七章\n","categories":["Compiler"],"tags":["Rc-lang"]},{"title":"Rc-lang开发周记4 函数其一","url":"/2022/01/16/rc-lang-dev/rc-lang-dev-4/","content":"本周主要是修复了之前C++代码生成的一些bug，之后开始搞函数定义与调用的部分。\n函数解析方式这里我一开始没想好怎么做的，所以会做的很诡异，最大的原因是静态类型语言和动态类型语言是不同的。由于我只对动态语言有一些了解，这里暂时只提动态语言的一些点\n动态语言手头动态类型语言的资料是相对较多的，而实际看编译出的产物也是相对熟悉一些。\n对于Ruby和Python来说，函数都是动态定义的。因此解析到一个函数的时候会产生一个定义函数的指令\nRuby\n0000 definemethod     :foo, foo      (   1)[Li]\n\n（后面的1是行号）\nPython\ndef f():0 LOAD_CONST    0 (code object f)3 MAKE_FUNCTION 06 STORE_NAME    0 (f)\n\n而函数本体内容则是创建了一个函数对象并放到了其他的位置，以及地址是重新从0开始的。这个地址应该是相对地址，因为会动态装载\n这两个的源代码不一样的，只是想展示地址都是从0开始。dump出来的内容差异也比较大\nRuby\ndef foo a = 3 * 2end\n\n== disasm: #&lt;ISeq:foo@&lt;compiled&gt;:9 (9,0)-(11,3)&gt; (catch: FALSE)local table (size: 1, argc: 0 [opts: 0, rest: -1, post: 0, block: -1, kw: -1@-1, kwrest: -1])[ 1] a@00000 putobject                              3                         (  10)[LiCa]0002 putobject                              20004 opt_mult                               &lt;calldata!mid:*, argc:1, ARGS_SIMPLE&gt;[CcCr]0006 dup0007 setlocal_WC_0                          a@00009 leave\n\nPython（函数体被编译成的内容\ndef f():\tprint(&quot;Function&quot;)\n\n0 LOAD_CONST 1 (“Function”)3 PRINT_ITEM4 PRINT_NEWLINE5 LOAD_CONST 0 (None)8 RETURN_VALUE\n\n实现一开始是想仿照做一个动态的实现，但是后来觉得还是静态的好，导致产生了如下的代码。\n对于一个函数，我生成了一个DefineFun。FunLabel是因为我不知道它们是如何判断函数结尾到哪里的，这属于我当时的一个理解错误，编译的时候函数体的内容会被编译好放到其他位置，而不是说运行时再看到一个函数的标签，再将之后的一段代码跳过。\n# 只展示关键部分# 错误版本def on_function(node)  [DefineFun.new(node.name), super(node), Return.new, FunEnd.new]end\n\n正确的做法应当是在编译的时候就将这些代码单独放到其他位置，运行时再进行装载。\n调用无参函数函数调用我们先从简单的无参函数说起\ndef f1    a = 1    1end\n\ntarget那么首先，我们需要考虑到call的target如何来做处理。很自然的会想到target可以使用字符串。\n尽管使用字符串的话会导致指令长度膨胀，解析复杂等。但目前不考虑那些，解析的也是字符串指令，所以先这样\n去哪里找目标函数的信息这个自然来说是需要符号表中保存了\n符号表中的函数信息对于符号表来说，表中条目需要保存的信息有以下几条\n\n参数个数（目前全部为无类型，因此返回类型也无需考虑）\nlocal变量的信息\n函数体的指令地址\n\n这些目前来说都是编译期间可知的，所以也会以字符串的方式dump出来供vm去解析。至于函数体地址的问题牵扯到链接，而目前我们先不需要考虑链接的情况，只需要将生成的符号表中的地址加载进来就好了。\n生成符号表由于以上需求，我们在编译的时候需要生成符号表信息\n我们之前设计的全局符号表是这样的\nclass GlobalEnv &lt; Struct.new(:define_env,:const_table, :fun_env)end\n\n暂时不考虑常量表，我们需要的是剩下两个表的信息。\n生成vm指令这个阶段会将一个全局定义表（define_env，目前仅存其定义），将其定义更改为args以及offset\noffset都是未知的所以先设置为一个未定义值，因为我是通过返回数组并且把数组连接起来的形式，所以这个时候并不知道偏移量。这里用一个数组存放值的做法实在很差劲，但是实在没精力改进了…先能跑吧\ndef on_function(node)    ...      @global_env.define_env[node.name] = [node.args, &#x27;undefined&#x27;]    ...end\n\n重新设置偏移量\ninst.each_with_index do |ins, index|      if ins.is_a? DefineFun            @global_env.define_env[ins.name][1] = index      endend\n\n而fun_env表，则是保存了每个表的参数以及局部变量的信息。拥有fun_env表和define_env表（这两个表其实应该合并，下次一定…）的信息，我们就能够生成出上面所需的信息了\ndef gen_sym_table(global_env)      global_env.define_env.map do |name, (args, offset)|        &quot;#&#123;name&#125; #&#123;args.size&#125; #&#123;global_env.fun_env[name].size&#125; #&#123;offset&#125;&quot;      end.join(&quot;\\n&quot;)end\n\n生成示例 格式为 函数名，参数个数，local var个数，起始地址\nmulti 2 2 0main 0 1 6\n\n函数符号表中的条目\nstruct FunInfo&#123;        FunInfo(): FunInfo(0, 0, 0) &#123;&#125;        FunInfo(size_t _argc, size_t _locals, size_t _begin): argc(_argc), locals(_locals), begin(_begin) &#123;&#125;        FunInfo(constFunInfo&amp; other) =default;        FunInfo(FunInfo&amp;&amp; other) =default;        FunInfo&amp;operator=(constFunInfo&amp; other) =default;        FunInfo&amp;operator=(FunInfo&amp;&amp; other) =default;        size_t argc;        size_t locals;        size_t begin;&#125;;\n\n调用栈既然要调用函数，那么就需要调用栈这个东西了\n就目前的需求来说，调用栈中的栈帧需要有以下几种成员\n\n前一个栈帧（跟踪整个调用链）\n返回的pc地址（函数调用结束后需要返回到调用者）\n当前栈帧在栈中的起始地址（起始地址开始分配局部变量的空间）\n\n关于多个栈帧之间的存储方式，由于需要频繁添加删除尾部结点，因此选择了链表的方式。如果使用数组的话会牵扯到长度不够再重新分配数组空间的情况\n而实际栈内数据的布局是\n----------------    tmp var----------------        f1    local var----------------  ----------------    tmp var----------------        main    local var----------------\n\n注意这里和实际的栈不同，对于实际的栈来说类似于返回的pc地址，以及前一个栈帧的地址都是保存在栈内的\n返回值目前的设计是返回值最后放到栈顶，这样返回的时候直接从栈顶取值，之后再恢复栈就可以了\n调用带参数的函数def f1(a, b)\t    c = a + b\t    cend\n\n参数传递目前采用的是push的方式直接push参数，这个体现在函数调用的时候编译出的指令上\ndef on_fun_call(fun_call)    fun_call.args.map &#123; |arg| push(visit(arg)) &#125; + [Call.new(fun_call.name)]  end\n\n栈内数据排布\n----------------    tmp var----------------    local var           f1----------------       args----------------  ----------------     tmp var----------------    local var           main----------------       args----------------\n\n关于参数传递的话题其实还有很多，比如说顺序，变长参数，谁来释放，在之后的内容再一点点补足\n正文无关闲谈首先是最重要的一点：本周的内容就充满了各种应付式的内容，这在往期我都是会直接当场修改掉的，但实属有些无力…我在想这样的内容发出来会不会很不负责任，但是如果停更那我所做出的每周更新的承诺这么快就要被打破了，而且以后更容易不遵守了。\n本周的内容相对少的多，最加对于压力的感知更加明显了，尽管我反复将注意力转移到当前做的事情上（每天也会有对应冥想练习），但很多事情依然力不从心。时间安排的太满，我不会的太多，但每一项我都无法舍弃，最后分配到做这个的时间真的不多了，还要一边查看各种实现学习一边写，好多东西都是周日写的时候才学习修改的。学习实现基本上也是靠看书，看前人总结过的内容，对于大型项目实在没有精力去扒。这周还在看Ruby的YJIT的论文，本就不多的时间更没多少了，最后论文也没看多少（就看了几段介绍…），这篇论文读明白后也会再出一篇博客，尽管只看了一点但也让我增加了许多JIT方面的常识\nYJIT: a basic block versioning JIT compiler for CRuby\n如何能摆脱这种状态，如果读者有经验还请赐教\n如果我是学生的时候就能开始做这件事情就好了..可是没有那么多如果\n","categories":["Compiler","VM"],"tags":["Rc-lang"]},{"title":"Rc-lang开发周记6 OOP其二","url":"/2022/01/30/rc-lang-dev/rc-lang-dev-6/","content":"在上一周的内容中，我们大概介绍了整个流程，以及少数的实现。本周的内容则是聚焦于实现，建议和上周的内容一起来看\n在之前的代码中内容都是偏向于无对象的结构，因此要先改正为适合面向对象的结构。\n本周修改的主要方向：所有的函数操作都是基于一个类的（因此函数信息也都会放到类中）\n在功能上要修改的有以下三个方面（测试这里暂且不谈）\n\n符号表分析\n生成vm指令\nVM运行时解析执行方式\n\n与此同时还更改了”链接”的方式，所有函数全部在第一次使用时动态加载\n符号表定义以前的\nclass GlobalEnv &lt; Struct.new(:define_env, :const_table, :fun_env)end\n\n现在的\nclass GlobalEnv &lt; Struct.new(:const_table, :class_table)end\n\n可以看到将所有信息都集成到一个class_table符号表目前全部依靠一个class_table进行运作，目前的内容也很简单，只是保存instance methods和vars的信息\nclass ClassTable  attr_accessor :instance_methods, :instance_vars  def initialize    @instance_methods = &#123;&#125;    @instance_vars = &#123;&#125;  end  def add_instance_method(name, define)    @instance_methods[name] = define  end  def add_instance_var(name, define)    @instance_vars[name] = define  endend\n\n这种时候需要单独解释类型信息，这就是动态类型的头疼之处，想试试Scala，但是没时间学了\nclass InstanceMethodInfo &lt; Struct.new(:define, :env, :args)end\n\ndefine在符号分析的时候是ast的结点，而在后面翻译到vm指令的时候\n相比之前取消了offset，因为全要等到运行时加载，这里的offset没有意义了\n而env就是在global_env中被干掉的fun_env，参数信息没什么好说的，目前仅保存名字以及只用于统计数量\n实际分析class_table的初始化def initialize  @define_env = Env.new  init_class_table  @const_table = Set[]  @cur_class_name = Rc::Define::GlobalObjectenddef init_class_table  @class_table = Env.new  @class_table.define_symbol(Rc::Define::GlobalObject, ClassTable.new)endmodule Rc  module Define    GlobalObject = &#x27;Kernel&#x27;    UndefinedMethod = &#x27;Undefined&#x27;    ConstructorMethod = &#x27;initialize&#x27;  endend\n\n塞进去一个默认的全局类，在vm执行的时候也会提到这里\n类def on_class_define(node)  # save old  old_class_name = @cur_class_name  # make new and update  @cur_class_name = node.name  class_table = ClassTable.new  # define before visit fun, because of this is a context used for visit fun  @class_table.define_symbol(node.name, class_table)  # visit and add value to class_table  node.fun_list.each &#123;|f| visit(f)&#125;  node.var_list.each &#123;|v| class_table.add_instance_var(v.name, v.val)&#125;  # restore name  @cur_class_name = old_class_nameend\n\n访问到类的时候创建一个类表，之后遍历visit成员的var和method，将这些信息添加到类表中\nmethod是在visit的内部添加的，这里目前这样做是因为如果是Kernel的method，则不会经过on_class_define，这里应当在前面ast层面就做处理。先记下来以后来修改，目前比较想赶快赶工到能做GC的地方\n函数之前\ndef on_function(node)    @define_env.define_symbol(node.name, node)    @cur_fun_sym = Env.new    @cur_fun_var_id = 0    @cur_fun_sym.merge(node.args.map&#123; |arg| [arg, EnvItemInfo.new(cur_fun_var_id, &#x27;&#x27;)]&#125;.to_h)    visit(node.stmts)    @fun_env[node.name] = @cur_fun_sym  end\n\n现在\ndef on_function(node)  @cur_fun_sym = Env.new  @cur_fun_var_id = 0  @cur_fun_sym.merge(node.args.map&#123; |arg| [arg, EnvItemInfo.new(cur_fun_var_id, &#x27;&#x27;)]&#125;.to_h)  visit(node.stmts)  @fun_env[node.name] = @cur_fun_sym  cur_class.add_instance_method(node.name, InstanceMethodInfo.new(node, @cur_fun_sym, node.args))end\n\n也没什么可说的，主要还是符号表存储方式的差别导致了这里信息存储的位置不同了\nvm代码生成translate之前的实现\ndef translate(ast, global_env)  @global_env = global_env  inst = visit(ast).flatten.compact  inst.each_with_index do |ins, index|    if ins.is_a? FunLabel      @global_env.define_env[ins.name].offset = index    end  end  @global_env.define_env.reject! do |name, table|    name.include? &#x27;@&#x27; or table.is_a? Rc::AST::Function  end  instend\n\n现在的实现\ndef translate(global_env)  global_env.class_table.update_values do |class_name, table|    @cur_class_name = class_name    table.instance_methods.update_values do |f_name, method_info|      @cur_method_info = method_info      method_info.define = visit(method_info.define).flatten.compact      method_info    end    table  end  global_envendclass Hash  def update_values(&amp;block)    each do |key, value|      self[key] = block.call(key, value)    end  endend\n\n尽管都是以一个函数为单位进行visit，但是对于现在的实现来说更大的遍历单位是一个class\n可以看到这里已经不再设置offset了，等到vm执行的时候再生成offset\non function之前\ndef on_function(node)  @cur_fun = node.name  @global_env.define_env[node.name] = Rc::FunTable.new(cur_fun_env, node.args, &#x27;undefined&#x27;)  [FunLabel.new(node.name), super(node), Return.new]end\n\n现在\ndef on_function(node)  @cur_fun = node.name  [FunLabel.new(node.name), super(node), Return.new]end\n\non_function只会在translate调用，只需要获取编译出的所有指令就可以了，关于表的更新都在translate中做\n此外，获取当前函数的env要修改一下\n之前\ndef cur_fun_env  @global_env.fun_env[@cur_fun]end\n\n现在\ndef cur_fun_env  @cur_method_info.envend\n\ncur_method_info可以在前面的translate中看到不断的更新值\ndump信息目前全部dump到了一个文件中\n源码class Foo  def initialize()  end  def add(x, y)    x + y  end  var a = 1enddef main    var f = Foo.new()end\n\n编译出的文件Kernelmain 0 1FunLabel mainAlloc FooCall Foo initializeSetLocal 0ReturnFoo # 类名a # 成员变量initialize 0 0 # 成员函数名 args数量 local_var数量FunLabel initialize # 函数定义Returnadd 2 2FunLabel addGetLocal 0GetLocal 1AddReturn\n\nFunLabel或许也可以删掉了，目前先这样留着吧，说不定debug会用得上\n写到一半才意识到完全可以使用一些现有的格式来做到这件事情，但这也只是临时用的东西，最后一定会转成真正的字节码而不是这种dump，先这样吧，大家千万不要跟我学坏\n实现这个也没什么好讲的，并非重点，相比之前不同也是以类为一个单位。目前是都编译到了一个文件，目前这样就够用\ndef gen_class_table(global_env)  global_env.class_table.map do |class_name, table|    &lt;&lt;SRC#&#123;class_name&#125;#&#123;table.instance_vars.keys.map(&amp;:to_s).join(&#x27; &#x27;)&#125;#&#123;table.instance_methods.map &#123; |name, info| gen_method(name, info) &#125;.join(&quot;\\n&quot;) &#125;SRC  end.join(&quot;\\n&quot;)enddef gen_method(name, method_info)  &lt;&lt;SRC#&#123;name&#125; #&#123;method_info.args.size&#125; #&#123;method_info.env.size&#125; #&#123;method_info.offset&#125;#&#123;method_info.define.map(&amp;:to_s).join(&quot;\\n&quot;)&#125;SRCend\n\nVM符号表这里要和ruby的符号表一致。用两种语言做这种时候就很麻烦，要再做一份\nstruct ClassInfo&#123;    std::vector&lt;std::string&gt; _vars;    SymbolTable&lt;FunInfo&gt; _methods;&#125;;struct FunInfo&#123;  \tsize_t argc;    size_t locals;    size_t begin;    std::vector&lt;std::shared_ptr&lt;VMInst&gt;&gt; inst_list;&#125;;\n\n不过要注意FunInfo中这里要保存起始地址，因为装载以后就会有地址了，默认为0（不可能存在的地址，视为未链接）\n加载文件先这样凑合用好了\nSymbolTable&lt;ClassInfo&gt; parse() &#123;    std::ifstream f(_path);    std::string str;    SymbolTable&lt;ClassInfo&gt; class_table;    while (std::getline(f, str)) &#123;        // 1. class name        auto class_name = str;        // 2. member vars        std::getline(f, str);        auto member_vars = split(str);        // 3. functions        std::getline(f, str);        SymbolTable&lt;FunInfo&gt; fun_table;        while(!str.empty())        &#123;            // 3.1 info            auto fun_info = split(str);            auto name = fun_info[0];            auto args = std::stoi(fun_info[1]);            auto local_vars = std::stoi(fun_info[2]);            // 3.2 add to class_table            fun_table.define(name, FunInfo(args, local_vars));            // 3.3 define            std::getline(f, str);            auto &amp;inst_list = fun_table[name].inst_list;            while(std::getline(f, str) &amp;&amp; !str.empty())            &#123;                auto list = split(str);                inst_list.push_back(get_inst(list));            &#125;            std::getline(f, str);        &#125;        ClassInfo class_info(member_vars, fun_table);        class_table.define(class_name, class_info);    &#125;    return class_table;&#125;\n\n函数调用由于增加了类相关的内容以及“动态链接”，这里的变化会大得多\n之前\nvoid begin_call(const std::string&amp; f)&#123;    if(!_sym_table.contains(f))    &#123;        // todo: find definition        throw std::runtime_error(&quot;Target Function&quot; + f + &quot;Not Found&quot;);    &#125;    auto &amp;fun = _sym_table[f];    // 1. stack process    _eval_stack.begin_call(fun.argc, fun.locals, _pc);    // 2. set pc    _pc = fun.begin;    LOG_DEBUG(&quot;Call &quot; + f + &quot; PC:&quot; + std::to_string(_pc))&#125;\n\n之后\nvoid begin_call(const std::string&amp; klass, const std::string&amp; f)&#123;    if(!_sym_table.contains(klass) || !_sym_table[klass]._methods.contains(f))    &#123;        throw std::runtime_error(&quot;Target Function&quot; + f + &quot;Not Found&quot;);    &#125;    auto &amp;fun = _sym_table[klass]._methods[f];    if(fun.begin == UndefinedAddr)    &#123;        fun.begin = load_method(fun);    &#125;    // 1. stack process    _eval_stack.begin_call(fun.argc, fun.locals, _pc);    // 2. set pc    _pc = fun.begin;    LOG_DEBUG(&quot;Call &quot; + f + &quot; PC:&quot; + std::to_string(_pc))&#125;\n\n变化主要有两个\n\n查找被调用函数的方式，需要先查找类表再从中查找到对应函数信息\n加载\n\n关于加载的实现\nsize_t load_method(const FunInfo&amp; f)&#123;    // 1. get start    auto start = std::max&lt;int&gt;(0, static_cast&lt;int&gt;(_inst_list.size() - 1));    // 2. load inst to inst_list    for(auto &amp;&amp;inst : f.inst_list)    &#123;        _inst_list.push_back(inst);    &#125;    return start;&#125;\n\n目前的需求来说这些就足够了，因为目前没有牵扯到一些相对寻址的指令。之后加到那些指令的时候再来更新\n初始化里面目前就这么一行代码，其实也没有太大变化，只是入口需要指定类了\nbegin_call(VMGlobalClass, VMEntryFun);\n\n最后正式开始构造对象以及调用构造函数要等到GC弄出来再写了（尽管编译器这边已经做了，但是VM不做出对应功能毫无意义）。下个周不出意外的话应该要开GC的坑了，尽管放假了，但依然有一堆事情要处理，就像写博客回顾、重构代码一样，我的生活也需要做一些打扫与清理，还有一些需要学习的新知识，所以大概率还是会维持平常的进度。不寻求太大的变化，能维持这样的进度我觉得也不错。\n我觉得这种对比修改前后代码的方式还挺不错的，以后如果再涉及到修改已有设计的地方都会再加一些。\n最近有些疏于测试了..尤其是VM代码一点都没有，下次一定\n","categories":["Compiler","VM"],"tags":["Rc-lang"]},{"title":"Rc-lang开发周记7 GC也没有那么可怕 其一","url":"/2022/02/06/rc-lang-dev/rc-lang-dev-7/","content":"本周的内容主要是写了一点点GC，同时做了一些对接GC的改动，之后接入了gtest开始测试。\n由于GC基本的功能还没写完（你这也太慢了），本周将着重介绍一下GC的原理 ，让读者对GC对一些概念之类有个大概的了解，实现的细节以及我在实现中遇到思考的问题留到下周再说，可以等到下周养肥再一起看\n本周从质和量来说都无法令人满意，状态比较差要写不下去了，但是起码比咕了强\nGC的对象表示对象被保存在内存中，而对象则分为头和域两部分。\n其中头被用于标识对象信息，比如说类型，以及gc的tag信息，利用tag信息来判断当前对象的状态\n域则是能够被编程语言访问到的部分。域很显然可能是一个值，也可能是一个指向对象的指针\nRuby让我们看一下Ruby的RObject的定义\nstruct RObject &#123;    /** Basic part, including flags and class. */    struct RBasic basic;    /** Object&#x27;s specific fields. */    union &#123;        struct &#123;            uint32_t numiv;            VALUE *ivptr;            struct st_table *iv_index_tbl;        &#125; heap;        VALUE ary[ROBJECT_EMBED_LEN_MAX];    &#125; as;&#125;;\n\n不需要关心过多的细节，可以看到很明显是分为了头和域两部分。\n让我们再来看一下头部 RBasic\nstructRUBY_ALIGNAS(SIZEOF_VALUE)RBasic &#123;    VALUE flags;    const VALUE klass;&#125;\n\n很显然，一个标记和一个类信息。Ruby采用的也是标记算法，这里有flags保存标记信息\nPython再来看一下Python的实现。这次我们从头部开始看起\ntypedef struct _object &#123;    _PyObject_HEAD_EXTRA    Py_ssize_t ob_refcnt;    PyTypeObject *ob_type;&#125; PyObject;\n\nObject本质上是对象的头部信息。python是通过引用计数实现的GC，可以看到有一个ob_refcnt，同时还有一个保存Type的对象，\n第一行的_PyObject_HEAD_EXTRA\n#ifdef Py_TRACE_REFS/* Define pointers to support a doubly-linked list of all live heap objects. */#define _PyObject_HEAD_EXTRA            \\    struct _object *_ob_next;           \\    struct _object *_ob_prev;#define _PyObject_EXTRA_INIT 0, 0,#else#  define _PyObject_HEAD_EXTRA#  define _PyObject_EXTRA_INIT#endif\n\n可以看到这是为了方便测试以及跟踪执行情况而添加的内容\n看一下Python的对象\ntypedef struct &#123;    PyObject ob_base;    Py_ssize_t ob_size; /* Number of items in variable part */&#125; PyVarObject;\n\n其中的ob_size是用于可变长对象使用的，例如List\n对比Python是每个对象的头部有一个PyObject的指针，不同的类型是基于这个扩展的\n而Ruby是每个对象是一个RObject，对象内部也有一个相同的头部RBasic，而不同的类型都是RObject本身\n虽然实现的方式略有不同，但是本质上还是一样的。而对于GC的实现也是一样，所以我们之后只是大概提一下实现方式的本质\n实现算法在这里只简单谈及标记清除、引用计数以及复制，这三者是最基本的算法，改进版本暂且也不会提及，本周的内容的目的只是希望读者能够对GC有一些了解。其他算法都是从它们衍生出来的本质并没有发生变化（其实主要是因为我只看了这三个）\n标记清除标记清除，我个人觉得用追溯更形象一些，因为需要从一些节点开始遍历访问所有的对象，对这些对象设置上tag，之后再对没有打上tag的对象进行回收\n引用计数在对象的头部设置一个字段用于标记有几个对象正在应用当前对象，在被创建的时候会设置标记为1，而被一个新的对象引用的时候计数就加1\n当然这个做法存在一个很明显的问题，就是如果两个对象互相保存了对方的引用，那么就会造成循环引用的情况。C++的智能指针也是使用循环计数，因此依然会遇到这样的问题，而在C++中的解决方案是需要使用一个不获取对象所有权的weak_ptr来解决这个问题。\n复制对于复制算法来讲，实际上将堆等分为两部分。一部分是正在使用的空间，另一部分是作为复制的临时空间。\n复制算法将所有的活动对象从当前正在使用的空间复制到临时空间，之后直接将两块空间交换，也就是说没被复制的对象直接被销毁了\n参考书籍垃圾回收的算法与实现\nPython源码剖析\n","categories":["GC"],"tags":["Rc-lang"]},{"title":"Rc-lang开发周记5 函数其二&OOP其一","url":"/2022/01/23/rc-lang-dev/rc-lang-dev-5/","content":"本周要做的第一件事情当然是把之前写的脏代码全部干掉！神清气爽\n那么就让我们进入本周的正题。最近几周的代码可能会较少而且内容非常碎片，时间短缺且这块内容跨度非常大，需要参考其他已有实现，再加上第一次做并不熟悉正处于开荒期，更多的是学习于思考相关的知识。\n函数在VM的实现回顾之前没有提及函数相关的内容在vm是怎么实现的，所以这里首先提及这个话题\n函数的实现无外乎就是调用与返回的情况，这里再多加一个关于getlocal和setlocal以及计算的实现部分。\n先来简单回顾一下我们的栈上的信息\n--------------------       tmp var--------------------      local var           f1--------------------         args--------------------  ----------------       tmp var--------------------      local var           main--------------------         args--------------------\n\n除了这些再来看一下我们的栈帧\nclass StackFrame&#123;    std::shared_ptr&lt;StackFrame&gt; _prev;    char *_base;    size_t _ret_addr;&#125;;\n\n关于这些成员都是因为什么需要增加的，请回顾上期内容\nRc-lang开发周记4 函数其一 | Homura’s Blog\n具体实现call\n去符号表找符号\n这一步在vm中处理，找到符号的话将信息传递给栈来做第二步\n\n栈处理\n\n更新pc\n\n\n着重讲一下栈的处理\n\n设置当前栈帧基址\n由于目前参数是在call之前push的（这个push一定紧接着call），因此需要先将stack_top指针移动到第0个参数的位置，得出基址\n\n分配局部变量空间\n根据局部变量的数量再将栈基址向上移动\n\n创建新的栈帧\n\n\n实现代码，都在eval_stack.h中\nvoid begin_call(size_t argc, size_t locals, size_t ret_addr)&#123;    // 1.set stack base    auto *base = get_args_begin(argc);    // 2.alloc local var space    _stack_top = stack_move(base, static_cast&lt;int&gt;(locals));    // 3.create new stack frame    _frame = std::make_shared&lt;StackFrame&gt;(_frame, base, ret_addr);&#125;char *get_args_begin(size_t argc)&#123;    return _stack_top - argc * WordLength;&#125;char *stack_move(char *stack_pos, int offset)&#123;    return stack_pos + offset * WordLength;&#125;\n\n关于WordLength\nconstexpr static size_t WordLength = sizeof(int);\n\nreturn\n获取返回值\n由于在函数体内计算的时候最后会将返回值push到栈顶，那么这里需要先pop将值取出来\n\n栈帧回退\n\n重置pc\n\n返回值放到栈顶\n\n\n这个返回值有点折腾…目前就先这个样子\n这里也是着重讲一下栈帧回退\nsize_t end_call()&#123;    auto ret_addr = _frame-&gt;ret_addr();    _stack_top = stack_move(_frame-&gt;base(), -1);    _frame = _frame-&gt;prev();    return ret_addr;&#125;\n\ngetlocal/setlocal就是简单的从当前栈基址添加偏移量\nint get_local(size_t offset)&#123;    return *get_base_offset(static_cast&lt;int&gt;(offset));&#125;void set_local(size_t offset, int value)&#123;    *get_base_offset(static_cast&lt;int&gt;(offset)) = value;&#125;int *get_base_offset(int offset)&#123;    return get_offset_pos(_frame-&gt;base(), offset);&#125;\n\n运算template&lt;typename Callable&gt;void exec(Callable &amp;&amp;f)&#123;    auto new_v = f(pop(), pop());    push(new_v);&#125;\n\n函数最基本的功能完成了，那我们该做创建对象相关的部分了。\n从常见的类开始我们从一个常见的类的例子开始引入我们的问题\nclass Foo\tattr_reader :a\tdef initialize(a)    @a = a\tend\tdef add(b)\t\t@a + b\tendend\n\n这个类很简单，一个成员变量、一个构造函数和一个实例方法。\n在我们想要使用这个类之前，我们需要在编译期间先解析这个类的信息\n解析成员创建一个类表。保存了所有定义的类的定义，以及可以作为一个类型查询表。\n这个解析的过程一度想要直接从Ruby抄一套类似的，但是工作量会非常大，因为需要到基类查找方法，牵扯到继承等各种问题\n目前类的ast结构\nclass ClassDefine\tattr_reader :name, :define, :parent, :fun_list, :var_listend\n\n这个定义中define是之前做的对于现在来说是不必要的内容，但是我目前时间有限不太敢动，怕前面的东西都乱套了，留个todo再说。parent是因为之前ast解释器的部分做了继承，但是目前vm这边还没有开始做，也就先不管它\n对于成员函数全部翻译一遍，重命名一下符号，而对于成员变量，直接将信息添加到对应的表中即可。所以目前ClassTable是这样的\nclass ClassTable  attr_accessor :instance_methods, :instance_vars  def initialize    @instance_methods = &#123;&#125;    @instance_vars = &#123;&#125;  end  def add_instance_method(name, define)    @instance_methods[name] = define  end  def add_instance_var(name, define)    @instance_vars[name] = define  endend\n\n除了解析信息，还需要在运行的时候创建这个类的对象。创建对象则分为两步\n\n分配内存\n初始化\n\n分配内存关于分配内存我们需要知道\n\n为了知道所分配空间的大小，首先需要获取类型信息。那么该如何获取类型信息以及类型信息怎么存放，存在哪里\n\n目前不考虑元编程的地方，所以这些信息都是编译期间可知的。假设要做更多元编程的内容，那么需要将一部分的内容放到运行时处理。按照我的理解来说，到时候将类型信息传递给vm，以及添加一些指令专门用于做元编程（这样指令种类会增加很多）。但这仅限于我粗浅的理解，更详细的还是要等到我做的时候再考虑。\n\n如何计算空间大小\n\n这个时候可能会出现一个最简单不过的想法，直接将所有成员大小都加起来不就好了。但是如果这样做，地址无法对齐，在vm那边取是很麻烦的事情。关于对齐暂时也不考虑，目前只考虑数据全为一个字长的整型数字，因此产生的对象也只会有带有这样成员的数字。还有会遇到空对象的情况，没有任何成员函数该怎么办（关于空对象，下文会单独提一下）\n除了基本的空间大小，还需要考虑留有GC信息的头部。这个就牵扯到下一个问题\n\n数据保存的格式\n\nGC需要保存哪些对象信息，这些信息又是如何保存的。关于这一点在后面的Ruby的Object实现中会略微提及\nGC相关的更多内容要等到之后实现的时候再更详细的提及了\n关于这里实际上还有更多复杂的话题，比如说递归数据类型，Union等，这些也都以后做的时候再来讨论\n初始化生成方法这里涉及到了一个问题，一个最简单的Foo对象并没有构造函数，那么我们需要先在ast的阶段生成对应的“无参”构造函数。\n调用调用这里本质上是一个方法查找机制，目前想先做最简单的，后面按需添加。直接去对应的this指针，找到对应类的信息，然后再从类表中进行查找，还没做实现，大概会到下周的内容中\n同时这个方法也是作为一个成员函数被调用（尽管是外部不可见的），这里就顺便讲调用成员函数的做法\n首先考虑调用成员函数的时候就需要引入this指针了，这个属于固定在栈内的内容，所以我把它放到了栈帧的结构中，而不是栈的实际数据中。\n一些语言this相关说到this指针，我想到了两个语言\n第一个是Python，因为Python是需要显式传递self的\n另一个是C#，C#的extension机制大概是这个样子，通过这种方式来给某个类添加类函数，我没有深究过后面的实现机制，但我想大概是解析到这里就给符号表中的这个类添加一个成员函数吧\npublic static class SomeClassExtension&#123;    public static void method(this SomeClass instance, args)&#125;\n\nRuby本身也有一些相似的对象，定义类函数的时候会需要self。不过这里的self的含义变成了这个类，而不是某个实例成员\nclass Foo\tdef self.f\tendend\n\n特殊情况无成员变量类class Helper  def add(a, b)    a + b  endend\n\n这种情况最大的问题在于对象空间大小的问题。目前我已知的做法有如下几种\nC++中对于类似的类在实例化的时候会有一个一字节的空间占用，为的是区分地址\n而Rust则有一个叫ZeroSizedTypes的东东，在谷歌搜索的时候搜索到了这样一段代码\nuse std::mem::size_of;fn  main() &#123;   println!(&quot;&#123;&#125;&quot;, size_of::&lt;()&gt;());   println!(&quot;&#123;&#125;&quot;, size_of::&lt;[(); 100]&gt;());   let boxed_unit = Box::new(());   println!(&quot;&#123;:p&#125;&quot;, boxed_unit); &#125;作者：zqliang链接：https://ld246.com/article/1539826769170来源：链滴协议：CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0/\n\n运行结果\n000x1\n\n可以看到Rust不像C++一样会有一字节的空间占用\n带有GC的语言通常是会有一个header的开销（header用于存储类型以及GC信息），成员域部分会因实际实现不同而不同\n对于Ruby来说Object是这个样子的。因此对象即便为空也会有下面这个union的开销\nstruct RObject&#123;    struct RBasic basic;    union     &#123;        struct &#123;...&#125; heap; //省略        Value ary[ROBJECT_EMBED_LEN_MAX];    &#125;&#125;\n\nRuby的类与函数def f1\t9endclass S  def initialize    9  end  def f1    9  endendm = 1a = S.new()\n\n成员函数和“普通函数”定义对比== disasm: #&lt;ISeq:f1@&lt;compiled&gt;:1 (1,0)-(3,3)&gt; (catch: FALSE)0000 putobject                              9                         (   2)[LiCa]0002 leave                                                            (   3)[Re]\n\n== disasm: #&lt;ISeq:initialize@&lt;compiled&gt;:5 (5,2)-(7,5)&gt; (catch: FALSE)0000 putobject                              9                         (   6)[LiCa]0002 leave                                                            (   7)[Re]\n\n可以看到编译出的函数没什么不同。我想这是因为Ruby的一切皆对象的缘故。哪怕只是一个单独的函数，也是定义在Kernel中，本质上还是一个成员函数。\n而这个initialize也是和普通的成员函数是一致的，特别之处只是会在Object的new中被调用，甚至和普通成员函数一样可以被外部调用\n== disasm: #&lt;ISeq:f1@&lt;compiled&gt;:9 (9,2)-(11,5)&gt; (catch: FALSE)0000 putobject                              9                         (  10)[LiCa]0002 leave                                                            (  11)[Re]\n\n调用方式0011 putself                                                          (   9)[Li]0012 opt_send_without_block                 &lt;calldata!mid:f1, argc:0, FCALL|VCALL|ARGS_SIMPLE&gt;\n\n定义类0003 putspecialobject                       3                         (   3)[Li]0005 putnil0006 defineclass                            :S, &lt;class:S&gt;, 00010 pop\n\n这里可以看到，Ruby中类也是和method一样是通过特殊的vm指令进行动态定义的\n编译出的类定义的内容\n== disasm: #&lt;ISeq:&lt;class:S&gt;@&lt;compiled&gt;:4 (4,0)-(12,3)&gt; (catch: FALSE)0000 definemethod                           :initialize, initialize   (   5)[LiCl]0003 definemethod                           :f1, f1                   (   9)[Li]0006 putobject                              :f10008 leave\n\n调用构造函数的全部流程流程0016 opt_getinlinecache                     25, &lt;is:0&gt;                (   9)[Li]0019 putobject                              true0021 getconstant                            :S0023 opt_setinlinecache                     &lt;is:0&gt;0025 opt_send_without_block                 &lt;calldata!mid:new, argc:0, ARGS_SIMPLE&gt;0027 dup0028 setlocal_WC_0                          a@1\n\n除去前面的优化和后面的赋值操作，可以发现new对象的时候实际调用还是在new上而不是所谓的构造函数。可以从这里一定程度的看到Ruby创建对象的实现：Ruby在创建对象的时候是会先调用隐含的new函数（继承自Object），而这个new函数的默认实现会调用allocate，之后调用对应的initialize方法，最后再将new出来的对象返回。关于这个知识点在之前做TypeStruct的时候也提及过，有兴趣的可以去看一下\nRc-lang开发周记3 生成C++代码 | Homura’s Blog\n参考资料Ruby原理剖析\n垃圾回收的算法与实现\n","categories":["Compiler","VM"],"tags":["Rc-lang"]},{"title":"Rc-lang开发周记8 OOP之成员函数调用","url":"/2022/02/12/rc-lang-dev/rc-lang-dev-8/","content":"本周做的内容不多，主要都是在做基础的成员调用相关工作（也只处理了成员函数，还没处理成员变量），然后就是修复一些问题添加了一些dump设施（目前做的并不好，等做好了可以单独拿一期讲一下），以及学习了解了一些其他语言相关的知识。\n成员函数调用的过程我们先来想一下这个过程大致是怎样的\n\n被调用对象非静态方法的时候首先成员函数要依赖于一个具体的对象，那么我们则需要在调用之前先将被调用对象的指针push到栈上\n方法查找根据对象的信息找到对应的类表，然后在类表中找到对应方法的地址（牵扯到继承的话也是在这里找父类的方法）\n\n编译器的实现AST成员函数调用的AST是这样的\nclass ClassMemberAccess    attr_reader :instance_name, :member_name, :argsend\n\n其实这里当初设计想的是能够同时支持函数和成员变量的调用（也会加上无括号调用），但是我们现在认为它就是一个成员函数调用\nTranslatedef on_class_member_access(access)  argc = access.args.size  push_this = if access.instance_name == &quot;self&quot;    PushThis.new  else    push Ref.new cur_fun_env[access.instance_name].id  end  call = Call.new(access.member_name, argc)  [push_this] + access.args.map&#123; |arg| push(visit(arg))&#125; + [call]enddef on_fun_call(fun_call)  [PushThis.new] + fun_call.args.map &#123; |arg| push(visit(arg)) &#125; + [Call.new(fun_call.name, fun_call.args.size)]end\n\n再对比看一下旧的fun_call\ndef on_fun_call(fun_call)  fun_call.args.map &#123; |arg| push(visit(arg)) &#125; + [Call.new(@cur_class_name, fun_call.name)]end\n\n没什么可讲的，非常直观\nVM的实现call的实现思路之前的call的参数是一个类和一个函数名，完全可以说是用于静态函数调用的做法。（关于静态函数调用的实现我们之后再考虑）\n上面提到非静态方法需要依赖于具体对象，因此我们需要先将被调用对象的指针push到栈上。而类信息可以从对象上获取，因此不需要call参数中的类型名。而获取指针则需要知道有多少个参数，因此我们需要传递进去参数的数量。这个做法也可以处理变长参数的情况\n传递参数数量在ruby中也是类似的\n0004 opt_mult &lt;calldata!mid:*, argc:1, ARGS_SIMPLE&gt;[CcCr]\n\n写到这里的时候我突然想到了一个问题，为什么要先push被调用对象指针？顾思考了一下，如果在push完所有参数之后再push被调用对象指针则前面的参数无法直接作用于被调用函数中。\n代码实现FunInfo &amp;method_search(const RcObject * const obj, const std::string &amp;f)&#123;    auto klass = obj-&gt;klass();    if(!global_class_table.contains(klass) || !global_class_table[klass]._methods.contains(f))    &#123;        throw std::runtime_error(&quot;Target Function:&quot; + f + &quot; Not Found&quot;);    &#125;    return global_class_table[klass]._methods[f];&#125;void begin_call(const std::string&amp; f, size_t argc)&#123;    auto *obj = _eval_stack.get_object(argc);    auto &amp;fun = method_search(obj, f);    if(fun.begin == UndefinedAddr)    &#123;        fun.begin = load_method(obj-&gt;klass(), f, fun);    &#125;    // 1. stack process    _eval_stack.begin_call(fun.argc, fun.locals, _pc + 1, obj);    // 2. set pc    set_pc(fun.begin);    EXEC_LOG(&quot;Call &quot; + f + &quot; new PC:&quot; + std::to_string(_pc) + &quot; ret pc:&quot;        + std::to_string(_eval_stack.current_frame()-&gt;ret_addr()));&#125;\n\n也很直观，先获取被调用对象，之后找到函数，开始处理调用栈，除了获取调用对象的部分和之前差不多。而栈帧会多保存一个当前的obj。在这里我新记录了调用栈的深度，便于调试\nvoid begin_call(size_t argc, size_t locals, size_t ret_addr, RcObject *this_ptr)&#123;    // 1.set stack base    auto *base = get_args_begin(argc);    // 2.alloc local var space    _stack_top = stack_move(base, static_cast&lt;int&gt;(locals));    // 3.create new stack frame    _frame = std::make_shared&lt;StackFrame&gt;(_frame, base, ret_addr, this_ptr);    // 4.increase depth    ++_depth;&#125;\n\n关于set_pc\nvoid set_pc(size_t new_pc)&#123;    _pc = new_pc;    _pc_need_incr = false;&#125;\n\n新增了一个控制pc是否递增的成员，pc跳转的时候不应当继续递增pc，所以在各种跳转指令中都会直接使用set_pc\n而递增的逻辑也相应的发生了变化\nvoid pc_increase()&#123;    if(_pc_need_incr)    &#123;        ++_pc;    &#125;    else    &#123;        _pc_need_incr = true;    &#125;&#125;\n","categories":["Compiler","VM"],"tags":["Rc-lang"]},{"title":"Rc-lang开发周记10 分支与循环","url":"/2022/03/05/rc-lang-dev/rc-lang-dev-10/","content":"开头忏悔，上周因为年会出去玩了三天没写多少东西，加上回来太累了，也就咕了一周，本周会把上周的东西一起写进来\n本周更新的内容主要是修复之前的问题以及处理了分支循环\n继承与成员变量首先是上周遗留的继承的情况下成员变量id会有问题，我们先来看一下成员变量相关的实现\n\n使用id标明\n运行时存一个hash，按照名字来取\n\n我选择在添加parent的时候将parent的成员变量添加到当前的instance_vars中。这样需要布局在编译器确定，无法应对动态添加成员变量的情况，不过先不管那些\ndef instance_var_keys  @instance_vars.sort_by(&amp;:last).map &#123;|k, _|k&#125;enddef add_parents(parent_name, parent_table)  @parent = parent_name  unless parent_table.is_a? ClassTable    raise &quot;parent_table should be a ClassTable&quot;  end  parent_table.instance_vars.each do |var_name, _|    unless @instance_vars.include? var_name      add_instance_var(var_name)    end  endend\n\n分支最近才发现我还没有做分支以及循环的内容\nASTclass If\t# stmt_list: [[if_cond, stmt], [elsif_cond, stmt]*]\tattr_reader :stmt_list, :else_stmtsend\n\ntranslatordef on_if(node)  list = node.stmt_list.map do |cond, stmt|    c = visit(cond)    s = [visit(stmt), JumpAfterIf.new].flatten    cmp_and_jmp = push_eq_jmp(s.size)    [c, cmp_and_jmp, s].flatten  end.flatten  els = visit(node.else_stmts)  list = list + els  list.each_with_index do |inst, index|    if inst.is_a? JumpAfterIf      list[index] = RelativeJump.new(list.size - index + 1)    end  end  listenddef push_eq_jmp(true_branch_size)  [Push.new(1), EQ.new, JumpFalse.new(true_branch_size + 1)]end\n\n思路对于每一组（if或者elsif）if条件和stmt进行遍历\n\n生成判断条件的指令\n\n生成比较指令\n将判断执行的结果与true进行eq操作，失败则跳转到下一组elsif，也就是true分支之后的第一条指令\n\n生成当前组if中对应的true的分支\n最后要添加一个跳转到整个if结束的指令\n\n\n新指令可以看到这里引入了几个新的指令\nJumpAfterIf：用于跳转到if结束语句，提前占好指令位置，最后由RelativeJump代替\nRelativeJump：跳转到一个相对地址\n对于分支来说，判断指令也是需要的，因此还引入了GT，LT，EQ三个指令\ndef translate_op(op)  case op.op\t...  in &#x27;&lt;&#x27;    LT.new  in &#x27;&gt;&#x27;    GT.new  else    raise &#x27;unsupported op&#x27;  endend\n\n循环astclass While &lt; Struct.new(:cond, :body)end\n\ntranslatordef on_while(node)  cond = visit(node.cond)  body = visit(node.body).flatten  cmp_and_jmp = push_eq_jmp(body.size + 1)  while_inst = [cond, cmp_and_jmp, body].flatten  while_inst + [RelativeJump.new(-while_inst.size)]end\n\n这里的内容更简单，相比if来说只需要处理一个分支判断和true的语句，最后加一个回到while开头的跳转即可\n指令的VM实现新的pc寻址方式void VM::set_pc(size_t new_pc) &#123;    _pc = new_pc;    _pc_need_incr = false;&#125;voidVM::relative_pc(int offset) &#123;    DEBUG_CHECK(static_cast&lt;int&gt;(_pc) + offset &lt; 0,                &quot;invalid pc, pc:&quot; + std::to_string(_pc) + &quot;offset:&quot; + std::to_string(offset))    set_pc(_pc + offset);&#125;\n\n比较void visit([[maybe_unused]]  const EQ &amp;inst)&#123;    _eval_stack.exec(BinaryOp::EQ);&#125;void visit([[maybe_unused]]  const GT &amp;inst)&#123;    _eval_stack.exec(BinaryOp::GT);&#125;void visit([[maybe_unused]]  const LT &amp;inst)&#123;    _eval_stack.exec(BinaryOp::LT);&#125;\n\n关于这里，我把一些binary的op做了一下处理\nvoid exec(BinaryOp op) &#123;#define PUSH(_opname, _op) \\   case BinaryOp::_opname: \\      push(v1 _op v2);     \\      break;    // LT GT, FILO    auto v2 = pop();    auto v1 = pop();    switch (op) &#123;        PUSH(Add, +)        PUSH(Sub, -)        PUSH(Mul, *)        PUSH(Div, /)        PUSH(Mod, %)        PUSH(EQ, ==)        PUSH(LT, &lt;)        PUSH(GT, &gt;)    &#125;#undef PUSH&#125;\n\n有一个需要注意的点是第一个pop出来的是表达式右侧的变量，因为栈是先进后出的。不仅比较操作需要注意，减法和除法也是如此\nRelativeJumpvoid visit(constRelativeJump &amp;inst)&#123;    _vm.relative_pc(inst.offset);&#125;\n\nJumpFalsevoid visit([[maybe_unused]] const JumpFalse &amp;inst)&#123;    auto cond = _eval_stack.pop();    if(cond == 0)    &#123;        _vm.relative_pc(inst.offset);    &#125;&#125;\n\n其他过于急切的去摸了一点oop的边，甚至连基本的分支跳转之类的都没有做，这么匆匆忙忙是否表示我已经不想做了呢…不管怎么说，这个坑决定开了，不想做也要做下去，做的烂总比什么都没做要强的多（最近几周的内容不论是数量还是质量都开始大幅下降了…\n开始不想接着写当前的了，vm那边我觉得虽然没写多少但已经开始有屎山的倾向了，应该花点时间重新考虑下代码结构以及测试。\n优化以及类型分析之类的我觉得还是换一门静态类型的语言来做。最近也在开始进行编译器重写的工作，好在实际上东西不是很多。重写过后就会从优化以及类型开始做一些工作，而下周开始可能会花更大比例的时间在重写上。尽管东西不多，但由于我对新语言对不熟悉，而且尽可能的改用好的设计，还是要花上一定的时间\n","categories":["Compiler","VM"],"tags":["Rc-lang"]},{"title":"Rc-lang开发周记9 OOP之继承","url":"/2022/02/20/rc-lang-dev/rc-lang-dev-9/","content":"本周的内容主要是做了一些继承相关的实现工作，把项目文件结构好好修了一波，还有就是加了一些测试。本周代码我觉得大多比较简单，很多地方就不过多赘述了。关于parser和ast在之前已经写好了，所以就直接进入代码生成和VM的部分\n类的符号信息对于之前的类表实现是只有方法和成员变量的，而现在在获取符号表信息遍历到class的时候需要再添加一个parent的信息。\nclass ClassTable\tattr_accessor :instance_methods, :instance_vars, :parentend\n\nVM方法查找FunInfo &amp;method_search(const RcObject *obj, const string &amp;f, bool super) &#123;    auto klass = super ? get_parent_class(obj) : obj-&gt;klass();    return method_search(klass, f);&#125;FunInfo &amp;method_search(const string &amp;klass, const string &amp;f) &#123;    auto &amp;class_table = global_class_table[klass];    if (class_table._methods.contains(f)) &#123;        return class_table._methods[f];    &#125;    if(class_table._parent.empty()) &#123;        throw MethodNotFoundException(f);    &#125;    else &#123;        return method_search(class_table._parent, f);    &#125;&#125;\n\n再来看一下之前的实现做一个对比\nFunInfo &amp;method_search(const RcObject * const obj, const std::string &amp;f)&#123;    auto klass = obj-&gt;klass();    if(!global_class_table.contains(klass) || !global_class_table[klass]._methods.contains(f))    &#123;        throw std::runtime_error(&quot;Target Function:&quot; + f + &quot; Not Found&quot;);    &#125;    return global_class_table[klass]._methods[f];&#125;\n\n很显然多了去父类查找的部分。\n调用父类同名函数既然要继承了，那么也一定要涉及到调用父类的同名函数的问题。在上面的method_search的实现中，可以看到从obj查找method的时候有一个叫super的参数。因此如果要调用super的话一定是从父类开始查找，而不是从当前类\n而这个在源代码中是通过一个super方法来实现的，大概是这个样子\ndef value  super()end\n\nAST定义class InvokeSuper  attr_reader :args  def initialize(args)    @args = args  end  def to_s    &quot;InvokeSuper#&#123;args_to_s(@args)&#125;&quot;  end\n\nVM指令定义class InvokeSuper &lt; Struct.new(:argc)  attr_type :argc =&gt; :int  def to_s    &quot;InvokeSuper #&#123;argc&#125;&quot;  endend\n\n注意AST中保存的是实参，而指令中已经提前push好了参数，这里只需要传递一个argc用于寻找参数之前push的this指针就可以了\nast翻译到vm指令的实现def on_invoke_super(node)  [PushThis.new] + push_args(node.args.map) + [InvokeSuper.new(node.args.size)]end\n\nvm指令的执行void visit(const InvokeSuper &amp;inst)&#123;    _vm.begin_call(_eval_stack.current_method(), inst.argc, true);&#125;void VM::begin_call(const string &amp;f, size_t argc, bool super) &#123;    auto *obj = _eval_stack.get_object(argc);    auto &amp;fun = method_search(obj, f, super);\t\t...&#125;\n\n这个也非常简单，比起之前的实现，现在begin_call里添加了一个super传递给method_search\n成员变量储存既然要继承，那么就要保存父类成员的变量。目前的做法是像ruby一样直接覆盖父类同名变量，因此在创建对象的时候获取整个类继承链中所有变量的集合，然后获取其长度，在创建变量的时候使用这个长度来分配对应的空间。\n这个长度应该是编译期间就算出来的，这里这样写有一种应付的感觉…虽然说这样能够处理动态修改父类定义的方法，但是现在并没有做的那么动态，很多设计还没有敲定\nstd::set&lt;std::string&gt; find_all_var(const string &amp;klass) &#123;    auto parents = global_class_table[klass]._parent;    auto &amp;vars = global_class_table[klass]._vars;    auto result = std::set(vars.begin(), vars.end());    if(parents.empty())    &#123;        return result;    &#125;    else    &#123;        result.merge(find_all_var(parents));        return result;    &#125;&#125;size_t class_vars_size(const string &amp;klass) &#123;    return find_all_var(klass).size();&#125;\n\n读写成员变量AST定义class GetClassMemberVar  attr_reader :name  def initialize(name)    @name = name  endend\n\nVM指令定义对应了读和写两条指令\nclass GetClassMemberVar &lt; Struct.new(:id)  attr_type :id =&gt; :int  def to_s    &quot;GetClassMemberVar #&#123;id&#125;&quot;  endendclass SetClassMemberVar &lt; Struct.new(:id)  attr_type :id =&gt; :int  def to_s    &quot;SetClassMemberVar #&#123;id&#125;&quot;  endend\n\nid是用于标识是这个对象field域中的对象编号\n我目前是通过固定一个变量在field中的位置来读写变量，这样其实没有任何灵活性可言，无法支持动态定义新的变量。想要更灵活那就得存一个hash用名字索引才行，ruby中是这样做的。我这里也没有太想好要怎么样做，只能先做着，可能做下去以后再看就会有来新的看法。\n写博客的时候意识到了存在一个很大的bug，就是我没有处理继承成员时的id…所以说关于id的方面就不要作为参考实现了，写下来只是作为一个出错记录。\n翻译过程常规的读会直接翻译成对应的vm指令，从class表中获取要读的这个对象的编号\ndef on_get_class_member_var(node)  GetClassMemberVar.new(get_class_var(node))enddef get_class_var(var_obj)  cur_class_table.instance_vars[var_obj.name]end\n\n对于成员变量的赋值，则是在assign中，如果被赋值的对象是一个AST::GetClassMemberVar的话，则会转换成一个SetClassMember指令\ndef on_assign(node)  value = visit(node.expr)  if value.is_a? Value or value.is_a? Ref    value = push(value)  end  if node.var_obj.is_a? Rc::AST::GetClassMemberVar    [value, SetClassMemberVar.new(get_class_var(node.var_obj))]  else    res = visit(node.var_obj)    [value, SetLocal.new(res.ref)]  endenddef push(node)  if node.is_a? Value    Push.new(node.value)  elsif node.is_a? Ref    GetLocal.new(node.ref)  elsif node.is_a? GetClassMemberVar    node  else    raise &quot;Unsupported node type #&#123;node.class&#125;&quot;  endend\n\n而push也略有不同，函数的参数都是遍历然后对每一个进行push。在成员变量作为参数传入函数的时候，visit的结果则是一个GetClassMemberVar指令，因此需要添加对应的支持。\nVM实现void visit(const SetClassMemberVar &amp;inst)&#123;    auto *obj = _eval_stack.this_ptr();    obj-&gt;set_value(inst.id, _eval_stack.pop());&#125;void visit(const GetClassMemberVar &amp;inst)&#123;    auto *obj = _eval_stack.this_ptr();    _eval_stack.push(obj-&gt;get_number_field(inst.id));&#125;\n\n关于set与get的实现\nvoid set_pointer(int index, RcObject *value) &#123;    fields[index] = value;&#125;void set_value(int index, int64_t value) &#123;    fields[index] = reinterpret_cast&lt;RcObject*&gt;(value);&#125;RcObject *get_ptr_field(int index) const &#123;    return fields[index];&#125;int64_t get_number_field(int index) const &#123;    return reinterpret_cast&lt;int64_t&gt;(fields[index]);&#125;\n\nfields是std::vector&lt;RcObject*&gt; fields 用于保存所有的成员\n由于stack中取出来的是值，那么我们直接将值转换为指针赋值给成员，如果成员确实是值，那么我们将成员转换为指针存储（这里是一个非常不安全的操作，也许应该添加检查）。取的时候再根据需要取出不同的值\n类型多态以及接口这些，现阶段是不需要做的。因为目前偏向于鸭子类型，只要你有同名方法就OK，不需要走什么接口。等到后面加上了各种类型相关的操作再考虑引入这些东西\n关于鸭子类型，wiki是这样写的\n\n鸭子类型（英语：duck typing）在程序设计中是动态类型的一种风格。在这种风格中，一个对象有效的语义，不是由继承自特定的类或实现特定的接口，而是由”当前方法和属性的集合”决定\n\n实现oop的时候许多地方已经开始和类型系统强相关了。现在许多语言中也可以兼顾动态类型，kotlin和C#都有类似于dynamic class的概念。现在先按照动态类型的实现来做，即便之后要全面切入到静态类型，这些依然可以作为动态类型的类的实现\n其他很多地方都不知道该如何设计，同时也有应付了事的成分…目前的开发流程算是一次试水吧，后面的时候我会尽量克制应付了事的冲动，不仅是在代码上，做其他的事情我也是容易有相同的问题。昨天钢琴课老师也说，一定要先着重练好手型再去弹，速度多慢都不要紧，这另一种方面也是一种需要克制住“对手型应付了事”的冲动，克制住去做后面更有意思的事情的冲动。克制这件事不仅牵扯到能否做好，如果不克制可能还会浪费更多的时间，这对于时间本就不充足的我是一个很大的影响，在克制这方面我还是要多下功夫。\n过一段时间可能会迁移到另一门语言上，那个时候可以从头梳理一遍目前所做过的决策，同时对好的进行保留，坏的进行剔除。前面的parser我觉得写的一塌糊涂，而且这几周的内容也能看出来很多地方开始乱搞了，都是没有决定好一个语言的方向，导致一个地方偏向这个样子，另一个地方又会偏向完全相反的样子。\n要着重注意的是，重构是好的，但不要过于依赖重构来保证代码的好设计。\n","categories":["Compiler","VM"],"tags":["Rc-lang"]},{"title":"Rc-lang开发周记11 重构与Lexer","url":"/2022/03/13/rc-lang-dev/rc-lang-dev-11/","content":"本周一开始重构了一下vm的部分代码，之后基本上都是在用新语言重写parser的部分。\n重构vm目前代码很少，做的重构主要是将一些东西抽象拆分出来\n这是之前vm的成员变量\nstd::shared_ptr&lt;VMInstVisitor&gt; _visitor;std::vector&lt;std::shared_ptr&lt;VMInst&gt;&gt; _inst_list;size_t _pc = 0;EvalStack _eval_stack;std::string _cur_fun;bool _can_stop = false;bool _pc_need_incr = true;\n\n成员函数\nvoid run();void pc_increase();void set_pc(size_t new_pc);void relative_pc(int offset);[[nodiscard]] size_t pc() const &#123; return _pc; &#125;EvalStack&amp; eval_stack()&#123;    return _eval_stack;&#125;void begin_call(const std::string&amp; f, size_t argc, bool super = false);void end_call();size_t load_method(const std::string&amp; klass, const std::string&amp; name, const FunInfo&amp; f);[[nodiscard]] bool can_stop() const &#123; return _can_stop; &#125;void set_can_stop() &#123; _can_stop = true; &#125;[[nodiscard]] bool pc_need_incr() const &#123; return _pc_need_incr; &#125;\n\npc首先就是关于pc的部分，零碎的放在了vm的实现中，我们单独将这些实现挑出来作为一个类来实现，因此就有了\nnamespace RCVM &#123;class PC &#123;public:    PC() = default;    void absolute_jump(size_t new_pc);    void relative_jump(int offset);    void increase();    size_t current() const;    operator size_t() const    &#123;        return current();    &#125;    void force_need_incr();private:    size_t _inst_addr = 0;    bool _need_increase = true;&#125;;&#125;\n\n代码段其次是代码段的内容。和代码段相关的虽然只有一个指令的vector和一个load method方法，但是为了组件之间减少耦合、方便测试还是要拆出来（虽然我还没有写更多的测试…）。最后结果是多了一个这样的类\nnamespace RCVM&#123;class CodeSegment&#123;public:    size_t load_method(const std::string &amp;klass, const std::string &amp;name,                       const FunInfo &amp;f);    std::vector&lt;std::shared_ptr&lt;VMInst&gt;&gt; inst_list() const;    size_t size() const;    std::shared_ptr&lt;VMInst&gt; get_inst(size_t i) const;    std::shared_ptr&lt;VMInst&gt; operator[] (int i) const;private:    std::vector&lt;std::shared_ptr&lt;VMInst&gt;&gt; _inst_list;&#125;;&#125;\n\n重构后的成员class VM&#123;\t\t...    void run();    [[nodiscard]] PC pc() const &#123; return _pc; &#125;    EvalStack &amp;eval_stack() &#123; return _eval_stack; &#125;    void begin_call(const std::string &amp;f, size_t argc, bool super = false);    void end_call();    [[nodiscard]] bool can_stop() const &#123; return _can_stop; &#125;    void set_can_stop() &#123; _can_stop = true; &#125;    [[nodiscard]] bool out_of_code_segment() const;private:    void init();    friend class VMInstVisitor;    std::shared_ptr&lt;VMInstVisitor&gt; _visitor;    CodeSegment _code_segment;    EvalStack _eval_stack;    std::string _cur_fun;    bool _can_stop = false;    PC _pc;&#125;;\n\n看上去清爽了许多。目前先改到这里了\n相关前置知识之后的内容开始设计lexer和parser。假设读者没有相关知识，我先来大概讲一下编译器从源码生成到ast的流程。\n\n对输入的源码进行分词，生成一系列Token，我们称之为词法分析\n分词是什么呢？说的直白一些就是把字符串划分开，哪一部分是名字，哪一部分又是空格，哪一部分是数字，诸如此类。Token就是表明了这个东西到底是哪种词，如果不明白可以看后面的代码部分。\n\n将Token根据特定的规则进行解析，生成抽象语法树，我们称之为语法分析\n\n\n这些过程的实现方式不外乎两类\n\n使用生成器进行生成：常见的是Lex（生成词法分析器） + YACC（生成语法分析器）。这些需要自己编写一下规则，喂给生成器进行生成\n自行手写实现：手写的灵活性灵活度是会比生成器要高的，但是相对比较复杂\n\n关于手写方式有一种叫parser combaintor的技术，能够通过组合不同的函数来实现解析，实现起来自然是比传统的手写方式方便，而我这里选择的也正是这种方案\nLexer虽说是parser，但是肯定还是要先做分词的。之前的实现中是没有做分词的，很多地方都搞的比较难受。一开始我还疑惑了一会使用parser combaintor是否还要做分词，但是写了一会意识到还是需要，虽然可以直接隐含了分词的部分，但是这样会把两类逻辑全部糊在一起，对于调试、测试都是非常难受的问题，而且对于空格、换行之类的也会非常麻烦。\nToken先来看一下Token的定义\nenum Token extends Positional:  case IDENTIFIER(str: String)  case NUMBER(int: Int)  case OPERATOR(op: String)  case STRING(str: String)    case EOL  case COMMA  case EQL  case SPACE  case TRUE  case FALSE  case VAR  case VAL  case DEF  case RETURN  case END  case IF  case THEN  case ELSIF  case ELSE  case WHILE  case CLASS  case SUPER  case LEFT_PARENT_THESES  case RIGHT_PARENT_THESES  case LEFT_SQUARE  case RIGHT_SQUARE\n\n通过extends Positional进而让Token都携带了位置信息（行号列号）\n这是一份不是很好的定义。写这个的时候来不及改了，下周会改正，但是在这里将这个不太好的范例拿出来讲。我一开始也觉得这样很奇怪，但是也没深入思考有没有什么更好的方式（再一次见到了自己的惰性），对于Token来说这样平着展开也不能说不对，但是可以做得更好\n后来看到Rust中Token的一些地方我才反应过来，还是应该将keyword和一些间隔符单独揪出来，而不是这么完全扁平化。写这篇的时候来不及改了，只能拖到下周再说了\n一些简单的实现def NoValueToken(str: String, token: Token): Parser[Token] = positioned &#123;    str ^^^ token  &#125;def eol = NoValueToken(&quot;\\n&quot;, EOL)def eql = NoValueToken(&quot;=&quot;, EQL)def comma = NoValueToken(&quot;,&quot;, COMMA)def trueLiteral = NoValueToken(&quot;true&quot;, TRUE)def falseLiteral = NoValueToken(&quot;false&quot;, FALSE)def varStr = NoValueToken(&quot;var&quot;, VAR)def valStr = NoValueToken(&quot;val&quot;, VAL)\n\n这个也非常简单，读取到对应的字符串直接返回对应的token。外面包了positioned以后内部的内容就能够携带行号和列号的信息\ndef ops = &quot;[+\\\\-*/%^~!&gt;&lt;]&quot;.rdef operator: Parser[Token] = positioned &#123;  ops ^^ OPERATOR&#125;\n\n这是一个通过正则表达式匹配的例子，这里的^数量由三个变成了两个，三个的情况下是左边的条件匹配成功则返回右边的值，而两个的情况下是条件匹配成功后执行右边的函数并且返回其值。\noperator这里是通过正则表达式来进行匹配，ops则是一个正则表达式\n这里可能有一些引起困惑的地方。为什么下面需要返回函数的时候填的是返回的类型？我没有正经学过Scala，用我在其他语言学过的东西来说这大概是因为虽然OPERATOR本身是类型，但在这里是一个值构造器，用另一种表达方式的话就是一个传入OPERATOR所需参数返回一个OPERATOR实例的函数\n这里我可能解释的不是很正确，如有哪里用词/描述不当还请联系我指出\n间隔符与非间隔符核心代码\ndef allTokens: Parser[List[Token]] = &#123;\t((rep1sepNoDis(repN(1,notSpacer),spacer.+) ~spacer.*) |\t\t// BAA is imposible\t\t(rep1sepNoDis(spacer.+, repN(1,notSpacer)) ~notSpacer.?)) ^^ &#123;    case list ~ t =&gt;      list        .fold(List())(_:::_)        .concat(t match &#123;          case Some(v) =&gt; List(v)          case None =&gt; List()          case _ =&gt; t        &#125;)        .filter(_ != SPACE)  &#125;&#125;\n\n^^前都是解析的部分，解析部分的～是连接的意思，也就是说前面的解析完会接着解析后面的内容。后面处理的部分只是将每个解析部分生成的输出都连接起来，成为一个List[Token]。由于觉得用不到因此我在这里干掉了SPACE\n其中出现过的一些函数的定义\ndef space: Parser[Token] = positioned &#123;  whiteSpace.+ ^^^ SPACE&#125;def notSpacer: Parser[Token] = keyword | value | eoldef spacer: Parser[Token] = symbol | operator | eql | spacedef keyword: Parser[Token] = stringLiteral | trueLiteral | falseLiteral |    defStr | endStr | ifStr | thenStr | elsifStr | elseStr | whileStr |    classStr | superStr | varStr | valStrdef symbol: Parser[Token] = comma | eol | leftParentTheses | rightParentTheses | leftSquare | rightSquaredef value: Parser[Token] = number | identifier\n\n这里对我来说是一个比较难写的点，上周在写的时候头痛了好一阵子，想明白逻辑以后再回来看会好很多\n整体逻辑这里的逻辑是这样的：我们先定义不能作为间隔符的为A（notSpacer），可以作为间隔符的为B（spacer），那么我们需要的是A(B+A)*B*，或者是B+(AB+)*A?\n注：这里的*+?都是正则表达式的语义\n拆分逻辑关于为什么要这么设定，我们先从B开始。\n\n可以看到B包含了一些运算符，空格，一些标点符号，这些本身是和任何字符相连都是无歧义的（目前来说B中的内容是无歧义的），那么它们连续存在依然不会产生歧义。B本身是要存在的，因此这里可以推导出B+\n\n而A中的内容，比如说两个keyword之间一定要有空格，不然会被识别成一个identifier了，比如说传递参数的时候需要逗号分开（symbol），那么A是不可能连续存在的，因此这里可以推导出A\n\n由于我们需要A和B间隔放置，我首先想到的是rep1sep(A, B+)，而由于A和B都可能在第一个，因此有了rep1sep(A, B+) | rep1sep(B+, A)。（repsep举个例子，repsep(str, ‘,’)，对应的就是str, str, str这种以，分割的）但是repsep会扔掉B，因此我从rep1sep抄了一份修改了一下，变成了不扔掉B的版本\n以下rep1sepNoDis都用rep1sep代替\n\n\ndef rep1sepNoDis[T](p : =&gt; Parser[T], q : =&gt; Parser[Any]): Parser[List[T]] =    p ~ rep(q ~ p) ^^ &#123;case x~y =&gt; x::y.map(x =&gt; List(x._1.asInstanceOf[T], x._2)).fold(List())(_:::_)&#125;\n\n原版\ndef rep1sep[T](p : =&gt; Parser[T], q : =&gt; Parser[Any]): Parser[List[T]] =    p ~ rep(q ~&gt; p) ^^ &#123;case x~y =&gt; x::y&#125;\n\n\n但是只是repsep的做法无法处理AB（会残留一个B未解析），那么很自然的就会想到再后面接一个可选的B，因此就有了rep1sep(A, B+) ~ B?，同理无法处理BA，也就有了 rep1sep(B+, A) ~ A? 组合起来就有了 rep1sep(A, B+) ~ B? | rep1sep(B+, A) ~ A? \n\n事后回顾思路还算是捋的比较清晰，一直这样写或许也会有利于我之后写代码的时候逻辑梳理的能力。不过当时写的时候真的是整个人都不好了…这块写代码的时候想了半天，写博客尽管逻辑很流畅了但是还是写了很久\n逻辑与实现的一些出入拆分完逻辑后将\nrep1sep = rep1sepNoDis\nA = notSpacer\nB = spacer\n代入后，会发现有一些不一样的地方。我在rep1sep的A中做了repN(1, A)的操作。至于为什么这么写，是为了保证A和B哪一个在前哪一个在后都可以使用。一个值和一个List交换顺序还能连接的实现不知道有什么可用的，自己尝试写了一个\ndef link[T](l: List[T], v: T): List[T] = l:::v::Nildef link[T](v: T, l: List[T]): List[T] = v::ldef link[T](l1: List[T], l2: List[T]): List[T] = l1:::l2\n\n但是和前面的函数组合起来，在处理的时候一些看起来很自然的东西并没有通过类型检查，对于Scala的类型理解不到位也难以解决问题，因此就只好先这个样子。虽然用起了Scala，但是并没有学太多，凭着其他语言的经验直接就来写\n具体实例这么说过于抽象，我们通过看测试来实际理解以下例子。\n之所以要搞得这么复杂，是因为最后一个测试用例的那种情况。对于我之前lexer和parser混在一起写的做法处理这样的情况是非常难的。不过我不敢说已经想全面了，有问题再改吧\ndescribe(&quot;spacer&quot;) &#123;  // a is notSpacer, b is spacer\tit(&quot;AB&quot;) &#123;    expectSuccess(&quot;id&quot;, List(IDENTIFIER(&quot;id&quot;)))  &#125;\t  it(&quot;ABA&quot;) &#123;    expectSuccess(&quot;id id&quot;, List(IDENTIFIER(&quot;id&quot;), IDENTIFIER(&quot;id&quot;)))  &#125;  it(&quot;BAB&quot;) &#123;    expectSuccess(&quot; id &quot;, List(IDENTIFIER(&quot;id&quot;)))  &#125;  it(&quot;ABABB space and eol&quot;) &#123;    expectSuccess(&quot;def f \\n&quot;, List(DEF, IDENTIFIER(&quot;f&quot;), EOL))  &#125;  it(&quot;BABA&quot;) &#123;    expectSuccess(&quot; def f&quot;, List(DEF, IDENTIFIER(&quot;f&quot;)))  &#125;  it(&quot;only space&quot;) &#123;    expectSuccess(&quot; &quot;, List())  &#125;  it(&quot;local&quot;) &#123;    val v = List(IDENTIFIER(&quot;a&quot;), EQL, NUMBER(1))    expectSuccess(&quot;a = 1&quot;, v)    expectSuccess(&quot;a = 1 &quot;, v)    expectSuccess(&quot;a =1&quot;, v)    expectSuccess(&quot;a=1&quot;, v)  &#125;&#125;\n\n最后本来是想写一些parser的内容的，但是没想到这个token间隔符相关的逻辑就花了我这么久的时间。这块我觉得写的还是相对比较清晰，也算是比较满意，所以本周就先这么结束了。关于token一般来说不会有什么特别的内容了，所以关于解析输入，之后基本上就是parser的内容了。\n这个周我觉得进度比较慢，不会调加上前几天整个人都过于不稳定，回家会花一些时间在刷刷刷上，进而减少了编码的时间，不知道什么时候能做完重写啊…\n","categories":["Compiler"],"tags":["Rc-lang","Lexer","ParserCombaintor"]},{"title":"Rc-lang开发周记12 部分Parser","url":"/2022/03/20/rc-lang-dev/rc-lang-dev-12/","content":"\npixiv:95518122 \n\n本周内容主要就是parser，而ast的内容会穿插其中\nParser的一些问题换行由于是由换行来分句，我觉得一个头疼的点在于要想清楚哪里要换行，想清楚这个parser都是由什么组成，然后拼接在一起。但是写到这里的时候我才想到如果表达式有多行（这个也是非常常见的情况）就支持不了了…以后再做支持吧，这个或许可以对于表达式单独添加换行的支持。\n我目前的换行策略是统一由stmt以及item吃掉eol，其中的子parser是不会处理eol的。stmt是很自然的，一行是一个stmt，item的话目前则是由函数或者class组成，而函数和class也不需要管理换行统一由item管理\n左递归这个问题留到下次再讲（因为我还没写）\n关于设计在重写的时候发现很多原来的设计并不好，但是又一时不知该如何设计。后面觉得还是先实现一种，先功能完备再来考虑美化语法\n关于具体的设计还是要看parser和ast的实现\nexprastenum Expr extends Positional:  case Number(v: Int)  case Identifier(id: Id)  case Bool(b: Boolean)  case Binary(op: String, lhs: Expr, rhs: Expr)  case Str(str: String)  // false -&gt; elsif | else  case If(cond: Expr, true_branch: Block, false_branch: Option[Expr])  case Lambda(args: List[Expr], stmts: List[Expr])  case Call(target: Id, args: List[Expr])  case MethodCall(obj: Expr, target: Id, args: List[Expr])  case Block(stmts: List[Stmt])  case Return(expr: ast.Expr)  case Field(expr: Expr, id: Id)\n\n关于Expr, Stmt, Block之间不知道以什么样的形式比较好，就暂且学习了Rust的做法。自己不知道怎么做那去学习一些比较好的语言，这样的想法我觉得应该是没问题的。之前做的时候也是经常会参考Ruby的实现\n关于Expr我就不一个个放parser了，大部分比较简单没有什么可讲的内容。着重讲几个关键的点。代码中出现log的部分可以忽略\nifast的变化首先ast的定义相比于之前发生了变化\n这是之前if的ast定义\nclass If\t# stmt_list: [[if_cond, stmt], [elsif_cond, stmt]*]\tattr_reader :stmt_list, :else_stmtsend\n\n参考了rust中的if而现在转换成了这个样子\nIf(cond: Expr, true_branch: Block, false_branch: Option[Expr])\n\nfalse_branch可以是一个普通的else，也可以是接的另一个if，也就是将elsif这一语法糖还原为原始的if了，而elsif的if里又是同样的定义\n同时之前的if是一个stmt，而现在的if是expr。返回的是对应分支block的返回值。block是由多个stmt组成，其返回值则是最后一条stmt\nparserdef block: Parser[Block] = positioned &#123;  rep(statement) ^^ (stmts =&gt; Block(stmts))&#125;def multiLineIf: Parser[If] = positioned &#123;  oneline(IF ~&gt; expr) ~ block ~ elsif.* ~ (oneline(ELSE) ~&gt; block).? &lt;~ END ^^ &#123;    case cond ~ if_branch ~ elsif ~ else_branch    =&gt; If(cond, if_branch, elsif.foldRight(else_branch.asInstanceOf[Option[Expr]])(      (next, acc) =&gt; Some(If(next.cond, next.true_branch, acc))))  &#125;&#125;def elsif: Parser[If] = positioned &#123;  oneline(ELSIF ~&gt; termExpr) ~ block ^^ &#123;    case cond ~ branch =&gt; If(cond, branch, None)  &#125;&#125;\n\n可以看到elsif在这里被编译为了if，多个elsif则是被编译为了一个List[If]，在这里通过FoldRight的方式折叠为一个if。以else为初始值，不断的将List最右边的元素设置为下一个if的else\n逻辑展开是这样的\nA B C, ELSE: Option[Expr]A B Some(IF(C.cond, C.true_branch, ELSE))A Some(IF(B.cond, B.true_branch, Some(IF(C.cond, C.true_branch, ELSE)))Some(IF(A.cond, A.true_branch, Some(IF(B.cond, B.true_branch, Some(IF(C.cond, C.true_branch, ELSE))))\n\n代码中出现的asInstanceOf是因为我不知道这里的类型是怎样处理的，索性通过这种方式来回避编译错误。\ntermExprtermExpr只是为了parser的时候区分各种expr的一种方式，所以ast表示上是和常规的expr是一样的。可以看到term是一些可以用于各种操作符的东西，比如说1 + 1，1是一个term，整个是一个termExpr。后面我们需要将这一系列的term和operator组合成一个expr，因此需要有后面的termToBinary\ndef termExpr: Parser[Expr] = positioned &#123;  term ~ (operator ~ term).* ^^ &#123;    case term ~ terms =&gt; termsToBinary(term, terms.map(a =&gt; List(a._1, a._2)))  &#125;&#125;def expr: Parser[Expr] = positioned &#123;  multiLineIf | termExpr | ret&#125;def term: Parser[Expr] = positioned &#123;  bool | num | string | call | memField | memCall | idExpr&#125;\n\n关于termsToBinary的实现\ntrait BinaryTranslator &#123;  val opDefaultInfix = HashMap(&quot;+&quot;-&gt;10, &quot;-&quot;-&gt;10, &quot;*&quot;-&gt;10, &quot;/&quot;-&gt;10, &quot;&gt;&quot;-&gt;5, &quot;&lt;&quot;-&gt;5)  def findMaxInfixIndex(terms: List[Positional]): Int =    terms      .zipWithIndex      .filter((x, _) =&gt; x.isInstanceOf[OPERATOR])      .map((x, index) =&gt; (x.asInstanceOf[OPERATOR], index))      .minBy((op, index) =&gt; opDefaultInfix(op.op))._2  def replaceBinaryOp(terms: List[Positional], index: Int): List[Positional] = &#123;    var t = terms(index)    val left = terms.slice(0, index - 1)    val bn = Expr.Binary(      terms(index).asInstanceOf[OPERATOR].op,      terms(index - 1).asInstanceOf[Expr],      terms(index + 1).asInstanceOf[Expr])    val rights = terms.slice(index + 2, terms.size)    left.appended(bn):::(rights)  &#125;  def termsToBinary(term: Expr, terms: List[List[Positional]]): Expr = &#123;    if terms.isEmpty then return term    termsToBinary(term :: terms.flatten)  &#125;  def termsToBinary(terms: List[Positional]): Expr = &#123;    var newTerms = terms    while (newTerms.size &gt; 1) &#123;      val max_index = findMaxInfixIndex(newTerms)      newTerms = replaceBinaryOp(newTerms, max_index)    &#125;    newTerms.head.asInstanceOf[Expr.Binary]  &#125;&#125;\n\n实现逻辑：\n\n如果只有开头的一个term则返回该term\n否则将开头的和后面的terms组合起来进行处理\n\n找到最高优先级的op的位置\n\n将该位置以及左右的term组合为一个expr并且替换\n\n重复这个过程直至剩下一个term\n\n\n这里我觉得实现的有点脏…基本上是把我用ruby写的那一套抄过来了，我一时也没想到什么好的方案\n由于要对替换以后的expr再进行组合，这个过程中index会发生变动；如果要将组合后的拿出来，那还要处理哪些是拿出来的哪些是没有拿出来的，这样获取前后的term也会很不方便\nStmtastenum Stmt extends Positional:  case Local(name: Id, ty: Type, value: ast.Expr)  case Expr(expr: ast.Expr)  case While(cond: ast.Expr, stmts: Block)  case Assign(name: Id, value: ast.Expr)  case None\n\n这里的while和rust的不太一样，rust的while也是一个expr，尽管能够从理性上认识到这样做是为了返回最后一个block的结果，但我仍然觉得这个做法好奇怪。目前还是先将其作为stmt，以后发现了哪里不合适再进行修正\nparser这边也比较简单。内容不多就直接贴出来了\ndef local: Parser[Stmt] = positioned &#123;  (VAR ~&gt; id) ~ (EQL ~&gt; termExpr) ^^ &#123;    case id ~ expr =&gt; Stmt.Local(id, Type.Nil, expr)  &#125;&#125;def ret: Parser[Return] = positioned &#123;  RETURN ~&gt; termExpr ^^ Return&#125;def assign: Parser[Stmt.Assign] = positioned &#123;  (id &lt;~ EQL) ~ termExpr ^^ &#123;    case id ~ expr =&gt; Stmt.Assign(id, expr)  &#125;&#125;def whileStmt: Parser[Stmt.While] = positioned &#123;  oneline(WHILE ~&gt; parSround(termExpr)) ~ block &lt;~ END ^^ &#123;    case cond ~ body =&gt; Stmt.While(cond, body)  &#125;&#125;\n\n最后如果读者能够读到这里（虽然并不会有几个人，其中大概也不会有追更的），那很大概率不嫌弃我的内容，在这里可能要提前和各位说一声对不起，下周很有可能将是我第二次断更。（其实本周也有好几天都没写了…）\n下周工作之外的事情除了最低限度的练琴，我会尽可能的不去做什么事情。眼睛疼（写的现在也在疼），精神极其不稳定（经常不受控制的胡思乱想），这些都是原因。\n我也不想停，重写的进程还是比较慢，我的开发效率又偏低同时又要各种测试确保正确性。我好想赶快把这些基础的迁移完，然后去学习做优化，学习加上类型系统，等等，还想要多学习一些Scala，除此之外有很多创意想要实现还想去学swiftUI\n但是或许此刻再不停就真的要断线了，我需要花时间好好冷静一下，平复情绪，进行休整。我无法努力获得温暖，那就只有努力去平复情绪。面对至今为止最重要也最大的挑战（当前的不良状态），我也应该拿出应有的态度\n","categories":["Compiler"],"tags":["Rc-lang","ParserCombaintor","Parser"]},{"title":"Rc-lang开发周记15 Rust源码学习之desugar","url":"/2022/04/17/rc-lang-dev/rc-lang-dev-15/","content":"\npixiv:68232005 \n\n这周可以说几乎没写什么代码，都在学习别人的实现。在参考别人的做法之前自己写一版比较合适，这样会对整体有个了解（这样有利于阅读代码），知道哪些地方会有问题，看别人的代码后会发现哪里不一样并且去思考差异。不过我之前已经写过简易的实现了，因此直接来参考Rust的实现了\n本周看的内容一半是desugar，另一半是关于MIR的。讲解的话目前先讲一下desugar的内容，内容相对较少能够一篇讲完。MIR的东西非常多，笔记也没有整理好，之后会单独开启一个源码阅读系列的坑\n在讲之前首先要提的是为什么要学习他人的实现。尽管写出来能跑是没有问题的，但是参考这样的项目的过程中能学到他人写代码的方式，学到更多不一样的实现方式\ndesugar是什么我们现在在使用的编程语言中有一些语法糖，这些语法糖本质上是对一些功能的包装，让我们用的更方便，但是没有做到一些什么没有这个语法糖所做不到的东西。\n这里举一个很直观的例子，ruby中有一个关键字是unless，它的功能是如果false则执行第一个分支，否则执行第二个分支，相当于if !cond\n为什么需要上面也提到了只是包装，那么可能多种不同形式的语法糖都是针对同一种功能，像C语言中的while和for本质都是一个loop（Rust的for并不是，后面会提到这种for的desugar过程）\ndesugar的过程是将这些都转换为了更本质的东西，我觉得这属于一种“去重”的过程。还是上面的例子，假设需要对loop做优化，没有desugar的情况下我们需要对while和for两者都进行处理，两者又有轻微的差别，导致实现起来更不方便，每个优化都需要对这些细节做处理，那不如直接全部转换成一种形式来处理处理\n关于Rust的文档中的介绍是这样\n\nThis means many structures are removed if they are irrelevant for type analysis or similar syntax agnostic analyses.\n\nRust的实现官方的文档介绍\nhttps://rustc-dev-guide.rust-lang.org/lowering.html\n在这里我要给Rust一个好评，开发文档比较详细，而且一些注释也相对容易懂一些。后面的很多东西都会以注释为参考讲了大概做了什么，注意这里我们的目的并不是搞清楚细节，而是搞清楚都做了什么操作，所以细节部分点到为止，细节深究下去是无底洞，有兴趣可以去源码处深入看一下\ndesugar相关代码不特别说明根目录都是rustc_ast_lowering\n读代码之前需要了解的了解了这些能够更容易看明白代码\n\n各种参数更多是使用ir来标识以及获取的\nspan用于记录源码相关信息\narean.alloc是用于分配构建ir的，看实现的时候不需要在意这里的细节，只需要看传进去的IR\n\nDesugaringKind这个类型在rustc_span/src/hygine.rs中\n实际使用的时候主要用于创建span的时候填入相关信息，因此并没有放到ast_lowering的位置\npub enum DesugaringKind &#123;    /// We desugar `if c &#123; i &#125; else &#123; e &#125;` to `match $ExprKind::Use(c) &#123; true =&gt; i, _ =&gt; e &#125;`.    /// However, we do not want to blame `c` for unreachability but rather say that `i`    /// is unreachable. This desugaring kind allows us to avoid blaming `c`.    /// This also applies to `while` loops.    CondTemporary,    QuestionMark,    TryBlock,    /// Desugaring of an `impl Trait` in return type position    /// to an `type Foo = impl Trait;` and replacing the    /// `impl Trait` with `Foo`.    OpaqueTy,    Async,    Await,    ForLoop,    LetElse,    WhileLoop,&#125;\n\n先不考虑Async和Await，我们来一个个说其他的\nCondTemporary这部分都在src/expr.rs中\n我们先来看一下它的调用位置，发现是在manage_let_cond这个函数中\n// If `cond` kind is `let`, returns `let`. Otherwise, wraps and returns `cond`// in a temporary block.fn manage_let_cond(&amp;mut self, cond: &amp;&#x27;hir hir::Expr&lt;&#x27;hir&gt;) -&gt; &amp;&#x27;hir hir::Expr&lt;&#x27;hir&gt; &#123;    fn has_let_expr&lt;&#x27;hir&gt;(expr: &amp;&#x27;hir hir::Expr&lt;&#x27;hir&gt;) -&gt; bool &#123;        match expr.kind &#123;            hir::ExprKind::Binary(_, lhs, rhs) =&gt; has_let_expr(lhs) || has_let_expr(rhs),            hir::ExprKind::Let(..) =&gt; true,            _ =&gt; false,        &#125;    &#125;    if has_let_expr(cond) &#123;        cond    &#125; else &#123;        let reason = DesugaringKind::CondTemporary;        let span_block = self.mark_span_with_reason(reason, cond.span, None);        self.expr_drop_temps(span_block, cond, AttrVec::new())    &#125;&#125;\n\n转换条件根据函数名和参数我们可以得知这个是处理cond不为let的情况下，既然是cond那么应当会出现在while和if中\n实现实际查看manage_let_cond的usage也正是如此。这两处的处理都是类似的，因此我选取一段来介绍\nlet lowered_cond = self.lower_expr(cond);let new_cond = self.manage_let_cond(lowered_cond);\n\n可以看到十分简单，就是先对cond本身lower，然后再对整个cond lower\n然后我们再回到manage_let_cond的实现中\n根据实现可以看到对expr递归判断，如果包含let则直接返回原始cond，否则进行转换\nspan_block是用于记录信息的，关键在expr_drop_temps中\n本质行为进入实现可以看到\n/// Wrap the given `expr` in a terminating scope using `hir::ExprKind::DropTemps`.////// In terms of drop order, it has the same effect as wrapping `expr` in/// `&#123; let _t = $expr; _t &#125;` but should provide better compile-time performance.////// The drop order can be important in e.g. `if expr &#123; .. &#125;`.pub(super) fn expr_drop_temps(    &amp;mut self,    span: Span,    expr: &amp;&#x27;hir hir::Expr&lt;&#x27;hir&gt;,    attrs: AttrVec,) -&gt; &amp;&#x27;hir hir::Expr&lt;&#x27;hir&gt; &#123;    self.arena.alloc(self.expr_drop_temps_mut(span, expr, attrs))&#125;pub(super) fn expr_drop_temps_mut(    &amp;mut self,    span: Span,    expr: &amp;&#x27;hir hir::Expr&lt;&#x27;hir&gt;,    attrs: AttrVec,) -&gt; hir::Expr&lt;&#x27;hir&gt; &#123;    self.expr(span, hir::ExprKind::DropTemps(expr), attrs)&#125;\n\n实际做的事情就是转换为了DropTemps这种类型的Expr\nQuestionMark是什么QuestionMark是Result为Err或者Option为None的时候直接抛出错误的一种语法糖，摘选一段官方的例子\n#![allow(unused_variables)]fn main() &#123;use std::num::ParseIntError;fn try_to_parse() -&gt; Result&lt;i32, ParseIntError&gt; &#123;    let x: i32 = &quot;123&quot;.parse()?; // x = 123    let y: i32 = &quot;24a&quot;.parse()?; // returns an Err() immediately    Ok(x + y)                    // Doesn&#x27;t run.&#125;let res = try_to_parse();println!(&quot;&#123;:?&#125;&quot;, res);assert!(res.is_err())&#125;\n\n查看QuestionMark的usage，找到了lower_expr_try这个函数\n做了什么先来看注释，这里的注释可以说是非常清楚了，将一个QuestionMark转换为了一个模式匹配\n/// Desugar `ExprKind::Try` from: `&lt;expr&gt;?` into:/// ```rust/// match Try::branch(&lt;expr&gt;) &#123;///     ControlFlow::Continue(val) =&gt; #[allow(unreachable_code)] val,,///     ControlFlow::Break(residual) =&gt;///         #[allow(unreachable_code)]///         // If there is an enclosing `try &#123;...&#125;`:///         break &#x27;catch_target Try::from_residual(residual),///         // Otherwise:///         return Try::from_residual(residual),/// &#125;/// ```\n\n实现函数签名\nfn lower_expr_try(&amp;mut self, span: Span, sub_expr: &amp;Expr) -&gt; hir::ExprKind&lt;&#x27;hir&gt;\n\n既然是返回了一个match，那么我们先看一下Expr::Match的结构\n/// A `match` block, with a source that indicates whether or not it is/// the result of a desugaring, and if so, which kind.Match(&amp;&#x27;hir Expr&lt;&#x27;hir&gt;, &amp;&#x27;hir [Arm&lt;&#x27;hir&gt;], MatchSource)\n\n根据注释的内容看上去分为三个部分\n\nTry::branch()\n\n非常直接的操作，直接lower传进来的sub_expr\n// `Try::branch(&lt;expr&gt;)`let scrutinee = &#123;    // expand &lt;expr&gt;    let sub_expr = self.lower_expr_mut(sub_expr);    self.expr_call_lang_item_fn(        unstable_span,        hir::LangItem::TryTraitBranch,        arena_vec![self; sub_expr],        None,    )&#125;;\n\n\nControlFlow::Continue(val)\n\n// `ControlFlow::Break(residual) =&gt;//     #[allow(unreachable_code)]//     return Try::from_residual(residual),`let break_arm = &#123;\t\t... // 省略    let break_pat = self.pat_cf_break(try_span, residual_local);    self.arm(break_pat, ret_expr)&#125;;\n\n这里的arm是构建了hir的Match的Arm参数\n\nControlFlow::Break(residual)\n\n// `ControlFlow::Break(residual) =&gt;//     #[allow(unreachable_code)]//     return Try::from_residual(residual),`let break_arm = &#123;\t\t... // 省略    let break_pat = self.pat_cf_break(try_span, residual_local);    self.arm(break_pat, ret_expr)&#125;;\n\n和上面差不多，细节都在省略的部分\n在实际的处理中在最前面的有一部分像上面的CondTemporary一样，先创建一个span用于记录源码相关的信息，源码不再赘述\n还会创建一个*#[allow(unreachable_code)]* 供后面的match使用\nlet attr = &#123;    // `allow(unreachable_code)`    let allow = &#123;        let allow_ident = Ident::new(sym::allow, self.lower_span(span));        let uc_ident = Ident::new(sym::unreachable_code, self.lower_span(span));        let uc_nested = attr::mk_nested_word_item(uc_ident);        attr::mk_list_item(allow_ident, vec![uc_nested])    &#125;;    attr::mk_attr_outer(allow)&#125;;let attrs = vec![attr];\n\nTryBlock在lower_expr_try_block中被用到\n做了什么这里的注释解释的比较清楚了，我就不再赘述\n/// Desugar `try &#123; &lt;stmts&gt;; &lt;expr&gt; &#125;` into `&#123; &lt;stmts&gt;; ::std::ops::Try::from_output(&lt;expr&gt;) &#125;`,/// `try &#123; &lt;stmts&gt;; &#125;` into `&#123; &lt;stmts&gt;; ::std::ops::Try::from_output(()) &#125;`/// and save the block id to use it as a break target for desugaring of the `?` operator.\n\n最终都是转换为一个包含stmts和::std::ops::Try::from_output的block\n实现我们从返回值往上看，可以看到返回了一个Block，Block的第二个参数是Label，这里并不需要因此设置为了None\n那么我们顺着第一个参数block往上看来源，又回到了函数的开始\n和注释所讲的一样，根据是否有一个expr来做两种不同的处理方式，也是比较直观的实现\nfn lower_expr_try_block(&amp;mut self, body: &amp;Block) -&gt; hir::ExprKind&lt;&#x27;hir&gt; &#123;    self.with_catch_scope(body.id, |this| &#123;        let mut block = this.lower_block_noalloc(body, true);        // Final expression of the block (if present) or `()` with span at the end of block        let (try_span, tail_expr) = if let Some(expr) = block.expr.take() &#123;            (                this.mark_span_with_reason(                    DesugaringKind::TryBlock,                    expr.span,                    this.allow_try_trait.clone(),                ),                expr,            )        &#125; else &#123;            let try_span = this.mark_span_with_reason(                DesugaringKind::TryBlock,                this.sess.source_map().end_point(body.span),                this.allow_try_trait.clone(),            );            (try_span, this.expr_unit(try_span))        &#125;;        let ok_wrapped_span =            this.mark_span_with_reason(DesugaringKind::TryBlock, tail_expr.span, None);        // `::std::ops::Try::from_output($tail_expr)`        block.expr = Some(this.wrap_in_try_constructor(            hir::LangItem::TryTraitFromOutput,            try_span,            tail_expr,            ok_wrapped_span,        ));        hir::ExprKind::Block(this.arena.alloc(block), None)    &#125;)&#125;\n\nOpaqueTyOpaqueTy是什么OpaqueTy是impl Trait的一种别名，看一下这个例子\ntype Foo = impl Bar;\n\n实际参数使用Foo的时候只能使用Bar中的接口，不论实现了Bar的类型是否实现了其他类型\nlower做了什么关于这个lower的操作，在DesugaringKind::OpaqueTy的位置写的非常清楚了，只是做了简单的类型替换\n/// Desugaring of an `impl Trait` in return type position/// to an `type Foo = impl Trait;` and replacing the/// `impl Trait` with `Foo`.\n\nlower操作lower操作在lower_opaque_impl_trait这个函数中(src/lib.rs)\nfn lower_opaque_impl_trait(        &amp;mut self,        span: Span,        fn_def_id: Option&lt;LocalDefId&gt;,        origin: hir::OpaqueTyOrigin,        opaque_ty_node_id: NodeId,        capturable_lifetimes: Option&lt;&amp;FxHashSet&lt;hir::LifetimeName&gt;&gt;,        lower_bounds: impl FnOnce(&amp;mut Self) -&gt; hir::GenericBounds&lt;&#x27;hir&gt;,    ) -&gt; hir::TyKind&lt;&#x27;hir&gt; \n\n来看一下返回值的部分，可以看到主要处理分为两部分，一部分是处理ID相关的，另一部分是处理lifetime\n// `impl Trait` now just becomes `Foo&lt;&#x27;a, &#x27;b, ..&gt;`.    hir::TyKind::OpaqueDef(hir::ItemId &#123; def_id: opaque_ty_def_id &#125;, lifetimes)&#125;\n\n这里也就不展开了，上面的细节很多是关于type相关的，这部分我不了解，内容也比较长。\nlower_opaque_impl_trait这个函数则是被在上面的lower_ty_direct()调用\n...TyKind::ImplTrait(def_node_id, ref bounds) =&gt; &#123;  let span = t.span;  match itctx &#123;      ImplTraitContext::ReturnPositionOpaqueTy &#123; fn_def_id, origin &#125; =&gt; self          .lower_opaque_impl_trait(              span,              Some(fn_def_id),              origin,              def_node_id,              None,              |this| this.lower_param_bounds(bounds, itctx),          ),      ImplTraitContext::TypeAliasesOpaqueTy &#123; ref capturable_lifetimes &#125; =&gt; &#123;          // Reset capturable lifetimes, any nested impl trait          // types will inherit lifetimes from this opaque type,          // so don&#x27;t need to capture them again.          let nested_itctx = ImplTraitContext::TypeAliasesOpaqueTy &#123;              capturable_lifetimes: &amp;mut FxHashSet::default(),          &#125;;          self.lower_opaque_impl_trait(              span,              None,              hir::OpaqueTyOrigin::TyAlias,              def_node_id,              Some(capturable_lifetimes),              |this| this.lower_param_bounds(bounds, nested_itctx),          )      &#125;...\n\n可以看到这里的TypeKind为ImplTrait且ImplTraitContext为TypeAliasesOpaqueTy或者ReturnPositionOpaqueTy的时候才会做这个desugar操作\n\n 这里我其实不是很明白。。\n\nImpltraitContext来看一下ImpltraitContext，根据Disallowed注释大意和成员可以得知这个类主要关联了一个位置是否可以使用impl trait\n/// Context of `impl Trait` in code, which determines whether it is allowed in an HIR subtree,/// and if so, what meaning it has.#[derive(Debug)]enum ImplTraitContext&lt;&#x27;b, &#x27;a&gt; &#123;    /// Treat `impl Trait` as shorthand for a new universal generic parameter.    /// Example: `fn foo(x: impl Debug)`, where `impl Debug` is conceptually    /// equivalent to a fresh universal parameter like `fn foo&lt;T: Debug&gt;(x: T)`.    ///    /// Newly generated parameters should be inserted into the given `Vec`.    Universal(&amp;&#x27;b mut Vec&lt;hir::GenericParam&lt;&#x27;a&gt;&gt;, LocalDefId),    /// Treat `impl Trait` as shorthand for a new opaque type.    /// Example: `fn foo() -&gt; impl Debug`, where `impl Debug` is conceptually    /// equivalent to a new opaque type like `type T = impl Debug; fn foo() -&gt; T`.    ///    ReturnPositionOpaqueTy &#123;        /// `DefId` for the parent function, used to look up necessary        /// information later.        fn_def_id: LocalDefId,        /// Origin: Either OpaqueTyOrigin::FnReturn or OpaqueTyOrigin::AsyncFn,        origin: hir::OpaqueTyOrigin,    &#125;,    /// Impl trait in type aliases.    TypeAliasesOpaqueTy &#123;        /// Set of lifetimes that this opaque type can capture, if it uses        /// them. This includes lifetimes bound since we entered this context.        /// For example:        ///        /// ```        /// type A&lt;&#x27;b&gt; = impl for&lt;&#x27;a&gt; Trait&lt;&#x27;a, Out = impl Sized + &#x27;a&gt;;        /// ```        ///        /// Here the inner opaque type captures `&#x27;a` because it uses it. It doesn&#x27;t        /// need to capture `&#x27;b` because it already inherits the lifetime        /// parameter from `A`.        // FIXME(impl_trait): but `required_region_bounds` will ICE later        // anyway.        capturable_lifetimes: &amp;&#x27;b mut FxHashSet&lt;hir::LifetimeName&gt;,    &#125;,    /// `impl Trait` is not accepted in this position.    Disallowed(ImplTraitPosition),&#125;\n\n而在上面只有ReturnPositionOpaqueTy和TypeAliasesOpaqueTy的情况下可以使用，当然从名字就可以看出来这两种情况就是为了OpaqueTy而设计的\nForLoop调用处的函数签名\nfn lower_expr_for(        &amp;mut self,        e: &amp;Expr,        pat: &amp;Pat,        head: &amp;Expr,        body: &amp;Block,        opt_label: Option&lt;Label&gt;,    ) -&gt; hir::Expr&lt;&#x27;hir&gt; &#123;\n\n注释写的非常详细了，将一个ForLoop转换为一个iterator操作\n/// Desugar `ExprForLoop` from: `[opt_ident]: for &lt;pat&gt; in &lt;head&gt; &lt;body&gt;` into:/// ```rust/// &#123;///     let result = match IntoIterator::into_iter(&lt;head&gt;) &#123;///         mut iter =&gt; &#123;///             [opt_ident]: loop &#123;///                 match Iterator::next(&amp;mut iter) &#123;///                     None =&gt; break,///                     Some(&lt;pat&gt;) =&gt; &lt;body&gt;,///                 &#125;;///             &#125;///         &#125;///     &#125;;///     result/// &#125;/// ```\n\n实现比较长就不贴了，想要了解更详细的可以去源码处查看\nLetElse什么情况会转换在lower_let_else中被调用，而这个lower_let_else则是在lower_stmts中\n这是lower_stmts中的处理代码，可以看到是InitElse的情况下会进行处理\nlet mut expr = None;        while let [s, tail @ ..] = ast_stmts &#123;            match s.kind &#123;                StmtKind::Local(ref local) =&gt; &#123;                    let hir_id = self.lower_node_id(s.id);                    match &amp;local.kind &#123;                        LocalKind::InitElse(init, els) =&gt; &#123;                            let e = self.lower_let_else(hir_id, local, init, els, tail);                            expr = Some(e);\t\t\t\t\t\t\t\t\t\t\t\t\t\t// remaining statements are in let-else expression                            break;\n\n注意这里的break\n来看一下InitElse\npub enum LocalKind &#123;\t...\t/// Local declaration with an initializer and an `else` clause.\t/// Example: `let Some(x) = y else &#123; return &#125;;`\tInitElse(P&lt;Expr&gt;, P&lt;Block&gt;),&#125;\n\n实现函数签名\nfn lower_let_else(        &amp;mut self,        stmt_hir_id: hir::HirId,        local: &amp;Local,        init: &amp;Expr,        els: &amp;Block,        tail: &amp;[Stmt],    ) -&gt; &amp;&#x27;hir hir::Expr&lt;&#x27;hir&gt; &#123;\n\n一开始看到函数签名中的tail产生了一些疑惑，不知道用途是什么。一开始想到的是会往里添加东西，但是一看类型是immutable的（传进来的是一个array的slice），后面看到调用处的break才明白过来，具体用途后面会讲到\nfn lower_let_else(        &amp;mut self,        stmt_hir_id: hir::HirId,        local: &amp;Local,        init: &amp;Expr,        els: &amp;Block,        tail: &amp;[Stmt],    ) -&gt; &amp;&#x27;hir hir::Expr&lt;&#x27;hir&gt; &#123;\tlet ty = local\t      .ty\t      .as_ref()\t      .map(|t| self.lower_ty(t, ImplTraitContext::Disallowed(ImplTraitPosition::Variable)));  let span = self.lower_span(local.span);  let span = self.mark_span_with_reason(DesugaringKind::LetElse, span, None);  let init = self.lower_expr(init);  let local_hir_id = self.lower_node_id(local.id);  self.lower_attrs(local_hir_id, &amp;local.attrs);  let let_expr = &#123;      let lex = self.arena.alloc(hir::Let &#123;          hir_id: local_hir_id,          pat: self.lower_pat(&amp;local.pat),          ty,          init,          span,      &#125;);      self.arena.alloc(self.expr(span, hir::ExprKind::Let(lex), AttrVec::new()))  &#125;;  let then_expr = &#123;      let (stmts, expr) = self.lower_stmts(tail);      let block = self.block_all(span, stmts, expr);      self.arena.alloc(self.expr_block(block, AttrVec::new()))  &#125;;  let else_expr = &#123;      let block = self.lower_block(els, false);      self.arena.alloc(self.expr_block(block, AttrVec::new()))  &#125;;  self.alias_attrs(let_expr.hir_id, local_hir_id);  self.alias_attrs(else_expr.hir_id, local_hir_id);  let if_expr = self.arena.alloc(hir::Expr &#123;      hir_id: stmt_hir_id,      span,      kind: hir::ExprKind::If(let_expr, then_expr, Some(else_expr)),  &#125;);  if !self.sess.features_untracked().let_else &#123;      feature_err(          &amp;self.sess.parse_sess,          sym::let_else,          local.span,          &quot;`let...else` statements are unstable&quot;,      )      .emit();  &#125;  if_expr&#125;\n\n我们从返回值向上看，可以看到if_expr的参数是let_expr, then_expr, else_expr\n\nlet_expr的部分转成了HIR的let\n\nlet let_expr = &#123;    let lex = self.arena.alloc(hir::Let &#123;        hir_id: local_hir_id,        pat: self.lower_pat(&amp;local.pat),        ty,        init,        span,    &#125;);    self.arena.alloc(self.expr(span, hir::ExprKind::Let(lex), AttrVec::new()))&#125;;\n\n我们来看一下定义和注释\n/// Represents a `let &lt;pat&gt;[: &lt;ty&gt;] = &lt;expr&gt;` expression (not a Local), occurring in an `if-let` or/// `let-else`, evaluating to a boolean. Typically the pattern is refutable.////// In an if-let, imagine it as `if (let &lt;pat&gt; = &lt;expr&gt;) &#123; ... &#125;`; in a let-else, it is part of the/// desugaring to if-let. Only let-else supports the type annotation at present.#[derive(Debug, HashStable_Generic)]pub struct Let&lt;&#x27;hir&gt; &#123;    pub hir_id: HirId,    pub span: Span,    pub pat: &amp;&#x27;hir Pat&lt;&#x27;hir&gt;,    pub ty: Option&lt;&amp;&#x27;hir Ty&lt;&#x27;hir&gt;&gt;,    pub init: &amp;&#x27;hir Expr&lt;&#x27;hir&gt;,&#125;pub enum ExprKind&lt;&#x27;hir&gt; &#123;\t...\t/// A `let $pat = $expr` expression.  ///  /// These are not `Local` and only occur as expressions.  /// The `let Some(x) = foo()` in `if let Some(x) = foo()` is an example of `Let(..)`.  Let(&amp;&#x27;hir Let&lt;&#x27;hir&gt;),\t...&#125;\n\n\nthen_expr\n\nlet then_expr = &#123;    let (stmts, expr) = self.lower_stmts(tail);    let block = self.block_all(span, stmts, expr);    self.arena.alloc(self.expr_block(block, AttrVec::new()))&#125;;\n\n这里解答了我对传进来的tail的疑惑。这里的意思是then的话那么会继续lower tail的部分，将这部分插入到then的block中\n\nelse_expr\n\nlet else_expr = &#123;    let block = self.lower_block(els, false);    self.arena.alloc(self.expr_block(block, AttrVec::new()))&#125;;\n\n这里将传进来的els（InitElse的else block）lower到了一个block\n实际做了什么转换单个看起来可能不够直观，将三个部分组合起来的话这个逻辑就是\ncond中创建了一个expr bind\ntrue：将后面的stmts lower到一个新的block中（因此外面需要break）\nfalse：将els的部分lower到block\nfalse为什么不lower tail像我一样不了解这里语法的情况会觉得false的行为很奇怪，false就不走tail了吗\n于是我就写了这样的一个用例\n#![feature(let_else)]fn main() &#123;    let y:Option&lt;i32&gt; = None;    let Some(x) = y else &#123;         println!(&quot;fail&quot;) &#125;;    println!(&quot;test&quot;);&#125;\n\n直接报了编译错误，else中的内容是要强制从当前函数返回才行\nerror[E0308]: `else` clause of `let...else` does not diverge --&gt; src/main.rs:4:26  |4 |       let Some(x) = y else &#123;   |  __________________________^5 | |         println!(&quot;fail&quot;) &#125;;  | |__________________________^ expected `!`, found `()`  |  = note: expected type `!`             found type `()`  = help: try adding a diverging expression, such as `return` or `panic!(..)`  = help: ...or use `match` instead of `let...else`For more information about this error, try `rustc --explain E0308`.error: could not compile `playground` due to previous error\n\nWhileLoop在lower_expr_mut中被调用，在外部创建span信息然后在lower_expr_while_in_loop_scope中实际进行lower\n...ExprKind::While(ref cond, ref body, opt_label) =&gt; &#123;      self.with_loop_scope(e.id, |this| &#123;          let span =              this.mark_span_with_reason(DesugaringKind::WhileLoop, e.span, None);          this.lower_expr_while_in_loop_scope(span, cond, body, opt_label)      &#125;)  &#125;...\n\n做了什么注释也非常易懂，将一个while转换为一个loop加一个，cond作为一个if，cond为false则break\n// We desugar: `&#x27;label: while $cond $body` into://// ```// &#x27;label: loop &#123;//   if &#123; let _t = $cond; _t &#125; &#123;//     $body//   &#125;//   else &#123;//     break;//   &#125;// &#125;// ```//// Wrap in a construct equivalent to `&#123; let _t = $cond; _t &#125;`// to preserve drop semantics since `while $cond &#123; ... &#125;` does not// let temporaries live outside of `cond`.\n\n实现实际的实现代码也是非常直接，没什么可讲的\nfn lower_expr_while_in_loop_scope(    &amp;mut self,    span: Span,    cond: &amp;Expr,    body: &amp;Block,    opt_label: Option&lt;Label&gt;,) -&gt; hir::ExprKind&lt;&#x27;hir&gt; &#123;    let lowered_cond = self.with_loop_condition_scope(|t| t.lower_expr(cond));    let new_cond = self.manage_let_cond(lowered_cond);    let then = self.lower_block_expr(body);    let expr_break = self.expr_break(span, ThinVec::new());    let stmt_break = self.stmt_expr(span, expr_break);    let else_blk = self.block_all(span, arena_vec![self; stmt_break], None);    let else_expr = self.arena.alloc(self.expr_block(else_blk, ThinVec::new()));    let if_kind = hir::ExprKind::If(new_cond, self.arena.alloc(then), Some(else_expr));    let if_expr = self.expr(span, if_kind, ThinVec::new());    let block = self.block_expr(self.arena.alloc(if_expr));    let span = self.lower_span(span.with_hi(cond.span.hi()));    let opt_label = self.lower_label(opt_label);    hir::ExprKind::Loop(block, opt_label, hir::LoopSource::While, span)&#125;\n\n最后本来以为desugar的东西比较少就想都写完，但是越写发现越多，这还忽略了很多细节上的东西，导致了文章比较长\n在读代码的时候一开始我是没看到DesugaringKind这个类型的，想着既然要lower，那么首先将ast和hir的定义进行比较。由于内容比较多，只选了熟悉的Expr和Stmt进行对比。查看实际有哪些成员发生了变化，之后再去找到实现的位置。查看实现的过程中偶然看到DesugaringKind，之后看的过程就顺畅了许多\n","categories":["Compiler","源码阅读"],"tags":["Rc-lang","Rust","Desugar"]},{"title":"Rc-lang开发周记13 另一些Parser","url":"/2022/04/04/rc-lang-dev/rc-lang-dev-13/","content":"\npixiv:40165995 \n\n本周的内容主要就是添加剩下的一些parser，主要是和类相关的，同时还添加了数组的下标索引。内容稍微少一些，我觉得也没有太多值得讲的，基本上就是确定语法 + 直接写实现。代码写的也不多，花了不少时间在另一篇博客上，同时还要添加测试。到此为止原先的parser支持的差不多了。还增加了类型以及下标索引的内容，同时还有了更合理的测试。今天收下尾差不多可以开始写其他的内容了\n本周出现的所有语法首先我们要确定要写出什么样的语法。语法大致先这样，不知道怎么样的语法才是优雅的，先都做出来再说\nclass F &lt; Parent // 继承，类型名必须首字母大写  v1: Fun // 成员变量  v2: Int = 1 // 成员变量默认值  def update() // 成员函数\t\t@v2 = @v2 + 1 // @获取成员变量  endenddef f()\tvar v = F.new() // Class.new()的形式构建变量。new本质是object基类的方法\tv.update() // 调用成员函数  var arr = Array.new(2)\tarr[0] = 1 // 常规的取数组下标end\n\n类定义其实我有点中意下面这种写法，将vars和methods都限制在一起，但是后面如果类中可以添加新的东西那会麻烦一些，所以这个想法暂时保留\nclass Fvars:  v1: Fun  v2: Int = 1methods:  def f1()  endend\n\n实现def classDefine: Parser[Item.Class] = positioned &#123;  oneline(CLASS ~&gt; sym ~ (OPERATOR(&quot;&lt;&quot;) ~&gt; sym).?) ~ log(item | field | noneItem)(&quot;class member&quot;).* &lt;~ log(END)(&quot;class end&quot;) ^^ &#123;    case klass ~ parent ~ defines =&gt;      Item.Class(klass, parent,        defines.filter(_.isInstanceOf[Field]).map(_.asInstanceOf[Field]),        defines.filter(_.isInstanceOf[Item.Method]).map(_.asInstanceOf[Item.Method]))  &#125;&#125;def noneItem: Parser[Item] = positioned &#123;  EOL ^^^ Item.None&#125;def field: Parser[Field] = positioned &#123;  oneline(VAR ~&gt; (id &lt;~ COLON) ~ sym ~ (EQL ~&gt; expr).?) ^^ &#123;    case id ~ ty ~ value =&gt; Field(id, Type.Spec(ty), value)  &#125;&#125;def item: Parser[Item] = positioned &#123;  oneline(method | classDefine)&#125;\n\nExpr新增加的ast成员。其中Constant是大写字母开头的名字\ncase MethodCall(obj: Expr, target: Id, args: List[Expr])case Field(expr: Expr, id: Id)case Selfcase Constant(id: Id)case Index(expr: Expr, i: Expr)\n\nMethodCall调用成员函数\ndef memCall: Parser[Expr.MethodCall] = positioned &#123;  (termExpr &lt;~ DOT) ~ id ~ parSround(repsep(termExpr, COMMA)) ^^ &#123;    case obj ~ id ~ args =&gt; Expr.MethodCall(obj, id, args)  &#125;&#125;\n\nFielddef memField: Parser[Expr.Field] = positioned &#123;  (termExpr &lt;~ DOT) ~ id ^^ &#123;    case obj ~ name =&gt; Expr.Field(obj, name)  &#125;&#125;def selfField: Parser[Expr.Field] = positioned &#123;  (AT ~&gt; id) ^^ (id =&gt; Expr.Field(Expr.Self, id))&#125;\n\nIndexdef arrayIndex: Parser[Expr.Index] = positioned &#123;  termExpr ~ squareSround(termExpr) ^^ &#123;    case expr ~ index =&gt; Expr.Index(expr, index)  &#125;&#125;protected def squareSround[T](p: Parser[T]) = LEFT_SQUARE ~&gt; p &lt;~ RIGHT_SQUARE\n\n左递归lazy val beginWithTerm: PackratParser[Expr] = positioned &#123;  memCall | memField | arrayIndex&#125;def term: Parser[Expr] = positioned &#123;  bool | num | string | selfField | call | beginWithTerm | sym ^^ Expr.Constant | idExpr&#125;def termExpr: Parser[Expr] = positioned &#123;  term ~ (operator ~ term).* ^^ &#123;    case term ~ terms =&gt; termsToBinary(term, terms.map(a =&gt; List(a._1, a._2)))  &#125;&#125;\n\n添加了如上几个语法后，语法已经变成了左递归的形式。遇到这种问题一般来说是转成非左递归的语法，因为左递归的情况很容易堆栈溢出，而Scala的parser combaintor提供了记忆化的能力，简单来说就是能够缓存遍历过的情况，第二次递归到某个情况，如果这个情况已经被遍历过那么直接从缓存中取出即可，而不需要再次递归搜索\n想要使用这个功能需要两个步骤\n\nparser继承自PackratParsers。之前我的parser都是继承自Parsers，而更换成PackratParsers是兼容的，直接修改继承类名即可\n显式指定需要这个功能的parser返回PackratParser\n函数必须改成lazy val\n\n可以看到上面的beginWithTerm已经修改为了这种形式\n","categories":["Compiler"],"tags":["Rc-lang","ParserCombaintor","Parser"]},{"title":"Rc-lang开发周记17 一点AST检查","url":"/2022/05/01/rc-lang-dev/rc-lang-dev-17/","content":"\n聪明如我怎么会写出ast有错误的代码 pixiv:69589494 \n\n先说一声五一快乐！久违的长假，之后会花一些时间把其他一些写到一半的博客整理出来\n本来想要好好做一下检查相关以及类型推导的工作，但是目前来说我更需要先学习优化方面的知识，因此关于ast的检查以及类型推导和类型检查做的比较简易，过后有时间再回来做。本周虽然做了部分类型推导和类型检查，但是只做了一半，剩下的部分可能要下周再说了。下周大概就能做完简单的类型推导和检查\nAST检查目前所实现的检查无外乎这么几类\n\n名称冲突\n未定义符号\n变量的声明类型或者初始值必须有一个存在\n\n我挑出一些经典的部分讲解，不过多赘述重复的部分了\n实际上能做的类型无关的检查还有非常多\n名称冲突def dupNameCheck(names: List[Ident]): Result = &#123;  dupCheck(names, &quot;Name&quot;)&#125;def dupCheck[T &lt;: ASTNode](values: List[T], valueName: String): Result = &#123;  val s = Set[T]()  values.filterNot(s.add).map(n =&gt; ValidateError(n, s&quot;$valueName $n Dup&quot;))&#125;def checkModule(module: RcModule): Result = &#123;  dupNameCheck(module.items.map(item =&gt; item match    case Item.Class(name, _, _, _) =&gt; name    case Item.Method(decl, _) =&gt; decl.name  )):::module.items.flatMap(checkItem)&#125;\n\n比如说Module的检查中对所有item的名字检查是否存在冲突，并且再check每个Item本身\n关于返回值的Result只是一个type alias\ntype Result = List[ValidateError]case class ValidateError(node: ASTNode, reason: String)\n\n这里还有很多待改进的空间，比如说将实际的错误分类，或者写一个diagnosis类来管理这些错误信息等等\n这里使用一个type alias也是为了后面修改时候方便\n这里可以看到所有的错误信息都是组合之后返回，原因是我想将代码中的副作用范围缩到最小，这样能够保证调用的结果尽可能的不受外部状态影响\n未定义的符号目前只做了一些简单的处理。这里还没有处理全局的符号（比如说函数和类）\ncase class Scope(var localTable: Set[Ident] = Set()) &#123;  def add(ident: Ident): Boolean = &#123;    localTable.add(ident)  &#125;  def contains(ident: Ident): Boolean = &#123;    localTable.contains(ident)  &#125;&#125;case class ScopeManager() &#123;  private var scopes = List[Scope]()  def enter[T](f:() =&gt; T): T = &#123;    enter(Params(List()), f)  &#125;  def enter[T](params: Params, f:() =&gt; T): T = &#123;    val oldScope = scopes    scopes ::= Scope(mutable.Set.from(params.params.map(_.name)))    val result = f()    scopes = oldScope    result  &#125;  def curScope: Scope = scopes.last  def add(ident: Ident): Boolean = curScope.add(ident)  def contains(ident: Ident): Boolean = &#123;    !scopes.exists(_.contains(ident))  &#125;  def curContains(ident: Ident): Boolean = curScope.contains(ident)&#125;\n\n每个Scope有自己的table，每次通过enter进入一个table则将当前的放到List中\ndef checkBlock(block: Block, params: Params = Params(List())): Result = &#123;  scopes.enter(params, () =&gt; &#123;    block.stmts.flatMap(checkStmt)  &#125;)&#125;def checkMethod(method: Method): Result = &#123;  checkMethodDecl(method.decl)  checkBlock(method.body, method.decl.inputs)&#125;\n\n在每次进入一个Block的时候则进入了一个新的scope，比如说一个Method的body的expr\n对于Id表达式则会去检查是否存在这个符号，\ncase Expr.Identifier(id) =&gt; checkCond(scopes.contains(id), expr, &quot;$name not decl&quot;)\n\n初始值与类型二选一def fieldDefValid(fieldDef: FieldDef): Result = &#123;  fieldDef.initValue match &#123;    case Some(expr) =&gt; checkExpr(expr)    case None =&gt; checkCond(fieldDef.ty != TyInfo.Infer, fieldDef, &quot;Field without initValue need spec Type&quot;)  &#125;&#125;\n\n对于类的field做了这样的检查，存在initValue则去检查expr，否则检查ty是否为需要Infer的。如果没有initValue也没有ty信息，那我们无法在后面类型推导的时候得出类型\n","categories":["Compiler"],"tags":["Rc-lang","AST"]},{"title":"Rc-lang开发周记16 Rust源码学习之初识类型","url":"/2022/04/26/rc-lang-dev/rc-lang-dev-16/","content":"\n类型和猫咪先生有多少相似之处呢 pixiv:74795024 \n\n本周先了解了一些Rust Type相关的代码，之后开始写一些类型无关的语法检查。\n虽然上周看了Rust中desugar的代码，但我这里就先不做desugar了，现在东西比较少，没什么价值。由于语法检查还没写多少，xs因此留到下周讲解。本周还是讲一下我看Rust Type相关的信息的一些了解，其中大部分信息是文档中介绍的，在这里算是一个简单概括。\nhttps://rustc-dev-guide.rust-lang.org/ty.html\n不同的类型表示在Rust中，目前我看到的部分有这么“几种”类型\n\nast::Ty\nhir::Ty(rustc_hir::Ty)\nty::Ty\n\n关于ast::Ty到hir::Ty本质上是进行了desugar，所代表的Ty本质是没有变化的。至于为什么这么说，这就要谈及hir::Ty和ty::Ty的区别\nhir::Ty vs ty::Ty先来讲我认为最根本的区别。\nhir::Ty所表示的是在源码中出现的一个应当出现在需要类型位置的类型，换句话说它是关联到源码的Ty\n而ty::Ty则是编译器中对中间表示（这里是hir）分析过后产生的一种类型，包含了更切实的语义，换句话说是关联到编译器内部类型表示的Ty\n我来引用一下官方文档中出现的例子\nfn foo(x: u32) → u32 &#123; x &#125;\n\n在这段代码中出现了两个u32，很显然这段代码的上下文中这两个u32都是同一个类型（注意不同lifetime的type是不同类型的）\n每个u32本质上是关联到源码中某个位置的u32，比如说第一个关联的是源码第一行第10个字符开始的u32，而第二个则是关联到源码后面那个位置的u32。在没有type infer和type check之前我们并不知道是否关联相同的语义\n而对于最终的type infer以及type check之后在这个语义环境下这两个u32会被视为同一个类型，最终这两个u32会被转换为相同的ty::Ty\n文档中有这样一句\n\nthey have two different [Spans](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_span/struct.Span.html) (locations).\n\n之后我们来看一下官方文档中的总结表格，一切描述都是围绕着同一个核心区别\n\n\n\nrustc_hir::Ty\nty::Ty\n\n\n\nDescribe the syntax of a type: what the user wrote (with some desugaring).\nDescribe the semantics of a type: the meaning of what the user wrote.\n\n\nEach rustc_hir::Ty has its own spans corresponding to the appropriate place in the program.\nDoesn’t correspond to a single place in the user’s program.\n\n\nrustc_hir::Ty has generics and lifetimes; however, some of those lifetimes are special markers like LifetimeName::Implicit.\nty::Ty has the full type, including generics and lifetimes, even if the user left them out\n\n\nfn foo(x: u32) → u32 { } - Two rustc_hir::Ty representing each usage of u32. Each has its own Spans, etc.- rustc_hir::Ty doesn’t tell us that both are the same type\nfn foo(x: u32) → u32 { } - One ty::Ty for all instances of u32throughout the program.- ty::Ty tells us that both usages of u32 mean the same type.\n\n\nfn foo(x: &amp;u32) -&gt; &amp;u32)- Two rustc_hir::Ty again.- Lifetimes for the references show up in the rustc_hir::Tys using a special marker, LifetimeName::Implicit.\nfn foo(x: &amp;u32) -&gt; &amp;u32)- A single ty::Ty.- The ty::Ty has the hidden lifetime param\n\n\n要注意一个我刚才没有详细提及的点，那就是lifetime。由于经常会省略编写lifetime因此对于hir来说很可能不会包含其信息，这样的信息都是会转成hir之后再隐式插入的\n类型之间转换流程根据文档所说，在ast转换为HIR的时候会做一些基本的type infer以及type check。在type infer的过程中会产生ty::Ty并实际进行检查\n发生转换的入口则是在ast_ty_to_ty这里，而这个函数则是在AstConv这个trait中\n先来简单看一下十分直观的函数签名，传入一个hir::Ty返回一个ty::Ty\n/// Parses the programmer&#x27;s textual representation of a type into our/// internal notion of a type.pub fn ast_ty_to_ty(&amp;self, ast_ty: &amp;hir::Ty&lt;&#x27;_&gt;) -&gt; Ty&lt;&#x27;tcx&gt; &#123;    self.ast_ty_to_ty_inner(ast_ty, false, false)&#125;\n\nast_ty_to_ty_inner做了什么这个函数依然属于AstConv\nfn ast_ty_to_ty_inner(&amp;self, ast_ty: &amp;hir::Ty&lt;&#x27;_&gt;, borrowed: bool, in_path: bool) -&gt; Ty&lt;&#x27;tcx&gt; &#123;  let tcx = self.tcx();  let result_ty = match ast_ty.kind &#123; ... &#125;\tdebug!(?result_ty);  self.record_ty(ast_ty.hir_id, result_ty, ast_ty.span);  result_ty&#125;\n\n先忽略转换的细节，看一下整体做了什么\n\n获取TyCtxt\n实际转换\n记录类型\n\ntcx和recordself.tcx和self.record都是AstConv本身未实现的方法\n再来看一下一个实现了AstConv的部分实现（以下涉及AstConv未实现的部分都会以FnCtxt的实现作为参考）\nimpl&lt;&#x27;a, &#x27;tcx&gt; AstConv&lt;&#x27;tcx&gt; for FnCtxt&lt;&#x27;a, &#x27;tcx&gt; &#123;  fn tcx&lt;&#x27;b&gt;(&amp;&#x27;b self) -&gt; TyCtxt&lt;&#x27;tcx&gt; &#123;    self.tcx  &#125;\tfn record_ty(&amp;self, hir_id: hir::HirId, ty: Ty&lt;&#x27;tcx&gt;, _span: Span) &#123;    self.write_ty(hir_id, ty)  &#125;&#125;impl FnCtxt &#123;\t#[inline]\tpub fn write_ty(&amp;self, id: hir::HirId, ty: Ty&lt;&#x27;tcx&gt;) &#123;    debug!(&quot;write_ty(&#123;:?&#125;, &#123;:?&#125;) in fcx &#123;&#125;&quot;, id, self.resolve_vars_if_possible(ty), self.tag());    self.typeck_results.borrow_mut().node_types_mut().insert(id, ty);    if ty.references_error() &#123;        self.has_errors.set(true);        self.set_tainted_by_errors();    &#125;  &#125;&#125;\n\ntcx没什么可说的，大多数都是这样简单的返回\nrecord_ty中将一个hir的id与它的Ty进行关联，而这个hir的id则是hir::Ty的id。如果只看FnCtxt的record_ty的本身很容易以为一定是其他有类型的东西（比如expr或者Fn）的id关联到一个类型，但是往上看调用处没想到还会将一个hir::Ty指向ty::Ty\nast_ty to ty内容比较多，这里选择几个讲一下\n先来看一下里面是什么样子的\nlet result_ty = match ast_ty.kind &#123;    hir::TyKind::Slice(ref ty) =&gt; tcx.mk_slice(self.ast_ty_to_ty(ty)),    hir::TyKind::Ptr(ref mt) =&gt; ...&#125;\n\n根据ast_ty的不同kind做不同处理（下面只选取某一个kind的处理方式讲解）\ninfer先来看一下infer\nhir::TyKind::Infer =&gt; &#123;    // Infer also appears as the type of arguments or return    // values in an ExprKind::Closure, or as    // the type of local variables. Both of these cases are    // handled specially and will not descend into this routine.    self.ty_infer(None, ast_ty.span)&#125;// impl AstConv for FnCtxtfn ty_infer(&amp;self, param: Option&lt;&amp;ty::GenericParamDef&gt;, span: Span) -&gt; Ty&lt;&#x27;tcx&gt; &#123;    if let Some(param) = param &#123;        if let GenericArgKind::Type(ty) = self.var_for_def(span, param).unpack() &#123;            return ty;        &#125;        unreachable!()    &#125; else &#123;        self.next_ty_var(TypeVariableOrigin &#123;            kind: TypeVariableOriginKind::TypeInference,            span,        &#125;)    &#125;&#125;// Impl inferCtxtpub fn next_ty_var(&amp;self, origin: TypeVariableOrigin) -&gt; Ty&lt;&#x27;tcx&gt; &#123;    self.tcx.mk_ty_var(self.next_ty_var_id(origin))&#125;#[inline]pub fn mk_ty_var(self, v: TyVid) -&gt; Ty&lt;&#x27;tcx&gt; &#123;    self.mk_ty_infer(TyVar(v))&#125;#[inline]pub fn mk_ty_infer(self, it: InferTy) -&gt; Ty&lt;&#x27;tcx&gt; &#123;    self.mk_ty(Infer(it))&#125;pub fn mk_ty(self, st: TyKind&lt;&#x27;tcx&gt;) -&gt; Ty&lt;&#x27;tcx&gt; &#123;    self.interners.intern_ty(st, self.sess, &amp;self.gcx.untracked_resolutions)&#125;\n\n套娃比较多，不过内容也比较直观。关于intern_ty下一部分再仔细讲一下，先来看一下其他的例子\n注意一点，这里infer产生的代码是unchecked的，上面也提到过\n\n在type infer的过程中会产生ty::Ty并实际进行检查\n\n一些其他的hir::TyKind::Tup(fields) =&gt; tcx.mk_tup(fields.iter().map(|t| self.ast_ty_to_ty(t))),hir::TyKind::Slice(ref ty) =&gt; tcx.mk_slice(self.ast_ty_to_ty(ty)),hir::TyKind::Ptr(ref mt) =&gt; &#123;    tcx.mk_ptr(ty::TypeAndMut &#123; ty: self.ast_ty_to_ty(mt.ty), mutbl: mt.mutbl &#125;)&#125;pub fn mk_tup&lt;I: InternAs&lt;[Ty&lt;&#x27;tcx&gt;], Ty&lt;&#x27;tcx&gt;&gt;&gt;(self, iter: I) -&gt; I::Output &#123;    iter.intern_with(|ts| self.mk_ty(Tuple(self.intern_type_list(&amp;ts))))&#125;pub fn mk_slice(self, ty: Ty&lt;&#x27;tcx&gt;) -&gt; Ty&lt;&#x27;tcx&gt; &#123;    self.mk_ty(Slice(ty))&#125;pub fn mk_ptr(self, tm: TypeAndMut&lt;&#x27;tcx&gt;) -&gt; Ty&lt;&#x27;tcx&gt; &#123;    self.mk_ty(RawPtr(tm))&#125;\n\n看起来都比较直观，而每一个mk_xxx本质上都是直接或者间接调用了mk_ty，再进入intern_ty做处理\nInternTy实现代码\n/// Interns a type.#[allow(rustc::usage_of_ty_tykind)]#[inline(never)]fn intern_ty(    &amp;self,    kind: TyKind&lt;&#x27;tcx&gt;,    sess: &amp;Session,    resolutions: &amp;ty::ResolverOutputs,) -&gt; Ty&lt;&#x27;tcx&gt; &#123;  Ty(Interned::new_unchecked(    self.type_      .intern(kind, |kind| &#123;        let flags = super::flags::FlagComputation::for_kind(&amp;kind);        // It&#x27;s impossible to hash inference regions (and will ICE), so we don&#x27;t need to try to cache them.        // Without incremental, we rarely stable-hash types, so let&#x27;s not do it proactively.        let stable_hash = if flags.flags.intersects(TypeFlags::HAS_RE_INFER)            || sess.opts.incremental.is_none()        &#123;            Fingerprint::ZERO        &#125; else &#123;            let mut hasher = StableHasher::new();            let mut hcx = StableHashingContext::ignore_spans(                sess,                &amp;resolutions.definitions,                &amp;*resolutions.cstore,            );            kind.hash_stable(&amp;mut hcx, &amp;mut hasher);            hasher.finish()        &#125;;        let ty_struct = TyS &#123;            kind,            flags: flags.flags,            outer_exclusive_binder: flags.outer_exclusive_binder,            stable_hash,        &#125;;        InternedInSet(self.arena.alloc(ty_struct))      &#125;)      .0,  ))&#125;\n\n这里看起来大多是关于存储的细节，我也没有再过于深究了，但是要注意Ty的结构\n/// Use this rather than `TyS`, whenever possible.#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]#[rustc_diagnostic_item = &quot;Ty&quot;]#[rustc_pass_by_value]pub struct Ty&lt;&#x27;tcx&gt;(Interned&lt;&#x27;tcx, TyS&lt;&#x27;tcx&gt;&gt;);\n\n注意Ty这里保存了一个Interned，这个函数名本身也是intern_ty，那么这是代表了什么呢\n我们看一下Interned的注释\n\nA reference to a value that is interned, and is known to be unique.Note that it is possible to have a T and a Interned that are (or refer to) equal but different values. But if you have two different Interneds, they both refer to the same value, at a single location in memory. This means that equality and hashing can be done on the value’s address rather than the value’s contents, which can improve performance.The PrivateZst field means you can pattern match with Interned(v, _) but you can only construct a Interned with new_unchecked, and not directly.\n\nInterned本质是指向实际unique的值的一个引用。\n代码中可以看到将一个TyS传给了InternedInSet，而构建TyS的时候传入了一个stable_hash。关于这个stable_hash有着这样的注释\n\nThe stable hash of the type. This way hashing of types will not have to work on the address of the type anymore, but can instead just read this field\n\n在上面提及hir::Ty和ty::Ty的时候说过相同的类型最后会转换为同一个ty::Ty，我想应该就是通过这些行为做到的。\n要深入下去还有太多细节，而这些细节大多不是我目前关心的，所以就不深入了\n","categories":["Compiler","源码阅读"],"tags":["Rc-lang","Rust","Type"]},{"title":"Rc-lang开发周记14 重构与AST Visitor","url":"/2022/04/10/rc-lang-dev/rc-lang-dev-14/","content":"\n非pixiv作品 \n\n本周先是解决了上周遗留下来的一个非常头疼的问题，之后重构了Token和AST的定义以及考虑了一下Visitor。之后也编写了建立符号表的代码以及一半转换到vm指令的代码，但是总觉得哪里不太对劲就先停了下来，后续确认无误了再一起拿出来讲。还学习了一些rust的实现方式，关于IR方面有更多了解以后有意向再单独出一篇文章讲解自己的一些了解\nPackratReader上周为了解决左递归的语法使用了PackratParser，但是这会引入一个问题，PackratParser会使用PackratReader管理输入，而PackratReader并没有重载toString，因此在log的时候都是类似于\ntrying class member at scala.util.parsing.combinator.PackratParsers$$anon$1@4d3167f4\n\n我的解决思路如下\n首先尝试继承并且实现一个自己的PackratReader，因为之前TokenReader就是继承并实现了Reader。但是发现经过了PackratParser的处理后又会变成系统自带的reader\n查看源码发现有这么一段内容\ndef rest: Reader[T] = new PackratReader(underlying.rest) &#123;  override private[PackratParsers] val cache = outer.cache  override private[PackratParsers] val recursionHeads = outer.recursionHeads  lrStack = outer.lrStack&#125;\n\n可以看到每次获取rest的时候都会重新构造一个PackratReader，因此继承这条路行不通。之后我的思路一直在想着如何hack这个类的toString（用ruby的话我一定会这么做的，对于ruby来说这种做法是理所应当的），但是对于Scala来说并没有那么过分的元编程能力（至少我没有搜寻到相关解决方案）。\n反复尝试无果后，只好继续硬调代码了。调试的过程中偶然想到我可以重载log这个函数，前面的思路都是我需要它的字符串，但是我实际的需求是能够log输出正确的信息\n这是我重载以后的行为\nprivate def take[T](p: Reader[T], n: Int): List[T] = &#123;  if (n &gt; 0 &amp;&amp; !p.atEnd) then p.first::take(p.rest, n - 1) else Nil&#125;override def log[T](p: =&gt; Parser[T])(name: String): Parser[T] = Parser&#123; in =&gt;  in match &#123;    case reader: PackratReader[Token] =&gt;      println(s&quot;trying $&#123;name&#125; at ($&#123;take(reader, 3).mkString(&quot;, &quot;)&#125;)&quot;)    case _ =&gt;      println(&quot;trying &quot; + name + &quot; at &quot; + in)  &#125;  val r = p(in)  println(name +&quot; --&gt; &quot;+ r)  r&#125;\n\n这是原本的实现\ndef log[T](p: =&gt; Parser[T])(name: String): Parser[T] = Parser&#123; in =&gt;  println(&quot;trying &quot;+ name +&quot; at &quot;+ in)  val r = p(in)  println(name +&quot; --&gt; &quot;+ r)  r&#125;\n\n重构Token之前的博客也提到过Token的定义不太好，之前思路过于死板，只想着用enum来解决，但是这里可以更灵活的将trait和enum组合起来，可以通过类型更好的区分不同的Token，AST也是如此。以下这是新的定义的部分代码\ntrait Token extends Positionalenum Literal extends Token:  case NUMBER(int: Int)  case STRING(str: String)  case TRUE  case FALSEenum Delimiter extends Token:  case LEFT_PARENT_THESES  case RIGHT_PARENT_THESES  case LEFT_SQUARE  case RIGHT_SQUAREenum Ident extends Token:  case IDENTIFIER(str: String)  case UPPER_IDENTIFIER(str: String)enum Keyword extends Token:  // local  case VAR  case VAL  // method  case DEF  case RETURN  case END\n\n据我所了解rust的trait是不能携带变量的，在这方面上Scala好用的多，不需要再在每个Token里面保存一个position信息\n举一个这样写法实际比较有帮助的例子，比如说我现在Lexer结束获得了一个List[Token]，想要将其中Keyword的部分全部提取出来并且将这些信息传给编辑器插件高亮处理，那么我不需要再费力的去写一个麻烦的逻辑判断是否是Keyword的方法，而是直接匹配类型。再写其他逻辑不仅是麻烦的问题，实际也容易出错，比如说漏掉什么或者多写了什么，而这些东西直接写到类型定义中大大减少了问题的产生\n我没有写过插件，不知道实际是否是需要这样，但是这种想法和思路都是一样的\n实际处理代码\ntokens.filter &#123;  case k: Keyword =&gt; true  case _ =&gt; false&#125;\n\nAST大体思路都在Token部分讲的差不多了，这里贴一下部分关键的AST定义就好了\ntrait ASTNode extends Positionalenum Expr extends ASTNode:  case Number(v: Int)  case Identifier(ident: Ident)  case Bool(b: Boolean)  case Binary(op: BinaryOp, lhs: Expr, rhs: Expr)  case Str(str: String)  // false -&gt; elsif | else  case If(cond: Expr, true_branch: Block, false_branch: Option[Expr])  case Lambda(args: List[Expr], stmts: List[Expr])  case Call(target: Ident, args: List[Expr])  case MethodCall(obj: Expr, target: Ident, args: List[Expr])  case Block(stmts: List[Stmt])  case Return(expr: ast.Expr)  case Field(expr: Expr, ident: Ident)  case Self  case Constant(ident: Ident)  case Index(expr: Expr, i: Expr)enum Stmt extends ASTNode:  case Local(name: Ident, ty: Type, value: ast.Expr)  case Expr(expr: ast.Expr)  case While(cond: ast.Expr, stmts: Block)  case Assign(name: Ident, value: ast.Expr)\n\n之前写的str与Id的隐式转换函数放到了一个object中，需要的时候直接import这个object中的一个函数或者全部函数，将隐式转换函数都放在一个位置进行管理\nobject ImplicitConversions &#123;  implicit def strToId(str: String): Ident = Ident(str)  implicit def IdToStr(id: Ident): String = id.str  implicit def boolToAST(b: Boolean): Expr.Bool = Expr.Bool(b)  implicit def intToAST(i: Int): Expr.Number = Expr.Number(i)&#125;\n\n需要用到的时候\nimport ast.ImplicitConversions.*\n\nAST Visitor思路虽然在公司做的ai compiler的项目里也有visitor，但那终究只是对特殊形式对expr处理的，也可以说是针对一种DSL的，并不能直接套用。之前用ruby写的版本存在很多问题，同时也使用了动态语言才能写出来的方式。\n编写遍历的时候关键在于遍历函数的签名。除了结点本身之外应当传递什么参数？返回值又是怎样的？\n我的思路是先想一下之后的使用场景是怎么样的。能想到的场景大致有这么几种\n\nast check\ntype infer\nlower\n其他pass\n\nast check这个显然是要遍历所有结点\ntype infer没有做过，对于实际要怎么做我还没有一个思路\nlower在很多编译器也是作为一种pass存在，而我目前暂时想先作为一个单独的流程存在。\n其他pass只是参与过公司项目，但是传统compiler还没有做过。关于这个我还存有许多问题，比如说都会用到什么样的访问方式？我目前想到的方面是针对表达式或者说某个特定类型的结点进行处理，那么应用的时候是需要做\n最后结论还是去学习一下前人的做法，尝试查看Scala和rust的实现，Scala实现方式过于复杂，因此最终参考的是rust的实现（但Scala但是实现我还是挺感兴趣但，可能会再花一些时间研究一下）\nrustrust中写了一个visitor的trait，其中包含了各种ast中出现的内容：crate，stmt，ident等都有。其中每一个visit_xxx的默认实现都是调用了walk_xxx，而walk是访问当前这个节点的所有成员，因此默认实现的整个逻辑是：先进入visit，visit调用到了walk，walk对每一个节点进行visit，而每个节点的visit又是调用了walk\n从上面提及的函数签名的角度来看，传递了一个所需的ast结点，无返回值\npub trait Visitor&lt;&#x27;ast&gt;: Sized &#123;...\tfn visit_crate(&amp;mut self, krate: &amp;&#x27;ast Crate) &#123;\t    walk_crate(self, krate)\t&#125;&#125;pub fn walk_crate&lt;&#x27;a, V: Visitor&lt;&#x27;a&gt;&gt;(visitor: &amp;mut V, krate: &amp;&#x27;a Crate) &#123;    walk_list!(visitor, visit_item, &amp;krate.items);    walk_list!(visitor, visit_attribute, &amp;krate.attrs);&#125;\n\n这里有一个小问题我即便在写到这里的时候我还是没能理解，为什么要传一个visitor进来，直接作为trait的成员不就好了吗？rust的高层IR有好几层，起初我以为是为了给其他的ir使用（思考完这个问题我才意识到这是一个不良设计，每一层的东西应当隔离开来），但经过查看每一层但IR都是完全单独的visitor和walk，偶尔使用walk也是在impl ast visitor的时候\n实现选取片段\ntrait ASTVisitor &#123;  type R = Unit  def visit(modules: Modules): R = visitRecursive(modules)  def visit(module: RcModule): R = visitRecursive(module)  def visit(item: Item): R = visitRecursive(item)  def visit(expr: Expr): R = visitRecursive(expr)\t...\tfinal def visitRecursive(item: Item): R = &#123;\t    item match &#123;\t      case method: Item.Method =&gt; visit(method)\t      case klass: Item.Class =&gt; visit(klass)\t      case _ =&gt; throw new RuntimeException(&quot;NoneItem&quot;)\t    &#125;\t  &#125;\t...&#125;\n\n关于返回值的地方我也纠结了一下，虽然留有了一个R的类型，但是没想好之后怎么用。因此就先这样实现吧，之后根据需求再改。在不了解的情况下不应当想着一口气写出合适的实现，而是先从能用开始，再不断修改\n","categories":["Compiler"],"tags":["Rc-lang","Rust","AST"]},{"title":"Rc-lang开发周记18 简单类型推导","url":"/2022/05/08/rc-lang-dev/rc-lang-dev-18/","content":"\n不要小看我，这种程度我也可以做得出！非pixiv \n\n本周主要都在了解MIR相关，但是还存有非常多的问题，因此先来讲一下之前写的TypeInfer的内容\n我将Infer的过程分为了两部分。第一部分是最纯粹的类型推导，第二部分是实际将ast转换为带有类型信息的ast。\nType目前先这样做了一个非常简易的样子\nenum Type:  case Boolean  case String  case Int32  case Float  case Nil  case Fn(ret: Type, params: List[Type])  case Infer  case Err(msg: String)\n\nTyped对于类型相关的操作来讲，首先本身是有类型的才能进行infer，因此有了这样一个trait\ntrait Typed &#123;  var ty:Type = Type.Infer  def withTy(ty: Type): this.type = &#123;    this.ty = ty    this  &#125;  def withInfer: this.type = withTy(infer)  def infer: Type = Infer(this)&#125;\n\n注意这里默认的是Type.Infer，表示需要Infer才行\ninfer的过程则是调用了case object Infer（单例对象），后面会讲到\n用的时候直接mixin这个trait即可\nenum Expr extends ASTNode with Typed:  case Number(v: Int)  case Identifier(ident: Ident)enum Item extends ASTNode with Typed:  case Method(decl: MethodDecl, body: Block) extends Item with Typed\n\nTyCtxtctxt的部分主要存放一个全局符号表，以及一个局部符号表（这里的符号表只包含了类型信息）\n而局部符号表又分为了当前scope以及outer的两部分。\n接口也很简单，简单的添加与查找，以及进入一个新的scope\ncase class TyCtxt(val global:Map[Ident, Type] = Map[Ident, Type]()) &#123;  var outer = List[Map[Ident, Type]]()  var local = Map[Ident, Type]()  def lookup(ident: Ident): Option[Type] = &#123;    val ty = local.get(ident) orElse outer.find(_.contains(ident)) orElse global.get(ident)    ty.asInstanceOf[Option[Type]]  &#125;  def enter[T](f: =&gt; T): T = &#123;    outer ::= local    local = Map[Ident, Type]()    val result = f    local = outer.head    outer = outer.tail    result  &#125;  def addLocal(k: Ident, v: Type): Unit = &#123;    local += (k -&gt; v)  &#125;&#125;\n\n关于enter的参数需要讲一下，既不是一个f: T，也不是一个f: () ⇒ T。\n使用f: ⇒ T的写法可以推迟实际传进来的求值过程。既可以接受一个简单的T，也可以接受一个函数计算结果的T，同样也可以接受一个() ⇒ T\n看一个测试就明白了\nit(&quot;nested&quot;) &#123;  tyCtxt.enter(() =&gt; &#123;    val id = Ident(&quot;a&quot;)    val ty = Nil    tyCtxt.addLocal(id, ty)    tyCtxt.enter(testEnter(id))    assert(tyCtxt.enter(id) == String)    assert(tyCtxt.lookup(id).contains(ty))  &#125;)&#125;def testEnter(id: Ident): Type = &#123;\tassert(tyCtxt.local.isEmpty)  val innerTy = String  tyCtxt.addLocal(id, innerTy)  assert(tyCtxt.lookup(id).contains(innerTy))  innerTy&#125;\n\n可以看到这里的enter存在两种写法。\n在进入testEnter之前添加了local，进入之后local变成了空的，也就是说进入了一个新的scope。\n最初是觉得每次tyCtxt.enter(() ⇒ f())都要写() ⇒ 感到非常麻烦，后来发现了这样的写法\nInfer成员变量只有一个tyCtxt\ncase object Infer &#123;  var tyCtxt: TyCtxt = TyCtxt()\t...&#125;\n\ninfer的入口处\ndef apply(typed: Typed, force: Boolean = false): Type = &#123;  infer(typed, force)&#125;private def infer(typed: Typed, force: Boolean): Type = &#123;  if(!force &amp;&amp; typed.ty != Type.Infer) &#123;    typed.ty  &#125; else &#123;    infer(typed)  &#125;&#125;private def infer(typed: Typed): Type = &#123;  typed match    case expr: Expr =&gt; infer(expr)    case item: Item =&gt; infer(item)    case method: Item.Method =&gt; infer(method)    case stmt: Stmt =&gt; infer(stmt)    case _ =&gt; ???&#125;\n\nforce也很好理解，不是force的情况下原来有type则直接返回，而不是进行推导\nExpr inferprivate def infer(expr: Expr): Type = &#123;  expr match    case Number(v) =&gt; Int32    case Identifier(ident) =&gt; lookup(ident)    case Bool(b) =&gt; Boolean    case Binary(op, lhs, rhs) =&gt; common(lhs, rhs)    case Str(str) =&gt; String    case If(cond, true_branch, false_branch) =&gt; false_branch match      case Some(fBr) =&gt; common(true_branch, fBr)      case None =&gt; infer(true_branch)    case Return(expr) =&gt; infer(expr)    case Block(stmts) =&gt; tyCtxt.enter(infer(stmts.last))    case Call(target, args) =&gt; lookup(target)&#125;\n\nInfer的部分主要还是在于表达式的类型推导，实际上也很直观。有的种类表达式自身类型是确定了，需要考虑id的就去lookup，像if和binary这种通过common来获取。\nlookupprivate def lookup(ident: Ident): Type = &#123;  tyCtxt.lookup(ident).getOrElse(Err(s&quot;$ident not found&quot;))&#125;\n\n简单的在ctxt中查找符号的信息\ncommonprivate def common(lhs: Expr, rhs: Expr): Type = &#123;  val lt = infer(lhs)  val rt = infer(rhs)  if lt == rt then lt else Err(&quot;failed&quot;)&#125;\n\n这里我还抱有一些疑问，在这里产生一个TypeErr是否合适，但是如果lhs和rhs的类型是不兼容的情况那也无法得出一个正确的Type\n虽然名字叫common，然而这里做的非常简单，只是简单判别类型是否相同而没有考虑到type compatible\nenterdef enter[T](tyCtxt: TyCtxt, f: =&gt; T): T = &#123;  this.tyCtxt = tyCtxt  tyCtxt.enter(f)&#125;def enter[T](f: =&gt; T): T = &#123;  tyCtxt.enter(f)&#125;\n\n除了普通的enter，还支持通过指定一个typeCtxt来推导\nTranslatorcase object TypedTranslator &#123;  var tyCtxt: TyCtxt = TyCtxt()  def apply(tyCtxt: TyCtxt)(module: RcModule): RcModule = &#123;    // update local table in TypedTranslator will cause Infer ctxt update    // because of pass a typCtxt by Ref    Infer.enter(tyCtxt, RcModuleTrans(module))  &#125;  ...&#125;\n\n这里传递一个ctxt的引用给Infer，之后在translator里面通过tyCtxt更新各种local信息，这样Infer只做infer就可以了，不需要关心其他的事情。翻译的最小单元则是一个Module\ntranslator主要的想法就是通过infer获取类型，之后返回一个保存有意义的类型信息的ASTNode\nExprdef exprTrans(expr: Expr): Expr =\t(expr match    case Binary(op, lhs, rhs) =&gt; Binary(op, lhs.withInfer, rhs.withInfer)    case If(cond, true_branch, false_branch) =&gt; &#123;      val false_br = false_branch match        case Some(fBr) =&gt; Some(fBr.withInfer)        case None =&gt; None      If(cond.withInfer,        true_branch.withInfer.asInstanceOf[Block],        false_br)    &#125;    case Call(target, args) =&gt; Call(target, args.map(_.withInfer))    case Return(expr) =&gt; Return(expr.withInfer)    case Block(stmts) =&gt; tyCtxt.enter(Block(stmts.map(stmtTrans)))    case _ =&gt; expr).withInfer\n\n可以看到就是简单的将参数withInfer，之后重新构建起这个表达式，并且将这个表达式整体进行infer。\n为了避免一个个调用withInfer，因此在最后将expr的结果统一调用withInfer\n对于Stmt的部分本质做法是差不多的，就不再赘述了\n最后下周开始会开始专注于适合优化层面IR的内容了。最早我给自己规定的每天写一部分功能，不过我后来已经将写与学习成为了习惯，因此不会再局限于每天写这种事情。现在更多的是了解各种不同的做法，分析不同做法之间的差异（了解这些的过程有些上瘾，一不小心就会陷进去）。也因此下周开始的内容可能写的篇幅会少一些，会多一些对比分析\n","categories":["Compiler"],"tags":["Rc-lang","Type"]},{"title":"Rc-lang开发周记 序","url":"/2021/12/19/rc-lang-dev/rc-lang-dev-preface/","content":"之前毕业设计想尝试设计一门语言并且实现编译器，奈何时间加个人状态不佳只做到了十分简陋的ast解释器，最近又想着转成编译器并且打算认认真真做下去。既然要做那索性把这个过程中重要的部分记录下来，记录的过程能够反思做的内容，回顾有没有隐藏bug，并且能够督促我继续做下去。不过受限于时间精力，恕我不能一口气把以前写的部分的讲解补上，下次一定（咕咕咕）\nRclang长远的想法是作为一门教学相联系的语言（并不是给刚学编程的人教学的意思），但是那还太遥远，甚至都不知道能不能坚持到那个时候，现阶段的目标是能够编译正确的代码到VM上正确执行，并且在这个过程中加强自己编程语言、编译器以及VM的基础知识。所以会有许多为了能跑或者了解相关知识而实现的决策，并且会反复修改很多设计\n本人水平不足，代码赶工情况很明显，因为时间真的不多，每天都要上班，同时每天以及周末还需要去学习其他的东西，也因此博客会粗糙一些（记录下来花费的时间比我预想的要多很多）。一定会有许多地方理解不够或者存在问题，如发现问题或者不合适的地方十分欢迎联系我（低血压人群可放心食用，高血压人群慎追）\n该系列如无特殊情况每周日更新，你可以在这里找到这个系列所有的文章\n标签: rc-lang | Homura’s Blog\n项目地址：https://github.com/FusionBolt/Rc-lang\n我想一定会有人好奇为什么选择Ruby，对我来说Ruby写的很爽很开心，这就够了。能够开心的持续做下去这才是最重要的（不过VM还是要C++受苦就是了…）\n","categories":["Compiler"],"tags":["Rc-lang"]},{"title":"LLVM Pass 其四：PassManager的改进与迁移现状","url":"/2022/07/17/llvm-pass/llvm-pass-4/","content":"\n仪式召唤！降临吧，青眼混沌极龙！这样闹剧也就结束了，混沌的极限爆裂！\n \n\n这一期我们来做一下之前遗漏的AM和PM的对比分析、新的PM机制相比legacy PM做了哪些改进以及LLVM中PM的现状\nPassManager和AnalysisManager之前虽然单独讲过PassManager（简称PM）以及AnalysisManager（简称AM），但是没有将这两者放到一起对比，在这里我们简单对比一下PM、AM以及对应的Pass，通过对比我们能够更深入的理解普通Pass和Analysis的异同。这里算是一个回顾也就不再贴代码了，如果忘记了可以参考前面几篇，其中都包含了详细的代码\n显然的相同点这里的相同点更多的是代码实现方式上，而不是Pass（这段统称Analysis和Pass为Pass）自身性质之间的差异\nPass自身都采取了ConceptBase的实现方式，PM添加一个Pass的时候通过将这个Pass保存到一个相应的Model中，之后通过Model来执行Pass\naddPassManager的使用首先从添加Pass开始，对于两者来说都是保存了一个XXXModel在Manager中，但是对于普通Pass来说传入的参数是一个Pass的实例，而一个Analysis传入的是一个AnalysisBuilder，也就说Analysis的构建实际上是通过这个builder延迟执行的，如果这个Analysis存在的话则不会再重复构造\n这样的差异是由于对于一个Analysis来说只需要存有一个实例即可，每次做分析都会找到这个analysis进行分析，同时analysis不需要考虑顺序的问题，在普通Pass需要的时候进来找到对应Pass跑就可以了。对于普通Pass则会添加多个实例到整个流程中，普通Pass的执行顺序是依靠于添加的Pass实例的顺序\n还有一个差异是PM允许添加一个作为Pass的PM（换个说法PM也是一个符合条件的Pass），实际的行为则是将另一个PM的所有pass添加进来，这和上面提到的传参方式的差异本质是相同的\n执行PassPM执行的入口是run，这里没什么特别的，只要不是被指定skip的pass都会执行（执行Pass之前会有callback进行判断）\nAM执行的入口是getResult，由于AM不仅需要保存实例还需要缓存之前分析的结果，因此每次getResult都需要分析是否存在缓存再决定是否执行Analysis，也就是说并非一定会执行。\n新PM改进了什么接下来的内容以这个链接内容的解读为主，许多地方会讲的比较粗略，不明白的请优先参考原文\nhttps://blog.llvm.org/posts/2021-03-26-the-new-pass-manager/\n这个链接中主要提到了这么几个问题\nPass和Analysis分离在legacy Pass架构中普通Pass和Analysis都是相同的Pass，而在新架构中从类型以及实际执行上区分开了两者\n\nWith the legacy PM, each pass declares which analyses it requires and preserves, and the pass manager schedules those analyses as passes to be run if they aren’t currently cached or have been invalidated. Declaring ahead of time which analyses a pass may need is unnecessary boilerplate, and a pass might not end up using all analyses in all cases.\n\nlegacy Pass主要有以下这么两类问题\n\n执行不必要的分析\n执行Pass的时候可能还没到需要信息的地方就提前停下了，也就是说这些Analysis并没有被用上，又或者说根据分支结构有些修改没有执行（即不会影响某些分析结果），会导致实际没有修改的部分的分析又重新跑了一遍\n\nPass编写上十分麻烦\n\n手动指定依赖的analysis又蠢又麻烦\n还要写各种构造函数初始化\n\n\n\n除了作者提到的这些之外，我觉得还有两个重要的点\n\nPass的顺序\n这里的顺序主要还是指的普通Pass和Analysis之间。在legacy PM中主要是通过每次addPass的时候进行一次schedule来解决普通Pass依赖analysis的情况，而在新Pass中则是需要的时候再根据是否有缓存再实际跑分析，不需要考虑analysis应该什么时候执行的问题\n\n新的Pass很大程度的简化了各个和Pass相关部分的实现。不需要再手动指定是否为Analysis或者CFGPass了，直接通过类型来做区分而不是记录在PassInfo中，Pass自身的元信息记录内容以及记录方式都简化了许多，而用到这些信息的代码也会精简很多\n\n\n获取Analysis信息\nSince the legacy PM modelled analyses as passes to be scheduled and run, we can’t efficiently access analyses to arbitrary functions.For a function analysis, the corresponding analysis pass will only contain the info for the current function, which is created during the latest run of the analysis pass. We can manually create analyses for other functions, but they won’t be cached anywhere\n\n这里主要还是说legacy PM中analysis视为一个普通pass的话无法缓存结果。这些都是通过AM管理analysis以及缓存结果来实现的。AM最重要的意义我认为一个是不需要再通过各种schedule的方式来管理执行analysis的时间，另一个则是缓存机制来减少不必要的分析\nCGSCC Pass这部分我不太了解，目前还没有了解过CGSCC相关的代码，直接看一下原文吧\n\nHowever, the legacy CGSCC pass manager only stored the functions in the current SCC in memory and did not have a persistent call graph data structure to use as keys to cache analyses. So we need to keep the whole graph in memory to have something to use as a key. And if we have a persistent call graph, we need to make sure it is up to date if passes change its structure.\n\nPass结构关系\nWhen adding passes to the legacy pass manager, the nesting of different pass types is implicit.For example, adding function passes after a module pass implicitly creates a function pass manager over a contiguous list of function passes.\n\n对于legacy PM来说每次添加的Pass都是一个Pass基类，看不到任何类型之间的关系\nvoid PassManager::add(Pass *P) &#123;  PM-&gt;add(P);&#125;// PM-&gt;add/// \\copydoc PassManager::add()void add(Pass *P) &#123;  schedulePass(P);&#125;\n\n而在新pm中normal pass都是有着严格的类型限制，PM和Pass级别不同的时候使用各种adaptor显式转换的，而analysis则是通过各种proxy来处理\n这是上期里我们看过的图，这就是整个PM中保存的Pass结构\nflowchart TD    R(ModulePassManager)    R--&gt;MP(ModulePass)    R--&gt;FP(ModuleToFunctionPassAdaptor)    FP--&gt;FPS(FunctionPass)    R--&gt;FPTemp(ModuleToFunctionPassAdaptor)    FPTemp--&gt;LPP(FunctionToLoopPassAdator)    LPP--&gt;LPPS(LoopPass)\n\n避免过多的全局变量\nThe legacy pass manager relies on many global flags and registries. This is supported by macros generating functions and variables to initialize passes, and any users of the legacy pass manager must make sure to call a function to initialize these passes. But we need some way for a pass manager builder to be aware of all passes for testing purposes.\n\n在旧的Pass架构中存在过多的全局变量与registries，每个Pass都需要通过宏来注册，进而产生全局变量以及initialize函数。\nstatic void *initializeFlattenCFGLegacyPassPassOnce(PassRegistry &amp;Registry) &#123;  initializeAAResultsWrapperPassPass(Registry);  PassInfo *PI =      new PassInfo(&quot;Flatten the CFG&quot;, &quot;flattencfg&quot;, &amp;FlattenCFGLegacyPass::ID,                   PassInfo::NormalCtor_t(callDefaultCtor&lt;FlattenCFGLegacyPass&gt;),                   false, false);  Registry.registerPass(*PI, true);  return PI;&#125;static llvm::once_flag InitializeFlattenCFGLegacyPassPassFlag;void llvm::initializeFlattenCFGLegacyPassPass(PassRegistry &amp;Registry) &#123;  llvm::call_once(InitializeFlattenCFGLegacyPassPassFlag,                  initializeFlattenCFGLegacyPassPassOnce, std::ref(Registry));&#125;\n\n在新的架构中通过传递PassManager以及使用PassBuilder统一来注册Pass到PM中来解决这个问题（实际LLVMRunPasses的情况）\nout of tree passes我对legacy的注册out of tree passes的情况不太了解，看官方的example中是\n/* Legacy PM Registration */static llvm::RegisterStandardPasses RegisterBye(    llvm::PassManagerBuilder::EP_VectorizerStart,    [](const llvm::PassManagerBuilder &amp;Builder,       llvm::legacy::PassManagerBase &amp;PM) &#123; PM.add(new LegacyBye()); &#125;);static llvm::RegisterStandardPasses RegisterByeLTO(    llvm::PassManagerBuilder::EP_ModuleOptimizerEarly,    [](const llvm::PassManagerBuilder &amp;Builder,       llvm::legacy::PassManagerBase &amp;PM) &#123; PM.add(new LegacyBye()); &#125;);\n\n新 PM的注册\n/* New PM Registration */llvm::PassPluginLibraryInfo getByePluginInfo() &#123;  return &#123;LLVM_PLUGIN_API_VERSION, &quot;Bye&quot;, LLVM_VERSION_STRING,          [](PassBuilder &amp;PB) &#123;            PB.registerVectorizerStartEPCallback(                [](llvm::FunctionPassManager &amp;PM, OptimizationLevel Level) &#123;                  PM.addPass(Bye());                &#125;);            PB.registerPipelineParsingCallback(                [](StringRef Name, llvm::FunctionPassManager &amp;PM,                   ArrayRef&lt;llvm::PassBuilder::PipelineElement&gt;) &#123;                  if (Name == &quot;goodbye&quot;) &#123;                    PM.addPass(Bye());                    return true;                  &#125;                  return false;                &#125;);          &#125;&#125;;&#125;#ifndef LLVM_BYE_LINK_INTO_TOOLSextern &quot;C&quot; LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfollvmGetPassPluginInfo() &#123;  return getByePluginInfo();&#125;#endif\n\n这个简单的例子看起来写的更麻烦的了，复杂的情况使用callback的形式或许会更方便实现。比起写法上来说，更大的差异是不再需要一大堆global成员了，以及legacy中还要对LTO以及非LTO做处理，但是对于新PM来说LTO也是依靠的PassBuilder来注册Pass，也就是说不需要再对两处进行注册。\n新PM的注册是通过在PassBuiler中注册callback形式实现的。在文章中提到了这样一句\n\nAlthough there is a global list of functions, there is no mutable global state since each pass manager builder can parse pass pipelines without going through a global registry.\n\nparallelize这篇文章的后面提到了并行相关的问题。对于SCC的Pass来说是比较容易并行的，但是对于其他的就不一样了。比如说这里\n\nSome passes only use analyses if they are cached, so parallelization can cause non-determinism since a module analysis may or may not exist based on other parallel pipelines.The new PM only allows function passes to access cached module analyses and does not allow running them. This has the downside of needing to make sure that certain higher-level analyses are present before running a lower-level pipeline, e.g. making sure GlobalsAA has been computed before running a function pipeline.\n\n一个Module的analysis可能基于其他并行的pipeline，所以会导致不确定性。因此新的PM只允许获取cached的module analyses。比如说上期提到的ModuleAnalysisManagerFunctionProxy并非直接getResult获取结果，而是直接getCachedResult。我觉得这里说的可能更类似于多线程读一个只读变量的情况，但是我不知道自己的理解是否存在问题，如有不对还请指正\ntemplate &lt;typename AnalysisT&gt;static void getModuleAAResultImpl(Function &amp;F, FunctionAnalysisManager &amp;AM,                                  AAResults &amp;AAResults) &#123;  auto &amp;MAMProxy = AM.getResult&lt;ModuleAnalysisManagerFunctionProxy&gt;(F);  if (auto *R =          MAMProxy.template getCachedResult&lt;AnalysisT&gt;(*F.getParent())) &#123;    AAResults.addAAResult(*R);    MAMProxy        .template registerOuterAnalysisInvalidation&lt;AnalysisT, AAManager&gt;();  &#125;&#125;\n\n现状注：以下内容的实效性不强\n部分迁移\nCurrently the new PM applies only to the middle-end optimization pipeline working with LLVM IR. The backend codegen pipeline still works only with the legacy PM, mostly because most codegen passes don’t work on LLVM IR, but rather machine IR (MIR), and nobody has yet put in the time to create the new PM infrastructure for MIR passes and to migrate all of the backends to use the new PM. Migrating to the new PM for the codegen pipeline likely won’t unlock performance gains since there are almost no interprocedural codegen passes. However, it would clean up a lot of technical debt.\n\n根据这段所讲，目前codegen的部分还没有完成迁移，只做了少部分的处理。但是许多Pass依然是旧的形式，现在的代码中也能看到许多为了兼容legacy Pass的形式\n在旧的架构中codegen是通过加到legacy PM中的\n以下代码来自llvm的教程\nlegacy::PassManager pass;auto FileType = CGFT_ObjectFile;if (TheTargetMachine-&gt;addPassesToEmitFile(pass, dest, nullptr, FileType)) &#123;  errs() &lt;&lt; &quot;TheTargetMachine can&#x27;t emit a file of this type&quot;;  return 1;&#125;pass.run(*TheModule);\n\nLLVM目前的CodeGen这里的PassBuilder基本成形（新架构注册Pass相关的转换为了PassBuilder的形式）\ntemplate &lt;typename Derived&gt;Error CodeGenPassBuilder&lt;Derived&gt;::buildPipeline(    ModulePassManager &amp;MPM, MachineFunctionPassManager &amp;MFPM,    raw_pwrite_stream &amp;Out, raw_pwrite_stream *DwoOut,    CodeGenFileType FileType) const &#123;  AddIRPass addIRPass(MPM, Opt.DebugPM);  addISelPasses(addIRPass);  AddMachinePass addPass(MFPM);  if (auto Err = addCoreISelPasses(addPass))    return std::move(Err);  if (auto Err = derived().addMachinePasses(addPass))    return std::move(Err);  derived().addAsmPrinter(      addPass, [this, &amp;Out, DwoOut, FileType](MCContext &amp;Ctx) &#123;        return this-&gt;TM.createMCStreamer(Out, DwoOut, FileType, Ctx);      &#125;);  addPass(FreeMachineFunctionPass());  return Error::success();&#125;\n\n而这些addPass的变量我觉得是一种为了兼容临时过渡的形式，在使用的时候是这样的\ntemplate &lt;typename Derived&gt;void CodeGenPassBuilder&lt;Derived&gt;::addISelPasses(AddIRPass &amp;addPass) const &#123;  if (TM.useEmulatedTLS())    addPass(LowerEmuTLSPass());  addPass(PreISelIntrinsicLoweringPass());  derived().addIRPasses(addPass);  derived().addCodeGenPrepare(addPass);  addPassesToHandleExceptions(addPass);  derived().addISelPrepare(addPass);&#125;\n\ndeprecated在LLVM14的Release Notes中看到\n\nUsing the legacy pass manager for the optimization pipeline is deprecated and will be removed after LLVM 14. In the meantime, only minimal effort will be made to maintain the legacy pass manager for the optimization pipeline.\n\n看起来的意思是LLVM15都要移植完并且删除，LLVM15的文档还在施工初期，其中也并没有什么有价值的信息，codegen这部分不知道会不会也要全部移植完\ntest除了核心功能之外，还有一些Test目前依然是使用Legacy PM的形式\n比如说TimePassesTest中这段测试的代码\n// Clear and generate report again.TimePassesStr.clear();reportAndResetTimings(&amp;ReportStream);// Since we did not run any passes since last print, report should be empty.EXPECT_TRUE(TimePassesStr.empty());// Now run just a single pass to populate timers again.legacy::PassManager PM2;PM2.add(new llvm::Pass2());PM2.run(M);\n\n本系列结束正如本文开始的召唤台词“这样闹剧也就结束了”所说，这个系列到此也就结束了，在这里扯点感想啥的吧。结束的比预想的要早，一开始列出的大纲有一些不是很大的组件都被合并进了各期中。一共五期，也就意味着过去了28天，真的是不知不觉就过去了…\n内容上我不可能讲的面面俱到，但是我想如果你读完了这个系列的话会对整个新PM的结构，各个组件之间的关系有了一个了解。如果你还存有什么疑惑或者想法欢迎和我进行交流。\n后续一定会开新的系列，欢迎持续关注我的博客/推特。之后的方向不出意外应该就是Pass里的具体实现，可能会从某一个DefaultPipeline为线索开始。更新频率不敢保证，就我这段时间学习的过程来说，Pass内部实现的代码非常长，加上相关联的知识点也非常多\n","categories":["Compiler"],"tags":["LLVM","Pass"]},{"title":"快乐的死","url":"/2022/10/15/Reading/a-happy-death-albert-camus/","content":"这本书的后续发展和我预想的偏差比较大。还没开始读的时候，看到杀死富豪携带一大笔财产这件事情，想到的第一件事情就是有钱了依然不会快乐，我想主人公会拿这笔钱去娱乐，娱乐很久最后开始觉得无聊与没有意义，后来通过什么事件发现了快乐的真相，之后过上了快乐的日子。不过现在来想如果真的是这样的展开那可能就没意思了。\n对主人公梅尔索来说他觉得痛苦，母亲已经去世，没有人陪伴，即便有玛尔特但他并不爱她，他也不爱其他情人；他觉得自己没有钱，每天还要这样工作八小时；无所事事的过着每一天，每周都是在消磨时间，正如文中他所说的“又熬完了一个星期天”。这样的他看到他的租户卡多纳的惨状，推动了他现在就想要获取快乐的想法，因此他动手了。他认为拿到那笔钱自己就能脱离这种现状，有了钱不必再去每天花费时间工作，有钱就自由了。\n除了不用工作以及最后买了房子之外，似乎并没有什么地方体现出这笔钱的价值，哪怕描写钱对于快乐的帮助没有那么大这件事情都不存在，也许是因为我被自己的想法所束缚住了。关于钱的观念借扎格尔斯也提到过一些，比如他说的“大多数有钱人完全不知快乐为何物。但这不是问题所在。有钱，就是有时间。”以及“我想说清楚一点，不要觉得我在说金钱能带来快乐。我的意思是，对某个阶层的人来说，在有时间的前提下，快乐是可能的，而有钱，就能摆脱金钱的困扰”。但写到这我想作者后续的内容很少提及拿到的那笔钱也许正是对于这些观点的体现。有了钱，他不需要浪费时间去工作，而钱又无法带来快乐，因此没有什么体现出钱的重要性的地方。\n作者没有采取表现出钱带不来快乐这一方面，而是着重在了其他方面。最重要的就是孤独。从他踏上行程后第一部分就在描写他独自一人在外的孤单，试图摆脱也未成功。即便在后面远离熟识的人们选择独自居住的时候依然会保持和新村子中居民的联系，和以往熟识的人们见面。\n这本书借由扎格尔斯表达的内容除了对金钱的态度外似乎一直在强调要有追寻快乐的心，也许是想要表达不论环境如何关键是自己的心态与看法。后面作者还说到“要懂得让自己的心顺应每天的节奏，而不是非要每天的节奏顺应每天的心意”，追寻快乐，去做些什么固然重要，但是不是说一定要去达到了什么目的、做到了或者改变了什么才是快乐的，而是自己的心意如何去看待与解释周围一切，通过这种角度尽可能让自己的快乐程度多一分。\n翻开书的第一页就是“要不计代价地追求快乐，抵抗这个用愚蠢和暴力将我们包围的世界。”（不知道其他译本是否是这样）但是他为什么最后一个人去住了呢，和卡特琳娜的对话仿佛是在说如果没有和快乐相反的经历无法体现快乐的经历一样。也许这是非常重要的一个观点，他说“我在意的，是有一定质量的快乐。只有当快乐和它相反的事物呈现出持久而激烈的对峙时，我才能够品尝到快乐的滋味”。只有他自身孤独的瞬间才会让他觉得和别人在一起是多么美好，快乐本身是由相反的事物衬托出来的。\n说了那么多废话，最关键的结论大概是我们不应去追求什么理想的没有痛苦的世界，而是基于此时此刻，基于自己现在的人生，改变自己的看法，接纳与快乐相反的那一部分。真实的世界就存在于那里，但我们眼中的世界是由我们自己塑造的。\n我被这本书的书名以及内容概要吸引而来，大概为了看到想要看到的东西以及为了明白些东西。那么我得到了什么呢，好像没有什么，这也无妨。那么读着这本书的我，感到快乐吗？遇到好事自然会快乐，但无法说整体的基调是快乐的。不算快乐。那痛苦吗？除了会对身体的不适感到痛苦之外，其他情绪上的好像也无所谓，或者做不到想做的事情就会难过，但那更像是踢到了石头一样的痛苦，也因此无法说整体基调是痛苦的。我对此似乎也不会在意，只是像个机器，按照命令做一切事情。\n自己精神上对于快乐的追求好像没有那么强烈，我很喜欢jojo里吉良吉影的态度，“不需要疯狂的喜悦，相反也就没有深沉的绝望”，这句话也算是印证了上面提到的快乐是由相反的事物衬托的，对我个人来说这样的平静是最好的。\n解读出来这些也都只是大道理，无法引起什么感受。只有道理本身或许也不会产生什么影响，尽情去生活、阅读与思考，也许有一天一切都会连接起来，震撼到心灵。\n","categories":["Reading"],"tags":["加缪"]},{"title":"基于xv6 riscv实现学习os 其零：helloworld","url":"/2022/11/13/xv6-riscv-os/xv6-riscv-os-0/","content":"\n学习os的时间开始了! pixiv:30933181 \n\n前言这个系列的目的还是以讲解xv6-riscv的代码以及记录我在做的事情为主，也会掺杂许多mini-riscv-os的代码介绍（关于xv6-riscv和mini-riscv-os的链接请看参考），并非教程倾向（但也会尽可能讲解一些基础知识），很多细节不会讲到。如果想要更详细的教程我建议你查看参考资料中引用的内容，在这一期我会列出一部参考的项目。\ncompiler的坑还没走多远，我又要开新的坑了，这是我很久之前想做但不敢做的事情。以前也做过一些尝试，比如说《30天自制os》以及6.828，前者讲的相对比较容易理解一些，但是当时的我缺少实践，后者难度较高，看不懂课后习题只能去查看别人的实现，东抄西抄总算抄完了前四章的内容，最后只留下了一些概念的印象。对我来说学会什么东西只有通过具体去实现，自己很难从什么概念去理解某个东西，也因此之前学的很多知识其实都是非常肤浅无用的。\n实现os这件事情看起来是挺吓人的，本身复杂的概念和各种实现，同时需要许多前置知识。同时大多数os的开始都是离谱的x86bootloader，我想这个应该劝退了非常多的人。但最近发现做一个最简易的os或许并没有那么可怕，搜了一些项目，最简单的功能很少的系统只有一两千行代码，相对比较容易学习，同时riscv的bootloader部分没有乱七八糟的历史遗留，十分简洁，不会再因为这个劝退别人。也在这里感谢他们的付出。\n注意事项\nmini-riscv-os是针对riscv32，而xv6针对的是riscv64，导致一些汇编上、编译选项以及一些其他的内容会有所不同\n代码引用会直接使用项目名/路径的格式\n\n此后不再赘述\n环境配置交叉编译工具链参考链接\nhttps://pdos.csail.mit.edu/6.828/2019/tools.html\n我是在mac（M1）下开发的，homebrew在安装riscv-tools的时候会提示需要安装一些依赖。在我配置的时候遇到了flock这个依赖搞不定的问题，发现直接brew install flock安装的flock是其他东西，因此需要卸载flock并且使用brew tap的命令，安装好依赖再去按riscv-tools\nbrew uninstall flockbrew tap discoteq/discoteqbrew install flockbrew install riscv-tools\n\nqemu这个没什么好说的，直接用包管理安装就是\n启动所需代码bootloader做了什么\n设置栈的起始地址\n跳转到c代码中\n\n代码mini-riscv-os/01-HelloOs/start.s\n.equ STACK_SIZE, 8192.global _start_start:    # setup stacks per hart    csrr t0, mhartid                # read current hart id    slli t0, t0, 10                 # shift left the hart id by 1024    la   sp, stacks + STACK_SIZE    # set the initial stack pointer                                     # to the end of the stack space    add  sp, sp, t0                 # move the current hart stack pointer                                    # to its place in the stack space    # park harts with id != 0    csrr a0, mhartid                # read current hart id    bnez a0, park                   # if we&#x27;re not on the hart 0                                    # we park the hart    j    os_main                    # hart 0 jump to cpark:    wfi    j parkstacks:    .skip STACK_SIZE * 4            # allocate space for the harts stacks\n\ncsrr是从csr（Control and Status Register）寄存器中read值，而其中的csrr reg, mhartid则是将hart id读到对应的reg中。hart是riscv中硬件线程的最小单位，在riscv的spec中是这样描述的\n\nA RISC-V compatible core might support multiple RISC-V-compatible hardware threads, or harts, throughmultithreading.\n\n这里的代码判断如果hart id不是0就跳到park这个循环中。实质上是只开启了一个hart\nxv6-riscv/kernel/entry.S\n# qemu -kernel loads the kernel at 0x80000000        # and causes each hart (i.e. CPU) to jump there.        # kernel.ld causes the following code to        # be placed at 0x80000000..section .text.global _entry_entry:        # set up a stack for C.        # stack0 is declared in start.c,        # with a 4096-byte stack per CPU.        # sp = stack0 + (hartid * 4096)        la sp, stack0        li a0, 1024*4        csrr a1, mhartid        addi a1, a1, 1        mul a0, a0, a1        add sp, sp, a0        # jump to start() in start.c        call startspin:        j spin\n\nxv6的启动代码中考虑了多个hart启动的情况，给每一个hard都设置stack的起始地址。而stack的起始地址是写在其他的c代码中\n// entry.S needs one stack per CPU.__attribute__ ((aligned (16))) char stack0[4096 * NCPU];\n\nc代码在c代码中打印出一个血统纯正的helloworld。这里其实隐含了很多的内容，但是暂且知道这样做就可以打印出helloworld即可。\n对于xv6来说在进入os的main之前有许多设置状态的内容，这里暂且不讨论。\nmini-riscv-os/01-HelloOs/os.c\n#include &lt;stdint.h&gt;#define UART        0x10000000#define UART_THR    (uint8_t*)(UART+0x00) // THR:transmitter holding register#define UART_LSR    (uint8_t*)(UART+0x05) // LSR:line status register#define UART_LSR_EMPTY_MASK 0x40          // LSR Bit 6: Transmitter empty; both the THR and LSR are emptyint lib_putc(char ch) &#123;\twhile ((*UART_LSR &amp; UART_LSR_EMPTY_MASK) == 0);\treturn *UART_THR = ch;&#125;void lib_puts(char *s) &#123;\twhile (*s) lib_putc(*s++);&#125;int os_main(void)&#123;\tlib_puts(&quot;hello, world\\n&quot;);\twhile (1) &#123;&#125;\treturn 0;&#125;\n\nldscript这里主要是需要指定这么几项内容\n\n对于qemu来说，启动之后会读位于0x80000000这个地址的内容，因此我们需要将我们的内容放到这个地址开始。\n指定OUTPUT_ARCH( “riscv” )\n指定汇编入口地址，比如ENTRY( _entry )\n\nxv6-riscv/kernel/entry.S\nOUTPUT_ARCH( &quot;riscv&quot; )ENTRY( _entry )SECTIONS&#123;  /*   * ensure that entry.S / _entry is at 0x80000000,   * where qemu&#x27;s -kernel jumps.   */  . = 0x80000000;  .text : &#123;    *(.text .text.*)    . = ALIGN(0x1000);    _trampoline = .;    *(trampsec)    . = ALIGN(0x1000);    ASSERT(. - _trampoline == 0x1000, &quot;error: trampoline larger than one page&quot;);    PROVIDE(etext = .);  &#125;  .rodata : &#123;    . = ALIGN(16);    *(.srodata .srodata.*) /* do not need to distinguish this from .rodata */    . = ALIGN(16);    *(.rodata .rodata.*)  &#125;  .data : &#123;    . = ALIGN(16);    *(.sdata .sdata.*) /* do not need to distinguish this from .data */    . = ALIGN(16);    *(.data .data.*)  &#125;  .bss : &#123;    . = ALIGN(16);    *(.sbss .sbss.*) /* do not need to distinguish this from .bss */    . = ALIGN(16);    *(.bss .bss.*)  &#125;  PROVIDE(end = .);&#125;\n\nmakefilemini-riscv-os/01-HelloOs/Makefile\nCC = riscv64-unknown-elf-gccCFLAGS = -nostdlib -fno-builtin -mcmodel=medany -march=rv32ima -mabi=ilp32QEMU = qemu-system-riscv32QFLAGS = -nographic -smp 4 -machine virt -bios noneOBJDUMP = riscv64-unknown-elf-objdumpall: os.elfos.elf: start.s os.c\t$(CC) $(CFLAGS) -T os.ld -o os.elf $^qemu: $(TARGET)\t@qemu-system-riscv32 -M ? | grep virt &gt;/dev/null || exit\t@echo &quot;Press Ctrl-A and then X to exit QEMU&quot;\t$(QEMU) $(QFLAGS) -kernel os.elfclean:\trm -f *.elf\n\n这里没什么好讲的，绝大多数选项都用不到，唯一要注意的是-march的值\nriscv是一种模块化的指令集，不同的名字代表支持的扩展指令集不同，关于详情参考\nRISC-V#ISA_base_and_extensions\n之后直接通过make命令编译出elf之后通过qemu启动就好\n参考https://github.com/cccriscv/mini-riscv-os\nhttps://github.com/mit-pdos/xv6-riscv\nSpecifications - RISC-V International\n","categories":["os"],"tags":["xv6-riscv","mini-riscv-os","bootloader","riscv"]},{"title":"Rc-lang开发周记 一些变动","url":"/2022/05/15/rc-lang-dev/rc-lang-change/","content":"关于开发周记周更这件事情现在继续做的必要性我开始产生了疑问。\n首先我写这个一方面是为了养成写博客的习惯，另一方面则是为了促进我形成写代码的习惯。然而随着我不断的做这样的事情，需要学习分析其他编译器实现的次数越来越多。这并非是因为我不继续做下去而要放弃，反而是我想要更好的做这件事情。这些分析的结果我更倾向于转换为其他系列的博客，因此我决定不再周更开发周记。\n当然并不是说后面完全不更新了，如果我代码开始写新的内容一定会更新的，同时之后写的新内容一定会关联到对应一期分析的博客。至于分析的内容，当我了解完成一个阶段以后会对这些内容进行一个整理并且发布到我的博客。更新频率未必会周更，视我学习的进度而定，主要是想要尽可能保证内容的完整与连贯，有一些内容还是放在一起写会比较合适。\n","categories":["Compiler"],"tags":["Rc-lang"]},{"title":"世界尽头与冷酷仙境","url":"/2022/08/21/Reading/Hard-Boiled-Wonderland/","content":"冷酷仙境冷酷仙境的人们有心却又无法交心，心仿佛摆设一样。名为冷酷仙境，我不是很能明白名字的用意，也许是有了心因此相比于世界尽头算是仙境，但是人们之间无法交心因此是冷酷的。\n其中情感外壳非常坚固的主人公的这段想法让我印象十分深刻\n\n也许，我想。任何人都不会紧紧搂抱我，我也不会紧紧搂抱别人。我就这样一年老似一年，像贴在海底岩石的海参一样孤单单地一年年衰老下去。\n\n紧紧搂抱是多么温暖的一件事情，但是却寻求不到。不会有人来抱着自己，自己也不会去抱别人。海底是那么的黑暗，陪伴自己的却只有冰冷的岩石，独自贴在上面又是多么的孤单的一件事情。即便是在海洋这种充满了生物的环境，在这么隐蔽的地方就不会被看到，也不会有人愿意来这里看，最终只会只身孤单下去，直到死去。即便有人会来到这里，自己却习惯了贴在岩石之上，因为长时间在这样的环境之中内心已经开始形成了一层层的外壳来保护自己，因此不愿去和他人接触，不愿去拥抱他人。\n同时前后文中女郎的回应同样让我印象深刻\n\n在又黑暗又孤寂难过渴望别人拥抱的时候周围却没有人拥抱自己\n\n\n即使花钱买很多很多女郎同床，即使同很多很多萍水相逢的女孩睡觉，也都不是实实在在的，谁都不会紧紧搂抱你的身体\n\n冷酷仙境的世界即便大家都有心，都能够正常生活，却无法找到和自己紧紧搂抱的人。人虽然正常的生存在这里，能够与他人产生交集，却无法与他人产生些什么深入的联系，无法产生爱意，即便身处人流之中却依然感到十分孤单，因为没有建立起密切联系的人。\n冷酷仙境就是这样孤单的世界。\n世界尽头世界尽头的人们进入了小镇后心会逐渐消失。名为世界尽头的深意，除了故事中提到的人进来了就要失去影子并且无法再出去之外，我觉得如果人没有了心那么也就到了其世界的尽头了。\n这个世界这样能够运行很奇怪吧，本应当和人一体的影子逐渐和人分离，后面就会渐渐变得虚弱，最终死去，此时人也就彻底失去了心。人们即便没有心却依然这样生存着，每个人做事情也没有什么原因，没有什么自己的想法，只是因为要做这件事情。\n心没了，情感自然也就没了所在之处。而这样的人并非不会产生情感而是都被独角兽吸去了。独角兽们带着情感逝去，被看门人斩下带有情感的头骨，再转生，像情感本身一样不断的诞生与消亡。\n从记忆中就没有心的图书管理员不会对现状感到任何异样与奇怪，未曾感受过温暖也不知温暖为何物。而没有心的她也无法对主人公的想法产生任何回应，就像大校所说的：即便能和她在一起，能同她睡，但她没有心依然无法回应你。人的心意无法传达到，无法感受到她人的心意都是非常悲伤的事情。\n世界尽头就是这样的“墓穴”。\n世界尽头与冷酷仙境不论是冷酷仙境中的主角和女郎，还是世界尽头的人们，大家都以各自的形式缺少爱与温暖，但是对他们来说这个样子都是可以生存的。是可以生存，但是仅仅如此罢了。这样的世界该是多么孤独与悲伤啊。明知是这样孤独与悲伤的故事，却又无法从心底唤起什么情感，可能我像图书管理员一样早已没了影子，又或许我已经不知什么时候成为了世界尽头的居民吧，回过神的时候自己的影子就已经不知何时被看门人分离了，而它现在也只能虚弱的躺在床上。\n不论是心还是情感对于人都是非常重要的。冷酷仙境中的人们有心但未能对他人真正产生情感，而世界尽头的人们更是直接失去了心。不论是哪一方，在旁观者的角度来看都是那么的孤单和悲伤。\n最后两个世界交汇的方式着实有点意外，也许这个结局是在暗示一直将自己包裹在坚固外壳中的孤独者的最终归宿就是在世界尽头中与自己的影子分离，最终彻底失去自己的心。写到这里多少有些感伤了。\n","categories":["Reading"],"tags":["村上春树"]},{"title":"虞美人草","url":"/2022/10/16/Reading/papaver-rhoeas/","content":"从小野身上的阴影中看到了自己。从差劲的过去与环境中脱离，只想要斩断过去，但是斩的断吗，不可能的，每个人都不可能断绝和过去的联系；小野与井上家相处的态度，小野认为自己的生活和井上家父女二人相差甚远，尽管还怀有恩情，但是对他们产生了鄙视；小野为了利益，不惜逐渐失去真诚，破坏承诺，选择去追求藤尾。这些内容相关的描述大多让我感同身受，不断的触动着我我内心黑暗的部分。我一直在迷茫，不知如此不真诚的自我有多少是该修正的，又要如何修正这些部分。小野最后受宗近所助解开了心结，那身为读者的我们如果也是这样该怎么做呢？写这些内容的时候偶然刷到诺贝尔奖获得者被爆出性侵少女，我对于小野这个角色所蕴含的意义多了一点想法。身为银表持有者，几乎代表了高学识的人们，但即便是这样的人们，也未必都是追寻道义的。许多人像小野一样，为了利益和欲望去做一些违反道义的事情，甚至是违反合理的法律，而大多数人不会像小野一样有人劝阻，我想作者一定是有对这样的人的批判在的。\n而甲野与其完全相反，即便继承许多财产却依旧不为所动，坚持道义，有一种看透一切超脱于一切的感觉，但过于上帝视角，让人难以有代入感，或许也是因此作者给他设定为哲学专业，以及通过甲野相关的许多内容道出真理。宗近看似性格和甲野相差甚远，但从他对待不同人的态度可以看出对于道义他也是有着自己的坚持方式与追求。宗近和他家人对话的描述和小野与井上家相处的对比真的是非常强烈，宗近和他父亲以及他妹妹的谈话中充满了真诚，他是真的在关注他的家人，关注朋友。宗近与小野相交的剧情描写的不多，但每次相交小野都不会占上风，不论是买东西回家时小野感到被宗近的贬低，还是最后宗近的劝说，小野在这个真诚的人的眼前感到无力，只能感到他的耀眼，只能羡慕他的真诚。\n藤尾母亲的虚荣、狡猾，为了面子无聊的伪装，无论哪一个行为决策都将她的这些特点描绘的淋漓尽致。描绘出了一个非常现实的形象，尤其是为了面子在意周围邻居看法这一面，特别像我们家长那一辈人，他们和亲戚以及邻里的关系更密切，他们也更重视这些所谓的外人看法，总是为了无聊的面子和外人看法做出一些毫无意义的事情；又或者为了利益层层计算这一点，现实中有太多这样的例子了，争夺家产，或者只是单纯的设下计谋以谋取利益。最后讲到藤尾自身，所有的主要角色都和她有着很强的关联，她更像是串联起这一切角色的线索。而到了故事的最后，通过藤尾的死来结束这一故事。藤尾更像是她母亲扭曲下的牺牲品，性格的塑造离不开她母亲，正如最后宗近所说：”您平素的想法确实有问题“，也正是因为这些产生了藤尾这样扭曲的性格，产生了这样的结局。\n结局甲野的日记诉说着人们只看着不遵循道义的眼前利益，却忘了抛弃道德的代价，只看着美好的生却忘却了可怕的死，或许这和这和《快乐的死》中提到的非快乐的事情才能体现出快乐的事情略微相似，无论是好的还是坏的我们都不能忽视。在故事中小野即便打算找浅井回绝和小夜子的婚事，但他依然内心不安，甚至想要不遵守与藤尾的约定，也正如宗近所说，如果他这样选择下去了他一辈子都会置于痛苦中，而这就是他的代价。藤尾的母亲日常狡猾的话术，对于物质以及虚荣的执着，最终得到的就是甲野的抛弃与藤尾的死亡。宗近最后回复甲野的那句“此地只流行喜剧”真的是太嘲讽了，此时此地规定都已变成了这样，而社会上大多数人们的想法也是这样。大家在乎的是眼下的利益、是喜剧、是生，而不是更远的道义、悲剧、死亡。人们内心的黑暗普遍存在，《海边的卡夫卡》中有这样一段话\n\n外部世界的黑暗固然彻底消失，而心的黑暗却几乎原封不动地剩留了下来。我们称为自我或意识的东西如冰山一样，其大部分仍沉在黑暗领域，这种乖离有时会在我们身上制造出深刻的矛盾和混乱。\n\n只有真的去追求道义的人才会点亮这些黑暗，而这样的人又是很少的。另外社会上只有“喜剧”才被允许接纳和存在，只有“喜剧”才被允许传播，尤其是在这里。幸福的人千篇一律，不幸的人各不相同，而不同的悲剧带给我们各不相同的生的意义以及不同的教导，我们看不到这些悲剧那么我们迟早有一天会重复踏入这些悲剧之中。\n道义这件事情，总觉得是一个难以谈论的话题。追求道义的人是极少的，做少数选择的人在生存上更加困难，同时有的人追求的又或者持有的是虚假的道义。在我眼里人类这一抽象存在是恶的，人的内心也确实普遍存在着许多黑暗，追求道义的过程我想也是点亮内心的过程。在这里似乎隐含了我对于不追求道义的人一些不接受，或许这个行为本身就是不够道义的。而追寻道义本身也是困难的，许多时候需要付出些什么，放弃眼前的利益这件事情又是违背人性的，而道义的边界似乎也模糊不定，这部分边界几乎是由环境的文化所决定。我为追求道义这件事感到苦恼，要做到怎样的地步，我又要如何战胜自己黑暗的人性，不断怀疑自己是否在虚假的寻求它。为此痛苦，为此迷茫，独自行走在茫茫人海中，不想追随人流，却也不知自己要去向哪里。希望有一天我能找到自己的答案。\n","categories":["Reading"],"tags":["夏目漱石"]},{"title":"Hello World","url":"/2021/04/19/Other/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n"},{"title":"我原本计划停下一周，然而...","url":"/2022/03/28/Other/rest-for-a-week/","content":"最近的精神状态愈发差劲，无止境的压力涌入身体，我也没有什么好的排解途径（本文不是讲我状态多差的，但是这些属于所需要了解的上下文，希望不要看到这个就直接关掉了文章）。我觉得不能再这个样子了，因此我想要尝试为期一周的“在家只休息”计划（过于直接的命名）\n这周是如何度过的计划很美好，现实嘛…大家都懂\n第一天清理了卧室的垃圾，做了一些轻微的收拾。之后的时间都是习惯性的就要去抓手机，想要放音乐。看到这里，你可以一会尝试一下一段时间什么也不做是怎样的感受。\n停下来什么都不做还是很难，不知所措的时候突然想到一些东西就开始记了下来，最后花了一个小时的时间手写了满满一页纸的想法（这也不算是在休息）。最后也是不知不觉就十二点了，早睡也没能成功\n后面几天本周的精神状态极差，回家只想获取简单快速的反馈，因此结果和我预料的也差不多，第二天开始回家只有各种刷视频，以及玩一些游戏。后面几天愈发过分，甚至到了快一点\n周末由于事情比较多导致只有晚上在家，然而周末晚上也没有多少改善\n总结发现自己现在的情况，所谓的休息在情绪高压下根本就是找理由刷推特和视频，这种休息还不如不休，但是不休息又会持续积累压力和疲劳，那…\n\n仔细想想还是应该注重维持我的日常规划的同时在不同任务之间进行轻微的休息，而减少大片的休息时间。这是非常必要的事情，不能一直紧绷着精神。否则就会像我现在这个样子，在状态差到只想刷刷刷以及处理任务之间反复游走，从来没有真正的休息过\n第一天我都写了些啥？尽管写满了一页A4纸，在这里只挑出一些提及一下。\n很久没有这样决定不逼着自己做些什么了（但是另一种角度说我还是在逼着自己不做事情，尽管也没能成功。\n回想起以前的各种略悠闲的生活：回想起三年前在家的时候自己买菜做饭自己去海边溜达的日子，回想起在学校和舍友满学校找猫喂猫的日子。我也有那样的时光啊。\n而现在的我显得忙碌与疲劳，不断给自己添加非常多的压力，这给我的第一反应是与之前的生活有着极大的反差。\n但是后来想起现在的我会去买花，会去公园拍照，会去看星星拍星星，会关心云彩是什么样的，这样想下去现在也没有那么枯燥无谓。相比之前能做以及实际去做的事情都多了非常多，感兴趣的事情也多了许多，自己渐渐开始主动接触各种各样的事物，自己不再是只知道上学学习与打游戏的一个人了。\n一些想法休息也不能白休，偶尔也会感受一下，会想一下自己的状态，进而记录了一些想法。\n外界push不论因为什么，我目前都是处于一个身体不想做事情的状态（实际表现就是想做什么但并不会去做）。这个现象我一直隐约有所察觉，但是并没有做过多想法，或许是想了也没有用，再怎么想还是会这样。对于现在的话，更多的是将这个东西有意识的提醒自己，这是很重要的问题自然不能忽略\n我有那么多想做的事情，都是觉得有意思想要尝试的东西，最后没有利用时间去做大多是如此。由于总处于疲惫状态，不管学的东西再有意思也不可能在累的时候还想要用力\n关于这个问题，想起了我第一次接触精神药物的时候，当时因为睡眠不好大夫给我开了黛力新，之后的半个月内真的是精神十足，没有觉得累，也不像以往一样什么都不愿做，讨厌的英语材料也能一直在啃（绝不是给我现在回避啃英语找借口），随后一些原因效果都没了，一共也就吃了两个月。那段时间我在看各种书的lab，然而药效小了以后的效率最多只有原来一半，只能硬逼着自己做，逼着自己做也会很快就产生厌烦，完全找不回那半个月的精神劲。如果能持续保持那样的状态那我大概几个月就会产生更为巨大的变化吧，可惜已经一去不复返了\n想要身体去做事情只有通过各种方式进行push，至少对我来说在被轻度push的时候状态基本上都是相对良好（重度可能会增加焦虑），之前也看到类似这样的话\n\n自己一个人努力是难的，需要有人拉你一把\n\n习惯然而不是总能有人来帮你，大多数情况需要靠自己。而对自己push对于我这样的情况来说是相对比较困难的，但我之前依然每天都能够坚持做些什么，这完全归功于习惯。\n只要逐渐养成习惯，那么做这些事情所需的阻力逐渐会减小，那么即便是相对疲惫的状态也能够一直做下去。\n关于如何逐渐养成习惯这些，我推荐去阅读《掌控习惯》这本书。这本书最初是由推友在推特推荐给我的，阅读之后觉得收益非常多。虽然只能将书中的少部分内容运用到实际中，但依然促进了我许多改变。\n关于习惯，周六心情不错的时候我一度认为这就是我破局最重要的东西之一。我写下了这样的一段话：我也不需要再担心自己会一直魔怔了，不过那要到何时我就不知道了。魔怔能不能解决我不知道，但是一定会帮助我解决非常多的问题。在这里我想起了上面提到的《掌控习惯》中提及了这样的内容\n\n不是应当达到某个目的，而是要达到某个系统\n\n一旦所需的习惯系统形成了，目的自然而然也就能够达到了\n“应该做的”停摆了一个周，很多事情没有去做也没有那么大的影响。（当然不是说我现在所做的事情都是不该做的意思）\n想到了自己时常会被自己心中所谓的“应该做的”事情所限制所约束所浪费时间。之前总是会把很多这样的事情塞给自己，然后就开始拖。拖到最后太多了就狠心全部清空，实际最后也没有太大的影响。\n你有多少事情也是这样？不过想明白自己真正应该做什么绝非易事，生活中的噪音太多了，而且即便没有这些噪音这也是一个非常难的问题。\n这一周我究竟得到了什么这一周的时间，我对所处的情况进行了一些思考，得出了一些结论。在写下成文的过程中再一次强化对这些想法的感知，希望能够帮助我强化一些正确的想法在脑中的印象并且更好的去实施提到的应当做的事情。\n意识到了习惯究竟有多么的重要，看到离开了习惯的我是如何打回原形的；意识到了应该什么时候休息，缺乏休息的后果。这些虽然潜意识的有意识到，但是这种事情还是需要从潜意识中提取出来才能真正开始产生一些影响。\n赶往目的地很重要，但是偶尔还是应该停下脚步，看看周边的风景\n","categories":["Thinking","Life"],"tags":["Habits","Rest"]},{"title":"我与博客","url":"/2022/05/08/Other/IandBlog/","content":"\n你愿意和我一起读下去吗 pixiv: 44636666 \n\n读《暗时间》这本书的时候看到关于你为什么应该写博客的章节，想先把自己有关博客的想法做一个记录，因此就有了本文。\n我和博客的开始以前也尝试过建立博客，也搞过什么Wordpress之类的，但也都是搭建好新鲜感过去来，之后就没写什么东西，之后也就不了了之了。\n去年三月多的时候又将这个事情回想了起来，决定好好对待这件事情。结果去年一年也没写上几篇\n今年的话渐渐有了更多的想法，内容也逐渐的有了一些。\n博客所带来的好处反复思考写博客本身是一个反复思考复盘的过程。不论是单纯记录还是思考，写下的过程中会不断复习这些知识，在这个过程中自己对这些知识的记忆会更加牢靠，同时可能产生了新的问题，进而产生新的思考。同时梳理思考的过程中会无意中发现一些问题，我在写自己的开发周记的时候发现了一些自己的bug。\n在讲解给读者的时候会强迫自己去思考，读者可能会提出哪些问题？这些地方自己是否真的明白了？有的技术博客我在写的时候也会发现自己知识的漏洞，现去弥补一下知识漏洞再来接着写。\n这样长期反复梳理思考下去我觉得慢慢这种思考就会变成一种习惯，不仅是写博客，在做其他的事情也会受益。\n展示自我看博客能够知道你是什么样的人。你写什么样的博客，你关注哪些内容，你的思考方式是怎么样的等等。这也算是一种特殊的自我介绍了，在网络上看一个人的几条发言可能看不出一个人是怎样的，但是如果他一直持续输出内容，则可以从输出的内容中对这个人多几分了解。或许还会有志同道合的人因此和你成为朋友，也许其中还会有非常聊得来的人。（首页中的图标和关于都有我的联系方式，欢迎私信）\n积累与激励看到自己写了那么多博客，既是一种积累，后面再回来看，看着自己的内容不断精进，不断变化，意识到自己的进步与成长，进而给自信添砖加瓦，激励自己后续持续学习和思考。这是一种良性循环，只要熬过了最初不知道该写什么与不知道怎么写的阶段，就会不断有所收获。\n遇到过的问题出师不利：不知道该写什么在刚开始写的时候，这个问题是最让我头疼的。去年年底开始写开发周记之前，基本上都没什么内容。后来开发周记写了几篇，读书的时候也开始能够留下一些笔记和想法，渐渐的有了一些想写的东西。读书感悟，简单的科普，开发问题复盘，自己的一些想法，我还有很多想法都没有写出来，很多来不及整理的只能在我的笔记中默默等待\n仔细考虑的话，发生这种改变的本质原因是我去年开始做了各种各样的事情，同时渐渐开始养成记录内容的习惯（这个记录的习惯真的是非常重要，我的很多博客都是从碎片整理来的），因此我渐渐的有一些东西可说。如果你实在不知道怎么写，那就试着多留心观察自己的想法，自己经历的事情，说不定会找到什么答案。\n但是因为不知道写什么就放弃不去写了这件事情是完全不一样的。如果不去做些什么的话，你不管放弃几次回头看可能都不知道写什么。只要写了一篇，就更可能有第二篇，以此类推\n我在初学编程的时候也是不知道该写什么，因为我对这个东西没有形成一些印象，后来过了非常长的时间总算是多少入了门。在这个过程中我一直没有停止学习接触相关知识，即便现在看来都是错误的方式，但最终都是我过去的行为推动了我现在的行为\n想着一定要写好当然保证质量是很重要的事情，但是也因此有的博客过于追求质量、又或者说把握不住详细到什么地步就难产了。\n后来我在写第一篇读书笔记的时候写了一部分了，剩下的不知道怎么写，当我想到了我之前难产的博客以及如果再这么要求质量的话可能就完不成的时候我决定草草收尾。\n对于一开始来说我觉得还是坚持写下去更加重要，尤其是在你觉得自己很不擅长这件事情的时候。之前看到一个人的推特写目标是坚持输出内容，前二十多期可以不追求质量，这也是同样的道理。一开始总是不熟练，那就放低要求，先以完成为目的。\n写博客的误区除了我上面提到的问题，《暗时间》这本书中还提到了一些写博客的误区，我也在这里提及一下，加入了一些我自己的想法，有兴趣的读者可以去看原书\n担心自己的内容如果担心自己写的东西别人都已经写过了，我认为不需要去关心这些。这里要注意一个非常关键的点：写博客是为了更好的学习与思考，而不是说一定要去写什么别人没写过的东西。这不是毕业论文，不需要担心这些问题，你在成文的过程中的思考有所收获就够了。\n如果担心内容质量不佳，那就像上面说的想着一定要写好一样，不再赘述。如果担心想法有漏洞，那更不必担心，这个漏洞不会因为你不写出来而消失，写出来被别人指正反而是更好的改进方式。\n关注反馈上面也提到了写博客的目的，对于外部的反馈以及其他博客的好处来说这不过是附赠品，同时如果是为了外部反馈而写，那么很可能做出偏离学习与思考这一本意的行为。\n暗时间中有这样一句话\n\n只做你最感兴趣的事情，钱会随之而来\n\n这个例子是类似的，牢记初心，专注于你当前真正要做的事情，其他的附属品都会随之而来。\n碎碎念阅读博客的人更希望得到信息而非噪音。每个人都会有想法牢骚的冲动，但是这应该是在其他一些适合发牢骚的平台，比如说Twitter。\n我在之前也非常容易碎碎念，看到这条以后我下定决心以后其他输出内容的地方都不会掺杂各种碎碎念，还请读者们监督。\n亲自动手写了博客才发现的事情最大的感悟是输出内容真的是不容易。完成一篇内容充足的博客需要很久，同时又要保证质量的话是非常难的事情。\n看别人写和自己写完全是两回事。经常看别人在知乎上写了那么长一大段的干货，真到自己写的时候发现是多么困难。（这里我不禁好奇他们是怎么有时间能写那么多那么长的回答？）\n由于这些感受，我对持续输出内容的人逐渐开始有了更多的尊敬，因为输出内容确实是一件比较辛苦的事情。尽管有的时候输出内容也很开心，但是最终能够持续输出的还是少数。\n我与博客虽然我第一次接触博客的时候没有做下去，但庆幸的是现在我已经逐渐形成了这个习惯。即便去掉开发周记也还剩下许多其他博客，看到这些我感到十分欣慰。我会持续的输出内容，并且在保证不影响写完的前提下提升质量。\n文章的最后我想引用一句《暗时间》中的话\n\n人太容易为各种各样的事情分心，要集中注意力做一件事情是非常难的，而正因为难，少有人做到，那些做到的，就都变成了牛。\n\n只有坚持做下去才能做到，而实际上博客所带来的基本上都是好处，为什么不坚持做下去呢？\n不过能不能变成牛这不重要，只要坚持学习、思考与行动，最终总会变成大牛。\n","categories":["Thinking"],"tags":["Blog"]},{"title":"所坚信的事情","url":"/2021/08/23/Other/trust_self/","content":"唯有这一点，在我接下来的人生中一定会坚信不疑\n我一定能够做到无限接近理想的自己想了很久不知道该用什么词放在最后，聚聚，大佬，诸如此类的词想了很多，但好像并不符合我的心愿。虽然这种说法十分空洞，显得没有目标，但确确实实是我现在的想法，并不想成为别人眼中的谁，而是想要成为自己眼中的谁。理想自我是不可能抵达的，故只有无限接近\n现在理想的自己是什么样子的？我想起码是有坚固的自信，无论何时都能鼓起勇气，能够让自己的朋友会为认识我感到开心，能够专精某些领域。\n为什么要发一篇这样的博客呢？\n乔布斯说过这样一段话\n\nYou have to trust in something, your gut, destiny, life, karma, whatever.\nBecause believing that dots will connect down the road will give you the confidence to follow your heart even when it leads you off the well-worn path. \nAnd that will make all the difference.\n\n我选择它作为我一生的信念，同时这也是值得花费一生去做的事情。\n从今天、现在开始，又是新的起点\n希望这能够带给我信心与勇气\n带上一份歪歪扭扭的签名\n\n","categories":["Thinking"]},{"title":"论柳比歇夫","url":"/2022/02/04/Reading/Lyubishchev/","content":"也许有小部分人听说过时间记录法，因此也有幸听过柳比歇夫的名字；甚至可能会有那么零星几位十分幸运的人（至少在我看来是幸运的），读过《奇特的一生》这本书并且对他有了一些了解\n大部分人看到标题，一定只有一个问题：柳比歇夫是谁？\n他是一个大半生都在支配时间的人。我想你一定会对支配时间这个词摸不着头脑，还会有人在想时间面前人人平等，时间怎么可能被他支配？\n那么我们先从他的成就谈起吧\n他的成就\n前苏联的昆虫学家、哲学家、数学家。毕业于圣彼得堡国立大学，一生发布了70余部学术著作，从分散分析、生物分类学到昆虫学等。业余时间研究地蚤的分类，还写过不少科学回忆录。 各种各样的论文和专著，他一共写了五百多印张。五百印张，等于一万二千五百张打字稿。\n\n除了这些，数学、历史与诗歌他都十分擅长。毫无疑问，他是一个全才，并且在一生中做出了超乎想象的成就。他是怎么达到这样的成就的呢？\n开始早在他28岁的时候他就已经找到了他一生的奋斗的目标：创造生物自然分类法。尽管遭受怀疑他依然开始着手他的任务，并且将一生投身到其中。\n\n他当然相信他能做到，但总是要从另外什么地方再去挖掘一些力量，再去挖掘一些时间。\n\n而为了完成这一切，他选择了“支配时间”\n时间完成事情需要时间，这是一个不可避免的内容。而对于时间的使用，很自然会想到利用好各种时间，他自然是做到了，将各种碎片时间利用到了极致。但只是利用碎片时间自然是不足以使他获得如此成就\n\n应当不断挖掘一切时间潜力。明摆着，人不能者是每天工作十四五个小时。应当正确利用工作时间。从时间中去找时间。\n\n接着他就开始了记录时间的生涯。他将自己做得几乎每件事情所需要的时间记录下来，进而达到能够十分清楚地了解自己做每件事情的时间，在了解自己的时间后进行十分周密的安排（注意，这是在他能够保证利用各种碎片时间的前提下）。\n这些内容我觉得比起我来讲不如来看摘录的原文\n\n计划就是挑选时间、规定节律，使一切都各得其所。头脑清醒的时候应当钻研数学，累了便看书。\n\n\n这个方法之所以能够存在，是依靠经常的计算和检查。没有计算的计划是盲目的计划，就象某些研究所那样，光会做计划，却不去操心这计划能不能完成。\n\n他对于时间的理解是非常深刻的。而最重要的则是他使用了一生来实践这样的方法。\n了解时间记录法后我偶然想到在一本书中看到的话：不是要达到什么目标，而是要形成一个自己想要的系统，目标会自然而然达到。再看柳比歇夫的经历，亦是如此\n而书中也有很多时间相关值得回味的内容，在这里摘录两段\n\n为了节约时间，实干家下了马车坐上火车，下了火车坐上飞机。发明了电报和电话来代替书信，电视代替了剧院，拉链代替了扣子，圆珠笔代替了鹅翎。电梯、计算机、百货公司、电传打字机、电动制刀——这一切发明，都是为了替人节省时间。然而，不知道为什么，人越来越感到时间不够用\n\n\n时间的分配几乎同两千年以前赛纳卡时代一摸一样：“我们一生的时间，大部分用于错误及种种恶行；很大一部分虚抛浪掷，无所事事。我们整个一生，几乎都没有用来干应当干的事\n\n代价与幸福可能很多人会觉得，这样机械式的生活真的快乐幸福吗？这里可以肯定的回答，至少对他来说是这样的。这里我有一个比较奇特的视角来讲，他清晰的明白自己的能力边界，因此他不需要担心时间不足或者担心自己做不到，他不需要焦虑在这种事情上，减少了焦虑并且能够更好的发挥自己的才能。\n而在作者看来他亦是幸福的。在书的一开始，作者就提到\n\n我从中得到的一切，对于我来说，是一个新发现，使我参透了一个人一生的秘密。\n这个秘密是——怎么生活得更好。\n\n但是这一切是有一个前提：他不断的给自己设定更高的要求，并且他有着源源不断的好奇心和求知欲，而这样做正是满足了他的欲望，因此这一切对他来说是十分幸福的。\n在写下前面的部分，回顾文中的内容，在最后也看到了作者持有着同样的态度\n\n只有一个人向自己提出崇高目标时，这个时间统计法才能成立\n\n能力边界与高要求他持续对自己高要求，并且在明确自己能力边界的情况下不断在边界中前进\n\n 他不让自己负担过重，力不胜任；他总是循着他能力的边缘前进，他对自己能力的掂量愈来愈精确。这是一条永不停顿的自我认识的道路”“如果每个人都能知道自己能干些什么，那生活会变得多么美好！因为每个人的能力都比他自己感觉到的大得多。他会变得比自己想象的更为勇敢；他会变得更坚韧、更有力，更能适应环境”\n\n还有一段我觉得是非常棒的描述\n\n对于柳比歇夫，任何时候都不能说他已“成为”怎样一个人。他永远正在“逐步成为”怎样一个人。他一直在探索，一直在变化，他总是重新考虑，不断提高对自己和对自己理想的要求\n\n对知识的热爱以及偏离目标他学习知识，数学、历史、文学、音乐等等各种方面。\n他不善于克制自己，经常迷上同他完全无关的东西中。他无法抗拒周围环境的诱惑，他无法抗拒那些知识。但是关于这些，作者给出了很明确的观点\n\n“天哪，对于嗜癖和精力分散我们又能知道些什么呢！谁能说清楚“人应当是怎么样的”。我们从何知道人应当是怎么样的呢”\n\n不过有一点要注意，不论怎么样他最后都能够确保任务的完成，这也和他对自己能力有着清晰的认识有关。\n而“偏离目标”，也就是学习各种看似不相关的知识实际上也会产生一些意想不到的效果。达芬奇就是一个非常擅长将不同领域的知识融合在一起的人，他的许多创作都是如此。\n关于这本书作者在本书的开头就在提到如何吸引读者这一件事情，而毋庸置疑的作者达到了他的目的，不像我后来看的达芬奇传（作者沃尔特 艾萨克森）真的是无聊至极。\n正如作者所期望的那样，每读一点我就更加迫不及待的想要看到后面的内容，作者巧妙的描述出了一个饱满的柳比歇夫的形象。读完这本书后让我产生了更强烈的阅读其他传记的欲望，之后也就顺势读完了乔布斯传。\n读这本书的过程中自己被柳比歇夫所吸引，也许这就是我所理想的样子。他对自我的要求、他的自由、他的幸福、他对自己的严格要求、他不断增长的边界，无一例外充满了魅力。在写到这一段的时候越写下去越发不可收拾，我着了迷、入了魔，那段时间读到相关的部分都会感到非常兴奋。\n我希望这本书给别人的印象不仅仅是只有柳比歇夫的时间统计法，尽管是在读者的角度，我依然想要让其他阅读这本书的人更多的去体会、感受柳比歇夫的各种特质，而并非只是局限于时间统计法，时间统计法本质上是他的特质的衍生产物，是他为了完成自己的目的所选择的一条道路。\n而完美的是作者也将这些特质巧妙的讲了出来，也没有花费太大篇幅去描述时间统计法。我最初也并不知道柳比歇夫是怎么样的人，但至少读完本书之后对他的形象有了一个饱满的认识，尽管这些只是局限于作者所描述的部分。\n最后整理这篇文章花费的时间比预想的还要多很多，整理的过程中几度想要放弃了，但是整理的时候多少又找回了一些热情，又回想起了很多，最后还是坚持了下来。请原谅我个人能力有限，文中内容简陋，而且内容有所遗忘，无法在这么短的篇幅中将他的魅力讲述到极致，只能提及部分性格特点，而书中所讲述的他更为有趣。如果你是对自己有要求的人，那么我非常推荐你去读这本书，去感受他的人生，感受他的精神，也许你会和我一样着迷。\n虽然我做不到柳比歇夫的时间记录法，但是我可以学习他的高要求、不断在自己的边界进步、他对知识的热情，这些也足够我获得很大的成长了。我应该认真思考如何像他一样对自己不断的提出要求并且达到这些要求，而不只是空谈，写完这篇文章的今天我该拿出时间好好反思。\n最开始写这些文字的内容是几个月前我刚读完这本书的时候，现在将其整理成文。开头一段现在回头看多少有点怪异，但我最后还是决定保留。不过不论如何，我现在依然很为能看到这本书并且了解这个人而感到幸运。\n","categories":["Reading"],"tags":["柳比歇夫"]},{"title":"运气","url":"/2021/06/12/Other/luck/","content":"攒了很多文想写，但由于总觉得自己了解的还不够加上生活比较忙碌迟迟没有写，不过哪怕写的再差，月底之前一定会再憋一篇技术文出来。\n最近比较想写运气这个话题的内容。因为各种意义上，我实在是”倒霉”，尤其是最近几个月。比如说前些时间让我很头疼的毕业相关事宜，刚从学校那边上回北京高铁，导员就通知我一个放进档案的表格字写的不合格要我重写，填一些论文以及实习材料的时候都全填完了论文指导老师才说哪里哪里应该怎么写，好多又白费了。\n先别急着关闭博客，我不是来讲我多”倒霉”的。\n倒霉不是倒霉我觉得这其中一部分并不是真正随机的事情，它们可以通过人为因素来一定程度的避免，这也是为什么我在前面的倒霉加了双引号表示。比如说要我重写的表格，明知道要放进档案但我还是没花太多精力去一笔一画的写导致字迹略草（虽说比平常的字好很多了），如果我当时再认真点写或许就可以避免这所谓的“倒霉了”。\n为什么要这样区分？这些事情中自己总有做的不够好的地方，如果能改正那可以减少下次发生类似事件的概率（@@@：重复同一件事情是无用的，木大木大），进而还能间接减少坏心情\n改变自己的视角，将出现的问题、差错视为一个发现自己问题并且纠正的机会（这是一场「试炼」，我认为这是一场让我战胜过去「试炼」，我接受了，只有在战胜那不成熟的过去后，人才能有所成长…你不也是一样吗？）\n把一切都推脱出去的行为一点也不可爱（划重点）\n误区尽管这类事情中很多是个人因素，但不要因此苛责自己，出错这件事情是不可避免的。并不是说因为自己应该做到些什么就把责任全部归咎于自己身上，比如说你在人行道没看路有摩托撞上来了，自己没看路是一方面，但是对方也没有遵守道路行驶规则。\n再重复一次，改变这些看法的本质只是为了改正自己做的不合适的地方，不要因为这个而苛责自己。实际上确实存在容易将责任归于自己身上的人，如果你是这样那希望本文能够让你意识到问题并且开始萌生改变的想法。\n人为防范的例子很多人可能都会有到学校/公司之后发现今天晚上会有雨，但是没有带雨伞的经历。其中也有不少认为今天真倒霉，偏偏要下雨了没带伞。但如果你考虑到这种情况还会发生，于是下次又买了一把伞放在学校/公司那就不一样了，不会因为同样的理由被雨淋，减少了觉得“倒霉”的次数，进而心情还会好一些。\n无可奈何的情况除了人为可控的情况，当然也有一些不可抗力，比如说抽卡，抽卡，还有抽卡，但你钱砸的够多还是能抽到。这种情况那我只能说平日多扶老奶奶过马路，多关心孤寡推友 比如作者\n最后，希望读者能够早日脱离“运气”的陷阱，减少运气对自己的情绪影响以及能够从中学到些什么。\n","categories":["Thinking"]},{"title":"iPhone Ultra Max(iPad mini)体验","url":"/2022/01/30/Life/iPadminiReview/","content":"曾经我以为，不考虑预算的情况下iPad就应该买最大屏幕的，直到那一天我将iPad mini放入了我的兜里。但iPad mini在我看来就是一个大号手机，某种意义上还是没错\niPad mini也已经入手有半个月了，半个月内重度使用，过了那阵新鲜劲以及各种问题踩坑也踩的差不多了，这个时候写下的体验我觉得应该是相对比较全面的了\n我的痛点我觉得iPad mini解决了我目前使用手机的各种痛点。我的iPhone8plus目前有存储不够，电池容量太小，只能单卡而我自己的卡流量又不够。如果只是这些问题可能有人说换新机不就完美解决了？但是换新机也不能解决屏幕太小的问题，想看点文章或者需要跨app处理一些内容iPhone这么小的一个屏幕实在不方便\n周末需要频繁挤地铁，地铁上的时间非常久，没有座位的时候拿iPad Pro非常不方便，即便有座位从包里拿出来也是很麻烦的事情，手机屏幕又太小，iPad mini的大小可以说是完美。\n所以我实质上是将iPad mini当作我的新手机，我的iPhone8plus还能再战好多年。以下体验更多是从手机的视角来看待\n\n实际体验首先：不玩手游，所以并不会提到相关的内容，想看手游相关的建议你去看各种评测视频\n重量感觉拿着没有任何压力，只比带着保护套的手机重了几十克。这个大小能够装到兜里，出门的时候看地图也非常方便。受益于大屏幕，看文章非常方便，不知道比iPhone高到哪里去了。\n电量够我出门用一天，再也不用挂着移动电源到处走了。这是我某一周的使用情况，如果开了省电模式一天非常稳妥，更何况我出门的时候电只有80左右\n\n出门在外，iPhone直接扔包里，有什么电话或者短信可以直接转接到iPad mini上\n网上所说的什么果冻屏至少我没什么感知，尽管有这也是显示技术不可避免的问题，120刷新率对于iPad mini来说不太可能用上（而且绝大部分情况不需要刷那么快）这一点争议非常大，建议你去实体店体验一下\n曾经我以为iPad正确的解释姿势就是Face ID，但直到出现了疫情…iPhone已经支持戴口罩解锁了，iPad pro什么时候才能用上？指纹解锁在现在这个到处需要戴口罩的情况下还是很棒的（但是我手指各种掉皮就还是白给\n谈一点没什么关联的，直到我用上了iPad mini才发现iPad Pro是多么大，以及各方面是多么好……不论是扬声器还是屏幕刷新率，这些我之前都毫无感觉，真的是没有对比就没有伤害\n不可避免的问题极其多余且愚蠢的设计这是我一定要着重说的一个问题。\n所谓的智能音量键调整位置，我的感受就是多此一举，用了一周并没有觉得多么方便，反而每次调整音量不仅要想按哪里，在屏幕没锁定旋转的情况下大概率会按反。我听的不同来源的音频声音响度是不同的，如果忘了提前调整音量则需要快速反应按下减音量，而这种设计又会导致你大概率要先思考或者先按错一次才能按到正确的地方，对于耳朵损伤还是非常大的\n因为有Touch ID，开屏的时候会提示按键位置在哪里，这个本身是好事，但是如果屏幕方向是竖直摆放这个提示则会导致无法看到电量，只是想打开屏幕看一下电量的时候非常难受\n上面这两条，我开始怀疑苹果的人机交互工程师有没有真的自己用一下，一家曾经以设计闻名的公司（个人看法）额外添加的这些设计却反而添加了负面体验，这么大的公司应该有合理的流程避免一些问题，尤其是对于apple来说。但是这种不良设计依然出现了，不知道该怎么评价了\n大屏幕大屏幕随之而来的就是你在看的东西更容易被其他人看到，对于非常重视隐私的人来说是灾难。另一个就是便携性不可避免的要下降一些，很多场景不能单手握持，但是只是读文章，单手下滑是没问题的，这是必须做出的取舍。还有就是我衣服兜比较浅，总觉得要掉（后来有一天不知道为什么过于大意，在同一个地方摔了两次….），装到裤子兜又麻烦，到了夏天衣物可能更难携带iPad mini\n字体略小，将字体调到了最大还算可以接受（除了一些app字体并没有适配好）\n到户外这个屏幕亮度不够用。这是我个人觉得最难受的\n双手握持打字略微有些头重脚轻的感觉（竖屏），而且有一种要滑出去的趋势。以及键盘还不是完全一样的，需要一点时间适应。但对我来说键盘录入大量内容可能还是偏少数，更多的是用它去阅读\nOS与应用iOS应用仍有一些不适配的情况，万幸的是可以手动放大到一个勉强能用的状态。但是更离谱的是支付宝只能登录一个设备，这产品经理是不是张小龙带出来的。当然这种环节不可避免要把微信拉出来挨打，目前iPad版和mac版是冲突的，干脆不用mac上的了，反正我的微信只用来联系家人。除此之外还有qq不能多个iPad上登陆，也有点小烦，等等还有很多类似的问题\n还有一些并非适配问题而是不能用的，比如说健康和Apple Watch的管理，这些还是要依赖于iPhone。以及就是iPad OS诟病已久的没有天气和计算器。以及某些离谱的应用，比如说企业微信第一次登陆还要手机确认……\n代替手机由于不能打电话的硬伤，你并不能真的完全离开你的手机。尽管现在的人电话场景是“十个里面九个骚扰电话，还有一个是快递”\n周末坐地铁的时候意识到不能刷nfc，突然想到还可以刷Apple Watch，但我戴在左手刷起来略显别扭。什么，你说扫码？\n\n购买相关如果去官网购买，很可能需要等待两个月才能到货，这个着实比较离谱了，因此我选择了京东购入，也就错失了刻上iPhone Ultra Max的机会\n本来想要购入一个紫色，但是去实体店查看跟示意图完全是两个样子…如果想要购入我建议你还是去实体店亲自看一下\n我会用它完全代替iPhone吗除了初拿到的欣喜，用了一段时间以后发现很多时候还是用手机方便，但是我依然没有后悔买了这个iPad mini，尽管在上面吐槽了它这么多问题，但我对它实在是非常满意（售价除外）。某种意义上可以说是因为没有竞争对手，我们只能忍受它的所有缺点。如果你有类似的需求，那非常推荐你。如果没有，那我还是推荐买大屏\n最后加一个小技巧：如果你的iPhone像我一样只是需要维持最低限度功能，你可以在快捷指令里面设置自动化，当断开电源的时候自动开启低电量模式，平常充电超过80%IPhone会自动关闭低电量模式\n本文绝大部分在地铁上一口气用iPad mini写完，再也不想用iPad mini打这么多字了\n","categories":["Life"],"tags":["iPadmini","Apple"]},{"title":"游颐和园","url":"/2022/09/17/Life/TourTheSummerPalace/","content":"下午从新建宫门入了颐和园，上次来已经是去年冬天的事情了，与上次不同的是十七孔桥现在不再设置栏杆，遂带着好奇心走向桥的另一端。到了对面看也没看到什么特别的，也没什么好拍的。倒是看到了许多经典十七孔桥照片的视角，但非金光穿洞日这些地方不太值得拍。\n走着走着开始感觉热了起来，身上出了很多汗，来的也不是个好时候，几乎可以说是一天中最热的时间段，北京这个日子甚至还能到30度。但之后走到了一处三面被树木环绕一面朝湖的阴凉地，此时微风携带着湖水的清凉吹过来，甚是舒服。也许是这阵清凉的感觉激起了我调动更多感官去感受周围一切的想法。我开始触摸岩石，建筑，体会它们的纹理与摸上去时手的触感。看起来尖锐的岩石摸上去并不扎手，大多锋利的边缘都已经被时间所打磨的光滑，像极了经历了几年工作后脱发的程序员群体们（bushi）。自己多久没有摸过这些东西了呢？每天的手接触的都是冷酷无情的机械设备，这样的我与自然完全断开了联系。\n由于包比较重，体验了没多久便找了个地方坐下休息一会，由于没什么事情做就开始发呆。看着湖中一艘艘小船驶过，脑袋里的新想法似有似无，但脑袋里想的事情哪怕是自己也很捉摸不透，就放任它在混沌中产生新的混沌吧。\n没多久又决定走回了起始点，向着北边的东门走去。路上回想着去年冬天拍的视角都是怎样的，想要拍一组对比的照片，之前拍的照片没有发过，而群晖的quickconnect太慢加上没有折腾内网穿透也就无法访问家里的照片查看，最后只有凭借着记忆多拍了几张。回来发现好多之前觉得不好看都删掉了，就剩下这组对比，视角差的还挺大，不过意思传达到了，有机会再补吧（下次一定！）\n\n\n拍的过程中刚才调动感官的想法再次冒了出来，开始像个新生儿一样带着好奇心触摸各种事物。树干带给我的印象是粗糙且潮湿，后者大概是因为在湖边吧；而树叶带给我的感觉是柔软但边缘有些不平整的毛刺，不同种类的树叶摸起来的感觉自然也不同，但没有太多的印象了。接着是感受着太阳烘烤下岩石的温暖，以及各种地面与建筑表面。看到了小时候经常看到的一种墙面，多久没有这样仔细触摸过这样的石墙了呢，不过这倒也不是什么问题。还仔细觉察脚踩到地面的感觉，鹅卵石地面与普通的水泥地有着各自独特的感觉，由于隔着鞋子需要更加注意才能体会到，不过最关键的还是去觉察那个部位的感觉，如果没有觉察那么习惯了以后很容易就会忽略掉这些感受。\n回到走向东门这个话题，本来此行就是为了桂花来的。中秋前两天忙着各种地方拍月亮，第三天累的只想休息，也就没来看桂花，明年可能会来吧。这里我所看到的有金桂和银桂两种，银桂只有一个小花苞，大概花期还要点时间，遗憾的是金桂大都凋谢的差不多了，万幸的是气味多少还残留一点。本着来都来了的优良传统，我想再好好找找再走，果不其然最后找到了一株还有一些花朵残留的金桂，兴奋的我赶紧放下背包赶紧收拾东西准备开拍。要去拍的时候发现有几个大爷大妈们拿着手机在拍，拍遮挡视线倒是也没啥问题，等一会有位置再拍就好，只是都把手机怼到了树枝里面，树枝的强烈颤动导致许多花都掉了下来。\n\n\n还拍到了一只小蜜蜂！\n拍完桂花则是向着东北角出发，尽管来过两三次但一直没有走过那边的路线。在看路线施工告示的时候一个老奶奶和阿姨跟我讲这里的路现在是怎么回事，后面跟着老奶奶和阿姨进了谐趣园，听了很多有意思的故事，比如说谐趣园里面有一个特别大的柳树，曾经有一只白鹭每天来水池里捕食鱼类，有一位拍到下落、下水捕捞、飞走的照片，之后第二天开园的时候就来了得有两百多的人把谐趣园水池旁边的路围绕的水泄不通，一个个都架好了长枪短炮。白鹭也确实来了，但是看到人这么多也就一直在柳树上没再下过水，老奶奶等到了中午十一点多没来也就走了（前一天是这个时间拍到的）。在北京的人应该能想象，无论你去什么有名景点总有一些老大爷全副武装在拍些什么。\n之后听老奶奶讲了很多关于谐趣园里的事情，这里建筑的风格、合适的拍照点、以及一些历史背景之类的。在园内几乎转了一圈，最后坐在了园内的走廊讲起了各种各样的事情。“什么也不做坐在这里喝杯茶、看看景、聊聊天就挺好的，按照我们老年人的想法是这样的”，对此我深表认同。这种宁静也未必一定要老年人才应该去享受，每日都市的喧嚣又快节奏的生活偶尔也需要这样安静的坐下来，不急于做些什么，只是看着周围漂亮的风景，和旁边的人聊聊天，大概此时周围的环境会像海绵一样吸收掉压力、焦虑与烦呐吧。谐趣园里面很多地方设计的也确实非常巧妙，景色也很不错，看到有人坐在走廊里读书。我想夏季的雨天在这里漫步一定非常惬意吧，听着雨击打池塘与地面的声音，看着满池子绽放的荷花与游动的鱼群，和旁边的人聊聊天或者看看书，这该是多么美妙的景象，明年如果还记得这件事情我一定要来体会一次。不过赶上休息日合适的时间下雨也确实是一件难事。\n我的照片难以显现出这里的一些设计之巧妙，还是需要亲自体会才行\n\n\n老奶奶还讲了很多关于圆明园的故事，说道圆明园今天有爱国教育活动免费，虽然早就得知了这件事但我想要避开人流，因此今天也就来了颐和园。即便圆明园很大，很多地方人多的话很多地方依然显得空，但是我更想要安静的地方。人也不需要那么多，有认识的人就够了。大概坐了半个多小时，老奶奶和阿姨与我告别了。我在园内又转了好久，拍了一些照片。幸运的是今天又拍到了停留在花朵上的蝴蝶，上一次拍到还是之前去玉渊潭的时候拍到的蝴蝶落在樱花上。\n\n拍了几张后出了谐趣园右转，发现这里有许多猫。每天云吸猫的我当然不肯放过这样的好机会，于是准备装备开拍。但这个时候我有些冲动，看到一个小孩子要拿一根草去动猫我竟然动手制止了，我并没有用什么力气，也没想吓到他，但是也算是碰到他了，还说出了不要动猫这样的话，随后他的家长说道他也没有要去动猫，我也不该动手。此时的我算是十分的羞愧，不是他是否真的要去动猫，而是我居然动手了，只能连忙道歉，他们走后我内心还是一阵不安，为了刚才做的错事感到一阵情绪存在。也许是赎罪性质，我只是挂着相机，但是迟迟没有去拍。我蹲在猫猫面前，一直学着招财猫的手势向猫猫摆手了半天，当然不仅是这个时候，之后我拍猫的时候一直都在这样摆手，不知为什么总想要做出这样的行为。随后我觉得不应该为了这些事情烦恼，拍猫要紧，连忙拍起了猫猫。这只猫一开始我以为它不开心，但是最后发现大概是困了，做什么动作，哪怕是接近它都毫无反应，最后它就在那边睡了过去，我也只好不再打扰。\n\n睡得可真香啊，在做什么样的梦呢\n随后周围拍其他猫的时候发现有一个铁栅栏后面有更多的猫，并且对面是可抵达的，遂即决定赶过去拍猫。赶向铁栅栏后的路上，开始感觉到疲惫逐渐侵蚀我的身心。开始有点无力，有一点点晕，还毫无理由的产生了一些负面的想法。虽然没走多少步，但架不住包和里面的东西实在太重，上午去上钢琴课还背了一大堆课本，同时手里还在举着相机四处拍照。但我不想就这么离开，找了个地方坐下尝试恢复一波能量后就继续出发。\n到了猫猫的聚集地，呆了半个多小时，拍了几张照片。拍照倒是没什么，有意思的是和猫猫的互动。和一只猫对视，我往后退一步，它就往前走一步。这个很难以照片的形式体现了\n\n\n\n\n猫猫也拍完了，我走向出口的路上坐在了一个延伸出的木台阶上，看着眼前翠绿的世界，就这么静静的坐着，除了偶尔听一下歌词的内容之外什么也不去想，什么也不去做。我很喜欢这里，宁静，有树有湖，让人感到安心，如果小雨天在这里散步该有多棒\n\n\n随后边走边随便拍几张，最后终于出了北门。饿的不行，便直冲离这最近的一家速食店，此时不得不说KFC虽然其他方面不行，但是店是真的多，这周围甚至都没看到其他能吃饭的店铺。KFC旁边的自动售货机买了一瓶脉动，象征性补充一下流失的其他物质，身体缺水的情况还是不太想直接去喝可乐，之后在KFC随便吃了点就坐上了回家的地铁。坐地铁的过程中倒是没什么好说的，离这也不远，大概五六站的路程，只是上车的时候正赶上日落的时间，出地铁时周围已是一片漆黑，不由得让人想要感叹时间流逝之快。\n今天比预想的逛的要久，非常累，明天大概会去圆明园吧，并且会更累。主要是听说那边现在有花海，我还没有亲身经历过什么花海，之前去过北京植物园但是并没有见到数量多到花海程度的花，毕竟植物园更关键的是多样性。\n以下是宝可梦爱好者的专享内容。\n虽然前面说道想要体会各种感官，但今天一下午都没有摘下耳机。下午基本上就是宝可梦dp相关的几首音乐反复听，原本是想找最终对战白菜姐的bgm，但是偶然搜到了动画的op，倒是也很好听就一起加入了清单。对战白菜姐的bgm就没什么可讲的了，讲讲op的部分吧。\ndp的动画主题曲给我印象最深刻的是这么两个地方：一个是跨越天冠山，另一个是超越时间与空间。\n高いテンガン山　越えていこう\n天冠山对于这作游戏来说是十分重要的，全部的游戏主线剧情，甚至整个地图我都觉得是围绕着天冠山设计的。而天冠山内部的剧情又相对比较难打，跨越这座山给我的感觉不仅是单独的征服一座山，而是克服诸多困难。尽管登山本身是如此，但是只是说跨越山对于我一个不爬山的人来说真的没有什么感觉。\n時空を超えて 僕らは会える、まぶしいみんなの顔\n本身dp的两个封面神就是代表时间与空间，而超越时空的相会又是十分珍贵的。后面还有きらめく瞳　ダイヤかパール这样的歌词，很容易就会联想到“友情是珍珠，回忆是钻石”这句话。不得不说dp不仅是神兽设定B格很高，而且动画本身的立意也很深刻。\n一直在听的除了上面提到的两首还有对战赤日的bgm，这首bgm给了我许多不一样的感觉，略低沉的开头让我联想到了对战之前黑暗的世界，想到了对战时黑暗的背景，同时联想到了赤日的角色性格。\n这几首都非常好听，况且这一作的宝可梦对我来说也是最喜欢的。\n对战dp神以及三蘑菇的bgm其实也很棒，但今天下午并没有反复听。听这一下午搞得我很想收藏ost\n最后放一下三首歌的Spotify的链接吧，其他的bgm都可以在专辑中找到\nop：together\nhttps://open.spotify.com/track/5eO5Bnv3wLgW9qawRpYfFR?si=421e89091bcb494a\n白菜姐对战时的bgm\nhttps://open.spotify.com/track/0u18DUjJSoq9gDQhxJBgxD?si=d257af05927d4c9d\n对战赤日的bgm\n[https://open.spotify.com/track/25ns1GhXoBMo7XFfFtcJbU?si=a949e8cbdac54081](\n","categories":["Life"],"tags":["颐和园"]},{"title":"2021年终总结","url":"/2021/12/26/Summary/summary-2021/","content":"下周末就是明年了，今年的事情不能拖到明年做，于是趁早把总结赶了出来。2021年对我来说算是各方面变化比较大的一年，还是有不少值得回顾的内容\n专业、工作与学习最大的变化莫过于大学毕业成为社畜了，找工作的过程算是十分坎坷，不过好在最终找到了一份合适的工作。工作中也学到了不少东西，自己也有了许多进步。看着自己的改变，看着自己的GitHub，今年总算可以说自己入门编程了。最大的遗憾是这一时间点来得太晚，每天下班回家留给写代码的时间只有一个多小时，如果还是学生的话时间能多太多。今年的习惯养成比较晚，所以只有最后的时间格子是填满的，明年的话会坚持每天下班后写代码，填满小格子\n\n今年的Github \n\n年初做了一个ast解释器作为毕业设计，随后随着找工作以及各种事情渐渐停止了维护。而年底又开始基于之前的内容添加编译的部分，希望明年能达到自己对于这个项目的初步目标，并且在这个过程中学习到更多编译器相关的知识。同时我开始每周写一篇博客记录本周开发的内容，序言链接在这里\nRc-lang开发周记 序 | Homura’s Blog\n今年开始读一些书，做到了平均一个月读一本专业之外的书，遗憾是读书笔记大都咕咕咕了，不过还有一些自己的思维片段，有时间会整理成文。明年的话会继续维持这个进度，会试着写一些读书笔记（在新建文件了）\n尝试入门GTD，但遗憾的是并没有用好，明年还要在这方面继续努力。\n尽管GTD运用不佳，但是年底的时候开始养成了一些习惯，这些习惯能够很大程度的帮助我抵抗自身的“懒惰”。其中一些习惯的养成受到《微习惯》和《原子习惯》这两本书的影响，后者比较推荐，能够涵盖了很多前者的内容。书中提到了一个让我印象深刻的概念：习惯叠加，意思是养成一个习惯之后可以在这个习惯之后接另一个习惯，而且很容易养成，像我现在每天晚上回家的时间都是数个习惯叠加在一起，养成的过程也没有太痛苦。\n生活由于成为了社畜，最显著的变化就是要自己租房住了。和宿舍生活相比，入睡时间再也不需要受到别人的影响了，同时住的地方肯定是比宿舍要大的，体验好的多\n另一个变化则是有了收入，因此能做的事情变得更多了\n比如说年底入手了种草许久的相机，开始尝试摄影，拍到了一些满意的照片，尽管其中也有许多瑕疵品。希望明年年底的时候能够自己设计出一个相册来展示自己笨拙的作品。\n除了能做的事情变多，同时还需要关心自己的开支情况。今年第一年工作，总之就是疯狂支出，月月实现负收入。买了各种以前就想买的东西，这个状态感觉还会维持一两年。明年开始大概会花很多钱在自己身上，通过氪金变强，存钱感觉比较困难，只能说尽力存一些吧\n年底渐渐开始接触各种各样的新事物，而这些事物又会激发我的各种想法（我逐渐理解一切了）。除了新事物，年底开始叠加了一些习惯使得我越来越忙碌。越来越多的事情我进入了我的生活中，可以说是有些充实，但是充实的不只有要做的事情，焦虑也是一样，对于事情做不完做不好的焦虑又逐步放大了起来，这也是我需要克服的点。\n除此之外，今年也有幸在推特上认识了一些新朋友，对于他们不嫌弃我这件事情深表感激\n自我好转一个很重点的问题就是自己的身心感受。比起去年或许有了一些好转，在一些事情上情绪波动也没有那么大了，我想这一定和感受到内心的不合理有关。至于治愈之法，上面提到的《神经症与人性的成长》书中也有提到\n\n所有精神方面可能涉及到的知识，都可以使每个人有机会找出自己的困难所在。此地我们同样地要问，病人必须要知道什么才能铲除他的自负系统，以及除去由此所衍生的一切附带影响？我们可以简单地说，他必须晓得我在本书中所提到的每一件事：他对荣誉的探求，他的“要求”，他的冲突，他个人的特别解决法，以及所有这些因素在他的人际关系方面与创造力方面所具有的影响此外，病人不可只知道这些个别因素，而且也应该知道其间的关系与其相互的作用\n\n我的理解是当你彻底理解各个组建之间的联系的时就会慢慢破除。可惜的是这本书我只是年初读过一遍，许多地方理解并不到位。对我现在来说读过一遍的书还是挺难再花时间去读第二遍的，更偏向于去读新的书，但是鉴于这本书的重要性明年一定要再读一遍。\n还有一个想到的好转是破除了一些所谓的“完美主义”的误区。我自己并没有什么完美主义，只是之前会以这个作为幌子，找借口逃避问题罢了。现在一些东西哪怕做的很烂，也会开始行动了，就像这篇总结以及目前正在维护的开发周记一样\n也许是冥想所带来的习惯，我渐渐开始体会自己的不同感受，发现了自己内心空无一物。能够发现这一问题就是一个很大的进步，希望明年能够通过更多的行动给自己的内部逐渐填充些什么\n顽固除了好转，自己依然有一些顽固成分无法脱离。比如说仍有许多无法避免也无法与之相处的执念，这对我造成了很严重的负面影响，经常会因此沉溺于痛苦之中\n以及今年还是比较“自闭”，这个好像没什么好办法。所谓的“不适合和别人相处”只是一个逃避问题的幌子罢了，更深的原因是内心里还残留的一些性格扭曲，这个问题比起无力处理更准确地说是我不想处理，也先这样吧\n上面说的内容很大一部分要归咎与身体与睡眠。睡眠这个对我来说是一直无法解决的问题，长期的睡眠质量差导致我很多时候状态并不好，这和我的焦虑、以及焦虑的应对措施都有着联系。\n目前的应对措施是每日冥想加周日的跑步锻炼，这样的运动量是不太够的，但是时间确实不够用以及日常是步行上下班因此削减了运动时间，明年的话准备采取一些新的方案来对抗这些严重的问题。\n这一年这么写下来，今年好像做了一些事情却又好像并没有做多少事情。做了一些事情是因为确实有一点成果，比如说读了书，思维发生了转变，专业方面有了进步，养成了一些习惯等；而没有做多少事情是因为这些事情对于一年这个周期来讲并不多，而且大半年里自己的周末时间很明显并没有怎么用好，基本上都是在无意义的消耗时间。\n另外许多事情是年底才开始做，起步比较晚，但是对于明年来说可以开一个好头\n明年愿景不用多说，身心健康是一定会有的，这个是持续的目标，也是最难达到的\n想要成为编译器专家，但是我觉得自己能熟练掌握就不错了，先以这个作为目标吧……我能做的只有一点点积累，所以会先从搞好当前在做的编译器开始，在这个过程中让自己编译器方面的知识获得提升\n想要拍到很多好照片，年底想做出自己的照片集，不过这还需要学习设计排版的知识。希望能在摄影的过程中发现更多的乐趣，并且能以此为媒介感受和表达更多的东西\n自己想要和别人一起努力，而不是都是自己一个人闷头做。我认为和他人一起努力很多时候会产生数倍的效果，但是我自身的种种导致最终总是会使得他人远离我，不论是哪里。我自知这很悲观且问题出自自身，但这也是我的无奈\n想要写好博客，而不是像今年一样咕咕咕；还想要学到很多新东西，想要认识新的人等等\n明年想要的太多了，我的贪心今年仍未衰减，反而更强烈了。明年也要为了自己的各种想法而努力，不过对于我这样各方面能力值都不够的人贪心一定要付出更多的代价：需要花费更多的时间（现在每天的时间都已经满满当当了），精力会分散，对于本来精力槽就不高的我提出了挑战\n最后自己的年终总结也没什么特别的感受与想法，只是简单地以流水帐的风格写了一下今年的事情，不过这就够了\n比较期待明年的到来（MBP，我的MBP）虽说回首过去与展望未来都会扰乱内心的平静，但我还是按耐不住自己的期待。\n明年一定是更加忙碌的一年，也是自己会有更多成长的一年\n","categories":["Thinking"]},{"title":"司机与列车","url":"/2022/05/21/Other/driver-and-train/","content":"\n与我在列车道相交处相遇吧 \n\n图片出自萌娘百科：天朝铁道少女:南车篇条目 \n\n列车\n提到列车，你第一时间想到的是什么？\n\n是去旅游的时候在列车上看到的沿途风景，还是在回家的时候的思乡之情。\n\n那么提到停不下来的列车呢？\n\n我的第一想法是人生，但仔细想下去这趟列车最终还是会停止的，尽管那是非常久以后的事情了。而对于这个年纪的我们还难以感知到终点，就像停不下来了一样\n\n坐在永远不会停下的列车会是怎么样的感受呢？\n\n是好奇后面的旅途？是对后面不确定的旅途感到恐惧？还是说一段时间之后将其视为理所当然，在列车上的这一意识逐渐淡薄？\n\n对于列车来说，最重要的应当是司机。上面几种情况的司机又是什么样的存在？\n\n对于1这样的普通情况来讲，自然是辛苦工作的司机了。而对于2这样的情况，那列车的司机可能是自己。\n\n除了司机，列车本身的形态又是怎样的呢？\n\n对于1来说自然就是平常看到的列车了，那对于2来说又是怎样的？我想自己能够看清列车内部构造，却看不清这趟列车的形态的，即便你能够“从窗口探出头”，那也只能看到一部分。但对于别人来说，他们能够看清你的外部形态，却看不到你的内部构造。\n\n看到的风景又是怎样的呢\n\n对于1来说自然是沿途的风景：有山川、有城市、有农田、有。对于2来说，可能取决于你是以怎样的视角看过去，而且对于每个人来说是完全不同的内容。\nhoka与列车hoka是UXCoffee这档播客的主持人。对于hoka而言，她不知道什么时候坐上了一趟看起来不会停下来的列车。而启动这辆车的司机是谁呢？列车的形态是怎样的？在列车上能看到怎样的风景？\n名为自己的列车去年4月，她晋升为了设计经理。晋升本是一件好事，但是随着她的晋升也带来了问题：要做的事情指数级增长，事情太多来不及处理。晚上夜深人静的时候会想起白天做不完的事情，这些事情在脑中挥之不去导致她开始失眠，甚至入睡了还会梦到相关的事情并且惊醒。\n每天超负荷工作，别人给到自身计划之外的任务会叹气，开始烦。工作日考虑要不要加班，不加班内心内疚，要不要加班和实际加班中内心争斗，无法做内心放松的事情，很焦虑，焦虑久了变得抑郁了。\n她的身体也逐渐开始发出信号：溃疡和胃炎。她开始觉得应当休息一下，但又觉得国内的人都是996，是不是只有自己不够努力，因此并没有停下来。\n她渐渐开始觉得自己像是不会停止的，永远在跑的列车。\n无法停下的列车她意识到了这一点，既然自己是这辆列车本身，那应当自己能够停下来才对，但是她并没有做到。她开始害怕：害怕工作安排的没有那么满就会有报应，害怕别人看出来自己没有安排那么满；害怕如果做得少了、慢了、做的不好了以后可能会失去我现在的认可吧；觉得自己努力，成长比较快，如果工作不那么满了会不会成长没有这么快，会不会被别人追上了。\n开始逐渐获取列车掌控权她最首先想到的自然是去旅游放松以下，但是在旅游的时候依然持续工作状态导致最后并没有真正得到休息。\n后来去咨询有经验的前辈，也得到了许多有意义的建议，她的想法开始些许改变，在这之前她认为这个样子是不得了的大事，遇到了人生的挫折，需要做出改变与换工作。但是在这之后她明白了人生会经历许多次这样的事情，并非每一次都要换工作来解决，如果她自身对工作的期待不变的话则很快就会迎来下一次。但这些还没有真正让她真的脱离当前的状态。\n直到去年年底的时候，已经没有什么任务了，大家纷纷开始结束了办公状态。她每天会和朋友做软陶，而工作的过程没有deadline，没有deadline也不觉得负罪，因为实在没办法有deadline。\n但是这个时候她意识到自己出乎意料的开心\n\n以前感觉自己没有在做正事就会有自己是一事无成的loser的感觉从来没想到如果做的每一件事情都是当下觉得喜欢且度过的时光里大部分都很开心，这样的日子里却没有在意有没有取得成绩、做的好不好很难得的是在那些日子里觉得就这样也挺好的，躺平做咸鱼也挺好的。过的比较轻松，即便依然有事情想要做好，但基本上生活的节奏还是比较轻松。\n\n\n如何不去想那些恐惧与焦虑，面对这个问题我以前觉得对抗这些地方是做的更好，害怕自己做的不够好，所以就去做得更好。做的越来越好、跑的越来越快，但我没想到我感动、放松、舒服、满足和快乐的时候，那些最原本的焦虑和恐惧直接不见了。我意识到是不是一开始就问错问题了，我问自己的时候是怎么样做更多去应对自己做的不够多的焦虑，但我没想到答案竟然好像是我做的更少、我让自己开心的话焦虑就随风而散了\n\n意识到可以这个样子来解决问题的时候，她开始尽可能保持比较好的状态，减少工作量，或者说把工作量控制在能够的负荷的程度上，尽可能减少工作里面不必要的焦虑，让我自己保持在一个相对比较轻松比较愉悦的状态逐渐的她所看到的风景也发生了变化。\n列车与风景的变化她开始觉得更喜欢休息那段时间那个样子的自己，更接受自己，也更善待他人，而在另一位主持人眼中也看到了她更加接受自己和善待自己的样子。\n她的视角开始发生了变化，她看到的风景也开始发生了变化。\n在这之前疲于处理人际关系，为了别人五分钟能处理事情的请求感到暴躁。同时不想社交，觉得社交浪费时间。\n在这之后，她和同事的工作和交流更有耐心，更加能够接受同事的一些问题。\n在这之前如果别人会议没有邀请她则会心里想“为什么不邀请我，是不是上一次交流的时候做错了什么，是不是他不喜欢我，是不是他觉得我很没用，他是不是不需要我不喜欢我“，一直在反复思考这样的事情。\n但是在这之后她开始问自己：这是自己想感受到的焦虑？这焦虑是不是有必要的？这对我是不是有帮助的？她开始能够产生情绪的时候多分析一下情绪本身，意识到这些以后负面想法自然而然的灰飞烟灭，并且能够正确的方式去解决问题。\n我与列车听到这一档播客的时候越听到最后越觉得非常沉重。并不是说节目的过程或者内容真的是多么沉重的内容，而是和我的想法几乎一模一样。\n控制列车前进注：这里以及后面的工作不是指去公司上班这样的工作，我觉得用自己认为自己要做的任务比较合适一些。\n觉得自己不行，就要想方设法的去做些什么，觉得自己本来就很没用如果不做些什么只会越来越没用。不过实际上我很多能力客观来讲确实有不足，加上本身精力极其差，很快就失去了控制，也就无法踩下刹车。\n现在依然觉得我各方面做的都很差，各方面都是非常有问题的一个人，但是我开始对于自评的准确性产生了更多的怀疑，自己看到的自己究竟多少是正确的，多少是错误的。\n与其他列车的轨道交错与他人交流的时候会有相似的想法，自己是不是做的不够好，是不是哪里做错了什么。我的客观情况是以前确实存在过许多类似的情况，但是数年过去我依然将想法停留在过去什么都没有做的我身上，而没有正视现在的自己的努力，正视自己的变化，正视周边的环境。\n我现在还是会因为各种和人之间交流中出现的各种错误而自责，但是我或许应该多一分对自己的宽容，多怀着这是应当被解决问题的角度去看待。\n尝试控制列车我尝试了许多，尝试了解自己这个样子的形成原因；尝试通过运动从身体层面改善；尝试一些有意思的兴趣爱好；尝试像卧室摆花这样的方式来感受生活；尝试培养许多习惯增强自己对生活的掌控感；尝试去强迫自己主动与他人建立连接。\n也尝试过和hoka一样的方法，遇到问题的时候反思这个焦虑是否合理、焦虑是怎么产生的，但是这个方法之前几次尝试对我来说效果不大。这个方法我在其他地方也见过多次，这也说明了同一个方法对于不同人的适用性是不同的。\n尝试了这么多，不过很多时候我还是无法快速恢复到原来的状态，但是我觉得通过这些努力在部分方面有一些进步，对我来说需要的可能不是契机，而是需要再经过一些时间。\nhoka的列车带给我的想法听这期节目的时候感觉非常压抑，但是节目最后有这样一句话\n\n这是一个契机帮助我了解我自己，我相信我一定可以从这个状态走出来，所以我不再害怕了\n\n也许是负面想法过于相似的缘故，听到这里感受到了一股温暖，压抑感也消失了一大半。\n很难说听了一期播客就能都想开了，但是这期节目又让我强迫自己去面对这样的想法，去审视反思自己该怎么做，如何将他人的经验能作为参考。\n不过比起上面说的那些，对我来说更重要的可能是这么厉害的人也会有这样的想法，让我觉得安心一些了。\n之前也见过“厉害的人也会有一些认为自己不行“的说法（并不是说越了解越发现自己无知的那种，而是觉得自己这个人不行），但是终究没有真实感，没有经历过终究只是一行文字罢了。\n只是听或许只是留下深刻印象，但是写这篇文章的时候我需要再次强迫自己重新审视自己，类似的情况自己是怎么样的，这些是只停留在听远远达不到的。\n列车交错这里不论自身的工作（职业与自我）还是面对他人的想法，终究都要归到人上。能力的高低需要和人进行比较，工作做的怎么样会影响到他人的评判进而影响到别人的看法。不论好与坏，都是如此。但是实际上人生就像列车一样并不需要和其他人做比较，每个人有着各自属于自己的独一无二的路线。\n但是大多数人并不能从心底接受这个想法（我也一样），因此我们在与他人建立联系的时候产生的不安全感，产生了焦虑、恐惧。\n说到这些内容，我回想起《神经症与人性的成长》这本书提到的人的基本焦虑（这本书十分推荐给大家，不要因为书名有神经症就放弃了这本书，这本书能够帮助你理解你在成长过程中遇到的一些问题的根本成因）\n\n“其结果是使得小孩缺乏对“我们”的“归属感”与“连带感”，而代之以深刻的不安全感与莫名的恐惧，此种现象我称之为“基本焦虑”，是因处身于自己所认为敌对的世界中，而产生的一种被孤立或无助的感觉。这种基本焦虑会使小孩无法抒发真正的情感以与人相沟通，并可因而逼他去寻求对付别人的方法。他一定会（潜意识地）需要以某种方式来对付别人，而且这种方式必须不会激起或增加此种基本焦虑，而是会缓和它。由此种潜意识的策略需要所产生的特殊态度，须视小孩子的气质及环境的偶然性而定；简言之，他会试图去依附周遭最有权势的人；会反抗与格斗；会使他的内在生活与他人隔绝开来，且意气用事地远离他人；通常这意味着他会亲近、反抗或者逃避他人。\n\n注：关于这里提及的内容如果觉得说的太过于绝对还请看原书上下文，都有更详尽的解释。\n对我来说一个人的时候就不会有这些内耗，想着不去建立联系就没有那么多问题了，这就是回避。但是这终究是错误的，同时也是不可能实现的。人们像列车一样总会以某种方式建立联系，对于列车来说可能会停在一起，可能会跑过相同的铁轨，可能相反会擦肩而过，可能会相同的方向发车。人们不也是如此吗，和别人相遇，和别人分离。好的联系，坏的联系；想要的联系，不想要的联系；会产生幸福感的联系，会产生焦虑感的联系，人们总会以某种方式产生关联，无法脱离开来。\n对于我这样经常回避的人来说，一定要意识到回避掉是不可能的这件事情，然后去做出改变才可能打破现状。而对于非回避的情况我认为很大程度上也需要认识到人与人之间的关系，并且去寻求前人的经验，寻求身边的人帮助。\n人的问题出在人与人之间的连接，但是解决问题的过程甚至最终方案依然要依赖于人与人之间的连接。\n各自的人生列车每个人的问题都是不同的，即便会有相似的情况，可以参考一部分别人的做法，但是不太可能完全依靠和他人相同的解决方案解决自身的问题。每个人根据自己的性格特点以及现状解决方案都是各不相同的，但我觉得大多数情况是需要自己做出什么改变，因为操控这辆列车的人是你自己。即便有外部因素将你推动到另一个方向上，你依然可以让列车回到正规。\n列车的行驶中一切不可能总是一帆风顺，如果这趟列车脱离了轨道，那请将这视为一个契机，发现问题，去解决问题。如果一时没能解决，很多时候并不是你的方法不对（就像hoka去旅游放松，本身并不是坏的选择），而是可能需要一些时间，可能需要一些其他契机。我认为最重要的是不管怎样不要害怕面对这个问题，即便你没有什么解决问题的想法。霍金说过“有生命就有希望”。\n最后贴上这期节目的地址\nhttps://uxcoffee.com/episodes/93\n我挺喜欢这个节目的，尽管我对设计没什么了解，但是听了很多期都非常喜欢，在这里也推荐这档播客给读到结尾的你。\n","categories":["Thinking"],"tags":["Podcast"]},{"title":"吹响吧！上低音号","url":"/2022/08/24/Animate/Sound-Enphonium/","content":"整部番一切都距离我的现实过于遥远，无法引起什么共鸣，但是依然能够感受到各个剧情所表达出的情感：努力过后取得成果的兴奋，失败的遗憾与不甘心等等，仿佛自己也是其中的一员一样。日常生活中点点细节的衬托，人物的台词和表情，无一例外都在推动着情感的变化，有的是直白的，有的是非常隐晦的。同时两季+剧场版充足的分量讲述了十分多的故事，包含了高中生活中的方方面面，或许对于各种各样的观众都会多少找到一些自身的影子，不论是兴趣爱好与升学的矛盾、角色的成长、角色的不甘心还是努力的成功与失败等等，包含了太多太多真实的人生，这也让整个故事更加让人感同身受。\n这部动画个人最喜欢的地方当然还是久美子和丽奈的互动。印象最深刻的是选拔的时候，久美子认为丽奈和别人不同，丽奈不能淹没在人群中，这部分的喊声将情绪全部带动起来。即便丽奈赢了要成为坏人久美子也会陪她一起，那句“我背叛你你可以杀了我”以及后面的台词简直是神来之笔，将两个之间的感情全部展现的淋漓尽致。\n随着各种故事的开展，每个角色都在不断成长，久美子的性格成长是最显著的，最开始被丽奈说“久美子性格真是差劲呢”，后面经历了各种各样的事情以后逐渐变的成熟，这种方面也是有些让人羡慕。同时各个角色的形象也逐渐变的饱满，最初看起来非常高冷的丽奈，但是在剧情的发展过程中不断展现出各种各样的性格，对久美子”爱的告白“，选拔的剧情，后面为了和老师说话早去练习（还被久美子说”丽奈的这一点真是可爱“），以及后面的大胆表白，都是我印象比较深刻的地方。\n有的作品天马行空，完全脱离现实，满足了人们的幻想；有的作品完全是贴近现实，引发情感冲动。京吹自然是后者，这两种不能说绝对的谁好谁坏，只是不同方面罢了。看京吹的时候注意力很难不放在可爱的角色上，看到可爱的角色们互动自然也会很开心，看同样为百合动画的Lycoris是这样的。但对于京吹来说，即便观众的注意力会被角色的可爱所吸引，但是接近现实的剧情更容易触动观众的内心，观众更会不自觉的把自己代入到其中的角色中，感受角色的想法，过于现实反而让人有感触，不像一些过于虚构的动画一样。不过最后总会从动画的幻想回到现实，这个时候会对自己所欠缺的开始感到羡慕、难过、渴求，或者说开始感受到更强烈的感受。而观众所感受到的这种强烈的感觉，我觉得也是京吹这部动画的魅力之一。\n","categories":["Animate"],"tags":["京阿尼"]},{"title":"与CI和链接大战三百回合","url":"/2022/03/29/Problem/solve-ci-and-link/","content":"\n攻撃隊、出撃！Vorwärts！ pixiv:54707001 \n\n噩梦开始的地方在C#的CI测试中（目前仅开启了ubuntu）DllImport报错DllNotFoundException。而报错的位置是我对自己搞的一个capi做的C#包装\n本地尝试遇到这种问题，我的第一反应还是先在本地的环境确认一下，这样的做法相对来说成本低很多，能够初步确认一些问题（但是由于自己配的环境的影响会导致很多问题无法排查）\n自然本地是失败了，切到了Windows的机器上依然失败，又切到了公司内部的ubuntu服务器（我没有做过什么环境配置，可以认为相对干净一些）依然是失败了\n查看类似的情况项目中也有其他使用我们自己做的C#包装的测试，因此我想到了确认一下它的正确性。我使用了自己的分支，而主分支是没有问题的。自己这里确认的过程中还是不够严谨，应该直接查看对应测试成功与失败的用例的执行情况，只是用这样想当然的想法来考虑。\nCI调试神器各种尝试无果（忘了做了哪些，总之都没有效果），之后尝试在Windows和mac下进行测试，这两者居然是能通过的。\n一时之间也没能想到有什么决定性的因素，后来想到以前看过本地模拟ci环境的东西，因此去搜索关于ci调试的信息，并且发现了这个神器\n- name: Setup tmate session  uses: mxschmitt/action-tmate@v3\n\n只要将这一段加到GitHub action的yaml文件中，即可在执行到这里的时候停住。此时会不断刷新ssh连接的命令。\n进入CI后我做的第一时间是检查so本身是否存在问题\n像以往一样写了一个最简单的main.c，之后 gcc main.c -L . llibname 查看报错。\n我一直使用这样的方式来检查实际链接的时候因为哪些符号是undefined导致链接挂掉，简单易实施，久而久之也开始潜意识的认为这样能过链接就没有问题了，还是对链接了解不够。\n这里出现了一个我忽略了的问题，也正是这个问题导致我浪费了大半天时间。因为这个库是我自己写的自己编的，不会依赖于系统库之外的so，我潜意识认为这里不会出问题，所以我没有使用ldd进行确认链接状态。\n启动一个裸docker测试前面那一步做好也就不会有后面的那么多操作了..总之后面的操作也回顾一下\n为了和跑测试的ci版本一致，启动了一个ubuntu18.04的docker（后面可以看到，幸好我这里选择了一致的版本，不然可能解决问题的时间需要更久…）\n由于是非常干净的镜像，什么都没有，折腾了半天安装所需要的基本组建，开始编译并且执行测试，依然是存在问题。之后也没什么好思路，后来跑了一下上面提及的类似性质的相关测试的正确性，发现docker中也是错的。（这里如果我之前更严谨的确认了可能也会减少一些重复过程）\n之后我就喊实现这块的同事和我一起看问题，切到了主分支测试也不能通过。后来不记得为什么了我随手敲了个ldd看了一下他的so，他看到了错误信息，一提醒我才看到。自己思考问题经常会钻牛角尖，以及经常会忽略掉一些信息，有的时候换个人从旁观者角度来看会好很多，自己想切换到旁观者角度还是有些难。\nGLIBC_x.xx not found看到的错误信息是这样的\n./libxxx.so: /lib/x86_64-linux-gnu/libm.so.6: version `GLIBCXX_3.xx&#x27; not found (required by ./libxxx.so)\n\n由于这是一个非常干净的ubuntu，所以甚至没有这个东西。这个时候我意识到了自己的库在CI中会不会也是类似的原因，我之前是否ldd检查过，检查过的话是否是忽略了这么重要的调试信息？（这个时候由于没有清晰的思路和严谨的做法，开始怀疑之前是否做过这个测试）\n随后意识到在ci中会不会也是类似的问题。于是进入了ci调试器，看到了\n./libxxx.so: /lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29&#x27; not found (required by ./libxxx.so)\n\n测试能通过的so中是没有类似的错误信息。使用strings /usr/lib/x86_64-linux-gnu/libc.so.6 查看其中的glibc版本信息，发现其中并没有我们所需的版本（注意不要去看libc.so，它虽然叫so但不是动态链接库，用file可以看到实际上是一个文本文件）\n这时可以确认问题就在这里了。\n“失误”这个时候我觉得离谱的是这个库我是通过github ci编译的，最后ci不能通过，也许还有什么因素应该控制但是我没有做好的。\n本来还想吐槽这个，最后想办法处理GLIBC版本不一致的时候发现自己编的时候用的是ubuntu-latest的ci…而测试的地方是18.04。这一部分是我不知道从哪里直接就拷贝过来的，没有确认是否有问题就进行拷贝（之前也没有遇到过这样的情况，确认可能也不会想到这一点。但是我也确实没有进行过核对）\n同时这次的经历意识到了自己编的库还是应该尽量依赖低版本的glibc\n关于glibc和GLIBC_XX这个我整理起来发现东西不少，以及要控制一下文章长度，因此整理到了另一篇博客上\nhttps://homura.live/2022/03/29/glibc-version/\n问题总结\nGLIBC的version版本对应不上（错误的根本原因）\n在写编译的ci的时候没有认真写，而是随便找了一个抄上就完事（错误的产生原因）\n没有一套严谨的确认问题的思路（花费了我大半天的原因）\n\n太多意想不到的地方出了问题，不论是ldd还是最后发现是系统版本错，也许是自己在这些地方都没有太注意，最后各种小问题堆积太多导致出现了这种坑。\n事后诸葛亮在此写一下理想的解决思路应该是怎么样的\n\n发现CI出现问题，查看错误是DllNotFoundException\n本地相同系统测试能通过，那么要确认查找的过程没有问题。多半是要排除掉环境变量的影响因素\n确认路径查找是没有问题的以后进入CI环境查看dll的状态\nldd查看依赖是否满足（本次错误看到a即可）\n如果依赖满足的则再手动链接查看是否有undefined的符号之类\n\n\n发现是glibc的问题，确认是否真的找不到版本（这里我真的遇到过（虽然是GLIBCXX）…安了conda以后因为会先找到conda的glibc，而这个版本可能又是不合要求的，然后就会报错了..解决方案是直接修改链接，如果你遇到类似的问题一搜就能搜到解决方案）\nglibc通常和环境有关，真的是没有匹配版本那么要查看环境的不同\n由于是ci环境，那么肯定首先要看ci的yaml文件，对比配置的差异（问题解决）\n\n先确认第三步其实也可以，最好的情况下我们先去做了第三步是会省了第二步的问题。但我觉得这种dll链接相关的路径查找的问题可能更多一些，总之这些都是需要确认的步骤。\n这个思路是在本地能够通过测试的前提条件下。需要调的这种情况一般是要合并了之类，这种情况肯定是要先在本地做好测试的。没有做好的情况肯定是要先测试的\n一些想法自己经常会遇到这种离谱的问题，然而每个问题看起来再离谱最终都是会找到原因的，而且这个原因往往出现在意想不到的地方。想要减少这种现象的出现，只有明确自己行为的后果，以及不断踩坑的过程中形成一套自己的应对策略。（如果是别人的库那首先要注意的肯定是查看相关位置的源码）\n这些问题的解决方式大多貌似都是口口相传，因此我打算再遇到这样类似的问题就进行一个记录。记录下我的思路，最终是如何解决问题的以及在这个途中有什么错误的想法，尽量避免第二次犯同样的错误，不断反思形成一套自己的解决问题方案，同时又会重新回顾在这之中有什么细节或者知识点是遗漏的。以后会增加更多这样的博客\n遇到这种问题很重要的一点是如果不能调试，那解决问题可能要付出成倍的时间代价。像这个例子如果我不进去ci环境查看，也比较难确定是否真的是版本问题，不断更新ci打log也可以，但是非常非常麻烦且低效。\n后面应该再写一个链接问题定位的博客（写的话大概会说一些自己踩过的坑）。我的思路未必全面，但是一定有着参考价值（下次一定，在新建文件了，难不成我还能咕咕咕吗）\n","categories":["Debug"],"tags":["Link","CI"]},{"title":"工作踩坑小结","url":"/2022/10/02/Problem/some-work-problem/","content":"前些时间工作中踩到的坑做个简单小总结，第一次搞裸机与交叉编译，本次内容也以此为主。\n编译一开始闹了一个小乌龙，工具链支持到c++17的标准，但是同事之前指定了14的标准，差点就要把filesystem相关的代码全改掉了。但是后来依然编译不过，在需要系统调用的标准库处报了错误，这才想到裸机并没有这种东西，最后还是加条件判断宏全部处理掉了…\n链接修复问题裸机的启动代码中有一些汇编，其中JAL跳转指令在链接的时候报了错\nstartup.S:120:(.text+0xbe): relocation truncated to fit: R_RISCV_JAL against symbol `SystemInit’ defined in .text.SystemInit section in\nhttps://stackoverflow.com/questions/10486116/what-does-this-gcc-error-relocation-truncated-to-fit-mean\n先说结论，JAL指令的立即数字段的长度是固定的，而所要跳转的地址超出了JAL这个字段所能代表的长度。\n最初猜想是否和我的lib大小有关系，尝试删掉了部分代码缩小了接近一半的体积后果然可行。但是依靠这种方法解决是不可行的，代码体积无法再简化了，而且以后lib体积只会增大。参考链接中设置mcmodel，然而依然报错。\n接着尝试修改链接顺序，因为符号的顺序是和链接的顺序相关的，想要将对应的符号放到链接的最前面，但是需要跳转到我的lib中的符号，又不方便再去调整lib中的顺序。\n最后在同事的提醒下修改了链接脚本，将这些报错的text section放到了最前面。\n.text : &#123;  . = ALIGN(0x8) ;  __stext = . ;  KEEP(*startup.o(*.text*))  KEEP(*startup.o(*.vectors*))  /* avoid link failed when lib too large */  *(.text.SystemInit)  *(.text.trap_c)  *(.text.vTaskSwitchContext)  *(.text.startup.main)\t*(.text)  *(.text*)  *(.text.*)  ...&#125;\n\nconda的环境问题在使用某个python库的时候提示了Could not find a suitable hostfxr library，一直以为hostfxr相关的库版本错了，直到我点进这个源码看\ndef load_hostfxr(dotnet_root: str):    hostfxr_name = _get_dll_name(&quot;hostfxr&quot;)    hostfxr_path = os.path.join(dotnet_root, &quot;host&quot;, &quot;fxr&quot;, &quot;?.*&quot;, hostfxr_name)    for hostfxr_path in reversed(sorted(glob.glob(hostfxr_path))):        print(hostfxr_path)        try:            return ffi.dlopen(hostfxr_path)        except Exception as error:            pass    raise RuntimeError(f&quot;Could not find a suitable hostfxr library in &#123;dotnet_root&#125;&quot;)\n\n一看血压直接拉满，抛了异常一律视为没找到。手动改成打印错误信息才发现是dlopen的时候所加载的glibcxx版本不对，由于是在conda环境下因此去修改conda的链接。不是第一次被conda坑了…\n优化与调试这算是我第一次实际遇到因为优化产生的问题。由于最近在调试内存分配相关模块的问题，我想要手动malloc/new一块内存复现问题。此处为代码\nvoid test_malloc() &#123;\tint *a = malloc(16);\tprintf(&quot;na\\n&quot;);\tint *b = malloc(32);\tprintf(&quot;nb\\n&quot;);\tfree(a);\tint *c = malloc(16);\tprintf(&quot;nc\\n&quot;);\tfree(c);\tint *d = malloc(32);\tprintf(&quot;nd\\n&quot;);&#125;\n\n由于用的是裸机专用的工具链，因此内存的分配和释放都会调用工具链中的代码，我在其中打了log，但是发现new的时候并没有打印log。\n没有调试器，想了半天怎么也想不明白，最后查看反汇编发现画风是这样的\n\n指定编译选项的部分都是其他同事编写的，我一开始也没往这里想。看了半天最后发现原来malloc被优化掉了。b和d很直接，是unused的代码，但是a和c都被free了却依然被优化掉。\n关于这个问题好奇搜了一下，搜到这个回答\nhttps://stackoverflow.com/questions/17899497/malloc-and-gcc-optimization-2\nthe optimizer knows malloc and considers it is a function with no side-effects，多半是编译器内部针对特定符号编写的优化\n","categories":["Debug"],"tags":["Link","CrossCompiling","Conda"]},{"title":"NuttX mm模块在64位环境下的问题","url":"/2022/10/02/Problem/nuttx-mm-in-64/","content":"随手记录一下最近折磨了我很久的一个问题。最近在基于某一套裸机工具链做交叉编译并且在某个模拟器上执行代码，模拟器上几乎没法断点，没法用调试器，只能手工加log的方式。加上打log本身非常拖累运行速度，几乎一秒一个字符，所以这个问题来来回回拖了好几天才解决。\n提供的工具链中内存分配和释放相关的代码是基于开源的nuttx做了一点点修改，不涉及代码隐私问题，因此这里也会直接贴对应的代码。nuttx是为32位设计的系统，直接拿来64位的环境自然会有不少问题。\nnuttx源码\nhttps://github.com/projectara/nuttx/tree/master/nuttx/include/nuttx/mm\nhttps://github.com/projectara/nuttx/tree/master/nuttx/mm/mm_heap\n最小可复现代码与初定位模拟器上执行代码的时候遇到vector的第三次push_back就会死循环在某个地方，写了一个vector push_back的用例来测试，依然会死循环卡住。\nvoid test_vector_pushback()&#123;  std::vector&lt;int&gt; v;  printf(&quot;p 1\\n&quot;);  v.push_back(1);  printf(&quot;p 2\\n&quot;);  v.push_back(2);  printf(&quot;p 3\\n&quot;);  v.push_back(3);&#125;\n\n这是最简单的用例，自然不可能是我代码写错了。后来想到模拟器或许能dump pc，拿到pc后再去反汇编代码中看（全部都是静态链接塞进去），发现在这里死循环了\nmm_mallinfo.c\nfor (node = heap-&gt;mm_heapstart[region];           node &lt; heap-&gt;mm_heapend[region];     node = (struct mm_allocnode_s *)((char *)node + node-&gt;size))&#123;\t//  printf(&quot;node=%p size=%d pre=%d (%c)\\n&quot;, node,\t//         node-&gt;size, (node-&gt;preceding &amp; ~MM_ALLOC_BIT),\t//         (node-&gt;preceding &amp; MM_ALLOC_BIT) ? &#x27;A&#x27; : &#x27;F&#x27;);  if ((node-&gt;preceding &amp; MM_ALLOC_BIT) != 0)  &#123;    uordblks += node-&gt;size;  &#125;  else  &#123;    ordblks++;    fordblks += node-&gt;size;    if (node-&gt;size &gt; mxordblk)    &#123;      mxordblk = node-&gt;size;    &#125;  &#125;\n\n看到这个for循环的更新和判断条件，第一反应想到的就是size在某个地方为0了，导致不断在原地打转，因此我打印了heap的start和end，以及开启了循环内的打印\nheapstart:00000000001C9B30heapend:000000001EFFFFE8...node=00000000001CAF08 size=0000000000000410 pre=00000000000011D0 (A)node=00000000001CB318 size=0000000000000010 pre=0000000000000410 (F)node=00000000001CB328 size=00000000001C75C8 pre=0000000000000000 (F)node=00000000003928F0 size=0000000000000000 pre=0000000000000000 (F)\n\n可以看到遍历到某个node的时候size就变成了空。但我这个时候注意力全都放在了size为空这件事情上，因为这个工程同事之前接触到free出错的情况，就让同事来帮忙看，这才意识到原来0 size node之前的node的size和pre也都不对劲。\n之后通过打各种log，将直接产生问题的地方定位到了free中，同时也就能在出错之前打印出原本正确的node信息。\nnode=00000000001CAF08 size=0000000000000410 pre=00000000000011D0 (A)node=00000000001CB318 size=0000000000000010 pre=0000000000000410 (A)node=00000000001CB328 size=0000000000000010 pre=0000000000000010 (A)node=00000000001CB338 size=000000001EE34CB0 pre=0000000000000010 (F)\n\n注意这里坏掉的是1CB328，也就是倒数第二个结点\n再看一下关于free的主要逻辑。源代码比较长，由于在这个例子中未进行merge，因此省略了对应的逻辑。\nvoid mm_free(struct mm_heap_s *heap, void *mem, void *caller)&#123;  struct mm_freenode_s *node;  struct mm_freenode_s *prev;  struct mm_freenode_s *next;  (void)caller;  //mvdbg(&quot;Freeing %p\\n&quot;, mem);  /* Protect against attempts to free a NULL reference */  if (!mem)    &#123;      return;    &#125;  ...  /* Map the memory chunk into a free node */  node = (struct mm_freenode_s *)((uint64_t)mem - SIZEOF_MM_ALLOCNODE);  node-&gt;preceding &amp;= ~MM_ALLOC_BIT;  ...  /* Add the merged node to the nodelist */  mm_addfreechunk(heap, node);&#125;\n\n这里很明显关键在于mm_addfreechunk。但是在看这个函数之前，我们先看一下heap和各种node是怎样的。\nheap与nodeheap的成员很多，我们在这里只放出我们这里需要关注的几个。\nstruct mm_heap_s&#123;  struct mm_allocnode_s *mm_heapstart[CONFIG_MM_REGIONS];  struct mm_allocnode_s *mm_heapend[CONFIG_MM_REGIONS];  struct mm_freenode_s mm_nodelist[MM_NNODES];&#125;;\n\n之后我们先来看一下初始化全局堆的地方\nvoid mm_heap_initialize(void)&#123;    mm_initialize(&amp;g_mmheap, &amp;__heap_start, (uint64_t)(&amp;__heap_end) - (uint64_t)(&amp;__heap_start));&#125;\n\nvoid mm_initialize(struct mm_heap_s *heap, void *heapstart,                   size_t heapsize)&#123;  int i;  //mlldbg(&quot;Heap: start=%p size=%u\\n&quot;, heapstart, heapsize);  /* The following two lines have cause problems for some older ZiLog   * compilers in the past (but not the more recent).  Life is easier if we   * just the suppress them altogther for those tools.   */#ifndef __ZILOG__  //CHECK_ALLOCNODE_SIZE;  //CHECK_FREENODE_SIZE;#endif  /* Set up global variables */  heap-&gt;mm_heapsize = 0;#if CONFIG_MM_REGIONS &gt; 1  heap-&gt;mm_nregions = 0;#endif  /* Initialize the node array */  memset(heap-&gt;mm_nodelist, 0, sizeof(struct mm_freenode_s) * MM_NNODES);  for (i = 1; i &lt; MM_NNODES; i++)    &#123;      heap-&gt;mm_nodelist[i-1].flink = &amp;heap-&gt;mm_nodelist[i];      heap-&gt;mm_nodelist[i].blink   = &amp;heap-&gt;mm_nodelist[i-1];    &#125;  /* Initialize the malloc semaphore to one (to support one-at-   * a-time access to private data sets).   */  mm_seminitialize(heap);  /* Add the initial region of memory to the heap */  mm_addregion(heap, heapstart, heapsize);&#125;\n\n初始化nodelist，添加一个region。（目前的代码中只有一个region\nvoid mm_addregion(struct mm_heap_s *heap, void *heapstart,                  size_t heapsize)&#123;  struct mm_freenode_s *node;  uintptr_t heapbase;  uintptr_t heapend;#if CONFIG_MM_REGIONS &gt; 1  int IDX = heap-&gt;mm_nregions;#else# define IDX 0#endif  /* If the MCU handles wide addresses but the memory manager is configured   * for a small heap, then verify that the caller is  not doing something   * crazy.   */#if defined(CONFIG_MM_SMALL) &amp;&amp; !defined(CONFIG_SMALL_MEMORY)  //DEBUGASSERT(heapsize &lt;= MMSIZE_MAX+1);#endif  /* Adjust the provide heap start and size so that they are both aligned   * with the MM_MIN_CHUNK size.   */  heapbase = MM_ALIGN_UP((uintptr_t)heapstart);  heapend  = MM_ALIGN_DOWN((uintptr_t)heapstart + (uintptr_t)heapsize);  heapsize = heapend - heapbase;  //mlldbg(&quot;Region %d: base=%p size=%u\\n&quot;, IDX+1, heapstart, heapsize);  /* Add the size of this region to the total size of the heap */  heap-&gt;mm_heapsize += heapsize;  /* Create two &quot;allocated&quot; guard nodes at the beginning and end of   * the heap.  These only serve to keep us from allocating outside   * of the heap.   *   * And create one free node between the guard nodes that contains   * all available memory.   */  heap-&gt;mm_heapstart[IDX]            = (struct mm_allocnode_s *)heapbase;  heap-&gt;mm_heapstart[IDX]-&gt;size      = SIZEOF_MM_ALLOCNODE;  heap-&gt;mm_heapstart[IDX]-&gt;preceding = MM_ALLOC_BIT;  node                        = (struct mm_freenode_s *)(heapbase + SIZEOF_MM_ALLOCNODE);  node-&gt;size                  = heapsize - 2*SIZEOF_MM_ALLOCNODE;  node-&gt;preceding             = SIZEOF_MM_ALLOCNODE;  heap-&gt;mm_heapend[IDX]              = (struct mm_allocnode_s *)(heapend - SIZEOF_MM_ALLOCNODE);  heap-&gt;mm_heapend[IDX]-&gt;size        = SIZEOF_MM_ALLOCNODE;  heap-&gt;mm_heapend[IDX]-&gt;preceding   = node-&gt;size | MM_ALLOC_BIT;#undef IDX#if CONFIG_MM_REGIONS &gt; 1  heap-&gt;mm_nregions++;#endif  /* Add the single, large free node to the nodelist */  mm_addfreechunk(heap, node);&#125;\n\nheapstart和heapend分别保存了一个指向heap开始和结尾的allocnode的地址，初始化的时候中间有一个非常大的空闲的freenode，而随着之后内存的分配，中间会有越来越多的node。\n注意allocnode和freenode的异同\nstruct mm_allocnode_s&#123;  mmsize_t size;           /* Size of this chunk */  mmsize_t preceding;      /* Size of the preceding chunk */&#125;;\n\nstruct mm_freenode_s&#123;  mmsize_t size;                   /* Size of this chunk */  mmsize_t preceding;              /* Size of the preceding chunk */  struct mm_freenode_s *flink; /* Supports a doubly linked list */  struct mm_freenode_s *blink;&#125;;\n\n显而易见，allocnode和freenode存储的时候都是以一个size和preceding开始，只是free的后面还会跟两个指针。\n其中的preceding保存了前一个chunk的size，同时也标记了当前的块是被分配的状态还是被释放的状态，allocnode和freenode的处理方式都是不相同的。\n我们再回到初始化的部分，可以看到start和end的size是SIZEOF_MM_ALLOCNODE，中间空闲的node size为heapsize - 2 * SIZEOF_MM_ALLOCNODE，也就是说这个size是算入了保存内存信息的空间。\nmm_addfreechunk我们再回来看mm_addfreechunk。我在这个函的前后从heapstart开始出发采用size递增的方式遍历，经过addfreechunk之后就开始死循环了。\nvoid mm_addfreechunk(struct mm_heap_s *heap, struct mm_freenode_s *node)&#123;  struct mm_freenode_s *next;  struct mm_freenode_s *prev;  /* Convert the size to a nodelist index */  int ndx = mm_size2ndx(node-&gt;size);  /* Now put the new node int the next */  for (prev = &amp;heap-&gt;mm_nodelist[ndx], next = heap-&gt;mm_nodelist[ndx].flink;       next &amp;&amp; next-&gt;size &amp;&amp; next-&gt;size &lt; node-&gt;size;       prev = next, next = next-&gt;flink);  /* Does it go in mid next or at the end? */  prev-&gt;flink = node;  node-&gt;blink = prev;  node-&gt;flink = next;  if (next)    &#123;      /* The new node goes between prev and next */      next-&gt;blink = node;    &#125;&#125;\n\n这个函数逻辑也比较简单，找到对应的节点，修改flink和blink，只是看着这段逻辑很难想到为什么会引起那么奇怪的问题。\n不过我一开始以错误的思路打下了一个log反而利于我想明白问题。最初理解node排布之后，我手动采用了node + size的方式访问到了这种方式访问到的最后一个node。我在mm_addfreechunk之前获取了最后一个node，并在前后打印该node的信息，发现并没有什么异常。后来晚上回家的路上突然意识到这样打印是有问题的，mm_addfreechunk会改变连接关系。但是这后来给了我一个提示，原来end node所在的地址没有被写掉。\n内存排布与解决方案最后我开始画了内存图，想明白了原因。\n回看最早出现死循环的地方，每次循环的递增是通过node = (struct mm_allocnode_s *)((char *)node + node-&gt;size))来做的，也就是说所有的node是排布在heapstart和heapend中间\nstart     328            338            free                 end|size|prec|size|prec|data|size|prec|data|size|prec|data      |size|prec|\n\n倒数第二个结点(338)坏掉，是因为倒数第三个结点(328)数据写越界了。这块空间被释放掉以后那么起始地址就会被视为一个freenode，在后面mm_addfreechunk修改对应的flink和blink的时候，由于除了size和preceding的数据大小小于了两个指针的大小，因此覆写了下一个内存块开头的部分。\n那么我们实际上需要保证每次分配给数据的大小需要大于等于两个指针的大小。\nmm_malloc.c\nvoid *mm_malloc(struct mm_heap_s *heap, size_t size, void *caller)&#123;  struct mm_freenode_s *node;  void *ret = NULL;  int ndx;#if defined(CONFIG_MM_DETECT_ERROR)  size_t real_size;#endif  /* Handle bad sizes */  if (size &lt; 1)    &#123;      return NULL;    &#125;#if defined(CONFIG_MM_DETECT_ERROR)  size = (size + 3) &amp; ~3;  real_size = size;  size += MDBG_SZ_HEAD + MDBG_SZ_TAIL;#endif  /* Adjust the size to account for (1) the size of the allocated node and   * (2) to make sure that it is an even multiple of our granule size.   */  size = MM_ALIGN_UP(size + SIZEOF_MM_ALLOCNODE);\n\n这里最后实际alloc的size是MM_ALIGN_UP以后的大小\nmm.h\n#if defined(CONFIG_MM_SMALL) &amp;&amp; UINTPTR_MAX &lt;= UINT32_MAX/* Two byte offsets; Pointers may be 2 or 4 bytes; * sizeof(struct mm_freenode_s) is 8 or 12 bytes. * REVISIT: We could do better on machines with 16-bit addressing. */#  define MM_MIN_SHIFT    4  /* 16 bytes */#  define MM_MAX_SHIFT   15  /* 32 Kb */#elif defined(CONFIG_HAVE_LONG_LONG)/* Four byte offsets; Pointers may be 4 or 8 bytes * sizeof(struct mm_freenode_s) is 16 or 24 bytes. */#  if UINTPTR_MAX &lt;= UINT32_MAX#    define MM_MIN_SHIFT  4  /* 16 bytes */#  elif UINTPTR_MAX &lt;= UINT64_MAX#    define MM_MIN_SHIFT  5  /* 32 bytes */#  endif#  define MM_MAX_SHIFT   22  /*  4 Mb */#else/* Four byte offsets; Pointers must be 4 bytes. * sizeof(struct mm_freenode_s) is 16 bytes. */#  define MM_MIN_SHIFT    4  /* 16 bytes */#  define MM_MAX_SHIFT   22  /*  4 Mb */#endif/* All other definitions derive from these two */#define MM_MIN_CHUNK     (1 &lt;&lt; MM_MIN_SHIFT)#define MM_MAX_CHUNK     (1 &lt;&lt; MM_MAX_SHIFT)#define MM_NNODES        (MM_MAX_SHIFT - MM_MIN_SHIFT + 1)#define MM_GRAN_MASK     (MM_MIN_CHUNK-1)#define MM_ALIGN_UP(a)   (((a) + MM_GRAN_MASK) &amp; ~MM_GRAN_MASK)#define MM_ALIGN_DOWN(a) ((a) &amp; ~MM_GRAN_MASK)\n\n根据这里的代码可以得知我们只需要修改对应的MM_MIN_SHIFT即可解决问题\n解决问题以后发现在这段代码的正上方也有相关的注释\n/* Chunk Header Definitions *************************************************//* These definitions define the characteristics of allocator * * MM_MIN_SHIFT is used to define MM_MIN_CHUNK. * MM_MIN_CHUNK - is the smallest physical chunk that can *   be allocated.  It must be at least a large as *   sizeof(struct mm_freenode_s).  Larger values may *   improve performance slightly, but will waste memory *   due to quantization losses. * * MM_MAX_SHIFT is used to define MM_MAX_CHUNK * MM_MAX_CHUNK is the largest, contiguous chunk of memory *   that can be allocated.  It can range from 16-bytes to *   4Gb.  Larger values of MM_MAX_SHIFT can cause larger *   data structure sizes and, perhaps, minor performance *   losses. */\n\n这个文件访问了很多次，但是每次都是为了访问特定的声明和定义，没有在意到其他地方的注释。不过自己潜入代码中去了解，自己去思考原因也算是一个增加经验的机会。就算提早看到了这个注释可能因为缺少很多信息也不会想到\n","categories":["Debug"],"tags":["Memory","Baremetal","NuttX"]},{"title":"AI Compiler是什么？","url":"/2022/02/05/Other/what-is-ai-compiler/","content":"为了让更多人对AI compiler有个了解，在此对这两者的区别和联系做一个科普，也因此本文以科普区别为主，不会深入。这篇文章一直想写，也算是对我去年工作中所学到的一部分东西的总结，但是硬是咕咕咕到了现在，最后选择了假期结束前把这一篇赶出来以提前适应上班状态，避免假期太强的假期综合症。个人水平有限，如有偏颇之处欢迎联系我指正\n本文将从两方面讲述内容，首先是AI compiler是什么，都在做什么，其次是和传统compiler的异同。为了让读者能更好的理解内容，所需的背景知识我会尽可能的在文中做注解\nAI compiler是做什么的将各种框架训练产生的模型文件进行编译，生成目标平台的代码。从这个角度来看是和传统compiler是非常类似的，但是模型文件更像一个DSL（ldomain-specific language）\n编译流程先从解析输入开始，按照编译的流程来讲解各个阶段的异同。而这些异同大都是由于ai compiler输入的特殊性质导致的\n编译对象首先要编译的对象就有很大的不同。传统compiler则是编译的语言源代码，而AI compiler编译的是各种各样的模型，编译对象的不同导致了后面的各种处理大相径庭。\n先来科普一下模型的组成：模型中包含了一个计算图以及各种数据，而计算图又是由许多算子构成的。每一个算子代表了一种计算\n我个人觉得模型也可以算是一种DSL，从模型的输出向上看相当于一个expr，而每个op结点相当于一些特定函数。\n解析输入方式不同而传统语言源代码需要经过各种的parse，手写parser更是非常费力不讨好的一件事情，尽管现在的parser generator技术比较成熟，parser写起来依然是非常麻烦的。\n对于AI compiler来说需要支持各种各样的模型的解析。这里不需要写什么复杂的parser了，像onnx会提供一个文件，可以通过protobuf解析这个文件生成对应的解析模型的源代码，直接调用生成的解析模型的源码中的函数即可。由于这个原因，你也不用担心不使用特定的语言进行编写还要自己做解析的工作，极端的讲，哪怕有一天要换语言做你也不需要担心解析的过程。在这个过程中更多的是将模型的数据取出来，放入设计好的IR中。\n但是对于ai compiler来说你需要支持各种模型，如果只是支持某一种格式的模型是远远不会有用户的，这里不像传统compiler只需要支持自己语言的parser就可以了。目前主流的框架大致有三类，pytorch、onnx以及tensorflow，这三类有着各自的模型格式，而三者都有一定的用户群体，框架的支持程度对于用户来讲是一个非常关键的点。\n高层IR设计上面提到了ai compiler需要支持多种格式的模型，而不同格式模型的算子定义又是有许多差异。想要做到兼容各种格式的模型又是一个非常麻烦的问题，假设你设计了一套对应了算子的高层IR，可能需要对输入的模型中的算子前后添加一些操作，使其达到等效于你所选择的这个算子的实现。用常规编程语言的例子就是C语言中要做到类似于成员函数调用通常会在这个函数的第一个成员传入结构体的指针。但是实际上麻烦的事情更多，很多算子甚至不能在不同框架转换，有的能转换也非常复杂，而关于这个问题本文就不深入探索了。\n而传统编程语言的高层IR（通常为ast）相对简化很多，高层不需要考虑兼容与转换的问题。\n优化将输入读取进来后要做的事情当然是优化，编译器不仅要能够正确的生成对应平台的可执行代码，还要尽可能保证性能。\n这个方面可讲的实在太多，不同层面的IR的优化方式又是各不相，而我所知的也比较有限（很多地方没有参与，但是有一些了解，我想做一个简单的科普还是不成问题），就挑ai编译器讲一下通常都有哪些方面的优化（简单提及概念），都是做什么用的，为什么要有这样的优化。\n图优化\n图节点合并：这个想法非常自然，只要减少了节点数量那么计算所需要的时间自然也会减少许多\n更换顺序：有的时候更换节点顺序后一些节点就可以自然的合并\n还有很多优化是基于算子自身定义的，这些在此就不提及了，本质上都是为了减少计算\n\nfuse将多个节点融合到一个子图中，直接影响到后面的tiling、调度、buffer分配，这是比较常见的一个步骤，因为本质上是为优化服务因此放到了这里。\ntiling ：数据切分与重排tiling这边我没有实际参与过，所以我只能大概讲一下在编译到ai加速器上的情况下我的理解。\n对于ai加速器来说，通常只会适应某一些满足条件的数据大小的计算，而实际给加速器的数据大小则是各种各样的，因此需要将数据切分到适应加速器的结构。而大部分情况图上的每个节点所需要数据的大小则是已知的，因此可以提前切分好数据进行计算。（也有节点的数据大小不固定的情况，这里暂且不谈）\n对于ai来说计算很多数据都是多维数组，而实际计算很多又是多层循环，常规的数据计算方式相对低效，而许多数据又是编译期间固定的，所以需要重新以一个高效的方式重排数据。\ntiling这个过程可以说是对性能影响最大的部分之一，相信大部分人都看过那个经典的按行遍历与按列遍历二维数组的例子，不仅如此，还会牵扯到计算单元的利用率以及数据传输的带宽利用。\n调度将计算图序列化，计算出一个合适的算子执行顺序\n如果要涉及多设备还要尽可能做到多设备之间减少依赖，同时要考虑到数据在不同设备之间传输的带宽\nbuffer分配数据是通常以一个tensor为单位（最简单的说法tensor就是一个多维数组，但是这样并不确切，但是理解这里足以），而一个tensor通常存在一个buffer之中，运算的时候从buffer中取数据\n通过合理的分配方式减少运算中内存的使用，其中牵扯到计算buffer的生命周期，什么时候可以及时释放掉这块buffer，什么时候可以重用已有的buffer等等\n生成代码与运行在这方面其实都是差不多的，ai compiler还经常会生成一些ai加速器用的代码。对于ai加速器来说更多是几条配置指令加一条计算指令来执行特定的算子（上面提到的数据切分重排也和这个问题有非常大的联系）\n关于生成产物的运行，和传统compiler相同也是有两类选择\n\n生成一个直接可以执行的程序\n生成类似于字节码的东西供另一个运行时的程序读取并且执行\n\n编译时间敏感度传统compiler还是对编译时间比较敏感的，因此导致了一些算法必须选择一个较好解，而最优解是需要很长时间的。\n对于ai compiler编译时间的敏感程度相对较小，而且如果开启量化需要跑量化矫正集那根本无法控制时间（也因此需要高性能的evaluator）。而且对目标执行速度要求高，因此有更多的时间去搜索更好的解，相对于炼丹来说这点时间洒洒水啦。\nAI compiler特有的部分量化这里的量化并不是指量化交易，而是指一种将浮点数转换为定点数的计算。在ai中通常使用float进行计算，为了缩小数据大小通常会将float量化到int8，而最后还会转换回float输出（这个则是反量化过程）。如果只是做常规的数据类型转换那一定会有很大的精度损失，因此需要各种量化的算法来尽可能减少这一影响。\n而量化通常需要统计数值范围，并且使用这个范围来算出一个适当的量化参数，而这个范围我们需要通过在编译期间实际执行整个模型来得到，这个时候我们就需要一个evaluator来执行。\nevaluator与kernel我觉得这里可以视为以模型和参数作为输入的解释器，对于模型来说最小单位是一个算子，那么我们就需要添加每一个算子所对应的实现，又称为kernel。\n而kernels的实现不仅要正确，还要尽可能的高效。原因有如下两条\n\n这直接影响到开启量化后的编译时间。\n对于ai加速器来说只能够加速特定的算子，而其他算子依然会使用cpu来执行。cpu上的算子执行如果要利用这些kernels的话那它们的性能也是非常重要。\n\n关于第二条，这只是做法之一，实际上加速器加速不到的算子也有很多的实现方式，在这里只是提及有这种实现方式不进行评价好与坏，所以仅供参考。\n利用传统编译器的技术来做ai compiler常量折叠、寄存器分配等技术都是可以从传统编译器来借鉴的。\n一个非常典型的利用传统编译器技术的莫过于TVM（最有名的开源ai compiler）。其中的高层IR（Relay）直接利用了lambda calculus\n\n既然我们知道如何做control flow（lambda calculus），为啥不直接用lambda calculus当IR呢？这就是relay了。(当然，传统DL compiler能做的还是一样，但是没啥好讲的（maybe sized tensor？but sized tensor is boring））。选取了lambda calculus为ir以后，由于这上面的研究很多，我们实现需求复杂的任务比其他框架简单得多 - 因为我们只需要照抄经典compiler算法。\n\n原文链接：https://www.zhihu.com/question/331611341/answer/875630325\n不过只是这些当然还不够，需要探索更多专为ai相关的技术才能做好ai compiler。\n最后当了解了一些知识以后，就很难从一个完全不知道的视角去讲述了，所以写完本文我也难以把握哪里是相关知识较少的人看不明白的地方。读者如果能够通过本文了解ai compiler大致是什么样子的话那是再好不过了，如果读完本文对ai compiler产生了兴趣也欢迎进入这个行业和我一起摸爬滚打\n","categories":["Compiler"],"tags":["AI"]},{"title":"书店之旅","url":"/2022/07/30/Life/BookshopTour/","content":"逛逛逛三联韬奋书店店面挺大\n\n刚出地铁大老远就能看到，里面设施感觉有些年头了。人也不多，看到了几个小孩子在看儿童绘本，整体上略显冷清\n不过这个小坡我有点喜欢\n\n商务印书馆涵芬楼\n\n已经不能用冷清来形容了，因为加上我一共只有三个顾客，而因为人少这家店的店员基本上都在看手机。可能是因为没什么人，一个角落的灯一直在闪烁也没有任何维修。但这家店一墙的相同配色书籍让人印象十分深刻，虽然我个人还是觉得各种各样不同风格包装的书籍塞到一起更好看\n\n这两家店里各种xxx谈xxxx的看着也有点烦了，明明只是一个书店却都得塞这样的东西到显眼的位置，也能理解书店的无奈，但是真的讨厌…\n不过这引发了我的思考，书店里的书究竟应该是怎样的存在呢，难得一定要文学才算书吗，说来十分惭愧我潜意识中或许有这样的误区，将读书这件事情赋予了无聊的外部意义，却忽视了读书这件事情本身，这应当是非常单纯的一件事情。也许是“喜欢读书的人大多都是文学作品爱好者”的印象（并非负面评价）导致了这样的想法\n万圣书店最后一家的位置非常不起眼，里面却最有书店味。\n\n和其他店铺在同一座楼，在店前面就贴着许多书相关的海报。\n\n也许因为旁边就是清北，这里的人相对来说多了非常多，并且具备了现代化书店的标配：咖啡馆。咖啡馆里倒是并没有多少在看书的人，一些人在戴着耳机用电脑学习，一些人在和一起来的人交流。这家书店不仅人多，也有许多结伴而行的，难免会有一些羡慕。\n不要抱猫逗猫那张有被可爱到\n\n\n店铺内相比前两家狭窄了许多，但是由于很好的利用了垂直空间书籍摆的非常满，空间狭窄加上肉眼所见范围全都是书给人一种在书堆中的沉浸感。去的时候正巧有一个工作人员在爬梯子整理高处的书，更有书店的感觉了。\n\n\n\n只可惜逛到这家的时候身体略有不适，无心过多感受氛围，但是确实留下了很不错的印象。最后走的时候注意到上下楼的台阶边缘容易发出异响，可能多少有点影响店内的体验，不过这个应该就不是书店的管辖范畴了\n出了书店看到了超大的棉花糖\n\n\n\n零碎的想法对于前两家店，一进店里就有非常浓重的书味，戴着口罩都能明显闻到，也许算是一种人少的体现？而对于最后一家则是有一种香气，大概是用了什么香薰，而味道也不会太浓重，能够让人安心的在店内看书。\n在这几家店逛的时候多少有些无聊，因为是本着看书店来的，而朋友推荐的书打算买纸质版了，也就断绝了在店内看书的想法。因为无聊发出了疑问，人们为什么会逛书店呢？最初的想法是也许不知道该读什么。但对于网络发达信息爆炸的现代，人们更多的是面对不会看的超长书单（当然我自己也是这样），很少会有人去书店。现在独自逛书店在店内看书的又是怎样的人呢？也许是喜欢书店的氛围人们，也许正因为如此前两家没有氛围的店都没什么人，而他们想必大多是非常感性的人，带着自己的思绪在书海中遨游。\n逛的时候看到琳琅满目的书多少有点心动，想要多看一下不同的书都在讲着些怎样的内容，产生了一些好奇，又想到还有那么多的事情要做多少有点不知所措，总之后面也会提到，每周会专门拿出时间心无旁骛的读书！\n回忆在路上想起了承载我儿时回忆的新华书店。我妈喜欢逛街，每次逛街我就去书店里呆着吹空调。很小的时候会在那边看走迷宫的图画书，后来大一些了会去看冒险小虎队。很多书都是没有试读版的，因此实际能看的书好像也没有多少，也许是我当时的关注点过于狭窄。那个年代网购还没有这么流行，大家都是去书店买书，每次去书店不论收银台还是各个书架前都有不少人\n家里有电脑后都在家里打游戏了，很久没有去，几年前经过的时候发现一层的店面一大部分变成了甜点店，不知楼上如何（原来是五层的店）。还记得每一层的内容都不一样，一层记得是什么都有，二楼更偏向一些专业性强的书籍，三楼就是我常去的地方，四楼貌似都是词典之类，五层都是卖一些点读机什么的\n印象里在这家店小时候只买过三本课外书的样子，一本是宝可梦386图鉴，两本冒险小虎队，这也非常的儿童了（可我就是个孩子嘛），还当时跟家里要一本课外书都得要磨很久很久才能同意\n回想一下除此之外自己所拥有的书，还有好几本不记得怎么来的冒险小虎队；有一本奇怪的植物书，不记得来源了，不过我记得第一次看到猪笼草就是在这里面，还有猴面包树这个东西；还有一本花了十块钱买的什么科普，不过也没有看过；还有一本从亲戚那里得到的水浒传，但是由于非白话文看的没什么兴趣，最后被我拿来夹叶子标本了。说起来距离当年夹入银杏叶标本已经有8个年头了，时间过的真快啊，前两年也拿出来看过几次，已经完全干了！可能还有一些其他的书，已经完全失去了印象，小时候的记忆残留的不太多。高中开始会网购了，后来开始悄悄存钱买各种二次元画册！（不是涩涩的那种x）\n我的童年和读书没有太多的缘分。小时候读不懂各种课文和文章，因为没什么经历，生活只有学校和家两点一线，没有旅游没有故事，朴素的不能再朴素的生活，早期这方面也没什么启蒙。唯有这两年才开始产生一些想法什么的，开始渐渐能够理解一些感受了，不过这也没什么不好，努力去了解并且理解也是一个有成就感的过程。\n嘲讽的是大学开始就会买各种乱七八糟的书，最后读了的也寥寥无几。最早肯定还是各种大部头专业书了，一开始确实读完了一些，之后随着成长渐渐开始买一些工具书，再后来开始读各种范围之外的\n喜好我讨厌读书吗？其实也没有，小时候不喜欢语文课文，但那都是因为读不懂。沉浸阅读故事时的感觉真的很棒，有的书看完前面就非常想往后看（柳比歇夫传记《奇特的一生》），有的书也会有不舍感（乔布斯传记《成为乔布斯》）。那读了多少呢？想想看也没读多少，但我觉得无妨，现在开始就好了。其实也不必太过在意数量，而是要专心读下去\n我在想也许读书这一“喜好”是自己给自己强加的，但自己并不讨厌。读书的过程会有各种消极情绪，但这都不是读书本身带给我的，而是我想要赶快读完的焦虑，认为读完了就等于学会了的天真，以及一直在功利性的阅读导致充斥了过多杂念，这些导致读书这个行为变了味\n想到这我觉得自己好像没什么喜欢的东西，大部分自称喜欢的东西都是自己强加的罢了，而不喜欢的东西大部分又是自己不会的。不过现在在做的事情即便自己强加给自己也不会讨厌它们，也能做的开心，说的功利点现在工作的方向还有不少钱拿也能感受到一些成就感，最初可能也是强加给自己的想法，但我觉得这样也够了，这个过程中难过的只有我自己在不懂时的不知所措，我现在并不讨厌学习什么东西，反而认为学习这件事情是每天都必须要做的\n回想童年或许能够找到自己喜欢的东西，我小的时候就喜欢画画，暑假拿着买来的宝可梦图鉴从第一只就开始临摹，少说也有好几十张吧，还能找到一些照片，本体还放在家里完好的保存。没有机会去进一步学习加上有点笨，画的都不怎么样。不过不管怎么样我都很开心，高中晚自习难过的时候就会不写作业偷偷画画。后来高中毕业后，我整个人也不知道为什么全变了，也渐渐的没法画了。画的时候想的是自己画的好烂，觉得自己不行，几乎再也没动过笔\n想起一个小插曲：高中学美术的同学问过我为什么要画这些，我说我喜欢。现在看起来自己有点小蠢，不知道在ta们看来是怎样的，不过这个事情也无需在意\n想要读扯的有点远，我对喜欢的事情与爱好的一些想法是这样的，继续回到读书吧。\n开始觉得周末花点时间什么也不考虑的读一会书也许不错，读这些的时候不会再期望学到什么，读明白什么，而是想用身心去感受。就像此时此刻写下这些想法一样，没有什么太多的原因和理由，没有什么太多的杂念，而是专注于当下的行为\n也不要什么电子书了，太过容易分神、会想要乱画一通、会想要截图发出来，并且电子书会有一种把书中感情都剥夺走的感觉，不会有那种握着纸张的触感，不会有真正翻页的声音，不会有费力要看靠近装订线的时候（这个更多的是书本排版设计有问题就是了。第一次阅读更想专心体会心中的感受，而不是这些无关紧要的杂物\n不过不管怎么说，只有三个字：想要读，想要不带杂念的阅读，希望能做到吧\n搞笑小插曲这人今天超级蠢，因为写想法太专心了导致两次地铁坐过站，还有一次差点坐反（最后一秒反应过来冲出来了）。不过这正说明我在专心写出我的想法，感受到了自己的这种专注力倒也不错。（这两天学习都没见过有这么专注，可能因为我挺享受这种将自己的想法写下来的过程吧\n写完这段之后我第三次坐过了，自己都笑了出来\n知春路出发，目的地是海淀黄庄，一开始在知春路差点坐反，之后坐过到了苏州街，从苏州街出发又坐过到了知春里\n\n","categories":["Life"],"tags":["书店"]},{"title":"利兹与青鸟","url":"/2022/08/15/Animate/LizAndTheBlueBird/","content":"利兹与青鸟一个充满了爱但是结局让人心情复杂的故事。\n第一遍的时候没有完全看明白最关键的点：青鸟为什么就这么飞走了，霙为什么在体会青鸟的心情以后就能够理解这一切了。当我在没有想明白这件事情的时候一口气写下了最初的版本，但是为了更仔细的了解这部番我又重新看了一遍关键的部分，发现许多地方和我想的完全不一样。第一次看的时候我的注意力全都在霙作为孤单的利兹的一面，霙的占有欲，霙对于希美深沉的爱意，同时掺入了我自身自私的想法。而第二遍则是开始寻找问题的答案，开始专注于故事所表现出的核心想法。\n一些想法既然已经写下，即便是错误的也会保留在文中，对比想法的变化我想也是有什么意义的，不过即便无意义也无妨。\n利兹与青鸟第一遍我不能接受这个结局因此感觉心情复杂，尽管能够理解利兹觉得自己限制了青鸟，想要让青鸟有更好的生活，因此放飞了青鸟。\n两个人是相爱的，都是由于爱做出了各自的选择。那么爱是什么呢？爱是对方着想为对方付出，体谅对方的想法吗？我不明白，只有从各种有限的文字中得知这样的知识。顺着这个想法想下去，这也就是我不能完全理解的原因。\n不论是否放飞都是对对方的爱。放飞是为了对方着想，为了对方有更好的生活；但既然知道彼此相爱，那么也应该尊重对方爱自己的想法，对方爱自己也是不想和自己分离。\n最后放飞的过程我不知为何觉得甚至有些半强迫性，我知道自己的这个想法不太对，其中也有讲到青鸟太过于爱利兹，因此只能照着利兹说的做，这种事情太奇怪了吧？\n但也不是说一定要禁锢住青鸟的意思，维持一定的关系并不一定会禁锢。但是按照这个故事来说，利兹和青鸟完全是彻底分离，可能不太会有机会再见了。这也是我觉得最难过，最不能理解的原因，相爱却要永久分离。自己不能认同和接受这样的故事结局，如果我是利兹的话也许会在其中掺杂了更多的自私（糟糕的性格），不想要放飞青鸟。\n这件事情上利兹自己肯定是最不愿意的，有了陪伴自己的人，自己不需要再只身一人了，结果现在又要回到过去孤独的生活。剧中还有这样的一句话：神啊，为什么要教给我打开牢笼的方法。她不想放飞青鸟，却又因为爱她选择了放手。\n关于青鸟，想起之前看过这样一句话：别为其他人擅作主张。这或许是看待这个故事的另一个角度，这个角度多少有些阴暗。我想这个故事的设定中利兹并没有充分倾听青鸟的想法，青鸟的内心也是不愿意和利兹这样分离。尽管爱她，觉得是为了她好，但这样完全分离对青鸟真的是好的吗？\n不管怎么说，这种问题也没有什么绝对的对与错，只是每个人的想法不同。对于故事中来说两种想法是冲突的，而这种事情放到实际来说可能又是并不矛盾的。或许也不必较真，毕竟只是一个简单的童话，但这就是我的想法。\n第二遍回看台词，利兹最后要放飞青鸟的时候说了这样的话\n\n我只是囚禁住你的鸟笼罢了，你拥有翅膀，拥有一片无垠的蓝天。我没有权利剥夺你的翅膀，来吧，离开这里，飞到更高更远的地方去吧，请让我目送你美丽的身影离去吧，这就是我表达爱的方式。我爱你\n\n利兹对于青鸟的爱是不限制不约束她\n而青鸟为什么就这么飞走了呢，引用霙的话来说\n\n因为利兹这么说她才接受，青鸟无法改变利兹的选择，因为青鸟太喜欢利兹了，就算再伤心，也不得不飞走\n\n老师问：那么，青鸟是不幸的吗?\n\n我不知道，但是青鸟衷心渴望利兹幸福，只有这点肯定没错。青鸟表达爱的唯一方式，就是展翅而去\n\n我想了半天，觉得这里是青鸟不想要让利兹觉得自己被利兹囚禁住了而难过。我不知道这样的理解是否是正确，不过不论如何飞走是青鸟对于利兹的爱。\n即便我能够理解一些这样的心情，但我依然不喜欢这个结局。\n霙我非常喜欢这个角色，角色的立绘本身就很可爱，不过更多的是被她那十分强烈的感情所吸引。\n爱意霙最触动我的情感是对于希美那种“我的眼中只有你”的感情。这种想法可能会有些沉重，沉重到让人承担不住，但是感情本身的炽热我觉得是非常打动人心的。因为“什么都爱等同于什么都不爱”，一个人爱的总量是有限的，分给越少的人，那么每个人得到的爱则更多，而一个人将所有的爱集中到唯一一个人身上，那必然非常强烈。\n前半段基本上都在表现出霙对于希美的爱。从霙和希美两个人单独开始，到出现了更多角色的时候开始展现出了霙不想被希美夺走的心情。霙一直在注视着和希美，注视着她和其他人开心聊天的场景，注视的同时又在期待着希美和她一起聊天，听到她和其他人计划出去吃饭，期待着希美邀请她一起吃饭。\n除了这些看着比较明显的表达方式，还有一些细节：看着希美所说的利兹与青鸟的故事，希美提到想要参加比赛的时候，又去借书认真了解这个故事。希美提到最喜欢的拥抱并且只说完”最喜欢“三个字的时候，希美说可爱这个词的时候，都有一个镜头给到了霙，霙那种眼神很明显就是在期待希美这样对自己说。\n只是她的眼里只有希美，后辈第一次邀请霙的时候她并不是那么高冷，所以不愿接受邀请；在京吹中她只将希美作为了自己唯一的朋友，忽视了周围所有的其他人（可怜的优子）。但是即便开始有了一些朋友，霙的爱依然都在希美身上，依然那么强烈。\n不安霙一直在不安，这种不安让人心疼。京吹中有这样的台词\n\n在吹奏乐社每天都过得很开心，但对希美来说我只是朋友之一，许多朋友里的一个。只有我不知道，她甚至从来没有和我商量过，我不敢知道我在她心中其实不值得一提的事实。我不懂，我为什么还要留在吹奏乐社\n\n\n那…那你为什么没有放弃呢\n\n\n乐器…只有乐器是我和希美之间唯一的联系了。因为我…只剩希美这个朋友了。如果连她也拒绝我\n\n在吹奏社开心是因为希美的存在，她也正是因为希美进入了吹奏乐社。\n每一句台词都在显现出霙的不安，甚至害怕，这看着让人非常难受，能够体会到那种心都要碎了的感觉，因此会感觉非常压抑，这种强烈的感觉又会让这个角色在心中留下十分深刻的印象。\n霙说过“正赛不要到来就好了”，而这句我觉得也对应了“只有乐器是我和希美之间唯一的联系了”这句话，担心没有乐器的联系两个人就要彻底分离了。\n希美写了这部分感觉内容有点偏向负面…但是并不是说讨厌这个角色。本来也没想写希美这部分的，但是我觉得从希美的角度也能够突出霙的心情。\n印象比较深刻的有这些片段：希美每次和霙一起走的时候都离着霙好远；霙想要在希美旁边一起看书的时候结果希美无意识走开了；希美提到要拥抱的时候霙是非常想要，但是霙刚要伸出手的时候希美就说了一句逗你的，然后就走开了；霙想要靠在希美身上但是被无意识的躲开了。\n而希美也未明确对霙表达过些什么，就像高一退部的时候觉得没必要说就没说了。也正是因为希美是这样的人，霙的不安越来越强烈，甚至在希美退部以后产生了那么强烈的反应。\n不过不论怎么说，希美也是对霙怀有感情的，本身的角色设定和描写来说也很难突出希美对霙的感情究竟到了多么强烈。而希美感情的表现在后面才开始。希美自己的未来意向也是空白；在前面合奏的时候感情过于强烈，没有和霙的相互聆听，合奏的时候画面不断失焦的表现手法；希美和霙的眼神交流；以及希美最后对于霙的放手。\n希美和霙这里的剧情一开始只是觉得霙就是利兹，而希美就是青鸟，但是万万没想到最后双方互为利兹与青鸟。\n最初希美作为青鸟一样帮助霙摆脱孤单，霙像利兹一样想要希美留在自己身边。\n但是到后面却发现是希美作为利兹一样限制住了霙的一切，想要放飞青鸟般的霙。\n霙最后像青鸟一样，表达出了自己的爱意给对方。而希美最后也像利兹一样，没有过多说什么，只是放手。\n最后的霙表达出了自己对希美的全部情感（霙最后说一连串喜欢的时候镜头拉伸简直绝了…），而希美只是说了一句喜欢听你的双簧管，我想这也是希美作为利兹的一种放飞方式。但不论怎么说都过于让人难过，希美对于霙的情感一定是存在的，而她为了放飞霙，却只能选择将这份情感封存到心底。\n两个人从互相禁锢，再到相互放手，放飞对方。而在这一切的事情彼此全部讲明白以后，有这样一个镜头\n\n也许是在暗示两个人互为彼此的利兹与青鸟，此时两个人都已经作为青鸟被作为利兹的对方放飞了\n一开始有一个比较奇怪的问题，在这之后的霙如果在某段关系中成为了利兹，是否也会选择放飞青鸟呢？一开始提出这个问题，写到这个部分的时候才反应过来霙和希美的关系中霙本身也是利兹，她已经放飞了青鸟。\n剧情从两个人早上一起上学镜头开始，到黄昏两个人一起回家的镜头结束。早上上学的时候两个人的距离非常远，而结束的时候两个人则是在一起行走。同时开头是disjoint，结局是joint。这里我没有明白，是因为两个人的心意相通了吗\n\n在看第一遍的时候看到一个想法我觉得蛮棒的：她们就像是在同一个家，但是出门做不同的工作一样。但是对于利兹和青鸟的故事我觉得并不是这样，对于希美和霙如果后面是这样的关系那我觉得真的是再好不过。\n但是回看的时候注意到这段剧情\n希美：其实我觉得，利兹放走的青鸟相见利兹时就随时来见面不就好了\n夏纪：那利兹的一片苦心不是都白费了吗\n第一遍的时候我就没有想明白一个问题。回看的时候发现这是一个非常重要的点。\n为什么利兹的苦心就白费了，是因为青鸟爱着利兹因此会经常回到利兹的身边，实际上还是以某种形式禁锢了青鸟吗\n爱到底是什么这是关于爱的故事，但是越看下去我越不明白，爱到底是什么？\n随便说几个词倒是简单，比如说不求回报的付出，为他人着想，但这最极致的情感使用这种文字来描述太空洞了。我只知道每个人表达爱的方式各不相同，就像利兹表达爱的方式是放手，而青鸟表达爱的方式是不想让利兹难过因此选择飞走。\n对于利兹和青鸟来说，她们用了各自的方式表达了各自的爱意，但是她们真正的幸福到底是什么呢？\n当我写到这个问题思路开始有些变化。爱有许多不同的方式，不同的角度，也有不同的目的。有的是为了他人好，有的是为了双方幸福，不同的选择之间没有绝对的好与坏。\n剧中几乎没有提到幸福这个词，唯一提到幸福的位置应该就是霙回答老师的时候所说的\n\n我不知道，但是青鸟衷心渴望利兹幸福，只有这点肯定没错\n\n我开始发现自己关注点过多放在了爱上却没有考虑幸福这个目的本身，可能我的潜意识里更多觉得爱还是为了幸福而存在。我觉得她们在一起的时候是幸福的，也就因此无法接受这样的结局。她们依然会彼此相爱，但是彼此永久分离，这样她们真的会幸福吗？\n有一个有些无聊的假设，如果利兹没有想到过自己是在禁锢着青鸟，那么利兹对于青鸟的爱意算是什么样的呢？这样的她们最终是幸福的吗？\n最后一开始是期待着看到甜甜的糖去的，但是当我看到青鸟第一次离开利兹的时候就感觉要不对劲。第一遍看完过于代入霙的心情却又站在霙作为利兹的立场掺杂了许多私心，整体看完最大的感受是十分压抑，几乎要哭了出来。当我第二遍看明白了整个剧情的时候整个人已经陷入了情绪之中，我不明白爱到底是什么。\n当我写完了这篇感受，尤其是写完了爱与幸福这一段，我仿佛脱离了出来，尽管我依然不明白爱到底应该是怎样的。但爱与幸福真正的答案是什么呢，或许并没有什么真正具有普适性的答案，人与人之间是完全不同的，而每两个人之间产生的关系更是大不相同。\n写到这里我就不继续补充内容了，因为我的情感部分已经写了进去，并且已经开始往里添加不想要的原作细节了。过于追求内容的长度，反应过来的时候就已经开始回看里面的对话并且进行分析了不少。尽管这一部有很多细节值得反复推敲，但写下这篇文章的意义不是为了分析，而是要将自己的感受彻底表达出来。内容非常混乱，观点也因为自身经历和情感的匮乏导致非常幼稚，但这就是我现在最真实的想法。\n和朋友探讨的几次回复出于隐私考虑就不放上朋友说的内容了，对话也有轻微改动\n1看到你提到人为的细节的问题，利兹与青鸟里面的细节真的太多了，分析都能分析上好几天，各种对应。“一帧帧的解读只会让人越陷越深，所有的解读最多都只是锦上添花”这个我也有感觉…我在最后也写到开始陷入解读的细节中了\n先不说自己无聊的部分，看到感想觉得你和自己看待整部剧的视角相差甚远。至少在这部中你更像是观众，你也写了“而回顾时却感觉到制作团队有意带着我们，以一个第三视角的距离去看”，而我基本上是在想霙的想法。你花费很大的篇幅在讲动画中各种描写各种环境的精彩，而我总在无聊的思考人生。一半原因是动画过于现实，另一半则是现在的自己大概就是这样无聊吧，功利且情感麻木。如果硬要为自己这样的行为再找个什么借口，那就是最后总要从动画中醒来吧。\n在未写完的京吹感想中我有这样一段评价\n\n这部番更加接近现实，人更会不自觉的把自己代入到其中的角色中，感受角色的想法，过于现实反而让人有感触，不像一些过于虚构的动画一样。不过最后总会从动画的幻想回到现实，这个时候会对自己所欠缺的开始感到羡慕、难过、渴求，或者说开始感受到更强烈的共鸣。而观众所感受到的这种强烈的感觉，我觉得也是京吹这部动画的魅力之一。\n\n我还是对于这种环境的描写与衬托没有那么敏感，几乎没读什么文学作品，以及这也象征了我内心的空洞与虚无吧。讲一个我今天回想起两三年前做过的梦，我想这个梦就是当时真实的自己。本来可能会写到《世》的感想中，现在就写到这里\n\n自己不知怎么在一个无底洞中，周围什么都没有，只有一片漆黑。一直不断的向下坠落，没有疼痛，没有害怕，什么都没有，但是我一点都没有感到难过。渐渐的没有了时间和空间概念，只知道自己向下坠落，不知道该做什么遂开始观察自身的感受，但是也是一片虚无，但又十分宁静。现在看来从入睡到做梦就像是《世》中主人公进入了第三世界一样，但是在我的第三世界中什么都没有，没有任何环境，没有自己的心，而这样的我有点像在世界尽头的居民一样，只不过除了自己以外的所有事物都消失了罢了。醒来以后也是出奇的平静，梦本身很清晰，而内容又让人印象深刻，使我至今无法忘记。\n\n现在的我变成了什么样子，我也不知道，真正看清自己是非常困难的事情。\n2你提到了好多我没有想到的角度\n“因为害怕孤单与分离所以拒绝了周围人的爱”\n说到这里我发现自己的关注点有大问题…我的关注点更倾向于mizore对于nozomi特殊的情感上，我写的感想中mizore相关的大部分也是基于这个来写的…这个根本问题就错了，过于关注了特殊的情感而忽略了其他爱别人的形式\n现在想想后面给后辈做簧片的时候已经开始对周围的人产生关心了，不过特殊的情感依然是全部对于nozomi的。这个时候mizore慢慢开始走了出来，爱意不再那么沉重，剩下的只有炽热，但这份炽热并不会让人窒息。\n自我救赎与自我毁灭也不是很明白，因为倾注了自我，将自我交给nozomi来决定，进而自我就毁灭掉了吗？记得mizore说过这么一句话：希美的决定就是我的决定，也许就是这个意思吧。\nnozomi的嫉妒我也没考虑过，更别说发挥到mizore身上这一点。只知道这里肯定是不甘心的，为什么只给了mizore发而没有给自己。那么利兹是否也一样有一些嫉妒呢，嫉妒青鸟能够飞上天空，这个我觉得没有什么表现的地方。甚至她的控制力也是没有想到，因为mizore交了新朋友所以会觉得远离了一些。\n表白的那一段nozomi躲躲闪闪我之前还以为是在压抑自己对于mizore的爱，没有考虑到她其他的复杂情绪。最后那句我喜欢mizore的双簧管，我之前只是觉得是nozomi放手的一种做法，不需要说那么多爱意。\n一直觉得关于nozomi的描写没有显得对于mizore有多么强烈的爱，一直觉得她们就是彼此那么相爱的只是nozomi的部分没有刻画出来，觉得是因为nozomi本身就是一个“直男”的角色，但我没有想过nozomi对于mizore不会是那种特殊的爱，只是好朋友之上但又没有那么特殊与强烈\n我想mizore在渐渐走出来的时候爱或许已经没有了沉重的部分，而是只剩下了炽热，最后也直接A了上去\nnozomi的放手我觉得还是很好明白，这个表现的比较明显了。那么如果nozomi不再自卑，结局又是否会完全不一样呢？\n用nozomi和mizore称呼哈哈哈哈确实这个叫法更好懂，我刚开始写的时候还在纠结nozomi要不要直接用伞哥称呼，mizore就直接用mizore。mizore我一开始还纳闷为什么翻译出来的字是那么少见的，打开日语输入法发现日语中mizore对应的汉字就是这个样子的\n以及优子妈妈真的是操碎了心\n3想到如果nozomi不是这个样子的话，mizore不知道什么时候才能从这个样子中走出来。mizore走出来以后的爱或许不再沉重，是可接受的吧。即便像姐姐像前辈一样照顾mizore，mizore的特殊情感可能依然无法得到回应。\n我回家以后又看了最后那段。因为嫉妒mizore，所以nozomi觉得自己应该被轻视吗，这里我还在奇怪为什么要这么说。nozomi看脚的细节，加上nozomi一直不敢正眼看mizore，多少能够体会那种卑微的感受…最后吸气声那里也太细节了。不过即便这样，nozomi的解脱我还是无法感同身受\n最后还是我之前说的，不同视角差别非常大这件事情。看到你在描述mizore的自我毁灭我就已经因为这段剧情开始觉得压抑，也许这就是我最初感到压抑的本质吧，我能体会那种处于和他人的关系中不安的心情，而这种理解就像你对于nozomi感同身受一样\n你讲的扬起的尘土最后却仍要回到路上，尽管明白空中回旋的过程并不是毫无意义的，但是依然会对最后落地的事实感到伤感\n","categories":["Animate"],"tags":["利兹与青鸟"]},{"title":"灵能百分百 mob的改变与成长","url":"/2022/12/31/Animate/MobPsycho100/","content":"\n灵能百分百，一个讲述了mob改变与成长过程中的故事。\n改变与成长改变与成长，对于每个人来说都是不可避免的问题，对于mob也是一样。人的成长与改变离不开人，与他人相遇，然后发生些什么事情。mob受到了他人的影响，开始产生改变，而在这个过程中，其他人也受到mob的影响发生改变。\n最上篇中mob所说的\n\n人是可以改变的，这是最上与浅桐小姐教我的。我也被大家改变了，我也明白了自己或许可以改变某个人。\n\n灵幻，小酒窝，花泽，芹泽，铃木等等许多人都是如此，受到了mob的影响所改变，而其中的许多人同时还是推动mob改变的一方，在人与人之间的交流中是互相影响和改变的。\nmob和铃木的对决中有这样的台词\n\n不管是谁，人都会在与他人的交往中成长，人需要别人，总有一天会需要他人\n\n而铃木从中学开始“认为自己凌驾于他人之上”，认为不需要他人，而mob则对铃木说“止步于中学时期的是你”。不需要他人的铃木也正因如此这么多年来在许多方面仍未成长。\n接纳自我而接纳自我，也是成长中非常重要的一部分。这部分主要都在最终的告白篇进行讲述与刻画。在这部分内容中，mob再次暴走了，而此刻是剧中唯一一次mob和暴走的自我进行持续对话，或者说他不得不在面对另一个自我。他畏惧情感化的另一个自己，但两者其实都是他自己。律一开始畏惧他，不断的跟自己说那不是哥哥，但到最后律明白了，那个也是mob的一部分，律选择去接受。\n\n他是一直被压抑的另一个哥哥，他们从根本上连在一起，无法剥离，哥哥今后也必须和这样的自己共存下去。\n\n正如律所说，暴走的是mob的一部分，而每个人则是由无数个这样的一部分组成的，我们要去尝试接纳自己的每一部分。现在回想看，似乎并非只有最终话才有接纳自我这件事情。mob最初对自己所拥有的力量感到烦恼，是灵幻教会他接受自己力量的方式以及使用力量的方式，这亦是一种接纳。\n大家一直在否认另一个mob，而???也讨厌被人否认，整个对话的过程他都在不断的强调自己的存在。\n\nmob:你的想法太不正常了\n\n\n???:什么叫正常，你又要否认我本身吗\n\n而”蕾只把我和龙套当成要好的朋友“很明显的是他将自己和mob区分开了。???想要认同，但他不被认同，同时他却未能认同另一个自己。自称不会被驯化的另一个mob，他只是不想被人当作一个会被否认的“特殊的存在”罢了。\n\n你并不特殊，每个人都有两面性。我也有，所以你不必烦恼。不对，烦恼一下倒也行，会烦恼其实也是理所当然的。我其实非常讨厌我隐藏起来的本性。但就是因为有这“虚假的一面”我才认识了你，你也是拥有这份力量…才有了今天的你吧。总之我想说，你其实，现在这样就可以了，现在的你就算没有我也不要紧了，别担心。是时候接纳了，接纳你自己。你能行…龙套一定能做到，我知道的。\n\n灵幻的这一番话表达了自己不认为另一个mob是特殊的，并且不是应当被否认的，从自己开始自我接纳，同时表达了对他接纳的意愿，mob的主人格也因此能够接纳他，他因此能够接纳师父和mob，一切也就回归了原样。不论哪一个自我，都是自己的一部分，都不是什么特殊的存在，都不是什么值得否定的存在。\n\n你是说你要接纳我吗？\n\n\n不…我希望你也能接纳我。就像大家接纳了我一样。\n\n即便是自认为最黑暗的部分，也只是自己的一部分，都不是什么特殊的、值得自己否定的存在，试着去接受它们吧。\nmob灵能百分百的剧情都是围绕着mob的成长展开的。最初的mob不善言辞，没有自己的想法，习惯性的压抑情感，无法接纳另一个情绪化的自己。在他第一次失控之后就开始抑制自己的情感，他对自己，或者说另一个自己感到畏惧。随着他与灵幻相遇开始发生了一些改变，而当他与更多的人相遇后，他逐渐开始找到自己所迷失的东西，开始有自己的想法和意见。但即便如此，他仍未能接纳另一个自我，他仍在压抑自己的情感，对于mob来说压抑情感和接纳另一个自我是相连在一起的事情。\n而在最终的结局， 灵幻的一番话让他接纳了自己，将他从失控的状态中拉回。此时的mob是影山茂夫100%，正因为他接纳了另一个自己，他不再抑制自己的情感，他才得以完整。也正是从这里开始他恢复了自己的情感流露，在表白失败以后直接哭了出来，在ed为灵幻的生日喝彩时他甚至放声大笑了起来，而在前面的剧情中mob几乎都未有这样的情感表现。\n灵幻提到灵幻，我想一开始给观众留下的印象就是利用mob的欺诈师，但灵幻对于mob的整个成长旅途来说是最重要的角色。整个剧情部分我觉得可以说是以灵幻接受了mob的烦恼咨询开始，而最后又以灵幻引导mob接受另一个自己结束。one老师并没有这么用俗套的按时间顺序开场，而是mob即将爆发时将灵幻接受mob的咨询插入到回忆之中，这样的安排使得角色的行为更加合理，同时这个时候插入回忆会给我们观众留下更深刻的印象。他除了灵能力和超能力外几乎什么都能做到，而mob则是超能力最强但除了超能力外什么都做不到，这样的两个人完全是一对。正是这样的灵幻，在mob的成长中给出了方向，大多数情况能够敏感的察觉到mob的情绪。他开导了迷茫的mob，他告诉mob不需要看空气配合别人，遇到不愿意的事情可以逃避，教给mob接受自己。\n在三季的boss战中每次灵幻的台词都让人十分感动。在第一季进攻爪支部的时候，其他人都在逼迫mob使用超能力，但只有灵幻察觉到了他不愿在这个时候使用。“住手，龙套，这么做你只会更加痛苦。不愿意的时候，逃跑也没关系”，用着这样的话语成功让mob从杀意转换为了逃避。第二季mob独自和爪的boss对峙时，灵幻独自赶了过去，对mob说出”还是觉得不应该让你独自来“这样的话。第三季面对另一个mob的时候，“你其实…现在这样的你就好，现在的你就算没有我也不要紧了，别担心。是时候接纳了，接纳你自己。你能行…mob一定能做到，我知道的“，这样引导mob接纳情绪化的自己。\n除了灵幻对mob引导的情节外，还有二人产生矛盾的情节，他未能及时发现mob的快速成长所带来的变化，而mob选择了暂时不去灵幻那里。这段时间随着剧情推动，我们一点点看到了灵幻不为人知的过去，同时看到了这个除了除灵不论遇到什么都能临机应变的人的另一面。平凡的毕业开始工作，后来自己开始独自靠“除灵”赚钱。他其实是非常孤单的，mob和朋友们去卡拉OK，开始有人陪伴，有自己的生活，mob的身边热闹起来，不再是只有师父了。对于灵幻来说只有mob能真的陪伴着他，即便是他被套路之前人们也只是图求利益接近他，当他想诉说些什么却也无人能够倾听，被套路之后则是更不会有人愿意接近他了。这些都充分体现出了mob对于灵幻的重要性，mob对他来说不仅仅是一个利用来除灵的人，而是一个真诚的朋友，一个陪伴自己的人。\n而在灵幻被套路后在记者发布会上记者提及到他作文中写的毕业期望的主题是“想成为什么”，他开始回忆起自己为什么要成为灵能力者，紧接着又从另一个角度讲述了他和mob相遇的故事。\n\n当时，我对那个少年产生了憧憬，我也想抓住些什么，想成为特别的人\n\n他做到了所想的事情，他抓住了他和mob之间的连接，成为了对于mob来说最为特别且不可或缺的人。灵幻虽然作为mob改变的推动者，但我想他也是被这场相遇改变的人。灵幻是一个圆滑处事的人，是会欺骗、利用mob的人，但他在面对另一个mob的暴走时却放弃了一切，没有选择圆滑的放弃，即便冒着生命危险，即便讲出自己欺骗的真相后mob可能会彻底离开，他也要将自己的想法传达给mob，就想要阻止他，我想这也是一种改变，他不再是那个只会圆滑处事的人了，而是重视朋友的人。\n小酒窝除了灵幻，最重要的角色非小酒窝莫属。灵幻对于mob来可以说是最重要的，而小酒窝几乎是陪伴他最久的。小酒窝初登场是作为教主的身份，他一直怀有想要通过宗教成为神的愿望。从最初的想要利用mob，但逐渐开始帮助mob，不知不觉中小酒窝和mob已经成为了能够互相信任的朋友。小酒窝其实只是世间众多迷茫者中的一员，即便成为灵那么久，依然不知道自己想要的什么，在到神树篇之前他未曾察觉到自己只是想要朋友罢了。小酒窝或许也算是受到mob的影响所改变，也许正因为mob开始信任他，mob把他当作一个普通的人对待，他开始信任mob，真正发自内心而不是以利用为目地的去帮助mob。\n小酒窝的出场，除了日常穿梭于各种剧情之中，以及被几大战力担当除灵，就是神树篇了。在神树篇之外几乎很少刻画小酒窝的想法和明显的变化，只有他的行动，而在神树篇中通过各种细节来刻画出他的想法，他的变化，将这个角色完整的表现了出来。\n在mob进入神树的前一晚，他还在邀请mob一起，即便他已经有了足够的力量，但他本质上只是想和mob，和这个非常要好的朋友在一起做这件事情。这里他的台词我觉得非常巧妙。\n不论是发出邀请时特意用的是“咱们”\n\n咱们是时候站上顶点了，一起去吧\n\n还是在mob拒绝以后，说出了这样的话\n\n你小子，想把本大爷排除在外吗\n\n这一切其实全都在表现他想要和mob一起的愿望，但他本人未曾察觉，而此时的mob由于忘乎所以也未注意到这一切。\n但即便闹了矛盾，但不论是开场先吐槽，还是一直不忍心用全力攻击mob，又或者发出神之光线后的担心，他还是我们熟悉的那个小酒窝。即便说着要一决胜负，看到mob的衣服后还是吐槽了起来，开始为mob担心。他自己也没有意识到，自己在和mob相处的过程中渐渐的将mob看做了朋友，一个需要担心的人。\n脱离了忘乎所以的mob，看到小酒窝对衣服的吐槽，发现他还是熟悉的小酒窝，决定100%信任小酒窝。并诚恳的道歉。而此时的小酒窝，才真正意识到自己想要的事情。\nmob：\n\n对不起，小酒窝…这是你一直想做的事…一直不懈追寻的东西，你却在愿望眼看就要实现的时候，向我发出了邀请。你有能力这样独自实现愿望，却还特意来邀请我，这才是…最重要的事情。你不是在打坏主意，你只是想实现自己的愿望，和我一起。是你信赖来了我，谢谢你\n\n\n你想做什么，我都会认真听的，作为你的朋友。\n\n小酒窝：\n\n之前一直没发现，本大爷其实…只是想要朋友。\n\n评价或许这部作品不温不火，但是我觉得它是我心目中的神作。\n原作我对原作的评价是one老师的剧情有趣、富有深度同时又浅显易懂，他想表达的事物已经切实传达到了我们这里。同时one老师笔下的角色都很有特点，某个积累了两年全勤记录的不良，我想大家都会在得知全勤记录的时候感受到这个角色的反差，花泽的各种奇特造型（包括两次被剃头以及多次出现的超高头发），篇幅所限这些角色就不再每个都聊一遍了。\n有的人吐槽one老师的画风，这个因人而异，对我而言不论是原作十分简单的画风还是tv动画中对原作的模仿都觉得挺有趣的。但我觉得这是一部不应被画风所限制的作品，one老师是真的想要传达给读者些什么，将更多的精力放在讲故事中。现在的时代大多是一些惊险刺激的作品，又或者迎合宅宅们口味的作品，像这种专注于通过故事传达给读者些什么的作品已经很少了。\nTV表现tv动画通过漫画做不到的方式增强了表现力，声优的精彩演绎，bgm的完美结合，通过与剧情密切相关的歌词，op的独特动画。众多因素结合调动了观众更多的感官，对观众的情绪施加了更强烈的影响。在最后灵幻冲到mob面前时，配上第一季op的歌词，每一个画面几乎都与歌词契合，我甚至有理由怀疑这是制作组早就计划好的事情。\n最终的结尾与最初的op相呼应，更加显现出第一季作为基础的地位。第一季虽然相对平淡。但是如果没有一开始的铺垫，我们不会感受到后面的精彩。随着三季动画的播出，我们也跟着一起见证了mob的成长，而在剧情中一直见证着这一切的人则一定是灵幻。在第三季op中最后那一段灵幻站起来拍着逐渐长大的mob的肩膀，已经看过前两季的我从这里的画面联想到他们之间强烈的联系，情感也随之迸发。\n最后告白篇最终灵幻与mob的那段真的非常棒，让我忍不住想为这部作品写点什么，也便有了本文。但我想绝不仅是因为这一个结尾部分非常精彩，这一部分情绪感受很大程度由前面所有内容的铺垫而来。自己未想过能为这部作品写这么多东西，也许是真的有所感触。还有很多值得写的和深挖的内容，情感，mob与朋友们的联系，其他的角色等等，但作者水平受限便写到这里停下了。我一直在寻求改变，一直在寻求灵幻一样的存在，我能够感受到mob改变路上的迷茫，同时我也真心为one老师笔下的mob所经历的成长而感到高兴，我想这些都是让我感受到剧情中强烈情感的原因。\n同样描述角色成长的京吹却未能像灵能百分百一样这么强烈的打动我，也许京吹更多的是校园的青春，也许是如我在京吹的感想中所说：“整部番一切都距离我的现实过于遥远，无法引起什么共鸣”，虽然京吹更加接近现实，但对我来说那种多人一起努力的青春场景远比灵能中的幻想世界更加遥远。我最喜欢的另外两部作品是魔法少女小圆，另一部是利兹与青鸟。这两部作品靠的是极致的情感吸引了我，而灵能则是整个mob成长经历的一点一滴，在最后将这些积累的东西全部爆发出来。\n希望读者和我都能像mob一样不断的改变与成长，试着接纳不同的自己，最终做到\n自我100%\n","categories":["Animate"],"tags":["MobPsycho100"]},{"title":"2022年终总结","url":"/2022/12/31/Summary/summary-2022/","content":"不知不觉这一年又过去了，时间快到让我心里没底。到现在北漂已经有一年半了，而这一年也慢慢适应了这个地方，今年依然没有什么丰富多彩的生活，平平淡淡的工作，学习，玩乐。\n去年的愿景去年的愿景许多方面我没有非常明确具体的目标，这对实现目标来说恰恰是致命的。以下这段来自我去年的年终总结\n\n不用多说，身心健康是一定会有的，这个是持续的目标，也是最难达到的\n想要成为编译器专家，但是我觉得自己能熟练掌握就不错了，先以这个作为目标吧……我能做的只有一点点积累，所以会先从搞好当前在做的编译器开始，在这个过程中让自己编译器方面的知识获得提升\n想要拍到很多好照片，年底想做出自己的照片集，不过这还需要学习设计排版的知识。希望能在摄影的过程中发现更多的乐趣，并且能以此为媒介感受和表达更多的东西\n自己想要和别人一起努力，而不是都是自己一个人闷头做。我认为和他人一起努力很多时候会产生数倍的效果，但是我自身的种种导致最终总是会使得他人远离我，不论是哪里。我自知这很悲观且问题出自自身，但这也是我的无奈\n想要写好博客，而不是像今年一样咕咕咕；还想要学到很多新东西，想要认识新的人等等\n明年想要的太多了，我的贪心今年仍未衰减，反而更强烈了。明年也要为了自己的各种想法而努力，不过对于我这样各方面能力值都不够的人贪心一定要付出更多的代价：需要花费更多的时间（现在每天的时间都已经满满当当了），精力会分散，对于本来精力槽就不高的我提出了挑战\n\n去年的年终总结：https://homura.live/2021/12/26/Summary/summary-2021/\n身心健康按我现在的状态怎么都算不上身心健康。今年去体检查出一大堆的小问题，其中一项还影响到了脑血管，某种物质代谢不完全残留在血液中，导致容易形成了斑块，大概是基因加饮食习惯的问题，及时查出来也算是好事，补充了一些维生素B族后相关参数明显恢复正常值了，还没来得及再复诊。\n精神状况今年一开始的时候状态还算可以，但是2月底有一次我超负荷运转了两三天，之后开始各种不太好。4月去医院大夫又加了新的药，后来6月底为了改善睡眠质量加上了安眠药，几个月后我发现这个大夫一直有问题就加药，同时每次和这个大夫沟通都感觉被当傻子一样对待，于是我又换了大夫，这个大夫让我停掉了安眠药。在这个不断换药的途中不论是睡眠还是精神状态都没有趋于稳定。\n说到健康一定离不开锻炼。这方面确实做得不够，每次都是锻炼了一段时间就因为各种各样的理由暂停了。也不是多么讨厌锻炼，只是没有形成一种自然而然的习惯。\n做好编译器一直到5月份还都在认真做自己的compiler，其中2月底开始用Scala换掉ruby，由于开发的效率不高，5月的时候前端的东西才差不多能跑了，此时需要开始做一些优化层面相关的事情，我从每天固定提交代码转变到了学习阶段。\n在前期实现的过程中研究了一段时间rust的代码，开始学习优化的时候又去学了一点LLVM的东西，从PassManager开始到一些简单的Pass，对LLVM的整体结构以及一些组件有了一些了解。之后关于compiler随便读了点书，了解了一些概念，实现了一点简单的分析和优化，还实现了一点后端部分，结合gcc能够生成非常简单的native代码，这些部分我就没有放到我的博客里了。这个过程大概持续到九月多，中间也有很长一段时间都很少去学些什么。\nLLVM相关的文章：https://homura.live/tags/LLVM/\n自己的compiler开发周记：https://homura.live/tags/Rc-lang/\n拍到很多照片今年也算是拍了一些照片，最初的安排是每周末出门拍照，只是从五月疫情严重居家办公开始，之后出门拍照的次数越来越少，而夏天也因为太热几乎没有出门拍照。不过到了合适的时节，（比如说中秋节）还是会去特定的地点拍一些照片。关于照片集，虽然有过想做的想法，也调研过一点点相关资料，但是后续似乎是因为当前照片素材不够，需要再拍一些再考虑成相册。关于设计和排版今年也学了一丁点相关软件的使用和一点点简单的知识，但是后面因为思路枯竭，没有应用场景，以及时间与生活节奏开始混乱，也没有再多学习了（总之就是给自己找各种各样的借口）。除了设计画册相关的之外也大概看了一点关于摄影的书籍，也多少有一些收获，但实践太少还是学的太肤浅。今年关于拍照相关的大概就是这些，最后选几张我还算喜欢的照片。（未进行调整，别问为什么，问就是懒）\n\n\n\n\n\n\n和别人一起努力这个目标是完完全全不沾边。我后来几乎没有考虑过这件事情了，也许我从最初就没有抱有过希望。有人一起努力，或者在某个圈子里一起努力，我觉得是非常有利于个人前进的事情，但是现在的我似乎并不能这样。我的行为习惯在让我避开他人，同时我慵懒的态度导致也无法跟上一直在努力学习的他人的步伐，也无法融入什么圈子。对于这个目标的态度我只有用“摆烂”这个词了，这个问题的依赖还没有被解决，这个问题本身也自然不可能去发生什么变化。\n博客不论是技术文还是水文，都算下来今年博客上提交了42篇文章。\n我本来的计划是一周一篇，但是自从我停下了周记后（5.15）渐渐开始打乱了节奏。之后的LLVM Pass系列的相关博客又维持了一阵子时间，但完结后又未能维持更新的节奏，尤其是这两个月几乎停摆。技术博客相关和我学习的进展有关系，今年后半段我学习的进展也是停滞不前，博客也跟着一起没什么变化。\n很多时候我都不知道该怎么写，即便今年过去了，我觉得自己对写博客这件事情依然没有那么熟练，对于让别人能看懂以及组织语言和结构这些事情都做不好，可能需要专门的练习，但我不太会专门花时间去做这件事情，至少先能保证稳定更新频率再说。\n写的时候都是抱着反正也没人看的态度，本身确实不会有什么人对我写的内容感兴趣，另一方面希望越大失望越大。但后来有的人看到了我的技术文，还找到我的联系方式来联系我，这让我感到意外和开心。虽然并不是为了功利去写，但是这也确实给了我比较正向的反馈。\n今年还做了些什么工作今年工作的内容比较杂，组内的项目在全部推倒重来，我基本上是每个环节都在跟着做，由于算是初期，各个方面都需要我们来做，以及都是优先移植好原有的功能，所以各方面涉及的都比较浅，但也可以说是熟悉每个模块，同时熟悉模块之间的关系，能够把握每个模块对于其他模块的影响，格局打开了！这个过程中也接触到了一些新东西，算是有所收获。工作的同时还开发了一些便于调试的工具，过去同事们的调试方法实在不适合我这种又笨又懒的人。\n有几篇博客记录了工作相关的一些踩坑经历\nhttps://homura.live/2022/10/02/Problem/nuttx-mm-in-64/\nhttps://homura.live/2022/03/29/Problem/solve-ci-and-link/\nhttps://homura.live/2022/10/02/Problem/some-work-problem/\n工作外的学习作为程序员那不可避免的要留下小格子的记录，趁着前段时间GitHub变蓝就留了个截图。\n\n这些提交基本上都是自己的东西，也有一部分是在其他分支没有统计到，总之今年什么时候在家的时间摸鱼一目了然。\n除了上面提到的编译器相关的内容，又开了os的坑，开这个坑很大一部分原因是上面提到的这篇博客。\nhttps://homura.live/2022/10/02/Problem/nuttx-mm-in-64/\n基于裸机系统修复了内存分配问题，让我想起了过去想实现os的愿望，接着参考现有的项目（xv6-riscv为主）抄了一部分的rvv os的实现，rvv的启动代码比起Intel的各种历史包袱真的是太简单了，难免产生了如果我早来看这个该多好的想法。抄os代码这部分也开了博客，不过目前只写了第0期。\nhttps://homura.live/2022/11/13/xv6-riscv-os/xv6-riscv-os-0/\n生活上的技能以及代码之外知识的学习也是必不可少的，各种乱七八糟的东西三分钟热度买了杂七杂八的书籍，趁着上头看了那么一点点，或者三分钟热度去搜了一些东西记到了笔记中。曾经有那么一段时间我意识到自己目前的行为方式就是这样三分钟热度，觉得目前改不掉，那不如就随着这股热情去，只要选择一种能够积累下东西的方式就可以了，比如说每次三分钟热度的内容都留下笔记，之后不论什么时候想重新回来看都不必从头再来。今年也算是在笔记软件里多少积累了一点点东西，希望能在以后用上。\n还做了些什么首先是前面尚未提到但是在实施的一些习惯。\n学习钢琴 从二月开始上钢琴课，也算是坚持了快一年，除了生病和偶尔几天实在专注不了外每天都有在坚持练习。这么久下来拜厄勉强通关了，虽然我练的非常慢，但和我一开始真的是天差地别了。\n读书的目标是平均一个月一本，今年也是轻松的达到了。我的阅读量很小，目标也不敢设的太高，就这样慢慢的积累也挺好的。今年在一个朋友的影响下读了一些文学，也写了一些感想，希望明年都能保持。看到许多朋友写了读书总结，我读的也不多，也不值得再开一篇文章，不过后面的部分会提我觉得不错的书。关于读书和影视相关的记录，7月开始我也开始在豆瓣上进行标记，这是我今年豆瓣的格子记录，虽然没什么用就是了。\n\n同时在继续更新自己的读书channel（尽管最近两个月都摸了），对愿意订阅这个channel的读者我在此表示感谢，希望明年能在channel发更多的内容，而不是像最近一样总是摸鱼。tg channel链接：https://t.me/homura_grand_archives\n还养成了见到镜子中的自己就笑一笑的习惯。最初想到这个是5月份，看到几个喜欢的up主一直都充满着笑容，我知道自己平常的表情更倾向于一脸阴沉，让人看着就不想接触，同时试图通过这种身体的行为改变去改变自己的情绪，半年下来这个习惯也算是养成了，只是最近似乎有些忘，需要再重复巩固一下。\n除了实施的一些习惯之外，今年还有幸接触到了许多以往未曾接触的东西，比如说开始学乐器，去听音乐会，去做瑜伽（做了半年就没继续了，实在太远了…），给朋友写信，尝试许多女装，去心理咨询等等。不过…还是没有谈过女朋友（悲），有好心人愿意介绍女生认识吗。\n接触的作品今年看的认为很不错的动画是《吹响！上低音号》，《利兹与青鸟》，《灵能百分百》第三季，都可以说是神作。\nhttps://homura.live/2022/08/24/Animate/Sound-Enphonium/\nhttps://homura.live/2022/08/15/Animate/LizAndTheBlueBird/\nhttps://homura.live/2022/12/31/Animate/MobPsycho100/\n今年读过的印象深刻且非常喜欢的书有费尔南多·佩索阿的《不安之书》（未读完），莎士比亚的《哈姆雷特》，夏目漱石的《草枕》和《虞美人草》，村上春树的《世界尽头与冷酷仙境》和《海边的卡夫卡》。现在回想《不安之书》是最让我感到惊奇的，《海边的卡夫卡》是最有趣的，只可惜我并没有为它们写点什么。\n虽然看到好多人在写年终阅读总结，我这里就不写了，读的太少不值得拿出来讲。今年内针对部分书籍写了一点想法，其他的书有的写了零碎一点就没好意思发出来，或者干脆没发。\n虞美人草：https://homura.live/2022/10/16/Reading/papaver-rhoeas/\n世界尽头与冷酷仙境：https://homura.live/2022/08/21/Reading/Hard-Boiled-Wonderland/\n加缪的《快乐的死》也还可以\nhttps://homura.live/2022/10/15/Reading/a-happy-death-albert-camus/\n计划与习惯我原本做了一个比较简单的计划用于规划晚上回家以后的时间，前半年执行的也都还可以。但是到了七月发生了一些事情，我的注意力全部被拉走了，完全破坏了执行习惯相关的要点。而这次一直持续了两个月，加上钢琴课作业我觉得需要更多时间，时间分配上也开始乱了套。而上个月底开始的居家办公，又因为我爆肝宝可梦导致又花了很多时间在打游戏上，最后每天只能保证基本的练琴了。尽管后期有些失败，但也算是切身体会到执行习惯的一些关键点的重要性。\n关于习惯参考了《掌控习惯》这本书，十分感谢推荐给我这本书的朋友。\n豆瓣链接：https://book.douban.com/subject/34326931/\n今年内也如往年一样，尝试做过各种规划，从改善各种坏习惯到想要做出什么改变，罗列了很多，当然也如往年一样绝大多数根本没成功。比如说想每月反思，定期选择新的习惯进行养成等。也许都是因为每次列了太多，而不是每次选择一个最重要的去培养，又或者是其他原因，现在的我还未能理解。\n自我写完后回头看去年的总结，没想到也是提到同样的主题，或许人的本性不会这么轻易改变吧。\n高浓度负能量和没意义的大道理警告⚠️，不喜欢请直接跳至下一节。\n对于我来说，重要的不仅是这一年我做了什么，还有到了今年年底我的心态变成了什么样子，我是个怎样的人。\n现状这一年来，我从来未停止过试图改变些什么，这种寻求改变的念头甚至到了魔怔的地步。我的一个朋友说我总是在试图改变，也有些着急改变，我的确是恨不得立刻就能把我身上的问题都改掉，因为在我的内心中如果我不去努力改变些什么那我不值得任何美好的事物，只值得另一个理想自我或者是他人的唾弃，夸张的说会觉得无法在社会生存。尽管有一些看起来像是真的因为追求些什么而去改变，但现在的我似乎又觉得这些所谓的追求也是同样为了“生存”。\n现在的我和过往一样，犯错犯蠢多到令人发指的地步，待人冷漠，经常会因为自我攻击而开始在网上说疯话胡言乱语，性格越来越扭曲。但相比去年来说更好的方面是我的自我觉察能力能强了，能理解此时此刻的我处于什么情境，我到底为什么会这样做，同时即便在说疯话我也能明白我此时此刻在做些什么。难过的是我即便了解这些，产生异样想法的时候试图用理智去说服自己，即便不断的重复，大部分情况仍未能起到什么用处。这些想法本身就令人痛苦，清醒的看着它们而无法做到些什么则会令人更痛苦。不过我在这个过程中也算是真正感受到理性的不可靠性，作为人来说还是感受更加重要，感受完全是不受理性束缚的，我却总想要用理性去修正感性，这也是完全不合理的。\n自己心怀自卑却依然会有自大的妄想，不过今年意识并且切身体会到在某些方面自己远远没有想象中的自己那样好。虽然说着要做这个做那个，但实际上每天都无所事事，经常沉浸于虚拟世界之中（特指各种动画片）。感受到理想与现实的割裂感，说的时候会依照想象中完美自我的说话方式，但行动上却依然是弱小的自己。这让我想到《哈姆雷特》里面国王的一句令我印象深刻的台词\n\n我的言语高高在上，我的思想滞留地下。没有思想的言语永远不会上升天界。\n\n尽管我没有剧情中国王那么坏，但这种不一致性和矛盾性是相通的。\n即使我知道今年有一些做的好的地方，但我依然无法认同自己，相比起这些“看起来微不足道”的改变，自己剩下的问题更严重。这本质是一个视角问题，即便当下的问题已经解决，我大概率也总会找理由去攻击自己。痛苦和折磨绝大部分来自于自身，自己看待问题的态度，自己的行为方式。\n和往年一样，感觉时间过的越来越快了，这让我很是害怕。也许是害怕死亡，也许是害怕一事无成，也许是害怕虚度光阴，我不敢断言害怕的东西到底是什么样的。今年工作日每日重复的时间地点行为，每周末也都是几乎类似的，重复这件事情本身我觉得并无大碍，我只是不舍得时间就这样过去了。上半年都在做着自己要做的事情，却还总是担心时间的流逝，也许是感觉自己的时间利用的很差劲，觉得最后什么都没做好，迷失在了时间的洪流之中又无力掌控方向。而实际似乎也因为并没有花费多少时间学习也就没有学到多少，大多数时间还在发呆，娱乐。\n前半年顺从着习惯，而后半年习惯渐渐瓦解，我的状态也各种有问题，做的事情渐渐开始变少了，不想做任何事情的状态再度袭来。后来我才真正体会到对于现在的我或许不需要去追寻什么非常喜欢的东西，至少当前不想做任何事情的时候是这样。我需要的是在我状态还算可以的时候选择几件事情，然后每日去做，不去想什么想不想做，只是每天一定要做的任务。\n在写总结的时候偶然想到似乎最近没有那么强烈的一定要成为什么大佬的想法，开始思考起所谓成为大佬这种事意味着什么呢，而这件事对我来说又意味着什么呢？仔细想想我也许只是为了那么一个名号，喊的只有成为这个结果，却没有去追求学会什么知识，只是想通过这样的结果和标签获取关注和认同罢了。我之前发表过想成为编译器专家这种暴论，但渐渐我发现了，现在的我不是能成为什么领域专家的人。在我看了各种乱七八糟东西以后，意识到这和一个人的行为习惯有很大的关系，人一天绝大部分都是依靠无意识的习惯。同时我的目标应该是学好某个方面的知识，到达什么名号或者名誉都不是我应该去考虑的。\n今年最后一个月的一半时间除了工作就是专心打游戏，这段时间非常平静，没有抱有对这种事情的执念。但当我从游戏世界中走出来，看着现实世界，思考起现实世界的问题，又难以恢复平静的心态，尤其是在最后几天大家纷纷放出了自己的年终总结，不由得对别人丰富多彩的一年感到羡慕，又三分钟热度想要成为多么好的人。想必明年也会如此，时而平静，时而扭曲，时而上推发疯。这些想法强烈的时候会非常痛苦，过去也不知该如何去缓解，也许需要等到真的接纳自己，真的觉得这样的自己也能很好的生存的时候，到时我的目标或许就会真正变为学好些什么，而不是成为什么带有名头的人。\n人为什么一定要向着顶端爬呢，有的人是因为想要征服山顶，有的人是因为不安。我一定是后者吧，没有能够安稳生存的自信，想要通过这一种极端的方式来掩盖所有生活中的其他问题，真是懦弱。\n年初的我\n我想过，我把时间分成这么多份最后的结果一定是每样都做不好。我不是说所有人都是这样，只是我比较笨，多方面全能的天才太多了，不论是看过的传记，还是推特上实际见到过的大佬，他们都是切实做到全才尽管我每样都不会做好，但是总比浪费时间要强的多。我在选择一些东西的时候就在想，如果不做这个，我的时间可以拿来做什么？答案显而易见，和我过去的周末一样，浪费时间。我也在想，这些东西是否真的有必要，但是我感兴趣就够了，什么东西能够起到什么作用这种事情充满了太多的未知。年初写下这些话，不知道年末的我怎么想\n\n一年下来，发现对我来说如果在做了就很好了，因为很多的时间依然被我随意浪费与挥霍。想要尽量减少浪费时间就去多做一些能够积累下来的东西，比如说学的东西用笔记的形式记录下来。而在这个时间洪流中前进的方法只有养成各种方面的习惯，习惯到了很多事情也就能做到了，但这个过程比做到什么事情本身还要难上许多。\n迷失方向找不到自己应去之处，找不到人生的方向，这是一个困扰着绝大多数人的问题，而我也是绝大多数人的其中一员。对于未来的发展方向今年有过许多乱七八糟的想法，年初有，但到年中逐渐开始变化，到年末变化太大导致年初的想法又全军覆没。其中也做过一些奇奇怪怪的努力，但是都有些无功而返。自己尚未具备选择些什么的决心，也缺少将其实现的能力与自信。有过许多想法，但几乎每次都在变。这样的我现在能做的或许只能像最上面所说，先选中一些什么东西，坚持做下去吧。\n除了之外，我对于自身的存在也感到迷茫。对于自己的人格，对于道德，对于对与错，对于各种各样的问题都在疑惑。疑惑也算是好事，起码我开始思考起这些问题了，开始想要跳出这个圈子看待问题，而不是继续陷入圈内。越发觉得不了解自己，不知道自己的兴趣爱好，不知道自己想要的是什么。因此什么都要，放弃做出选择，还会为得不到某些不需要的东西而产生负面情绪。也因此所追寻的大多数是别人的东西，外界所灌输的“我这样的人”所应该追求的，而不真正属于我自己想要的。我到底想要到哪里去，想要成为怎么样的人呢？\n生活疫情今年无疑是被疫情影响最大的一年。五月开始常态化核酸。后来核酸的频率降低，一直持续到了12月彻底放开。疫情影响导致多次居家远程办公，远程办公有好有坏，硬要说坏的方面比较多，但是家里的硬件设备远比公司舒服，同时又可以一直一个人窝着，因此还是更喜欢远程办公。彻底放开导致许多人都感染了新冠，而我选择蜗居在家，也因此暂时避免了感染。\n作息今年作息越来越阴间了，年初还是在12点睡，后来渐渐的12点半，10月底的时候差不多1点睡了。自从上个月底开始居家办公，仗着可以更晚起床，居然过分的到了一点半甚至到了两点才睡。\n经济今年涨了工资，经济状况相对来说宽裕了一些。今年依然在记账，虽然可能一如既往的记的不够精细，但是分析开销还是够用了。看了今年的账单，有点想打消整租的念头了，如果整租每个月起码要多支出2k多，以及冬天供暖还需要自己一个人承担费用。\n随便讲一下情况，最大头的分类自然还是必须支出，吃穿住用的日常用品。住就不提了，一年吃了2w8，也花了不少。今年舍得打车了，没想到打车就花了快2k…淘汰了很多旧衣服，这方面也花了不少钱，电费什么的也花了不少，还有各种买药，杂七杂八的日用品。第二大头就是消费了，电子产品居多。其中很大一部分都是去年分期买的（比如说去年24期分息入手了M1Max…），加装了显示器以及入了相机镜头什么的。最后一大部分就是钢琴课，心理咨询以及前半年瑜伽的费用。书也花了不少钱，尤其是双十一的时候囤了20多本，一年下来杂七杂八的书花了快2000…虽然可能没看多少吧，很多都是有需要买来翻一翻。\n人际我这个人独来独往习惯了，便不想和人去打交道。有不擅长的成分，有害怕的成分，有觉得浪费时间的成分，总之有很多乱七八糟的原因形成了我现在这个样子。不过大多数不会因为讨厌别人，也因此我几乎不会为了维持关系去私聊他人。用一句话来形容，大概就是“我为来来往往的人流感到烦躁，但并没有因为你而烦躁“（已不记得原话）。这也是一个非常复杂的问题，和咨询师提到过这个问题一两次，但后来因为生病加各种问题，未再深入讨论这个话题了，明年一定要再深入讨论下去。不过不论怎么讨论，最终都是需要我来做出些什么改变。\n今年发现了一个非常非常喜欢的网友，和他交流的过程中发现他简直就是我理想中的样子，追随着他的身影，也多少受到了他的一些正面影响。充满了想要成为他那样的想法，尽管那是不可能的。而在和他相处的过程中我受到了他的帮助，也改变并且成长了许多。人的成长还是要和什么人发生什么事情才行，只身一人游离于一切之外是不可能发生多少变化的，这是我今年的经历中切身体会到并且意识到的事情。\n自己现在认识人的途径几乎只有Twitter了，今年新认识了许多Twitter上的朋友，也面基了几位，也有一些朋友没来得及面基，今年也要感谢朋友们对我的帮助以及对这样的我的容忍。\n明年的愿景我是非常贪心并且做不出选择的人，因此想添加上非常多的愿景。写这么多其实是不利于实现的，或许应该找几个核心目标再围绕展开，但这里还是想到什么写什么。\n生活学习和生活想要恢复到今年刚开始的状态，并且希望能维持下去。身体健康方面还是要尽量下功夫，起码要保持每天运动的习惯，即便锻炼量很少，也要坚持动下去。关于情绪方面，尽管我有很多负面或者扭曲的想法，但是我大多能够及时觉察，认为自己能够一定程度的应对，只是很多时候由于各种大脑成分的原因我无法停止一些负面的想法，这些就不属于我改变想法就能做到的了。\n找画师约一个皮套，直接出道。目前打算每天直播回家以后的学习生活，但似乎实现起来会有很多不方便，所以暂且将目标定在约好皮套这一步。\n想遇到属于自己的madoka，这个是最想实现但是最不抱希望的了，做梦都没有这种好事的。\n疫情好一些的话可能会挑个假期去南方转转。\n希望今年能形成一些新的好习惯。\n学习compiler和os的坑会继续填，compiler的话继续开发我的玩具，以及再花些时间学习一下LLVM相关的内容，os起码要到把xv6里提到的功能抄一遍的地步，如果可以自制cpu这方面我也想开个坑，这个就尽力而为了。我觉得光是这些超大的坑就已经够占据我的精力了，暂时不去多想其他内容。\n博客希望起码能保证两周一篇，如果可以还是想一周一篇，可以实施以写博客为目的的学习，既能保证博客更新又能保证持续学到东西。\n除了专业技术之外我希望能多学一些专业之外的知识和技能，可能会向视觉类（设计/摄影）之类的靠近，也可能向一些科学方面的。\n读书还是维持每个月一本好了。双十一阶段一口气囤了二十多本书，也不奢求能读完，毕竟比起要求读完还是持续阅读并且享受书中的内容更加重要。\n自我希望能对自己的生活有更多的掌控力，而这件事情的实现需要依赖于每一件小事的积累，并不需要我特地完成什么，只要做好其他任务自然能够做到。希望通过这样的方式逐渐增长一点自信。\n最重要的是希望能够更加清楚的认识自己，找到自己的方向，不再因为没有自己想要的东西就去想要所有的东西，羡慕所有的人。\n还想要多探究一些自己的感受，而不是自己的想法，多接触一些带有情感的事物或者作品，而不是只有冷冰冰的机器和科学知识。\n不重要的想法这部分的内容都是随缘了，不会太过于关注。\n\n小概率可能会继续写日记。去年写了几天但是后来就没再写了。\n会试着强迫自己去再接触一些人，尤其是线下，也会试着开展新的交友渠道。\n希望夏天有机会拍到英仙座流星雨。\n想女装出门拍照，再修个图出来康康。\n尝试一些其他新事物什么的。\n\nThe End今年也多多少少做了一些事情，并且我能够确信有了不小的进步，这份进步也必然来自于我自身的行动。不过即便如此，这些内容放到一年的维度上来说真的是感觉非常渺小，每天都觉得在混日子一样的活着。因此说不上好，也说不上坏，只是又度过了一年平淡时光。\n不过，平平淡淡也没什么不好。\n\n你的人生你做主，平淡无奇又何妨。总有一天，定能发现，各自的答案。\n\n来自《灵能百分百》第一季op\n最后放一下今年最后一餐的烤鱼照片，不知为何今天突然想吃了，晚上火速下单！\n\n","categories":["Thinking"]},{"title":"调试器之工作原理","url":"/2023/01/09/Debugger/debugger-0/","content":"调试器之工作原理之前对于调试器并没有什么了解，对于很多问题也没什么头脑，比如说attach是怎么做到的，怎么实现运行时断点的。今天来简单了解一下调试器部分功能的工作原理。\n断点对于调试来说第一步是要下断点。断点本质是到了指定位置后中断当前的进程，进入对应的中断处理程序。（信号的本质是软中断，这里、统一称发生了中断）\n根据实现方式的不同分为如下三类。\n软件断点当cpu执行了特定调试指令后会发出一个中断，而软件断点要做的就是在对应的pc位置“插入”断点指令，说是插入，实际上是修改原指令，触发中断后再写回。\n以x86的INT3指令为例，在一个位置设置断点后会保存该位置的原指令，之后在该位置写入INT3，当执行到这条指令的时候发生软中断，内核向子进程发送SIGTRAP信号，之后这个信号转发给父进程，此时再用保存的指令替换之前写入的INT3指令等待中断恢复。\n硬件断点某些cpu包含调试用的寄存器，通过设置对应的值来控制对应产生中断的pc位置以及一些其他信息。\nx86 debug register - Wikipedia\ncpu在执行代码之前会先确定要执行的地址是否保存在中断寄存器中，同时确认访问的地址是否处于设置了硬件断点的区域内，满足条件后会触发INT1中断。\n内存断点通过设置对应内存位置所在页为guard page，对保护页访问则会触发异常，之后页面恢复访问前的状态。\nptraceLinux中我们可以直接通过ptrace来打断点、读取信息或者是单步执行等。\n关于ptrace的文档：https://man7.org/linux/man-pages/man2/ptrace.2.html\n直接调试首先我们来看一下用法示例\n#include &lt;sys/ptrace.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt;#include &lt;linux/user.h&gt; int main()&#123;   pid_t child;    long orig_eax;    child = fork();    if(child == 0) &#123;        ptrace(PTRACE_TRACEME, 0, NULL, NULL);        execl(&quot;/bin/ls&quot;, &quot;ls&quot;, NULL);    &#125;    else &#123;        wait(NULL);        orig_eax = ptrace(PTRACE_PEEKUSER,child, 4 * ORIG_EAX,NULL);        printf(&quot;The child made a &quot;&quot;system call %ld\\n&quot;, orig_eax);        ptrace(PTRACE_CONT, child, NULL, NULL);    &#125;    return 0;&#125;\n\n被调试的程序通过ptrace(PTRACE_TRACEME)来设定自身是被trace的对象，接着通过execl来执行对应的命令行程序，此时执行的程序作为调试器的子进程。\n而调试器进程本身则是通过wait去等待子进程停下来，等wait返回后就可以查看子进程的信息或者对子进程进行操作。对于ptrace使用方面来说最重要的是选择合适的__ptrace_request，大多数调试器常见的功能都能通过设置这个参数来实现，比如说单步。\n这个项目使用ptrace实现了许多debug的基础功能\nhttps://github.com/Kakaluoto/ptraceDebugger\nattach通过设置__ptrace_request为PTRACE_ATTACH或者PTRACE_SEIZE还可以调试一个当前已经启动的进程。\n对于常规的调试和attach的本质区别自然是进程间的关系，直接调试中调试器进程和被调试进程互为父子进程，而attach时两者是独立的，也因此有的时候attch会需要管理员权限。\n其他系统以上ptrace的实现都是基于Linux的api来讲的，macOS的ptrace的request缺少非常多基本功能，比如说读取寄存器的值。如果想要在mac下实现可以参考如下链接，如果是arm的Mac则这里很多接口仍然过时。（我反正不想折腾了，有这时间多看下Linux的不香吗）\nUninformed - vol 4 article 3\nUsing ptrace on OS X\n而对于windows来说则是提供了另一套完全不同的api，有兴趣的可以自行了解。\nDebugger Programming Extension APIs - Windows drivers\n后续这一期的内容都是一些非常容易搜到的基础知识，如果不鸽的话调试器后面会继续深入学习，造一个自己的debugger之类的。大概也会作为一个系列更新，可能深入的方向有如下几个\n\nptrace的具体实现细节代码\ndebug信息的格式以及源码级调试\nlldb的学习\n\n","categories":["Debugger"],"tags":["ptrace"]},{"title":"链接器起始篇","url":"/2023/01/17/linker/linker-init/","content":"\n又开始不务正业乱开新坑了。接下来会通过阅读mold的源码来学习如何实现一个ELF链接器，有精力也会再跟着plct的这个课程学习实现一个简单的RV ELF链接器，可能会跟着将代码换一门语言翻译一遍，将这个学习过程中遇到的知识点记录到博客中。如果坑能开到后面的话我还会针对这门课程实现的链接器在功能上与mold的进行比较，一门教学用的链接器和真正实用的链接器在功能上有哪些差别。\nhttps://github.com/rui314/mold\nindex\n从未了解过链接器实现的我，在跟着mold源码和这门课程之前，先来写一下根据我现有的知识去设想一个链接器内部应该大致有哪些功能。（本期内容不是教程，只是我个人对知识的回忆，因此很多地方都会缺很多东西）同时回忆过后对比检查理解的问题，在差不多理解整体运作过程的情况下学习会更有效一些。\n链接器做了什么\n链接器做的事情是将多个编译器生成的目标文件的内容合到一起\n处理符号。在编译期间要求编译生成的目标文件中每个符号小于等于一个定义，在链接的时候链接器负责找到未定义的符号的地址，重复符号的解决（如果是弱符号则根据规则选取其中一个定义，如果非弱符号则需要报错）\n\n目标文件要合并目标文件那么我们要知道目标文件的内容是什么样的（这里我们仅探讨ELF的格式）。先不查阅文档，想一下目标文件大概会有什么内容。\n段首先是对于我们写代码的时候经常提到的一些段，比如说代码段、数据段、BSS段、堆、栈等等。这些段本身只是一串数据，那么我们需要一个位置存放起始位置和数据长度。而其中的各种段名以及各种符号名也需要一个位置保存，因此目标文件中还需要有一个符号段用于保存各种用于链接使用的符号。（strip是否就是去掉这里）我们知道debug模式生成的代码包含debug信息，而这些信息对于elf来说是写在内部的，因此里面还需要有保存调试信息的段。\n文件头类似于段段起始和长度这种\n寻找保存具体信息的信息需要放到一个文件头中，除此之外文件头中还需要一些魔数来标识文件类型。\n符号表保存所有代码中符号的相关信息（而不是段名的符号），最容易想到的就是地址，其次上面提到了符号的强弱。\n行为控制而更精细控制这些行为的方式一个是命令行参数，另一个是链接脚本。由于系统中内置了默认的链接脚本，我们日常很少会接触到这些。读取链接脚本也是链接器很重要的一个功能。\n总结回顾下来，链接器主要的功能如下\n\n读取目标文件ELF文件头\n读取链接脚本并且按照链接脚本控制链接行为\n符号解析\n合并段\n生成对应的ELF文件\n\n而plct课程的大纲如下\n第一课：搭建开发环境、初始化项目、开始读取 ELF 文件\n第二课：继续读取 ELF 文件\n第三课：解析链接器参数\n第四课：解析静态链接库文件\n第五课：解析未定义符号，移除未使用文件\n第六课：处理 Mergeable Sections\n第七课：开始写文件\n第八课：处理 Output Sections\n第九课：继续处理 Output Sections\n第十课：Phdr 和 Merged Sections\n第十一课：处理重定向，课程回顾\n可以说做的功能大致类似，之后就会先从mold的源码开始开新系列了。\n","categories":["Linker"]},{"title":"mold源码阅读 其零 main","url":"/2023/02/12/mold/mold-0/","content":"\n我们从main函数的开始，大致讲一下都做了哪些事情。之后再从每个流程中的具体实现开始阅读（如果我记得的话会回头在这里补上对应的链接），或者会以解决某些问题为线索写一篇，比如说某一些常见的参数具体在mold中怎么生效的，比如说whole_archive这种。为保证两部分文章内容的连贯性，内容不可避免会有一定重叠。\n这个系列的一些约定\n\n只考虑elf的支持，其他平台相关的不再考虑\n文件路径都是项目根目录的相对路径\n\n文件结构由于代码比较少，项目的结构非常简单\n├── docs├── elf├── test│   └── elf└── third-party    ├── mimalloc    ├── rust-demangle    ├── tbb    ├── xxhash    ├── zlib    └── zstd\n\n根目录下有一些共用的文件以及一些项目的常规文件\n启动的main函数也是在根目录下\n在elf目录下是我们需要看的主要核心代码\n\n在这之中有两个作为主线的文件: main.cc和passes.cc\n实际执行链接的主要流程都存放在main.cc的elf_main中，而这个过程执行的代码大多会指向passes.cc中的函数。不同目标arch的文件都用相应的文件名区分开了，以及其他的文件看名字也相对比较易懂。\n链接前的准备流程main.cc\nint main(int argc, char **argv) &#123;  mold::mold_version = mold::get_mold_version();#if MOLD_IS_SOLD  std::string cmd = mold::filepath(argv[0]).filename().string();  if (cmd == &quot;ld64&quot; || cmd == &quot;ld64.mold&quot;)    return mold::macho::main(argc, argv);#endif  return mold::elf::main(argc, argv);&#125;\n\nelf/main.cc\n默认采用了X86_64\nint main(int argc, char **argv) &#123;  return elf_main&lt;X86_64&gt;(argc, argv);&#125;\n\n对于不同的Machine Type是通过模板类型来区分的。在elf_main里面创建了全局的Context对象（并非是代码实现层面上的全局对象，只是所有的流程都需要传递ctx）并且解析命令行参数（命令行参数的具体实现就不再细看了）\ntemplate &lt;typename E&gt;int elf_main(int argc, char **argv) &#123;  Context&lt;E&gt; ctx;  // Process -run option first. process_run_subcommand() does not return.  if (argc &gt;= 2 &amp;&amp; (argv[1] == &quot;-run&quot;sv || argv[1] == &quot;--run&quot;sv)) &#123;#if defined(_WIN32) || defined(__APPLE__)    Fatal(ctx) &lt;&lt; &quot;-run is supported only on Unix&quot;;#endif    process_run_subcommand(ctx, argc, argv);  &#125;  // Parse non-positional command line options  ctx.cmdline_args = expand_response_files(ctx, argv);  std::vector&lt;std::string&gt; file_args = parse_nonpositional_args(ctx);\n\n获取具体的machine_type\n// If no -m option is given, deduce it from input files.if (ctx.arg.emulation == MachineType::NONE)  ctx.arg.emulation = deduce_machine_type(ctx, file_args);// Redo if -m is not x86-64.if constexpr (std::is_same_v&lt;E, X86_64&gt;)  if (ctx.arg.emulation != MachineType::X86_64)    return redo_main&lt;E&gt;(argc, argv, ctx.arg.emulation);\n\nredo_main就是简单的根据命令行参数指定的target来选择对应的模板类型进行特化\ntemplate &lt;typename E&gt;static int redo_main(int argc, char **argv, MachineType ty) &#123;  switch (ty) &#123;  case MachineType::I386:    return elf_main&lt;I386&gt;(argc, argv);  case MachineType::ARM64:    return elf_main&lt;ARM64&gt;(argc, argv);  case MachineType::ARM32:    return elf_main&lt;ARM32&gt;(argc, argv);  case MachineType::RV64LE:    return elf_main&lt;RV64LE&gt;(argc, argv);  case MachineType::RV64BE:    return elf_main&lt;RV64BE&gt;(argc, argv);  case MachineType::RV32LE:    return elf_main&lt;RV32LE&gt;(argc, argv);  case MachineType::RV32BE:    return elf_main&lt;RV32BE&gt;(argc, argv);  case MachineType::PPC64V1:    return elf_main&lt;PPC64V1&gt;(argc, argv);  case MachineType::PPC64V2:    return elf_main&lt;PPC64V2&gt;(argc, argv);  case MachineType::S390X:    return elf_main&lt;S390X&gt;(argc, argv);  case MachineType::SPARC64:    return elf_main&lt;SPARC64&gt;(argc, argv);  case MachineType::M68K:    return elf_main&lt;M68K&gt;(argc, argv);  default:    unreachable();  &#125;&#125;\n\n链接大体流程根据注释和我个人的理解，分为如下这么几大部分\n\n解析所有的输入，包含命令行参数，输入的各种文件\n对于输入做链接器最基本的处理，包含符号解析，段合并，符号检查之类的\n创建一些synthetic的内容，包括一些段和符号\n将所有段、符号进行扫描以及按照需求进行排序，添加到全局的ctxt中\n计算与修正一些具体的信息，固定生成产物的memory layout\n修正某些地址，确保固定file layout\n将所有文件拷贝到输出文件中\n结束的清理操作\n\n其中有些地方可以根据Timer来协助划分链接的流程。比如说拷贝到输出之前有这样一行\nTimer t_copy(ctx, &quot;copy&quot;);\n\n而到了后面的部分有这么一行对应，中间的部分很自然就是这一个步骤做的事情了\nt_copy.stop();\n\n而main函数中的内容比较简洁，几乎每个小功能都划分为了一个函数，而且附加了大量的注释，比如说这样\n// Create .bss sections for common symbols.convert_common_symbols(ctx);// Apply version scripts.apply_version_script(ctx);// Parse symbol version suffixes (e.g. &quot;foo@ver1&quot;).parse_symbol_version(ctx);// Set is_imported and is_exported bits for each symbol.compute_import_export(ctx);\n\n再加上代码比较长，这里就不放后续完整代码了。\n","categories":["Linker"],"tags":["mold"]},{"title":"心理咨询是怎样的","url":"/2023/02/18/Life/psychological-counseling/","content":"本文根据自身心理咨询的认识与经历，写下了一些想要进行心理咨询的人们可能关心的问题。\n首先是价格，我目前在一些平台了解的结果，除去新手咨询师外价格通常在500-1000+不等（此处不推荐平台以及咨询师的选购指导）。而咨询的频率通常是在一周一次，具体频率需要和咨询师进行商定，间隔超过一周可能时间太久内容难以连贯，少于一周可能费用上更难接受一些，即便是最便宜的档次一周一次，一个月也要2000的费用，更何况这是一项长期的工作，如果你能接受这个价格再继续看下去。流程上也没有什么特别的，预约时间，当天到咨询师所在的地方进行一小时左右的沟通，基本上是一对一。（这里咱不探讨团体咨询以及多人咨询）\n咨询的方式有着不同的流派，而不论是什么流派，咨询的过程都是沟通为主。咨询师会问你各种问题，又或者由你自己挑起某些话题，如果可以还是自己选择某些比较关心的话题开场比较好，而具体的话题会因流派不同而异。有的流派会倾向于长期咨询，有的会倾向于短期解决问题，在选择的时候还是需要注意，通常咨询之前也会问你是想要进行短期还是长期的咨询ty。我在此更建议长期的咨询，首先咨询师需要几次对话充分了解你，你也需要几次机会去熟悉跟咨询师去讲述一些事情，后面需要更长的周期去一点点深入自己的内心，一点点的去修复问题。在对话的过程中，通常会涉及到你的许多想法、感受、过去、秘密、家庭、人际关系等等，同时在这个交流沟通的过程中，会不断探寻自己的内心，有的时候就戳到痛处，如果要选择咨询，要做好暴露一切的心理准备。有的人并不在意和陌生人讲这些，但也有的人面对陌生人会比较难以说出这些，这些人群需要一定时间去适应，也不必觉得因为自己不想说就完全不适合去咨询。咨询时有什么不适的感受也都尽情的跟咨询师提出，不用担心提出意见会有什么攻击性的反应，我之前对咨询师的一些问法感到厌烦，及时和咨询师进行沟通，这种厌烦感也就慢慢结束了。\n在我目前的理解与体验咨询主要以两种形式起作用。第一种是感性上的支持，对于心里积攒着很多想法的人来说，咨询师会耐心倾听你的诉说，在这个过程中你可以放心的讲你所不愿跟别人讲的秘密，或者你认为会被人厌烦的内容，不必担心被人拒绝，被人讨厌。而对于孤单的人来说，咨询师也是一个每周陪伴你的人，不会因为你做错了什么就会放弃你。他们会给予你情感上的支持，在你遇到问题会与你产生共情。第二种则是理性上的支持，对于需要咨询的人来讲，通常会有许多思维的误区，而找出这些误区也是咨询师们的工作之一。另外还会对你一些具体的问题会给出建设性的建议，最关键的是和你一起分析你的问题，你的思维方式，作为一个旁观者，而不是作为你自己来观察这一切，远比自己观察的要清楚。你需要明白这些，在这个过程中你可能会学会自己查找自己的问题，同时还会增强你对于自己问题的修正。\n以下是《神经症与人的成长》这本书中的摘录\n\n所有精神方面可能涉及到的知识，都可以使每个人有机会找出自己的困难所在。\n\n\n此外，病人不可只知道这些个别因素，而且也应该知道其间的关系与其相互间的作用。\n\n\n了解所有的这些因素，并非指懂得这些因素的死知识，而是意指要彻底地去认识它们。\n\n对于一些十分特别的流派或许会有其他更特别的解决方式，这里暂且不谈论。\n不论如何起作用，心理咨询的过程是一个不断探寻自己内心的过程，看到现在的自己和过去的联系，而目的是为了让你重新找回对抗问题的力量，而不是帮助你解决所有问题。理解了一个又一个的问题，解决了一个又一个问题的过程，同时也是在不断增强自身力量的过程。\n也许你会在纠结到底要不要进行咨询，你不如换个问题，你想要通过咨询获得什么？对于我来说，通常会对自己的想法进行基本的觉察与反思，也并没有什么一定要跟别人倾诉的苦水，我需要一个人从外部来看待我，帮助我更快的解决自己的问题，找到我自己难以看到的想法中的误区，毕竟“当局者迷”，同时想要有人跟我深入的探讨一些个人成长与性格中的一些问题。事实上我最近三次的咨询也确实达到了期望的效果。这些问题没法跟认识的绝大部分人去交流，有的人不关心这些，有的人不愿意聊这些，或者说没有那么要好的朋友，谈论这些内容或许是需要非常深入密切的关系才行，你需要袒露你内心中的秘密，你要愿意将这个秘密讲出来，而对方也要愿意接受你的秘密，愿意帮助你解决这些问题。\n在这里要认清一些思维误区。首先并不是去咨询了就一定能解决任何问题，也不是依靠咨询师就能解决大部分问题，咨询师只是辅助你解决问题，最终还是需要你自己去真正改变想法。其次咨询并不是什么丢人的事情，或许在大众的认知中去接受心理咨询就是所谓的“神经病“，但我想你看了上面的内容后或许不会这样想，即便是这个领域大师级别的人物仍然需要他人帮助自己进行心理咨询。\n如果想要了解更多关于心理咨询的过程或者其他内容，可以参考《也许你该找个人聊聊》。另外个人十分推荐《神经症与人的成长》，书中的一些分析讲的非常棒，非常有助于理解自己的一些问题。\n","categories":["Life"],"tags":["心理咨询"]},{"title":"美丽新世界","url":"/2023/02/19/Reading/brave-new-world/","content":"起初阅读前面对于这个“美丽新世界”构成的时候我并没有感觉到任何美丽，有的只有反感，这里的人们丧失自由，被制约，几乎人生的一切都被安排好，无法改变的人种歧视与阶级的固化，许多错误的观念从小就被根植在记忆深处，想法都是受到操纵的。\n\n到最后，孩童的心灵就是这些暗示，暗示的总和就是孩童的心灵。而且不只是孩童的心灵，成人的心灵也是——一辈子都是。下判断、产生欲望、做决定的那个心灵——就由这些暗示构成。但这所有暗示都是我们的暗示！\n\n这哪里美丽了，这简直是地狱。\n但是读到后面，我开始动摇了。在这里的人只需要舒适就可以了，无需遭受病痛的折磨，每个人之间都彼此相属也就因此不会因为孤单而痛苦，甚至不需要思考，顺从周围的人以及大脑中已经调整好的暗示去做就好了。即便遇到不如意的事情，还有索麻来将他们从痛苦的当下逃离。\n\n因为我们的世界跟奥瑟罗的世界不同了。你无法不用钢铁来制造福利佛——而没有不稳定的社会，你也不可能创造出悲剧。这个世界现在稳定了。人人都很快乐，他们得到他们想要的东西，而他们永远不会想要他们得不到的。他们很富裕，他们很安全，他们从不生病，他们不怕死，他们幸福地不知何谓激情与老迈，他们没有母亲或父亲的折磨，他们没有妻子、孩子或爱人可以激起强烈的感觉，他们被制约得这么厉害，以至于他们实际上忍不住要表现出他们应有的行为。而要是有任何事情出了错，还有索麻\n\n而上面提到的丧失自由，被歧视，阶级固化等内容，对于”劣等“的人种自身来说并不是什么问题，他们也从来没有觉得这是什么问题。这里的人们也并非丧失了所有的自由，他们有着局限于新世界法则的自由，对于他们来说这样就可以了。所有的消息渠道都不会让他们了解一切的真相，只要他们不了解，继续蒙在鼓里，那么就不会感到任何痛苦。\n\n对他们而言，他们不是牺牲品，他们是最没有抗拒能力的品系。他的制约已经铺好他该沿着哪条铁轨前进。他无法克制自己不这样做，他注定如此。\n\n遭受痛苦与折磨的我无法否认自己读到这里产生了对这种环境的向往，尽管有最初那么多令人反感的描述，尽管明知代价是失去自我、放弃真正的自由、放弃崇高的精神，但这里的人不需要承受痛苦，只需要舒适就可以了。这样撒手不管是很轻松，我想大多数人也都是更倾向于这样的选择，不去产生改变。\n如果身为当局者的话很难对这些问题进行讨论与判断，想法会受到世界本身的限制，如果我是那个世界中的一员，那么我大概率也是会和大多数人一样认为所谓真正的自由、痛苦都很荒谬。接下来还是回到旁观者的上帝视角来看待这一切。以上提到的内容在新世界中是完全对立的：是选择要自我、自由与痛苦，还是舒适和快乐。\n如管制官所说\n\n强调的重点从真理与美转移到舒适与快乐。普遍的快乐，让轮子稳定地转动下去，真理与美却做不到。\n\n新的世界也是如此形成的。追求真理与美是不可能舒适与快乐的，真理与美来自于经历苦难，破坏性的变化。这让我想起加缪的《快乐的死》中提到的观点，高质量的幸福需要通过痛苦体现。同时在管制官和野人的对话中屡次出现莎士比亚的作品，其作品以悲剧美而闻名，也是一个很好的例子。沉溺在舒适与快乐之中无法寻求到真理，每种科学的发现都有潜在的破坏性，而要突破这种破坏性并不会使得舒适与破坏性。在舒适和快乐中也无法体现出人性的美，罗翔老师举过一个例子。\n\n如果现在有一个小黄书，郭德纲相声，一个莎士比亚，三者都会给你带来一些快乐。但是你即便真诚的认为小黄书给你带来了愉悦，郭德纲的相声给你带来了快乐，但只能留一本书，你留哪本书？莎士比亚。这个故事告诉我们，越能体现人性尊严的快乐，越是一种最大的快乐，因为它跟人的尊严有关。\n\n对于“新世界”来说，他们无法得知这一切，大部分人也没有选择的权利。对于现实社会来说，我们完全可以了解到这一切，并且两者都选择，只是或多或少罢了。还是如罗翔老师所说\n\n我读莎士比亚并不妨碍我听郭德纲的相声，但是如果你的眼目永远只关心地下，你永远不知道向上看有多么快乐。\n\n不过我们现在所处的“小小世界”，在许多方面已经有了这样的影子，逐渐开始失去了选择的权利。从想法来说，所谓人们的想法就是来自所处的环境、所处的社会、所接触到的地域文化，这让我想到了某些洗脑的宣传，以及不断试图阻挡人们看到真相的，某个大家都很熟知的地方。既然你无法得知真相与其他答案，面前只有一个选项，那么你很大概率不会去考虑这个选项的对与错。除此之外，我还想到了昨天和朋友聊天的时候他提到的“异化”一词\n\n所谓的「自由而来的不自由」。你有一定的自由分工、自由迁徙的能力，但是正是由于深度的投入到了某个社会分工内而被困在了这个环境下的「不自由」。\n\n这个“世界”的人们都是如此，渐渐开始失去了部分的自由，而这份不自由也正是由所处的这个“世界”所造成的。大部分人像阿尔法一样遵循着一直以来的”睡眠教学法“，有的人们像伯纳德一样略微窥探到了一些，有的人像管制官一样看到了全部，即便看到了一切，但我们仍然是被禁锢着，只是所在的“瓶子”或许没有那么小但是不知道哪一天这个瓶子可能会缩到非常小，我想这也正是作者所担忧的事情，担心人们连自己选择一切的权利都失去了，担心人们人生的一切都是被安排的。\n这样的世界我无法断言好还是坏。如果选择经历苦难，那么你要具备面对苦难的能力，你要不断的经历痛苦以及发现真理与美。如果你选择舒适与快乐，那么你将放弃自我，放弃自由。管制官与“野人”的选择则是非常强烈的对比，两者在得知了一切并且有选择权的情况下，一个选择了前者，另一个选择了后者。不论选择哪一个，其实都要付出代价。在这样的世界，绝大部分人其实是没有选择的权利的，但是在现实世界中绝大部分人依然有选择的权利，如果只能在这两者之间选择，你是要成为野人，还是管制官呢？\n","categories":["Reading"],"tags":["奥尔德斯·赫胥黎"]},{"title":"mold源码阅读 其一 读取输入文件","url":"/2023/02/26/mold/mold-1-read-input-files/","content":"上一期主要讲了链接前的一些准备流程以及在mold中链接过程的简单介绍。这期开始我们从链接过程中的功能开始介绍。在开始之前，提前说明一下里面各种缩写有很多，我会在第一次出现时提及缩写具体含义是什么，如果后期更的期数比较多会考虑专门写一页缩写的参考，方便查阅。\n首先是解析输入，命令行参数解析的细节略过，但是这里不能略过elf文件的解析。我们从代码的实现去看elf的结构，再和文档中的图进行对比，同时尽可能从代码中去捋清不同结构之间的联系。\n我们从elf_main函数中的read_input_files开始\nread_input_files(ctx, file_args);\n\nread_input_filestemplate &lt;typename E&gt;static void read_input_files(Context&lt;E&gt; &amp;ctx, std::span&lt;std::string&gt; args) &#123;  Timer t(ctx, &quot;read_input_files&quot;);  std::vector&lt;std::tuple&lt;bool, bool, bool, bool&gt;&gt; state;  ctx.is_static = ctx.arg.is_static;  while (!args.empty()) &#123;    std::string_view arg = args[0];    args = args.subspan(1);    if (arg == &quot;--as-needed&quot;) &#123;      ctx.as_needed = true;    &#125; else if (arg == &quot;--no-as-needed&quot;) &#123;      ctx.as_needed = false;    &#125; else if (arg == &quot;--whole-archive&quot;) &#123;      ctx.whole_archive = true;    &#125; else if (arg == &quot;--no-whole-archive&quot;) &#123;      ctx.whole_archive = false;    &#125; else if (arg == &quot;--Bstatic&quot;) &#123;      ctx.is_static = true;    &#125; else if (arg == &quot;--Bdynamic&quot;) &#123;      ctx.is_static = false;    &#125; else if (arg == &quot;--start-lib&quot;) &#123;      ctx.in_lib = true;    &#125; else if (arg == &quot;--end-lib&quot;) &#123;      ctx.in_lib = false;    &#125; else if (remove_prefix(arg, &quot;--version-script=&quot;)) &#123;      MappedFile&lt;Context&lt;E&gt;&gt; *mf = find_from_search_paths(ctx, std::string(arg));      if (!mf)        Fatal(ctx) &lt;&lt; &quot;--version-script: file not found: &quot; &lt;&lt; arg;      parse_version_script(ctx, mf);    &#125; else if (remove_prefix(arg, &quot;--dynamic-list=&quot;)) &#123;      MappedFile&lt;Context&lt;E&gt;&gt; *mf = find_from_search_paths(ctx, std::string(arg));      if (!mf)        Fatal(ctx) &lt;&lt; &quot;--dynamic-list: file not found: &quot; &lt;&lt; arg;      parse_dynamic_list(ctx, mf);    &#125; else if (remove_prefix(arg, &quot;--export-dynamic-symbol=&quot;)) &#123;      if (arg == &quot;*&quot;)        ctx.default_version = VER_NDX_GLOBAL;      else        ctx.version_patterns.push_back(&#123;arg, &quot;--export-dynamic-symbol&quot;,                                        &quot;global&quot;, VER_NDX_GLOBAL, false&#125;);    &#125; else if (remove_prefix(arg, &quot;--export-dynamic-symbol-list=&quot;)) &#123;      MappedFile&lt;Context&lt;E&gt;&gt; *mf = find_from_search_paths(ctx, std::string(arg));      if (!mf)        Fatal(ctx) &lt;&lt; &quot;--export-dynamic-symbol-list: file not found: &quot; &lt;&lt; arg;      parse_dynamic_list(ctx, mf);    &#125; else if (arg == &quot;--push-state&quot;) &#123;      state.push_back(&#123;ctx.as_needed, ctx.whole_archive, ctx.is_static,                       ctx.in_lib&#125;);    &#125; else if (arg == &quot;--pop-state&quot;) &#123;      if (state.empty())        Fatal(ctx) &lt;&lt; &quot;no state pushed before popping&quot;;      std::tie(ctx.as_needed, ctx.whole_archive, ctx.is_static, ctx.in_lib) =        state.back();      state.pop_back();    &#125; else if (remove_prefix(arg, &quot;-l&quot;)) &#123;      MappedFile&lt;Context&lt;E&gt;&gt; *mf = find_library(ctx, std::string(arg));      mf-&gt;given_fullpath = false;      read_file(ctx, mf);    &#125; else &#123;      read_file(ctx, MappedFile&lt;Context&lt;E&gt;&gt;::must_open(ctx, std::string(arg)));    &#125;  &#125;  if (ctx.objs.empty())    Fatal(ctx) &lt;&lt; &quot;no input files&quot;;  ctx.tg.wait();&#125;\n\n首先是根据命令行参数确定要读取的输入文件，这里大部分的分支是为了读取符号version信息相关的，主要是看read_file的实现。在看实现之前可以看到传入了一个MappedFile，而这个类的实现其实就是在打开文件的时候使用了mmap进行映射，而must_open则是进行判断，失败了直接报错，这里也不贴具体细节代码了。\nread_filetemplate &lt;typename E&gt;void read_file(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf) &#123;  if (ctx.visited.contains(mf-&gt;name))    return;  FileType type = get_file_type(mf);\t... 省略对不同type的处理&#125;\n\n首先是get_file_type，这个是通过文件开头的值确定文件的类型，我们这里以ELF的代码为例。\ntemplate &lt;typename C&gt;FileType get_file_type(MappedFile&lt;C&gt; *mf) &#123;  std::string_view data = mf-&gt;get_contents();  if (data.empty())    return FileType::EMPTY;  if (data.starts_with(&quot;\\177ELF&quot;)) &#123;    u8 byte_order = ((elf::EL32Ehdr *)data.data())-&gt;e_ident[elf::EI_DATA];    if (byte_order == elf::ELFDATA2LSB) &#123;      elf::EL32Ehdr &amp;ehdr = *(elf::EL32Ehdr *)data.data();      if (ehdr.e_type == elf::ET_REL) &#123;        if (ehdr.e_ident[elf::EI_CLASS] == elf::ELFCLASS32) &#123;          if (is_gcc_lto_obj&lt;elf::I386&gt;(mf))            return FileType::GCC_LTO_OBJ;        &#125; else &#123;          if (is_gcc_lto_obj&lt;elf::X86_64&gt;(mf))            return FileType::GCC_LTO_OBJ;        &#125;        return FileType::ELF_OBJ;      &#125;      if (ehdr.e_type == elf::ET_DYN)        return FileType::ELF_DSO;    &#125; else &#123;      elf::EB32Ehdr &amp;ehdr = *(elf::EB32Ehdr *)data.data();      if (ehdr.e_type == elf::ET_REL) &#123;        if (ehdr.e_ident[elf::EI_CLASS] == elf::ELFCLASS32) &#123;          if (is_gcc_lto_obj&lt;elf::M68K&gt;(mf))            return FileType::GCC_LTO_OBJ;        &#125; else &#123;          if (is_gcc_lto_obj&lt;elf::SPARC64&gt;(mf))            return FileType::GCC_LTO_OBJ;        &#125;        return FileType::ELF_OBJ;      &#125;      if (ehdr.e_type == elf::ET_DYN)        return FileType::ELF_DSO;    &#125;    return FileType::UNKNOWN;  &#125;  ... 省略其他格式的判断&#125;\n\n先从数据开头的“\\177ELF”确定为ELF文件，之后根据ELFHeader里面的内容读取更多的信息。\nenum class FileType &#123;  UNKNOWN,  EMPTY,  ELF_OBJ,  ELF_DSO,  MACH_OBJ,  MACH_EXE,  MACH_DYLIB,  MACH_BUNDLE,  MACH_UNIVERSAL,  AR,  THIN_AR,  TAPI,  TEXT,  GCC_LTO_OBJ,  LLVM_BITCODE,&#125;;\n\nmold当前所支持的FileType就是这些，但是注意，GitHub中mold项目下只存在elf文件的支持，mach的格式则是在sold这个项目中处理。除此之外的文件格式都在以下的switch中进行处理\nhttps://github.com/bluewhalesystems/sold\nswitch (type) &#123;case FileType::ELF_OBJ:  ctx.objs.push_back(new_object_file(ctx, mf, &quot;&quot;));  return;case FileType::ELF_DSO:  ctx.dsos.push_back(new_shared_file(ctx, mf));  ctx.visited.insert(mf-&gt;name);  return;case FileType::AR:case FileType::THIN_AR:  for (MappedFile&lt;Context&lt;E&gt;&gt; *child : read_archive_members(ctx, mf)) &#123;    switch (get_file_type(child)) &#123;    case FileType::ELF_OBJ:      ctx.objs.push_back(new_object_file(ctx, child, mf-&gt;name));      break;    case FileType::GCC_LTO_OBJ:    case FileType::LLVM_BITCODE:      if (ObjectFile&lt;E&gt; *file = new_lto_obj(ctx, child, mf-&gt;name))        ctx.objs.push_back(file);      break;    default:      break;    &#125;  &#125;  ctx.visited.insert(mf-&gt;name);  return;case FileType::TEXT:  parse_linker_script(ctx, mf);  return;case FileType::GCC_LTO_OBJ:case FileType::LLVM_BITCODE:  if (ObjectFile&lt;E&gt; *file = new_lto_obj(ctx, mf, &quot;&quot;))    ctx.objs.push_back(file);  return;default:  Fatal(ctx) &lt;&lt; mf-&gt;name &lt;&lt; &quot;: unknown file type&quot;;&#125;\n\n简化下来这里主要分为这么几类文件\n\narchive file\nlto\nlinker_script\nobject_file\nshared_file\n\narchive filearchive file，也就是俗称的.a文件，其实就是许多个object文件塞到一起只需要解析其中所有member，之后将每个member进行读取即可。\ntemplate &lt;typename C&gt;std::vector&lt;MappedFile&lt;C&gt; *&gt;read_archive_members(C &amp;ctx, MappedFile&lt;C&gt; *mf) &#123;  switch (get_file_type(mf)) &#123;  case FileType::AR:    return read_fat_archive_members(ctx, mf);  case FileType::THIN_AR:    return read_thin_archive_members(ctx, mf);  default:    unreachable();  &#125;&#125;\n\n关于ar和thin ar\nar (GNU Binary Utilities)\n\nAn archive can either be thin or it can be normal. It cannot be both at the same time. Once an archive is created its format cannot be changed without first deleting it and then creating a new archive in its place.\n\n这里的具体细节暂且略过，如感兴趣可自行查看源码\nltolto是用于link time optimization的文件，而本质上还是一个object文件，\ntemplate &lt;typename E&gt;static ObjectFile&lt;E&gt; *new_lto_obj(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf,                                  std::string archive_name) &#123;  static Counter count(&quot;parsed_lto_objs&quot;);  count++;  if (ctx.arg.ignore_ir_file.count(mf-&gt;get_identifier()))    return nullptr;  ObjectFile&lt;E&gt; *file = read_lto_object(ctx, mf);  file-&gt;priority = ctx.file_priority++;  file-&gt;archive_name = archive_name;  file-&gt;is_in_lib = ctx.in_lib || (!archive_name.empty() &amp;&amp; !ctx.whole_archive);  file-&gt;is_alive = !file-&gt;is_in_lib;  ctx.has_lto_object = true;  if (ctx.arg.trace)    SyncOut(ctx) &lt;&lt; &quot;trace: &quot; &lt;&lt; *file;  return file;&#125;\n\n在mold中解析lto的方式是通过指定plugin，加载对应的so来进行处理\ntemplate &lt;typename E&gt;ObjectFile&lt;E&gt; *read_lto_object(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf) &#123;  // V0 API&#x27;s claim_file is not thread-safe.  static std::mutex mu;  std::unique_lock lock(mu, std::defer_lock);  if (!is_gcc_linker_api_v1)    lock.lock();  if (ctx.arg.plugin.empty())    Fatal(ctx) &lt;&lt; mf-&gt;name &lt;&lt; &quot;: don&#x27;t know how to handle this LTO object file &quot;               &lt;&lt; &quot;because no -plugin option was given. Please make sure you &quot;               &lt;&lt; &quot;added -flto not only for creating object files but also for &quot;               &lt;&lt; &quot;creating the final executable.&quot;;  // dlopen the linker plugin file  static std::once_flag flag;  std::call_once(flag, [&amp;] &#123; load_plugin(ctx); &#125;);\n\n学习解析文件的实现主要是要进一步了解ELF的格式，所以这里具体细节就不进行考据了。\nlinker scriptmold的linker script根据解析的过程来看比较简单，没有在ld的脚本中的指定SECTION地址之类的内容，主要是对format以及符号version的一些控制。\ntemplate &lt;typename E&gt;void parse_linker_script(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf) &#123;  current_file&lt;E&gt; = mf;  std::vector&lt;std::string_view&gt; vec = tokenize(ctx, mf-&gt;get_contents());  std::span&lt;std::string_view&gt; tok = vec;  while (!tok.empty()) &#123;    if (tok[0] == &quot;OUTPUT_FORMAT&quot;) &#123;      tok = read_output_format(ctx, tok.subspan(1));    &#125; else if (tok[0] == &quot;INPUT&quot; || tok[0] == &quot;GROUP&quot;) &#123;      tok = read_group(ctx, tok.subspan(1));    &#125; else if (tok[0] == &quot;VERSION&quot;) &#123;      tok = tok.subspan(1);      tok = skip(ctx, tok, &quot;&#123;&quot;);      read_version_script(ctx, tok);      tok = skip(ctx, tok, &quot;&#125;&quot;);    &#125; else if (tok.size() &gt; 3 &amp;&amp; tok[1] == &quot;=&quot; &amp;&amp; tok[3] == &quot;;&quot;) &#123;      ctx.arg.defsyms.emplace_back(get_symbol(ctx, unquote(tok[0])),                                   get_symbol(ctx, unquote(tok[2])));      tok = tok.subspan(4);    &#125; else if (tok[0] == &quot;;&quot;) &#123;      tok = tok.subspan(1);    &#125; else &#123;      SyntaxError(ctx, tok[0]) &lt;&lt; &quot;unknown linker script token&quot;;    &#125;  &#125;&#125;\n\nobject fileobject file是解析过程的重点之一。\ntemplate &lt;typename E&gt;static ObjectFile&lt;E&gt; *new_object_file(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf,                                      std::string archive_name) &#123;  static Counter count(&quot;parsed_objs&quot;);  count++;  check_file_compatibility(ctx, mf);  bool in_lib = ctx.in_lib || (!archive_name.empty() &amp;&amp; !ctx.whole_archive);  ObjectFile&lt;E&gt; *file = ObjectFile&lt;E&gt;::create(ctx, mf, archive_name, in_lib);  file-&gt;priority = ctx.file_priority++;  ctx.tg.run([file, &amp;ctx] &#123; file-&gt;parse(ctx); &#125;);  if (ctx.arg.trace)    SyncOut(ctx) &lt;&lt; &quot;trace: &quot; &lt;&lt; *file;  return file;&#125;\n\nmold以链接速度快出名，而其快的原因之一就是充分利用了多线程，实际进行多线程操作的地方是在这里，ctx.tg.run，tg则是一个tbb::task_group，简而言之就是在这里开启了多线程的解析input file。\n做了一些简单的in_lib参数处理，因为archive的链接机制默认是按需链接，而不是像shared file一样全部链接，之后在这里创建了object file并且开始parse。关于创建和parse的细节在后面再说。\nshared fileshared file同样是解析过程的重点之一。\ntemplate &lt;typename E&gt;static SharedFile&lt;E&gt; *new_shared_file(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf) &#123;  check_file_compatibility(ctx, mf);  SharedFile&lt;E&gt; *file = SharedFile&lt;E&gt;::create(ctx, mf);  file-&gt;priority = ctx.file_priority++;  ctx.tg.run([file, &amp;ctx] &#123; file-&gt;parse(ctx); &#125;);  if (ctx.arg.trace)    SyncOut(ctx) &lt;&lt; &quot;trace: &quot; &lt;&lt; *file;  return file;&#125;\n\n在这里做了和object file类似的事情。\nInputFile在详细讲解object file和shared file创建以及解析之前先介绍一下他们和InputFile类\n\nObjectFile和SharedFile都是简单的从InputFile中继承下来的。而这里的InputFile更像是代表了一个输入的ELF文件，构造的过程中做了一些ELF的基础解析，同时还提供了一些通用的接口，交由ObjectFile和SharedFile各自实现。\n我们来看一下InputFile的构造函数部分\ntemplate &lt;typename E&gt;InputFile&lt;E&gt;::InputFile(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf)  : mf(mf), filename(mf-&gt;name) &#123;  if (mf-&gt;size &lt; sizeof(ElfEhdr&lt;E&gt;))    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: file too small&quot;;  if (memcmp(mf-&gt;data, &quot;\\177ELF&quot;, 4))    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: not an ELF file&quot;;  ElfEhdr&lt;E&gt; &amp;ehdr = *(ElfEhdr&lt;E&gt; *)mf-&gt;data;  is_dso = (ehdr.e_type == ET_DYN);  ElfShdr&lt;E&gt; *sh_begin = (ElfShdr&lt;E&gt; *)(mf-&gt;data + ehdr.e_shoff);  // e_shnum contains the total number of sections in an object file.  // Since it is a 16-bit integer field, it&#x27;s not large enough to  // represent &gt;65535 sections. If an object file contains more than 65535  // sections, the actual number is stored to sh_size field.  i64 num_sections = (ehdr.e_shnum == 0) ? sh_begin-&gt;sh_size : ehdr.e_shnum;  if (mf-&gt;data + mf-&gt;size &lt; (u8 *)(sh_begin + num_sections))    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: e_shoff or e_shnum corrupted: &quot;               &lt;&lt; mf-&gt;size &lt;&lt; &quot; &quot; &lt;&lt; num_sections;  elf_sections = &#123;sh_begin, sh_begin + num_sections&#125;;  // e_shstrndx is a 16-bit field. If .shstrtab&#x27;s section index is  // too large, the actual number is stored to sh_link field.  i64 shstrtab_idx = (ehdr.e_shstrndx == SHN_XINDEX)    ? sh_begin-&gt;sh_link : ehdr.e_shstrndx;  shstrtab = this-&gt;get_string(ctx, shstrtab_idx);&#125;\n\n首先是从文件大小和文件头部标识信息进行ELF的校验，其次是做一些简单的解析。根据代码中可知，整个文件最开始的部分即可作为一个ElfEhdr（Ehdr：Elf Header）\n根据header的信息可以解析出是否为dso文件，ElfShdr（Shdr：Section Header）的起始地址和长度，以及shstrtab（Section Header String Table）的位置。\n大多数的参数直接可以获取，但是对于e_shnum和e_shstrndx来说，由于长度只有16bit的限制，因此如果值过大，则会分别存到第一个Shdr的sh_size以及sh_link中。\n那么根据这段代码我们可以看出ELF的文件信息是这样的\nObjectFilecreate首先是ObjectFile的创建\ntemplate &lt;typename E&gt;ObjectFile&lt;E&gt; *ObjectFile&lt;E&gt;::create(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf,                      std::string archive_name, bool is_in_lib) &#123;  ObjectFile&lt;E&gt; *obj = new ObjectFile&lt;E&gt;(ctx, mf, archive_name, is_in_lib);  ctx.obj_pool.emplace_back(obj);  return obj;&#125;template &lt;typename E&gt;ObjectFile&lt;E&gt;::ObjectFile(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf,                          std::string archive_name, bool is_in_lib)  : InputFile&lt;E&gt;(ctx, mf), archive_name(archive_name), is_in_lib(is_in_lib) &#123;  this-&gt;is_alive = !is_in_lib;&#125;\n\nObjectFile的构造函数被放入了private中，因此必须通过静态的create方法来创建实例。在每次创建的时候会将对应的obj对象放入到全局的ctx.obj_pool中，mold中的内存与生命周期的管理方式则是全部交由ctx保有，到最后一起释放。而对应的obj_pool为了多线程的设计也都使用了并发的数据结构。\ntbb::concurrent_vector&lt;std::unique_ptr&lt;ObjectFile&lt;E&gt;&gt;&gt;\n\nObjectFile的构造函数只是传递了参数，大部分的解析还是在InputFile的构造函数中执行。\nparse过程开始template &lt;typename E&gt;void ObjectFile&lt;E&gt;::parse(Context&lt;E&gt; &amp;ctx) &#123;  sections.resize(this-&gt;elf_sections.size());  symtab_sec = this-&gt;find_section(SHT_SYMTAB);  if (symtab_sec) &#123;    // In ELF, all local symbols precede global symbols in the symbol table.    // sh_info has an index of the first global symbol.    this-&gt;first_global = symtab_sec-&gt;sh_info;    this-&gt;elf_syms = this-&gt;template get_data&lt;ElfSym&lt;E&gt;&gt;(ctx, *symtab_sec);    this-&gt;symbol_strtab = this-&gt;get_string(ctx, symtab_sec-&gt;sh_link);  &#125;  initialize_sections(ctx);  initialize_symbols(ctx);  sort_relocations(ctx);  initialize_ehframe_sections(ctx);&#125;\n\nsymtab_sec首先是寻找symtab_sec的过程，寻找段的过程非常简单\ntemplate &lt;typename E&gt;ElfShdr&lt;E&gt; *InputFile&lt;E&gt;::find_section(i64 type) &#123;  for (ElfShdr&lt;E&gt; &amp;sec : elf_sections)    if (sec.sh_type == type)      return &amp;sec;  return nullptr;&#125;\n\nsymtab_sec不存在的情况多半是strip了，直接在elf中搜索symtab是能搜到的，但是如果strip以后就无法找到这个段了，也就是为空的情况\n\nsh_link和sh_info对于不同的section有不同的含义，对于这里的symtab来说sh_info就是保存了第一个global symbol的index，而sh_link就是保存了symbol_strtab的地址\n\ninitialize_sectionstemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::initialize_sections(Context&lt;E&gt; &amp;ctx) &#123;  // Read sections  for (i64 i = 0; i &lt; this-&gt;elf_sections.size(); i++) &#123;    const ElfShdr&lt;E&gt; &amp;shdr = this-&gt;elf_sections[i];\n\n针对所有的sections开始处理，以下内容都在个循环体之中\n特殊SHT的处理SHT（Section Header Type）\nif ((shdr.sh_flags &amp; SHF_EXCLUDE) &amp;&amp; !(shdr.sh_flags &amp; SHF_ALLOC) &amp;&amp;    shdr.sh_type != SHT_LLVM_ADDRSIG &amp;&amp; !ctx.arg.relocatable)  continue;\n\n这几个段无法在ELF标准中查到，后来查到了这么一段介绍\nSHF_EXCLUDE：This section is excluded from input to the link-edit of an executable or shared object. This flag is ignored if the SHF_ALLOC flag is also set, or if relocations exist against the section.\n\n如果alloc被set则失效，因此这里要SHF_EXCLUDE以及SHF_ALLOC都满足条件\n同时sh_type为SHF_LLVM_ADDRSIG且不是relocatable\n\n关于SHF_LLVM_ADDRSIG\nLLVM Extensions — LLVM 17.0.0git documentation\ngroups首先是关于Group的介绍\n\nThis section defines a section group. A section group is a set of sections that are related and that must be treated specially by the linker (see below for further details). Sections of type SHT_GROUP may appear only in relocatable objects (objects with the ELF header e_type member set to ET_REL). The section header table entry for a group section must appear in the section header table before the entries for any of the sections that are members of the group.\n\nhttps://refspecs.linuxbase.org/elf/gabi4+/ch4.sheader.html\n在实现中首先是寻找对应group的签名，签名是关联到了一个esym上，而这个符号的索引则是记录在sh_info中\n// Get the signature of this section group.if (shdr.sh_info &gt;= this-&gt;elf_syms.size())  Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: invalid symbol index&quot;;const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[shdr.sh_info];std::string_view signature;if (esym.st_type == STT_SECTION) &#123;  signature = this-&gt;shstrtab.data() +              this-&gt;elf_sections[esym.st_shndx].sh_name;&#125; else &#123;  signature = this-&gt;symbol_strtab.data() + esym.st_name;&#125;\n\n接下来就是一些特殊情况的处理。\n\n跳过wm4\n跳过entries[0]为0的情况\n如果[0]不是GRP_COMDAT则是错误\n\n之后获取comdat group members，并使用signature来关联一个ComdatGroup\n// Ignore a broken comdat group GCC emits for .debug_macros.// https://github.com/rui314/mold/issues/438if (signature.starts_with(&quot;wm4.&quot;))  continue;// Get comdat group members.std::span&lt;U32&lt;E&gt;&gt; entries = this-&gt;template get_data&lt;U32&lt;E&gt;&gt;(ctx, shdr);if (entries.empty())  Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: empty SHT_GROUP&quot;;if (entries[0] == 0)  continue;if (entries[0] != GRP_COMDAT)  Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: unsupported SHT_GROUP format&quot;;typename decltype(ctx.comdat_groups)::const_accessor acc;ctx.comdat_groups.insert(acc, &#123;signature, ComdatGroup()&#125;);ComdatGroup *group = const_cast&lt;ComdatGroup *&gt;(&amp;acc-&gt;second);comdat_groups.push_back(&#123;group, (u32)i, entries.subspan(1)&#125;);break;\n\n关于上面处理过程中出现的成员的定义\n// in contexttbb::concurrent_hash_map&lt;std::string_view, ComdatGroup, HashCmp&gt; comdat_groups;// in ObjectFilestd::vector&lt;ComdatGroupRef&lt;E&gt;&gt; comdat_groups;template &lt;typename E&gt;struct ComdatGroupRef &#123;  ComdatGroup *group;  u32 sect_idx;  std::span&lt;U32&lt;E&gt;&gt; members;&#125;;\n\n首先是根据签名关联一个group空，之后将对应group的引用传递给ObjectFile中的comdat_groups\n里面的i就是section的index\n来看一下这个group段的排布\n| SectionSize | Group1SectionIndex | Group2SectionIndex | … |\n\n关于GRP_COMDAT文档中也有提到\n\nThis is a COMDAT group. It may duplicate another COMDAT group in another object file, where duplication is defined as having the same group signature. In such cases, only one of the duplicate groups may be retained by the linker, and the members of the remaining groups must be discarded.\n\n常规SHT处理此处还有很长的特殊段以及开启—gdb-index后需要处理的内容，并非重点，此处先跳过。\n常规处理就是简单创建了一个InputSection\nthis-&gt;sections[i] = std::make_unique&lt;InputSection&lt;E&gt;&gt;(ctx, *this, name, i);\n\nAttach relocation sections to their target sections.到这里，所有的section已经执行过了一遍，最后再进行关联\n// Attach relocation sections to their target sections.for (i64 i = 0; i &lt; this-&gt;elf_sections.size(); i++) &#123;  const ElfShdr&lt;E&gt; &amp;shdr = this-&gt;elf_sections[i];  if (shdr.sh_type != (is_rela&lt;E&gt; ? SHT_RELA : SHT_REL))    continue;  if (shdr.sh_info &gt;= sections.size())    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: invalid relocated section index: &quot;               &lt;&lt; (u32)shdr.sh_info;  if (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;target = sections[shdr.sh_info]) &#123;    assert(target-&gt;relsec_idx == -1);    target-&gt;relsec_idx = i;  &#125;&#125;\n\n针对RELA和REL处理，设置上对应的relsec_idx\ntemplate &lt;typename E&gt;static constexpr bool is_rela = requires(ElfRel&lt;E&gt; r) &#123; r.r_addend; &#125;;\n\ninitialize_symbols这部分的过程主要是将esym转换为Symbol。esym则是ElfSym的缩写，也就是Elf文件中的Symbol定义，而Symbol则是mold中自己定义的，相当于转换为自己想要的格式。\n这里的symtab_sec是parse刚开始的时候寻找的section，对应的符号表不存在则不进行这个过程。首先初始化了local_syms以及第0个符号\ntemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::initialize_symbols(Context&lt;E&gt; &amp;ctx) &#123;  if (!symtab_sec)    return;  static Counter counter(&quot;all_syms&quot;);  counter += this-&gt;elf_syms.size();  // Initialize local symbols  this-&gt;local_syms.resize(this-&gt;first_global);  this-&gt;local_syms[0].file = this;  this-&gt;local_syms[0].sym_idx = 0;\n\nlocal symbolfor (i64 i = 1; i &lt; this-&gt;first_global; i++) &#123;    const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[i];    if (esym.is_common())      Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: common local symbol?&quot;;    std::string_view name;    if (esym.st_type == STT_SECTION)      name = this-&gt;shstrtab.data() + this-&gt;elf_sections[get_shndx(esym)].sh_name;    else      name = this-&gt;symbol_strtab.data() + esym.st_name;    Symbol&lt;E&gt; &amp;sym = this-&gt;local_syms[i];    sym.set_name(name);    sym.file = this;    sym.value = esym.st_value;    sym.sym_idx = i;    if (!esym.is_abs())      sym.set_input_section(sections[get_shndx(esym)].get());  &#125;\n\n首先是对于common符号的判断\nbool is_common() const &#123; return st_shndx == SHN_COMMON; &#125;\n\n关于这个SHN_COMMON\n\nSHN_COMMON Symbols defined relative to this section are common symbols, such as FORTRAN COMMON or unallocated C external variables.\n\n大意是common的话不能是local，比如这里说的unallocated C external variables，external和local就是冲突的。\n除了报错的common符号之外，其他符号在后面获取对应的名字，如果是section name则去shstrtab中寻找，否则就是常规的符号名，去symbol_strtab中寻找。这里的名字本质上是一个距离对应字符串段的offset，因为字符串相关的数据都统一保存在这shstrtab和symbol_strtab中了。\n之后就是获取local_syms的引用，开始设置对应的信息。\n在最后，对非abs符号的处理。\nbool is_abs() const &#123; return st_shndx == SHN_ABS; &#125;\n\n\nSHN_ABS This value specifies absolute values for the corresponding reference. For example, symbols defined relative to section number SHN_ABS have absolute values and are not affected by relocation.\n\n非abs符号，也就是说都是相对地址，会affected by relocation。\n而实际set_input_section则是设置其mask位，用于区分什么性质的符号。\ntemplate &lt;typename E&gt;inline void Symbol&lt;E&gt;::set_input_section(InputSection&lt;E&gt; *isec) &#123;  uintptr_t addr = (uintptr_t)isec;  assert((addr &amp; TAG_MASK) == 0);  origin = addr | TAG_ISEC;&#125;\n\n用2bit区分不同情况\n// A symbol usually belongs to an input section, but it can belong// to a section fragment, an output section or nothing// (i.e. absolute symbol). `origin` holds one of them. We use the// least significant two bits to distinguish type.enum : uintptr_t &#123;  TAG_ABS  = 0b00,  TAG_ISEC = 0b01,  TAG_OSEC = 0b10,  TAG_FRAG = 0b11,  TAG_MASK = 0b11,&#125;;\n\nglobal symbolthis-&gt;symbols.resize(this-&gt;elf_syms.size());i64 num_globals = this-&gt;elf_syms.size() - this-&gt;first_global;symvers.resize(num_globals);for (i64 i = 0; i &lt; this-&gt;first_global; i++)  this-&gt;symbols[i] = &amp;this-&gt;local_syms[i];\n\n在开始处理之前可以看到这里又有两个resize容器的位置，目前为止有三处，这里写明了对应的容器以及所处的类，用于区分这个信息是否为ObjectFile only的\n\nlocal symbols(InputFile)\nsymbols(InputFile)\nsymvers (ObjectFile)\n\n之后将local_sym绑定到symbols中\n之后是详细的处理过程\n// Initialize global symbolsfor (i64 i = this-&gt;first_global; i &lt; this-&gt;elf_syms.size(); i++) &#123;  const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[i];  // Get a symbol name  std::string_view key = this-&gt;symbol_strtab.data() + esym.st_name;  std::string_view name = key;  // Parse symbol version after atsign  if (i64 pos = name.find(&#x27;@&#x27;); pos != name.npos) &#123;    std::string_view ver = name.substr(pos + 1);    name = name.substr(0, pos);    if (!ver.empty() &amp;&amp; ver != &quot;@&quot;) &#123;      if (ver.starts_with(&#x27;@&#x27;))        key = name;      if (!esym.is_undef())        symvers[i - this-&gt;first_global] = ver.data();    &#125;  &#125;  this-&gt;symbols[i] = insert_symbol(ctx, esym, key, name);  if (esym.is_common())    has_common_symbol = true;&#125;std::vector&lt;const char *&gt; symvers;\n\n这里不需要再区分是否为Section的符号，因为global符号不包含section符号。\n这里最主要的是需要解析symbol version，因为有的符号会依赖于版本号。要注意的是这个东西并非ELF的官方定义，而是GNU的一个扩展，因此去看elf specification是找不到的。关于名称规范也很简单，常规符号名后接@加符号版本\n解析符号版本完成后设置到symvers中，关于这个版本号，最常见的就是GLIBC，以下是本机helloworld代码的示范\n~/tmp &gt; nm ./a.out | grep &quot;@&quot; w __cxa_finalize@GLIBC_2.2.5 U __libc_start_main@GLIBC_2.34 U puts@GLIBC_2.2.5\n\n之后是insert symbol，并且设置其common属性。要注意除了这些解析方式外，global symbol和local symbol相比还有一个比较隐藏的不同，global symbol没有设置对应的file，后面很多符号的处理会进行判断file。\n接下来是insert symbol的实现\n// Returns a symbol object for a given key. This function handles// the -wrap option.template &lt;typename E&gt;static Symbol&lt;E&gt; *insert_symbol(Context&lt;E&gt; &amp;ctx, const ElfSym&lt;E&gt; &amp;esym,                                std::string_view key, std::string_view name) &#123;  if (esym.is_undef() &amp;&amp; name.starts_with(&quot;__real_&quot;) &amp;&amp;      ctx.arg.wrap.contains(name.substr(7))) &#123;    return get_symbol(ctx, key.substr(7), name.substr(7));  &#125;  Symbol&lt;E&gt; *sym = get_symbol(ctx, key, name);  if (esym.is_undef() &amp;&amp; sym-&gt;wrap) &#123;    key = save_string(ctx, &quot;__wrap_&quot; + std::string(key));    name = save_string(ctx, &quot;__wrap_&quot; + std::string(name));    return get_symbol(ctx, key, name);  &#125;  return sym;&#125;template &lt;typename C&gt;std::string_view save_string(C &amp;ctx, const std::string &amp;str) &#123;  u8 *buf = new u8[str.size() + 1];  memcpy(buf, str.data(), str.size());  buf[str.size()] = &#x27;\\0&#x27;;  ctx.string_pool.push_back(std::unique_ptr&lt;u8[]&gt;(buf));  return &#123;(char *)buf, str.size()&#125;;&#125;\n\n这里不只是不存在key就创建key并返回那么简单。\n\n关于save_string的问题，这里也是和之前一样，创建了string后由ctx来管理生命周期，返回一个string_view提供使用。\n除此之外get_symbol的部分是实际执行了符号不存在则创建新符号并且返回的工作\n\n// If we haven&#x27;t seen the same `key` before, create a new instance// of Symbol and returns it. Otherwise, returns the previously-// instantiated object. `key` is usually the same as `name`.template &lt;typename E&gt;Symbol&lt;E&gt; *get_symbol(Context&lt;E&gt; &amp;ctx, std::string_view key,                      std::string_view name) &#123;  typename decltype(ctx.symbol_map)::const_accessor acc;  ctx.symbol_map.insert(acc, &#123;key, Symbol&lt;E&gt;(name)&#125;);  return const_cast&lt;Symbol&lt;E&gt; *&gt;(&amp;acc-&gt;second);&#125;\n\n\n最后提一下-wrap option选项\n\n这个-wrap是在main中read_input_files之前的地方设置的\n// Handle --wrap options if any.for (std::string_view name : ctx.arg.wrap)  get_symbol(ctx, name)-&gt;wrap = true;\n\n关于这个选项我参考了这个回答里的内容，虽然是gcc的介绍，但是本质是相同的\nHow to wrap functions with the --wrap option correctly?\n我摘选了一些关键的段落\n\n-wrap=symbolUse a wrapper function for symbol. Any undefined reference to symbol will be resolved to “__wrap_symbol”. Any undefined reference to “__real_symbol” will be resolved to symbol.…If you link other code with this file using –wrap malloc, then all calls to “malloc” will call the function “__wrap_malloc” instead. The call to “__real_malloc” in “__wrap_malloc” will call the real “malloc” function.\n\n\n… Any undefined reference to symbol will be resolved to “__wrap_symbol”. Any undefined reference  to “__real_symbol” will be resolved to symbol.\n\n至此，initialize_symbols就结束了\nsort_relocations// Relocations are usually sorted by r_offset in relocation tables,// but for some reason only RISC-V does not follow that convention.// We expect them to be sorted, so sort them if necessary.template &lt;typename E&gt;void ObjectFile&lt;E&gt;::sort_relocations(Context&lt;E&gt; &amp;ctx) &#123;  if constexpr (is_riscv&lt;E&gt;) &#123;    auto less = [&amp;](const ElfRel&lt;E&gt; &amp;a, const ElfRel&lt;E&gt; &amp;b) &#123;      return a.r_offset &lt; b.r_offset;    &#125;;    for (i64 i = 1; i &lt; sections.size(); i++) &#123;      std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec = sections[i];      if (!isec || !isec-&gt;is_alive || !(isec-&gt;shdr().sh_flags &amp; SHF_ALLOC))        continue;      std::span&lt;ElfRel&lt;E&gt;&gt; rels = isec-&gt;get_rels(ctx);      if (!std::is_sorted(rels.begin(), rels.end(), less))        sort(rels, less);    &#125;  &#125;&#125;\n\n根据注释，这里的sort是为了将不遵守约定没按照r_offset排序的rv的relocations转换为遵循约定的格式\ninitialize_ehframe_sections关于这里的内容比较长，不仅要包含解析本身，还有ehframe本身的内容，因此留到下期再继续讲。\n图解总结画了一些比较粗糙的图示将今天的内容串联起来（未标记长度信息，部分大小不标准，没精力画了）\n\n首先是读取InputFile时的流程，主要是ElfHeader指向ELF文件的哪一部分\n\n其次是读取Section的时候符号表相关的查找流程，这里还没来得及画具体取名字的部分\n从Section Header Table中找到对应sh_type为SHT_SYMTAB的段，之后根据offset和size找到具体存放symbol的位置，同时通过sh_info确定第一个global symbol的index\n参考资料汇总Sections\nElf Specification 1.2\n","categories":["Linker"],"tags":["mold"]},{"title":"mold源码阅读 其二 读取SharedFile","url":"/2023/04/05/mold/mold-2-read-shared-files/","content":"\npixiv:70054356 \n\n这期的内容主要是讲完读取输入的部分，有一些之前遗漏的信息，以及之前未讲完的初始化ehframe以及shared object读取的部分。有许多地方默认读者读过上期内容，建议先阅读上期内容后再来查看本期。\nhttps://homura.live/2023/02/26/mold/mold-1-read-input-files/\nObjectFileget_string之前在读取符号表的时候是通过这种方式读取的，但我们没有讲解这个读取的细节\nthis-&gt;symbol_strtab = this-&gt;get_string(ctx, symtab_sec-&gt;sh_link);\n\nelf/mold.h\ntemplate &lt;typename E&gt;inline std::string_view InputFile&lt;E&gt;::get_string(Context&lt;E&gt; &amp;ctx, i64 idx) &#123;  assert(idx &lt; elf_sections.size());  if (elf_sections.size() &lt;= idx)    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: invalid section index: &quot; &lt;&lt; idx;  return this-&gt;get_string(ctx, elf_sections[idx]);&#125;\n\ntemplate &lt;typename E&gt;inline std::string_viewInputFile&lt;E&gt;::get_string(Context&lt;E&gt; &amp;ctx, const ElfShdr&lt;E&gt; &amp;shdr) &#123;  u8 *begin = mf-&gt;data + shdr.sh_offset;  u8 *end = begin + shdr.sh_size;  if (mf-&gt;data + mf-&gt;size &lt; end)    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: section header is out of range: &quot; &lt;&lt; shdr.sh_offset;  return &#123;(char *)begin, (size_t)(end - begin)&#125;;&#125;\n\n实际上是找到文件中对应offset的data作为开始，根据长度构造一个string_view，注意这里并不是实际构造了一个string，因此返回的string并没有这块空间的所有权。\n由get_string衍生出来的方法还有get_data，之前在读取elfsyms的时候就是使用了get_data\nthis-&gt;elf_syms = this-&gt;template get_data&lt;ElfSym&lt;E&gt;&gt;(ctx, *symtab_sec);\n\ntemplate &lt;typename E&gt;template &lt;typename T&gt;inline std::span&lt;T&gt;InputFile&lt;E&gt;::get_data(Context&lt;E&gt; &amp;ctx, const ElfShdr&lt;E&gt; &amp;shdr) &#123;  std::string_view view = this-&gt;get_string(ctx, shdr);  if (view.size() % sizeof(T))    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: corrupted section&quot;;  return &#123;(T *)view.data(), view.size() / sizeof(T)&#125;;&#125;template &lt;typename E&gt;template &lt;typename T&gt;inline std::span&lt;T&gt; InputFile&lt;E&gt;::get_data(Context&lt;E&gt; &amp;ctx, i64 idx) &#123;  if (elf_sections.size() &lt;= idx)    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: invalid section index&quot;;  return this-&gt;template get_data&lt;T&gt;(elf_sections[idx]);&#125;\n\n这里直接获取了get_string的结果，并且将对应的结果映射为了一个对应数据的span\nget_shndx在之前从符号表取数据的时候是通过get_shndx实现的\nelf/mold.h\ntemplate &lt;typename E&gt;inline i64 ObjectFile&lt;E&gt;::get_shndx(const ElfSym&lt;E&gt; &amp;esym) &#123;  assert(&amp;this-&gt;elf_syms[0] &lt;= &amp;esym);  assert(&amp;esym &lt;= &amp;this-&gt;elf_syms[this-&gt;elf_syms.size() - 1]);  if (esym.st_shndx == SHN_XINDEX)    return symtab_shndx_sec[&amp;esym - &amp;this-&gt;elf_syms[0]];  return esym.st_shndx;&#125;\n\n虽然符号中是有对应的shndx字段，但是这个字段的长度为16bit，如果超出这个长度的index那么需要去symtab_shndx_sec中获取。\n这个限制在之前读取输入的时候多次遇到，比如说在构造InputFile类，读取shstrtab_idx的时候\ninput-files.cc\n// e_shstrndx is a 16-bit field. If .shstrtab&#x27;s section index is// too large, the actual number is stored to sh_link field.i64 shstrtab_idx = (ehdr.e_shstrndx == SHN_XINDEX)  ? sh_begin-&gt;sh_link : ehdr.e_shstrndx;\n\neh_frameeh_frame段对于大多数人来说比较陌生，因此首先来讲解eh_frame是什么。eh_frame是包含了记录如何处理异常信息的段，当异常抛出的时候runtime会寻找一个eh_frame记录的信息并且来处理。\n我们来看一下hello world的汇编\n#include &lt;stdio.h&gt;int main()&#123;    printf(&quot;Hello world\\n&quot;);    return 0;&#125;\n\n.section\t__TEXT,__text,regular,pure_instructions\t.build_version macos, 12, 0\tsdk_version 12, 1\t.globl\t_main                           ; -- Begin function main\t.p2align\t2_main:                                  ; @main\t.cfi_startproc; %bb.0:\tsub\tsp, sp, #32                     ; =32\tstp\tx29, x30, [sp, #16]             ; 16-byte Folded Spill\tadd\tx29, sp, #16                    ; =16\t.cfi_def_cfa w29, 16\t.cfi_offset w30, -8\t.cfi_offset w29, -16\tmov\tw8, #0\tstr\tw8, [sp, #8]                    ; 4-byte Folded Spill\tstur\twzr, [x29, #-4]\tadrp\tx0, l_.str@PAGE\tadd\tx0, x0, l_.str@PAGEOFF\tbl\t_printf\tldr\tw0, [sp, #8]                    ; 4-byte Folded Reload\tldp\tx29, x30, [sp, #16]             ; 16-byte Folded Reload\tadd\tsp, sp, #32                     ; =32\tret\t.cfi_endproc                                        ; -- End function\t.section\t__TEXT,__cstring,cstring_literalsl_.str:                                 ; @.str\t.asciz\t&quot;Hello world\\n&quot;.subsections_via_symbols\n\n关于eh_frame我有一个疑问，是否能像符号一样被strip掉？手动strip以后发现elf大小并没有发生改变。关于这个问题stackoverflow有这样一条回答\nWhy GCC compiled C program needs .eh_frame section?\n\nYou can disable generation of .eh_frame with -fno-asynchronous-unwind-tables for individual translation units, and this mostly eliminates the size cost\n\n\nYou cannot strip them with the strip command later; since .eh_frame is a section that lives in the loaded part of the program (this is the whole point), stripping it modifies the binary in ways that break it at runtime.\n\n大意是不能通过strip消除，但是eh_frame在gcc中可以通过开启特殊的编译选项避免生成。\neh_frame的结构Exception Frames\n这里不详细介绍里面的具体字段了。简单来说，每个eh_frame段中会包含至少一个CFI（Call Frame Information），而每个CFI包含一个CIE（Common Information Entry），之后紧接着跟着许多FDE（Frame Description Entry）\n一个CFI对应了一个单一的object文件，如果是多个object文件合并那么就会有多个，因此至少存在一个。CFI中包含了一个CIE，也就是这个object里的common information，而后面跟随的许多FDE则是对应了各个function。\n这里引用一下MaskRay聚聚的资料，里面包含了更具体严谨的描述。\n\ninitialize_ehframe_sections对于链接器来说，ehframe和其他段不同是单独进行parse的。注释中给出了以下几条原因\n\n避免大量dead section的字段。如果只是最后拷贝所有的eh_frame则会有许多针对dead section的字段。\n减少section的大小。删除function的时候顺便删除FDE，所以eh_frame不包含dead FDE。\n增加搜索效率。扫描eh_frame段查找一个record是一个O(n)操作，通过linker创建一个sorted list后可以通过二分查找降低复杂度到O(log n)。\n\n接下来我们看一下具体的实现\ntemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::read_ehframe(Context&lt;E&gt; &amp;ctx, InputSection&lt;E&gt; &amp;isec) &#123;  std::span&lt;ElfRel&lt;E&gt;&gt; rels = isec.get_rels(ctx);  i64 cies_begin = cies.size();  i64 fdes_begin = fdes.size();\t// Read CIEs and FDEs until empty.\tstd::string_view contents = this-&gt;get_string(ctx, isec.shdr());\ti64 rel_idx = 0;\tfor (std::string_view data = contents; !data.empty();) &#123;    i64 size = *(U32&lt;E&gt; *)data.data();    if (size == 0)      break;    i64 begin_offset = data.data() - contents.data();    i64 end_offset = begin_offset + size + 4;    i64 id = *(U32&lt;E&gt; *)(data.data() + 4);    data = data.substr(size + 4);    i64 rel_begin = rel_idx;    while (rel_idx &lt; rels.size() &amp;&amp; rels[rel_idx].r_offset &lt; end_offset)      rel_idx++;    assert(rel_idx == rels.size() || begin_offset &lt;= rels[rel_begin].r_offset);    if (id == 0) &#123;      // This is CIE.      cies.emplace_back(ctx, *this, isec, begin_offset, rels, rel_begin);    &#125; else &#123;      // This is FDE.      if (rel_begin == rel_idx || rels[rel_begin].r_sym == 0) &#123;        // FDE has no valid relocation, which means FDE is dead from        // the beginning. Compilers usually don&#x27;t create such FDE, but        // `ld -r` tend to generate such dead FDEs.        continue;      &#125;      if (rels[rel_begin].r_offset - begin_offset != 8)        Fatal(ctx) &lt;&lt; isec &lt;&lt; &quot;: FDE&#x27;s first relocation should have offset 8&quot;;      fdes.emplace_back(begin_offset, rel_begin);    &#125;  &#125;\n\n根据这个解析过程以及参考格式描述我们能够画出这样一张图\n\n在读取完所有基本的段以后，将CIE关联到FDE中\nauto find_cie = [&amp;](i64 offset) &#123;  for (i64 i = cies_begin; i &lt; cies.size(); i++)    if (cies[i].input_offset == offset)      return i;  Fatal(ctx) &lt;&lt; isec &lt;&lt; &quot;: bad FDE pointer&quot;;&#125;;for (i64 i = fdes_begin; i &lt; fdes.size(); i++) &#123;  i64 cie_offset = *(I32&lt;E&gt; *)(contents.data() + fdes[i].input_offset + 4);  fdes[i].cie_idx = find_cie(fdes[i].input_offset + 4 - cie_offset);&#125;\n\n最后将FDE关联到InputSection中。注意这里进行了stable_sort，上面提到的第三条增加搜索效率就是通过这里实现的。\nstd::stable_sort(fdes.begin() + fdes_begin, fdes.end(),                 [&amp;](const FdeRecord&lt;E&gt; &amp;a, const FdeRecord&lt;E&gt; &amp;b) &#123;  return get_isec(a)-&gt;get_priority() &lt; get_isec(b)-&gt;get_priority();&#125;);for (i64 i = fdes_begin; i &lt; fdes.size();) &#123;  InputSection&lt;E&gt; *isec = get_isec(fdes[i]);  assert(isec-&gt;fde_begin == -1);  isec-&gt;fde_begin = i++;  while (i &lt; fdes.size() &amp;&amp; isec == get_isec(fdes[i]))    i++;  isec-&gt;fde_end = i;&#125;\n\n至此，整个eh_frame部分的初始化就完毕了。\nSharedFilecreate首先我们来看一下SharedFile的构造\ntemplate &lt;typename E&gt;SharedFile&lt;E&gt; *SharedFile&lt;E&gt;::create(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf) &#123;  SharedFile&lt;E&gt; *obj = new SharedFile(ctx, mf);  ctx.dso_pool.emplace_back(obj);  return obj;&#125;template &lt;typename E&gt;SharedFile&lt;E&gt;::SharedFile(Context&lt;E&gt; &amp;ctx, MappedFile&lt;Context&lt;E&gt;&gt; *mf)  : InputFile&lt;E&gt;(ctx, mf) &#123;  this-&gt;is_needed = ctx.as_needed;  this-&gt;is_alive = !ctx.as_needed;&#125;\n\n这部分没什么特别要讲的，关于is_needed和is_alive会涉及到关于whole-archive这个选项，之后会再单独开文章讲解。构造基类InputFile之前在ObjectFile的部分已经讲过了，不再赘述。接着来看parse的部分。\nparse首先是找到DYNSYM段\ntemplate &lt;typename E&gt;void SharedFile&lt;E&gt;::parse(Context&lt;E&gt; &amp;ctx) &#123;  symtab_sec = this-&gt;find_section(SHT_DYNSYM);  if (!symtab_sec)    return;\n\n之后读取符号表和ver信息，这些是Shared only的成员。而soname是针对一个dso的，所以个dso关联一个soname\nthis-&gt;symbol_strtab = this-&gt;get_string(ctx, symtab_sec-&gt;sh_link);soname = get_soname(ctx);version_strings = read_verdef(ctx);\n\n读取具体的符号信息以及符号版本信息\n// Read a symbol table.std::span&lt;ElfSym&lt;E&gt;&gt; esyms = this-&gt;template get_data&lt;ElfSym&lt;E&gt;&gt;(ctx, *symtab_sec);std::span&lt;U16&lt;E&gt;&gt; vers;if (ElfShdr&lt;E&gt; *sec = this-&gt;find_section(SHT_GNU_VERSYM))  vers = this-&gt;template get_data&lt;U16&lt;E&gt;&gt;(ctx, *sec);\n\n对于DYNSYM来说symtab_sec-&gt;sh_info是开始的符号数量\nfor (i64 i = symtab_sec-&gt;sh_info; i &lt; esyms.size(); i++) &#123;  u16 ver;  if (vers.empty() || esyms[i].is_undef())    ver = VER_NDX_GLOBAL;  else    ver = (vers[i] &amp; ~VERSYM_HIDDEN);  if (ver == VER_NDX_LOCAL)    continue;  std::string_view name = this-&gt;symbol_strtab.data() + esyms[i].st_name;  bool is_hidden = (!vers.empty() &amp;&amp; (vers[i] &amp; VERSYM_HIDDEN));  this-&gt;elf_syms2.push_back(esyms[i]);  this-&gt;versyms.push_back(ver);  if (is_hidden) &#123;    std::string_view mangled_name = save_string(      ctx, std::string(name) + &quot;@&quot; + std::string(version_strings[ver]));    this-&gt;symbols.push_back(get_symbol(ctx, mangled_name, name));  &#125; else &#123;    this-&gt;symbols.push_back(get_symbol(ctx, name));  &#125;&#125;\n\n这个for循环中针对每个符号信息来说做了以下几件事情\n\n处理version信息。\n\n跳过只有一个VER_NDX_LOCAL属性的\nvers为空或esym未定义，则是global的（大概用于symbol resolve去寻找定义。因此设为了GLOBAL\n不为空且有定义，那么就不是HIDDEN的\n\nstatic constexpr u32 VER_NDX_LOCAL = 0;static constexpr u32 VER_NDX_GLOBAL = 1;static constexpr u32 VERSYM_HIDDEN = 0x8000;\n添加elf_syms2（Shared Only的字段）以及versysms\n\n处理hidden的符号，hidden的话要mangled才行\n\n 为什么呢…\n\n\n\n设置基本信息后结束\nthis-&gt;elf_syms = elf_syms2;this-&gt;first_global = 0;static Counter counter(&quot;dso_syms&quot;);counter += this-&gt;elf_syms.size();\n\n这里first_global设置为0，也就是说dso中所有的符号都是global的。\nget_sonametemplate &lt;typename E&gt;std::string SharedFile&lt;E&gt;::get_soname(Context&lt;E&gt; &amp;ctx) &#123;  if (ElfShdr&lt;E&gt; *sec = this-&gt;find_section(SHT_DYNAMIC))    for (ElfDyn&lt;E&gt; &amp;dyn : this-&gt;template get_data&lt;ElfDyn&lt;E&gt;&gt;(ctx, *sec))      if (dyn.d_tag == DT_SONAME)        return this-&gt;symbol_strtab.data() + dyn.d_val;  if (this-&gt;mf-&gt;given_fullpath)    return this-&gt;filename;  return filepath(this-&gt;filename).filename().string();&#125;\n\n找到DYNAMIC段，从里面的ElfDyn中查找tag为DT_SONAME的，找不到就用依靠完整文件路径作为soname。\n关于ElfDyn\ntemplate &lt;&gt; struct ElfDyn&lt;RV64LE&gt;     : EL64Dyn &#123;&#125;;struct EL64Dyn &#123;  ul64 d_tag;  ul64 d_val;&#125;;\n\n在elf规范中关于DT_SONAME这个tag的信息\n\n\n\nName\nd_un\nExecutable\nShared Object\n\n\n\nDT_SONAME\nd_val\nignored\noptional\n\n\n\nThis element holds the string table offset of a null-terminated string, giving the name of the shared object. The offset is an index into the table recorded in the DT_STRTAB entry. See “Shared Object Dependencies” below for more information about these names.\n\nverdef\nSymbol versioning is a GNU extension to the ELF file format.\n\n\nVersions are just strings, and no ordering is defined between them. For example, “GLIBC_2.15” is not considered a newer version of “GLIBC_2.2.5” or vice versa. They are considered just different.\n\n\nIf a shared object file has versioned symbols, it contains a parallel array for the symbol table. Version strings can be found in that parallel table.\n\n\nOne version is considered the “default” version for each shared object. If an undefiend symbol foo is resolved to a symbol defined by the shared object, it’s marked so that it’ll be resolved to (foo, the default version of the library) at load-time.\n\ntemplate &lt;typename E&gt;std::vector&lt;std::string_view&gt; SharedFile&lt;E&gt;::read_verdef(Context&lt;E&gt; &amp;ctx) &#123;  std::vector&lt;std::string_view&gt; ret(VER_NDX_LAST_RESERVED + 1);  ElfShdr&lt;E&gt; *verdef_sec = this-&gt;find_section(SHT_GNU_VERDEF);  if (!verdef_sec)    return ret;  std::string_view verdef = this-&gt;get_string(ctx, *verdef_sec);  std::string_view strtab = this-&gt;get_string(ctx, verdef_sec-&gt;sh_link);  ElfVerdef&lt;E&gt; *ver = (ElfVerdef&lt;E&gt; *)verdef.data();  for (;;) &#123;    if (ret.size() &lt;= ver-&gt;vd_ndx)      ret.resize(ver-&gt;vd_ndx + 1);    ElfVerdaux&lt;E&gt; *aux = (ElfVerdaux&lt;E&gt; *)((u8 *)ver + ver-&gt;vd_aux);    ret[ver-&gt;vd_ndx] = strtab.data() + aux-&gt;vda_name;    if (!ver-&gt;vd_next)      break;    ver = (ElfVerdef&lt;E&gt; *)((u8 *)ver + ver-&gt;vd_next);  &#125;  return ret;&#125;\n\n拿一个helloworld的elf看一下\nreadelf -S ./a.out[ 8] .gnu.version      VERSYM           0000000000000516  00000516     000000000000000e  0000000000000002   A       6     0     2\n\n这里的全体大小为2，我们再看一下符号\nnm ./a.out | grep &quot;@&quot;w __cxa_finalize@GLIBC_2.2.5U __libc_start_main@GLIBC_2.34U puts@GLIBC_2.2.5\n\n其中两个是重复的符号，去重后也就是2个符号\n对比ObjectFile和SharedFile最后我们通过分析ObjectFile和SharedFile相关的异同来结束这期内容。\n相比于ObjectFile的复杂解析过程，SharedFile的整个过程显得十分简单。这和文件本身的性质与使用场景都有关系。dso加载符号的定义以及其他信息绝大部分都是在运行时，因此在链接期间并不需要做太多操作，其主要用途是将会被引用的符号加入到决议过程，同时将对应符号的版本信息和dso的soname加入到生成的产物中，以便在运行时进行加载。在谷歌搜索的时候搜到了这样一句话，我觉得概括的更好\n\nA DSO can be used in place of archive libraries and will minimize overall memory usage because code is shared.\n\n在链接的时候dso的作用是in place of archive libraries，所以并不需要太多的信息。\n虽然SharedFile在链接的时候并没有解析ObjectFile中许多信息，但是那些信息仍然是存在的，只是在链接的时候无需参与，而是全部交给运行时加载来处理。虽然在mold的类结构中ObjectFile和SharedFile都是直接继承自InputFile，但对于实际的object和dso来说我觉得dso更倾向于是特别的object，不过这个从dso的全名（dynamic shared object）也能看出来了。\n我的博客即将同步至腾讯云开发者社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=239vtuizwri8w\n","categories":["Linker"],"tags":["mold","eh_frame"]},{"title":"mold源码阅读 其三 符号决议","url":"/2023/04/09/mold/mold-3-symbol-resolve/","content":"\npixiv:72272420 \n\n前面两期将读取输入的部分全部讲完了，本期开始涉及链接过程中的处理。在讲主要的符号决议之前，先讲一下mold在符号决议执行之前做的一些其他处理。\ndso uniquely在读取完输入后首先做的是将shared object根据soname进行去重，因此我们可以在链接的过程中链接多个相同soname的库而不会产生冲突。\nelf/main.cc\n&#123;    std::unordered_set&lt;std::string_view&gt; seen;    std::erase_if(ctx.dsos, [&amp;](SharedFile&lt;E&gt; *file) &#123;      return !seen.insert(file-&gt;soname).second;    &#125;);&#125;\n\napply_exclude_libself/passes.cc\ntemplate &lt;typename E&gt;void apply_exclude_libs(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;apply_exclude_libs&quot;);  if (ctx.arg.exclude_libs.empty())    return;  std::unordered_set&lt;std::string_view&gt; set(ctx.arg.exclude_libs.begin(),                                           ctx.arg.exclude_libs.end());  for (ObjectFile&lt;E&gt; *file : ctx.objs) &#123;    if (!file-&gt;archive_name.empty())      if (set.contains(&quot;ALL&quot;) ||          set.contains(filepath(file-&gt;archive_name).filename().string()))        file-&gt;exclude_libs = true;  &#125;&#125;\n\n这里就是简单将所有包含在exclude-libs里的lib名字对应的exclude_libs设置为true，而这个设置在后面符号决议的过程会用到。\nexclude_libs是命令行中获取的\nelse if (read_arg(&quot;exclude-libs&quot;)) &#123;      append(ctx.arg.exclude_libs, split_by_comma_or_colon(arg));&#125;\n\ncreate_internal_fileinternal file是什么内部的文件，用来保存linker-synthesized符号。linker-synthesized符号或许也可以理解为编译产物中不存在的符号。作为一个并不实际存在的文件，依然会作为一个普通的ObjFile加入到obj_pool中，主要用途是在create_output_sections以后来add_synthetic_symbol，与之相关联的有一个internal_esyms，里面都是具体相关的符号。\n实现在main函数中调用是这样的\nif (!ctx.arg.relocatable)  create_internal_file(ctx);\n\nelf/passes.cc\ntemplate &lt;typename E&gt;void create_internal_file(Context&lt;E&gt; &amp;ctx) &#123;  ObjectFile&lt;E&gt; *obj = new ObjectFile&lt;E&gt;;  ctx.obj_pool.emplace_back(obj);  ctx.internal_obj = obj;  ctx.objs.push_back(obj);  ctx.internal_esyms.resize(1);  obj-&gt;symbols.push_back(new Symbol&lt;E&gt;);  obj-&gt;first_global = 1;  obj-&gt;is_alive = true;  obj-&gt;priority = 1;\n\n首先创建了基本的ObjectFile对象并且进行了一些初始化的处理。\n之后添加从命令行参数中读取的–defsym里的所有的defsym\nfor (i64 i = 0; i &lt; ctx.arg.defsyms.size(); i++) &#123;  std::pair&lt;Symbol&lt;E&gt; *, std::variant&lt;Symbol&lt;E&gt; *, u64&gt;&gt; &amp;defsym = ctx.arg.defsyms[i];  add(defsym.first);  if (std::holds_alternative&lt;Symbol&lt;E&gt; *&gt;(defsym.second)) &#123;    // Add an undefined symbol to keep a reference to the defsym target.    // This prevents elimination by e.g. LTO or gc-sections.    // The undefined symbol will never make to the final object file; we    // double-check that the defsym target is not undefined in    // fix_synthetic_symbols.    auto sym = std::get&lt;Symbol&lt;E&gt; *&gt;(defsym.second);    add_undef(sym);  &#125;&#125;\n\n处理完defsym后再从命令行参数中读取的SectionOrder的符号\nfor (SectionOrder &amp;ord : ctx.arg.section_order)  if (ord.type == SectionOrder::SYMBOL)    add(get_symbol(ctx, ord.name));\n\n关于SectionOrder的定义\nstruct SectionOrder &#123;  enum &#123; NONE, SECTION, GROUP, ADDR, ALIGN, SYMBOL &#125; type = NONE;  std::string name;  u64 value = 0;&#125;;\n\n最后设置obj类的一些参数\nobj-&gt;elf_syms = ctx.internal_esyms;obj-&gt;symvers.resize(ctx.internal_esyms.size() - 1);\n\ndefsym关于前面提到的defsym，我们来看一下mold的测试代码一部分来理解其作用。\ncat &lt;&lt;EOF | $CC -fPIC -o $t/a.o -c -xc -#include &lt;stdio.h&gt;extern char foo;extern char bar;void baz();void print() &#123;  printf(&quot;Hello %p %p\\n&quot;, &amp;foo, &amp;bar);&#125;int main() &#123;  baz();&#125;EOF$CC -B. -o $t/exe $t/a.o -pie -Wl,-defsym=foo=16 \\  -Wl,-defsym=bar=0x2000 -Wl,-defsym=baz=print$QEMU $t/exe | grep -q &#x27;^Hello 0x10 0x2000$&#x27;\n\n通过defsym指定了符号名以及其实现的位置，尽管对应的符号在代码中并没有实现。\n关于这里的add和add_undef的实现\nauto add = [&amp;](Symbol&lt;E&gt; *sym) &#123;  obj-&gt;symbols.push_back(sym);  // An actual value will be set to a linker-synthesized symbol by  // fix_synthetic_symbols(). Until then, `value` doesn&#x27;t have a valid  // value. 0xdeadbeef is a unique dummy value to make debugging easier  // if the field is accidentally used before it gets a valid one.  sym-&gt;value = 0xdeadbeef;  ElfSym&lt;E&gt; esym;  memset(&amp;esym, 0, sizeof(esym));  esym.st_type = STT_NOTYPE;  esym.st_shndx = SHN_ABS;  esym.st_bind = STB_GLOBAL;  esym.st_visibility = STV_DEFAULT;  ctx.internal_esyms.push_back(esym);&#125;;auto add_undef = [&amp;](Symbol&lt;E&gt; *sym) &#123;  obj-&gt;symbols.push_back(sym);  sym-&gt;value = 0xdeadbeef;  ElfSym&lt;E&gt; esym;  memset(&amp;esym, 0, sizeof(esym));  esym.st_type = STT_NOTYPE;  esym.st_shndx = SHN_UNDEF;  esym.st_bind = STB_GLOBAL;  esym.st_visibility = STV_DEFAULT;  ctx.internal_esyms.push_back(esym);&#125;;\n\n通过add和add_undef函数把defsym指定的符号添加到symbols中，并且设定为了特殊值，关联到了一个esym里。主要的差别就在于st_shndx被设置为了不同的值。\n符号决议接下来是链接过程中比较重要的一个环节，符号决议（symbol resolve）\n在mold中，这个部分做了四件事情\n\n检测所有需要使用的objet files\n移除重复的COMDAT段\n进行符号决议的过程。在多个不同的esym中选择出一个更高priority的关联到sym中\nLTO的处理，处理后再次执行决议\n\nresolve_symbolstemplate &lt;typename E&gt;void resolve_symbols(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;resolve_symbols&quot;);  std::vector&lt;ObjectFile&lt;E&gt; *&gt; objs = ctx.objs;  std::vector&lt;SharedFile&lt;E&gt; *&gt; dsos = ctx.dsos;  do_resolve_symbols(ctx);  if (ctx.has_lto_object) &#123;\t\t...\t\tdo_resolve_symbols(ctx);  &#125;&#125;\n\n这里先省略lto相关的具体处理，很多处理和do_resolve_symbols中是类似的，因此放到后面再说。\ntemplate &lt;typename E&gt;void do_resolve_symbols(Context&lt;E&gt; &amp;ctx) &#123;  auto for_each_file = [&amp;](std::function&lt;void(InputFile&lt;E&gt; *)&gt; fn) &#123;    tbb::parallel_for_each(ctx.objs, fn);    tbb::parallel_for_each(ctx.dsos, fn);  &#125;;\t// 1. 检测object files\t// 2. 消除重复COMDAT\t// 3. 符号决议&#125;\n\n1. 检测object filesarchive extraction: .a成员只会在满足非archive object文件未定义符号之一的情况下才会被包含在最终的二进制文件中\n链接时为了满足archive extraction的规则，mold采取的策略是：\n\n初步resolve：假设全部include，match undef符号\nmark sweep消除无需使用的archive成员\n删除掉非archive成员\n\n下面是具体的实现\n&#123;    Timer t(ctx, &quot;extract_archive_members&quot;);    // Register symbols    for_each_file([&amp;](InputFile&lt;E&gt; *file) &#123; file-&gt;resolve_symbols(ctx); &#125;);    // Mark reachable objects to decide which files to include into an output.    // This also merges symbol visibility.    mark_live_objects(ctx);    // Cleanup. The rule used for archive extraction isn&#x27;t accurate for the    // general case of symbol extraction, so reset the resolution to be redone    // later.    for_each_file([](InputFile&lt;E&gt; *file) &#123; file-&gt;clear_symbols(); &#125;);    // Now that the symbol references are gone, remove the eliminated files from    // the file list.    std::erase_if(ctx.objs, [](InputFile&lt;E&gt; *file) &#123; return !file-&gt;is_alive; &#125;);    std::erase_if(ctx.dsos, [](InputFile&lt;E&gt; *file) &#123; return !file-&gt;is_alive; &#125;);  &#125;\n\n\nfor_each_file针对objs和dsos处理resolve，mark live，clear，erase file\n标记所有可访问的输出到文件的object，之后合并可见性\n清除file的symbols\n最后清除掉objs和dsos中非alive的file\n\ntemplate &lt;typename E&gt;__attribute__((no_sanitize(&quot;thread&quot;)))void InputFile&lt;E&gt;::clear_symbols() &#123;  for (Symbol&lt;E&gt; *sym : get_global_syms())    if (sym-&gt;file == this)      sym-&gt;clear();&#125;\n\nmark_live_objectstemplate &lt;typename E&gt;static void mark_live_objects(Context&lt;E&gt; &amp;ctx) &#123;  auto mark_symbol = [&amp;](std::string_view name) &#123;    if (InputFile&lt;E&gt; *file = get_symbol(ctx, name)-&gt;file)      file-&gt;is_alive = true;  &#125;;  for (std::string_view name : ctx.arg.undefined)    mark_symbol(name);  for (std::string_view name : ctx.arg.require_defined)    mark_symbol(name);  std::vector&lt;InputFile&lt;E&gt; *&gt; roots;  for (InputFile&lt;E&gt; *file : ctx.objs)    if (file-&gt;is_alive)      roots.push_back(file);  for (InputFile&lt;E&gt; *file : ctx.dsos)    if (file-&gt;is_alive)      roots.push_back(file);  tbb::parallel_for_each(roots, [&amp;](InputFile&lt;E&gt; *file,                                    tbb::feeder&lt;InputFile&lt;E&gt; *&gt; &amp;feeder) &#123;    if (file-&gt;is_alive)      file-&gt;mark_live_objects(ctx, [&amp;](InputFile&lt;E&gt; *obj) &#123; feeder.add(obj); &#125;);  &#125;);&#125;\n\n首先对所有参数中传入的undef以及require_define的符号所关联的文件进行mark，之后遍历所有alive的obj和dso，加入到root中，之后再进行mark_live_objects。部分文件会因为特殊的链接选项，比如说whole-archive会影响是否设置为is_alive，这部分会之后再以这个为主题单独讲一篇。\n对于ObjectFile和SharedFile的mark方式也是不同的。\nObjectFile::mark_live_objectstemplate &lt;typename E&gt;voidObjectFile&lt;E&gt;::mark_live_objects(Context&lt;E&gt; &amp;ctx,                                 std::function&lt;void(InputFile&lt;E&gt; *)&gt; feeder) &#123;  assert(this-&gt;is_alive);  for (i64 i = this-&gt;first_global; i &lt; this-&gt;elf_syms.size(); i++) &#123;    const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[i];    Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[i];    if (!esym.is_undef() &amp;&amp; exclude_libs)      merge_visibility(ctx, sym, STV_HIDDEN);    else      merge_visibility(ctx, sym, esym.st_visibility);    if (sym.traced)      print_trace_symbol(ctx, *this, esym, sym);    if (esym.is_weak())      continue;    if (!sym.file)      continue;    bool keep = esym.is_undef() || (esym.is_common() &amp;&amp; !sym.esym().is_common());    if (keep &amp;&amp; fast_mark(sym.file-&gt;is_alive)) &#123;      feeder(sym.file);      if (sym.traced)        SyncOut(ctx) &lt;&lt; &quot;trace-symbol: &quot; &lt;&lt; *this &lt;&lt; &quot; keeps &quot; &lt;&lt; *sym.file                     &lt;&lt; &quot; for &quot; &lt;&lt; sym;    &#125;  &#125;&#125;\n\n针对所有global的符号进行处理。\n\n首先对esym进行merge_visibility，对于存在定义的exclude_libs的符号来说是HIDDEN的，关于这一点在命令行参数处有说明。\n\n-exclude-libs LIB,LIB,.. Mark all symbols in given libraries hidden\n\n\n跳过弱符号以及文件不存在的符号。\n\nkeep并且fast_mark成功的符号加入到root中。\n\n\nkeep这里需要是undef的情况，我认为是因为如果esym存在定义，那么定义就是存在于当前的ObjectFile中，也就不需要再重复加入到root中了。common我想同样是因为这种情况下所在的文件已经加入到root中了。\n关于merge_visibility\ntemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::merge_visibility(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym,                                     u8 visibility) &#123;  // Canonicalize visibility  if (visibility == STV_INTERNAL)    visibility = STV_HIDDEN;  auto priority = [&amp;](u8 visibility) &#123;    switch (visibility) &#123;    case STV_HIDDEN:      return 1;    case STV_PROTECTED:      return 2;    case STV_DEFAULT:      return 3;    &#125;    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: unknown symbol visibility: &quot; &lt;&lt; sym;  &#125;;  update_minimum(sym.visibility, visibility, [&amp;](u8 a, u8 b) &#123;    return priority(a) &lt; priority(b);  &#125;);&#125;\n\n这里首先将INTERNAL转换为HIDDEN，之后按照最小的priority来更新visibility。\nupdate_minimum只是一个针对多线程的封装，本质上是一个compare and exchange操作。\ntemplate &lt;typename T, typename Compare = std::less&lt;T&gt;&gt;void update_minimum(std::atomic&lt;T&gt; &amp;atomic, u64 new_val, Compare cmp = &#123;&#125;) &#123;  T old_val = atomic.load(std::memory_order_relaxed);  while (cmp(new_val, old_val) &amp;&amp;         !atomic.compare_exchange_weak(old_val, new_val,                                       std::memory_order_relaxed));&#125;\n\nfast_mark也是针对多线程的一个封装，如果是false则更新为true。\n// An optimized &quot;mark&quot; operation for parallel mark-and-sweep algorithms.// Returns true if `visited` was false and updated to true.inline bool fast_mark(std::atomic&lt;bool&gt; &amp;visited) &#123;  // A relaxed load + branch (assuming miss) takes only around 20 cycles,  // while an atomic RMW can easily take hundreds on x86. We note that it&#x27;s  // common that another thread beat us in marking, so doing an optimistic  // early test tends to improve performance in the ~20% ballpark.  return !visited.load(std::memory_order_relaxed) &amp;&amp;         !visited.exchange(true, std::memory_order_relaxed);&#125;\n\nSharedFile::mark_live_objectstemplate &lt;typename E&gt;voidSharedFile&lt;E&gt;::mark_live_objects(Context&lt;E&gt; &amp;ctx,                                 std::function&lt;void(InputFile&lt;E&gt; *)&gt; feeder) &#123;  for (i64 i = 0; i &lt; this-&gt;elf_syms.size(); i++) &#123;    const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[i];    Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[i];    if (sym.traced)      print_trace_symbol(ctx, *this, esym, sym);    if (esym.is_undef() &amp;&amp; sym.file &amp;&amp; !sym.file-&gt;is_dso &amp;&amp;        fast_mark(sym.file-&gt;is_alive)) &#123;      feeder(sym.file);      if (sym.traced)        SyncOut(ctx) &lt;&lt; &quot;trace-symbol: &quot; &lt;&lt; *this &lt;&lt; &quot; keeps &quot; &lt;&lt; *sym.file                     &lt;&lt; &quot; for &quot; &lt;&lt; sym;    &#125;  &#125;&#125;\n\n这里要说的唯一一点是因为mark的是object而不是shared file，因此dso的情况下不会进行mark\n2. 移除重复的COMDAT段&#123;  Timer t(ctx, &quot;eliminate_comdats&quot;);  tbb::parallel_for_each(ctx.objs, [](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;resolve_comdat_groups();  &#125;);  tbb::parallel_for_each(ctx.objs, [](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;eliminate_duplicate_comdat_groups();  &#125;);&#125;\n\ntemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::resolve_comdat_groups() &#123;  for (ComdatGroupRef&lt;E&gt; &amp;ref : comdat_groups)    update_minimum(ref.group-&gt;owner, this-&gt;priority);&#125;\n\n更新所有comdat_groups的priority\ntemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::eliminate_duplicate_comdat_groups() &#123;  for (ComdatGroupRef&lt;E&gt; &amp;ref : comdat_groups)    if (ref.group-&gt;owner != this-&gt;priority)      for (u32 i : ref.members)        if (sections[i])          sections[i]-&gt;kill();&#125;template &lt;typename E&gt;inline void InputSection&lt;E&gt;::kill() &#123;  if (is_alive.exchange(false))    for (FdeRecord&lt;E&gt; &amp;fde : get_fdes())      fde.is_alive = false;&#125;\n\neliminate重复的section。将section和fde的is_alive都设置为false。\n这里将fde设置为false正对应了上期提到单独解析eh_frame的原因之一：消除重复的fde。\n3. 实际进行符号决议的过程for_each_file([&amp;](InputFile&lt;E&gt; *file) &#123; file-&gt;resolve_symbols(ctx); &#125;);\n\nresolve_symbols的实现对于ObjectFile和SharedFile是不同的\nObjectFiletemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::resolve_symbols(Context&lt;E&gt; &amp;ctx) &#123;  for (i64 i = this-&gt;first_global; i &lt; this-&gt;elf_syms.size(); i++) &#123;    Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[i];    const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[i];    if (esym.is_undef())      continue;    InputSection&lt;E&gt; *isec = nullptr;    if (!esym.is_abs() &amp;&amp; !esym.is_common()) &#123;      isec = get_section(esym);      if (!isec || !isec-&gt;is_alive)        continue;    &#125;    std::scoped_lock lock(sym.mu);    if (get_rank(this, esym, !this-&gt;is_alive) &lt; get_rank(sym)) &#123;      sym.file = this;      sym.set_input_section(isec);      sym.value = esym.st_value;      sym.sym_idx = i;      sym.ver_idx = ctx.default_version;      sym.is_weak = esym.is_weak();      sym.is_imported = false;      sym.is_exported = false;    &#125;  &#125;&#125;\n\n符号决议是针对global symbol的elf_sym的。未定义的esym都跳过了，它们都不需要参与resolve的过程，因为resolve本质是找到需要加入到生成产物的符号实现，但是注意在前面mark的时候还是需要的。\n也就是说Symbol类的sym其实是保留的最终唯一定义。而在决议的过程，不断的将esym和对应的sym进行比较。如果esym的rank小，也就是更加优先，那么就将sym中的信息更新为对应的esym的信息，这就是实际决议过程中做的事情。而这里也是实际初始化symbols成员里global的值的地方，local的部分初始化在parse的阶段就做好了，因为local的符号并不需要进行resolve。\nget_ranktemplate &lt;typename E&gt;static u64 get_rank(const Symbol&lt;E&gt; &amp;sym) &#123;  if (!sym.file)    return 7 &lt;&lt; 24;  return get_rank(sym.file, sym.esym(), !sym.file-&gt;is_alive);&#125;// Symbols with higher priorities overwrites symbols with lower priorities.// Here is the list of priorities, from the highest to the lowest.////  1. Strong defined symbol//  2. Weak defined symbol//  3. Strong defined symbol in a DSO/archive//  4. Weak Defined symbol in a DSO/archive//  5. Common symbol//  6. Common symbol in an archive//  7. Unclaimed (nonexistent) symbol//// Ties are broken by file priority.template &lt;typename E&gt;static u64 get_rank(InputFile&lt;E&gt; *file, const ElfSym&lt;E&gt; &amp;esym, bool is_lazy) &#123;  if (esym.is_common()) &#123;    assert(!file-&gt;is_dso);    if (is_lazy)      return (6 &lt;&lt; 24) + file-&gt;priority;    return (5 &lt;&lt; 24) + file-&gt;priority;  &#125;  if (file-&gt;is_dso || is_lazy) &#123;    if (esym.st_bind == STB_WEAK)      return (4 &lt;&lt; 24) + file-&gt;priority;    return (3 &lt;&lt; 24) + file-&gt;priority;  &#125;  if (esym.st_bind == STB_WEAK)    return (2 &lt;&lt; 24) + file-&gt;priority;  return (1 &lt;&lt; 24) + file-&gt;priority;&#125;\n\nget_rank的实现，根据注释我们可以看到不同类别符号的优先级。\nSharedFiletemplate &lt;typename E&gt;void SharedFile&lt;E&gt;::resolve_symbols(Context&lt;E&gt; &amp;ctx) &#123;  for (i64 i = 0; i &lt; this-&gt;symbols.size(); i++) &#123;    Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[i];    const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[i];    if (esym.is_undef())      continue;    std::scoped_lock lock(sym.mu);    if (get_rank(this, esym, false) &lt; get_rank(sym)) &#123;      sym.file = this;      sym.origin = 0;      sym.value = esym.st_value;      sym.sym_idx = i;      sym.ver_idx = versyms[i];      sym.is_weak = false;      sym.is_imported = false;      sym.is_exported = false;    &#125;  &#125;&#125;\n\n对于SharedFile中的符号中不需要考虑是否是global的问题，上期解析SharedFile的部分也有提到，对应的first_global就是0。相对于\n4. LTO的处理if (ctx.has_lto_object) &#123;  // Do link-time optimization. We pass all IR object files to the  // compiler backend to compile them into a few ELF object files.  //  // The compiler backend needs to know how symbols are resolved,  // so compute symbol visibility, import/export bits, etc early.  mark_live_objects(ctx);  apply_version_script(ctx);  parse_symbol_version(ctx);  compute_import_export(ctx);  // Do LTO. It compiles IR object files into a few big ELF files.  std::vector&lt;ObjectFile&lt;E&gt; *&gt; lto_objs = do_lto(ctx);  // do_resolve_symbols() have removed unreferenced files. Restore the  // original files here because some of them may have to be resurrected  // because they are referenced by the ELF files returned from do_lto().  ctx.objs = objs;  ctx.dsos = dsos;  append(ctx.objs, lto_objs);  // Redo name resolution from scratch.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;clear_symbols();    file-&gt;is_alive = !file-&gt;is_in_lib;  &#125;);  tbb::parallel_for_each(ctx.dsos, [&amp;](SharedFile&lt;E&gt; *file) &#123;    file-&gt;clear_symbols();    file-&gt;is_alive = !file-&gt;is_needed;  &#125;);  // Remove IR object files.  for (ObjectFile&lt;E&gt; *file : ctx.objs)    if (file-&gt;is_lto_obj)      file-&gt;is_alive = false;  std::erase_if(ctx.objs, [](ObjectFile&lt;E&gt; *file) &#123; return file-&gt;is_lto_obj; &#125;);  do_resolve_symbols(ctx);&#125;\n\n关于apply_version_script, parse_symbol_version, compute_import_export这三个过程，会在之后的过程中讲解。这里简单来讲就是获取符号对应的版本信息以及对应import/export的属性。\n这个部分做了这么几件事情\n\n计算出符号所需的基本信息\n实际执行lto\n将lto结果的object加入到全局\n清理旧的lto文件\n再次执行do_resolve_symbols整个过程\n\n","categories":["Linker"],"tags":["mold","symbol_resolve"]},{"title":"1984","url":"/2023/04/09/Reading/1984/","content":"未来会是怎么样的呢？许多人都会在设想一种美好的乌托邦，比如说美丽新世界中所描述的，尽管有些黑暗的真相但是对于参与者来说都是富足快乐的，但1984的作者赫胥黎给出的是更加令人恐惧且残酷的世界。\n\n是老派改革家想象中那种愚蠢快乐主义乌托邦的精确对立面。一个恐惧、背叛与折磨的世界，一个践踏与被践踏的世界，一个在变得更精致的同时会变得更加残酷，而非更不残酷的世界。我们这个世界里的进步，会是朝向带来更多痛苦的进步。\n\n而人们所在的世界，其实更仅一步来说是由所在的社会构成，社会的构成又很大程度归结于所在国家的权力机构。我一直在想人们对于“关注政治和社会问题”这个问题本身应该怀有怎样的态度，至少我一直是不太关心，也不想去关心。但读完了这本书似乎让我对这个问题的想法产生了一些变化。起源于温斯顿和茱莉亚的交流过程，茱莉亚是一个学会在这种环境下生存的人，也会认为这个环境很蠢，但是不愿去谈论这些。当温斯顿和她讲述关于一些党的内容却是毫不关心。\n\n对于党内教条的种种分支，她连一点兴趣都没有。每次他开始讲到英社的种种原则、双重思想、过去的易变性、对客观现实的否定，还有用到新语字汇时，她就会变得既无聊又困惑，还说她从来不去注意那种事情。你知道那全都是废话，那么为什么要让自己去操心那个？\n\n而在后面的内容作者讲述了这样一段的内容\n\n他们可以被动地接受最明目张胆的违反现实，因为他们从来没有彻底掌握到他们受到的要求是多么大的罪恶，对于公共事件也不够有兴趣，不足以注意到发生了什么事。因为缺乏理解力，他们保持心智健全。他们就只是把什么都吞下去，就像一颗玉米粒完全未经消化，就通过了一只鸟的身体。\n\n这个世界是很残酷的，当读到这些内容，我觉得作者很明显是想告诉我们应该意识到问题，而不应该无视这一切。关于政治问题，基于国情似乎已经没什么办法，但是关于社会问题与我们越来越息息相关，比如说前两年的疫情的情况，比如说退休年龄的变动。而我想这个问题也可以引申为人们对于外在信息的态度，不应当照单全收，而是应该去思考，否则很容易受到欺骗。虽然受到过一些要敢于怀疑答案和质疑的教育，但是似乎并没有留下多深的印象，在我写这部分内容之前已经忘却了大半。不管你怎么处理，首先要自己主动去理解，遇到错误的时候也不是所有的事情都能去纠正的。\n而书中也谈及了许多社会相关的一些根源问题。印象深刻的是阶级的固化这部分内容，我认为在上层的人想要巩固自己阶级的位置，下层的人未曾想过也很难去改变，中间层的人大多又向上爬，或许这也是阶级的本质。而作者也表达出了类似的观点：\n\n就算在极大的动乱与看似无法挽回的改变之后，同样的模式总是会自动重新确立，就像一个陀螺仪不管朝着此方或彼方推得多用力，总是会回归均衡状态。\n\n我想也正因如此，1984的世界中强权者才肯放任“最下层”的普罗阶级，因为他们不会去想改变这些，只想留在原地，同时在文化和信息的限制下他们也无法习得去改变这一行为，只是去对党员进行十分严格的管制。温斯顿一直认为“希望在普罗阶级”，“普罗阶级一直保持人性。他们并没有变得心如铁石。他们坚守着他自己必须刻意努力重新学习的那些原始情绪。“，换个角度来说为了维持稳定，党员们这些所谓的“人性”都要被扼杀。\n前面提到了阶级，那么平等问题是不可避免要被提及的，产生了阶级就意味着不平等。但是平等的话上位人就无法获得权力，以下是作者的观点：\n\n不平等是文明的代价。然而随着机器制造的发展，状况改变了。就算人类还是必须做不同类型的工作，他们却不再有必要过着社会或经济水平不同的生活。所以，在即将攫取权力的新群体眼中，人类的平等不再是值得奋起争取的理想，而是一个必须回避的危险。\n\n本文开头提到的《美丽新世界》尽管是人们富足快乐的世界，但是同样存在着上面所诉说的一些问题，并且和1984一切同样都是建立在强权统治下。相对于《美丽新世界》来说1984有些许多可以对比谈论的问题。在两个世界中，强权者都做了许多事情来避免大多数人们来动摇自己的权力。\n首先是文化与信息上。两者都在避免人们了解过去了，不过一个是隐藏，一个是修改与破坏。同时在通过各种手段“修改与限制”人们的独立思考，一个是从小开始进行反复洗脑催眠，另一个则是出动”思想警察“来限制人们。正如1984中所说\n\n因为要是所有人都享有同样的闲暇与安全，在常态下被贫困弄得傻头傻脑的绝大多数人类都会变得有文化学识，也将学会如何为自己思考，而他们一旦做到这件事，他们迟早会领悟到掌握特权的少数根本没有用处，他们会把那些人扫到一旁去。长期来说，阶级社会只有在贫穷与无知的基础上才可能成立\n\n两者都谈到了技术的停滞，新世界的技术是为了稳定，因为科技、真理代表破坏现有的平衡，而1984则是为了限制自由，甚至只有在技术产物能够透过某种方式缩减人类的自由时，技术的进步才会发生。但是对于强权者来说，本质都是为了巩固自己的权力。\n但对待大多数人们的态度是完全不同的。一个类似于让人们共同富裕，催眠洗脑，乐不思蜀，另一个类似于压迫，强权，威吓。但是两者又都明确了阶级，在美丽新世界中是不同的人种，同时又会对这些人种进行催眠，让他们觉得自己就应该做当前的事情，1984中则是明确区分了党员和普罗阶级，对于违反规定的党员进行最恐怖的制裁，使得他们“心甘情愿”产生改变。让我印象最深刻的是这样一句话：\n\n早就期待着的子弹进入了他的大脑。\n\n相比起1984来说，新世界确实非常美好。这个世界到底会走向什么样子呢？就目前的情况来说我想并不会那么乐观，至少对于大部分的地方如此。想要超越别人、掌控别人我觉得是人类作为动物的兽性中衍生出的一部分，那么也不可避免的有许多人会去追求权力，最后有人为了巩固强权做出什么也不奇怪。而在这样的世界中，大部分人能做的或许只有去学着不被动接受外部的信息，多进行独立思考，作者也许是想要警醒人们，并且试着影响读者们这样来做，至少能够一定程度上推迟或者避免这样的世界到来。\n","categories":["Reading"],"tags":["赫胥黎"]},{"title":"mold源码阅读 其四 mergeable section","url":"/2023/04/16/mold/mold-4-mergeable-section/","content":"\npixiv:83834646 \n\n上一期的内容讲完了一些针对文件的简单处理以及符号决议，这一期的主要内容是在这之后针对mergeable section的决议与合并。\nresolve_section_pieces这个过程是将mergeable的section split到更小的pieces中，并且将每一个piece和其他来自不同文件的pieces进行合并，最典型的例子是不同object file中string段的合并。mold中称mergeable section原子单元为section pieces。\n所以这里的过程分为了两部分\n\n将普通的section转换为MegeableSection\nresolve and merge\n\ntemplate &lt;typename E&gt;void resolve_section_pieces(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;resolve_section_pieces&quot;);  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;initialize_mergeable_sections(ctx);  &#125;);  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;resolve_section_pieces(ctx);  &#125;);&#125;\n\ninitialize_mergeable_sectionsmold中attach section pieces symbols\ntemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::initialize_mergeable_sections(Context&lt;E&gt; &amp;ctx) &#123;  mergeable_sections.resize(sections.size());  for (i64 i = 0; i &lt; sections.size(); i++) &#123;    if (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec = sections[i]) &#123;      if (std::unique_ptr&lt;MergeableSection&lt;E&gt;&gt; m = split_section(ctx, *isec)) &#123;        mergeable_sections[i] = std::move(m);        isec-&gt;is_alive = false;      &#125;    &#125;  &#125;&#125;\n\n针对每一个section进行split_section，转换为一个MergeableSection，之后将原始的section设置为非alive。\nMergeableSection首先我们来看和MergeableSection相关的数据结构，有如下三个\n\nMergeableSection\nMergedSection\nSectionFragment\n\n其中每个MergeableSection中包含了多个SectionFragment，又关联了其对应的MergedSection。MergedSection是一个chunk，而chunk则是在链接后期要输出到文件的时候的一个基本单位，暂时先不进一步讲解。SectionFragment则是MergedSection根据MergeableSection传入的信息构造的，并且返回给MergeableSection保存的结构。\ntemplate &lt;typename E&gt;struct MergeableSection &#123;  std::pair&lt;SectionFragment&lt;E&gt; *, i64&gt; get_fragment(i64 offset);  MergedSection&lt;E&gt; *parent;  u8 p2align = 0;  std::vector&lt;std::string_view&gt; strings;  std::vector&lt;u64&gt; hashes;  std::vector&lt;u32&gt; frag_offsets;  std::vector&lt;SectionFragment&lt;E&gt; *&gt; fragments;&#125;;\n\ntemplate &lt;typename E&gt;class MergedSection : public Chunk&lt;E&gt; &#123;public:  static MergedSection&lt;E&gt; *  get_instance(Context&lt;E&gt; &amp;ctx, std::string_view name, u64 type, u64 flags);  SectionFragment&lt;E&gt; *insert(std::string_view data, u64 hash, i64 p2align);  void assign_offsets(Context&lt;E&gt; &amp;ctx);  void copy_buf(Context&lt;E&gt; &amp;ctx) override;  void write_to(Context&lt;E&gt; &amp;ctx, u8 *buf) override;  void print_stats(Context&lt;E&gt; &amp;ctx);  HyperLogLog estimator;private:  MergedSection(std::string_view name, u64 flags, u32 type);  ConcurrentMap&lt;SectionFragment&lt;E&gt;&gt; map;  std::vector&lt;i64&gt; shard_offsets;  std::once_flag once_flag;&#125;;\n\ntemplate &lt;typename E&gt;struct SectionFragment &#123;  SectionFragment(MergedSection&lt;E&gt; *sec) : output_section(*sec) &#123;&#125;  SectionFragment(const SectionFragment &amp;other)    : output_section(other.output_section), offset(other.offset),      p2align(other.p2align.load()), is_alive(other.is_alive.load()) &#123;&#125;  u64 get_addr(Context&lt;E&gt; &amp;ctx) const;  MergedSection&lt;E&gt; &amp;output_section;  u32 offset = -1;  std::atomic_uint8_t p2align = 0;  std::atomic_bool is_alive = false;&#125;;\n\nMergedSection并不暴露对应的构造函数，而是通过对应的get_instance来获取实例\nMergedSection&lt;E&gt;::get_instance(Context&lt;E&gt; &amp;ctx, std::string_view name,                               u64 type, u64 flags) &#123;  name = get_merged_output_name(ctx, name, flags);  flags = flags &amp; ~(u64)SHF_GROUP &amp; ~(u64)SHF_COMPRESSED;  auto find = [&amp;]() -&gt; MergedSection * &#123;    for (std::unique_ptr&lt;MergedSection&lt;E&gt;&gt; &amp;osec : ctx.merged_sections)      if (std::tuple(name, flags, type) ==          std::tuple(osec-&gt;name, osec-&gt;shdr.sh_flags, osec-&gt;shdr.sh_type))        return osec.get();    return nullptr;  &#125;;  // Search for an exiting output section.  static std::shared_mutex mu;  &#123;    std::shared_lock lock(mu);    if (MergedSection *osec = find())      return osec;  &#125;  // Create a new output section.  std::unique_lock lock(mu);  if (MergedSection *osec = find())    return osec;  MergedSection *osec = new MergedSection(name, flags, type);  ctx.merged_sections.emplace_back(osec);  return osec;&#125;\n\n每次获取的时候去ctx中寻找实例，不存在则创建新的并且返回。\nsplit_sectiontemplate &lt;typename E&gt;static std::unique_ptr&lt;MergeableSection&lt;E&gt;&gt;split_section(Context&lt;E&gt; &amp;ctx, InputSection&lt;E&gt; &amp;sec) &#123;  if (!sec.is_alive || sec.sh_size == 0 || sec.relsec_idx != -1)    return nullptr;  const ElfShdr&lt;E&gt; &amp;shdr = sec.shdr();  if (!(shdr.sh_flags &amp; SHF_MERGE))    return nullptr;\n\n由于是针对mergeable section，而判断标准则是根据section header中的sh_flgas的值，因此先通过检查flga来进行过滤。\nstd::unique_ptr&lt;MergeableSection&lt;E&gt;&gt; rec(new MergeableSection&lt;E&gt;);rec-&gt;parent = MergedSection&lt;E&gt;::get_instance(ctx, sec.name(), shdr.sh_type,                                             shdr.sh_flags);rec-&gt;p2align = sec.p2align;// If thes section contents are compressed, uncompress them.sec.uncompress(ctx);std::string_view data = sec.contents;const char *begin = data.data();u64 entsize = shdr.sh_entsize;HyperLogLog estimator;\n\n做一些基本的初始化操作，包括创建了MergeableSection以及关联对应的MergedSection，取出数据等。\nsplit string// Split sectionsif (shdr.sh_flags &amp; SHF_STRINGS) &#123;  if (entsize == 0) &#123;    // GHC (Glasgow Haskell Compiler) sometimes creates a mergeable    // string section with entsize of 0 instead of 1, though such    // entsize is technically wrong. This is a workaround for the issue.    entsize = 1;  &#125;  while (!data.empty()) &#123;    size_t end = find_null(data, entsize);    if (end == data.npos)      Fatal(ctx) &lt;&lt; sec &lt;&lt; &quot;: string is not null terminated&quot;;    std::string_view substr = data.substr(0, end + entsize);    data = data.substr(end + entsize);    rec-&gt;strings.push_back(substr);    rec-&gt;frag_offsets.push_back(substr.data() - begin);    u64 hash = hash_string(substr);    rec-&gt;hashes.push_back(hash);    estimator.insert(hash);  &#125;&#125;static size_t find_null(std::string_view data, u64 entsize) &#123;  if (entsize == 1)    return data.find(&#x27;\\0&#x27;);  for (i64 i = 0; i &lt;= data.size() - entsize; i += entsize)    if (data.substr(i, entsize).find_first_not_of(&#x27;\\0&#x27;) == data.npos)      return i;  return data.npos;&#125;\n\n\n找到terminator（’\\0’）\n将对应的rec的strings添加找到的str\n添加对应的frag_offsets\n添加string的hash到estimator中\n\nestimator是用于优化时间的方案，等到最后会提及，不影响合并的正确性。\nsplit otherelse &#123;    // OCaml compiler seems to create a mergeable non-string section with    // entisze of 0. Such section is malformed. We do not split such section.    if (entsize == 0)      return nullptr;    if (data.size() % entsize)      Fatal(ctx) &lt;&lt; sec &lt;&lt; &quot;: section size is not multiple of sh_entsize&quot;;    while (!data.empty()) &#123;      std::string_view substr = data.substr(0, entsize);      data = data.substr(entsize);      rec-&gt;strings.push_back(substr);      rec-&gt;frag_offsets.push_back(substr.data() - begin);      u64 hash = hash_string(substr);      rec-&gt;hashes.push_back(hash);      estimator.insert(hash);    &#125;  &#125;\n\n和split string的区别在于不是通过’\\0’而是通过entsize判断一个piece的结束位置\nrec-&gt;parent-&gt;estimator.merge(estimator);static Counter counter(&quot;string_fragments&quot;);counter += rec-&gt;fragments.size();return rec;\n\n最后的收尾\nObjectFile::resolve_section_pieces\n 如何判断是相同的字符串？？对应地址怎么办\n\ntemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::resolve_section_pieces(Context&lt;E&gt; &amp;ctx) &#123;\tfor (std::unique_ptr&lt;MergeableSection&lt;E&gt;&gt; &amp;m : mergeable_sections) &#123;    if (m) &#123;      m-&gt;fragments.reserve(m-&gt;strings.size());      for (i64 i = 0; i &lt; m-&gt;strings.size(); i++)        m-&gt;fragments.push_back(m-&gt;parent-&gt;insert(m-&gt;strings[i], m-&gt;hashes[i],                                                 m-&gt;p2align));      // Shrink vectors that we will never use again to reclaim memory.      m-&gt;strings.clear();      m-&gt;hashes.clear();    &#125;  &#125;\n\n将所有MergableSection的数据merge到对应的parent中。\nfor (i64 i = 1; i &lt; this-&gt;elf_syms.size(); i++) &#123;  Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[i];  const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[i];  if (esym.is_abs() || esym.is_common() || esym.is_undef())    continue;  std::unique_ptr&lt;MergeableSection&lt;E&gt;&gt; &amp;m = mergeable_sections[get_shndx(esym)];  if (!m)    continue;  SectionFragment&lt;E&gt; *frag;  i64 frag_offset;  std::tie(frag, frag_offset) = m-&gt;get_fragment(esym.st_value);  if (!frag)    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: bad symbol value: &quot; &lt;&lt; esym.st_value;  sym.set_frag(frag);  sym.value = frag_offset;&#125;\n\n之后是attach section piece to symbols的过程。本质的操作是将对应的有定义的且非abs的符号关联到对应的fragment。\n// Compute the size of frag_syms.  i64 nfrag_syms = 0;  for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : sections)    if (isec &amp;&amp; isec-&gt;is_alive &amp;&amp; (isec-&gt;shdr().sh_flags &amp; SHF_ALLOC))      for (ElfRel&lt;E&gt; &amp;r : isec-&gt;get_rels(ctx))        if (const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[r.r_sym];            esym.st_type == STT_SECTION &amp;&amp; mergeable_sections[get_shndx(esym)])          nfrag_syms++;  this-&gt;frag_syms.resize(nfrag_syms);\n\n之后寻找满足条件的esym，统计对应的size。\n注意寻找的是ElfRel中的esym，只有ElfRel中的esym才能被relocation，因为merge的过程中必然会修改各种地址信息。\n这里根据sym得到的index获取对应的mergeable_section是在前一步init的过程中初始化的，也就是说这个index对于mergeable_section和原始的section是完全对应的，如果不是mergeable的section则返回的会是空指针。\n接下来是引用mergeable section的relocation symbol，会针对每一个这样的symbol redirect rel sym到一个新创建的dummy到symbol上。\n// For each relocation referring a mergeable section symbol, we create// a new dummy non-section symbol and redirect the relocation to the// newly-created symbol.i64 idx = 0;for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : sections) &#123;  if (!isec || !isec-&gt;is_alive || !(isec-&gt;shdr().sh_flags &amp; SHF_ALLOC))    continue;  for (ElfRel&lt;E&gt; &amp;r : isec-&gt;get_rels(ctx)) &#123;    const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[r.r_sym];    if (esym.st_type != STT_SECTION)      continue;    std::unique_ptr&lt;MergeableSection&lt;E&gt;&gt; &amp;m = mergeable_sections[get_shndx(esym)];    if (!m)      continue;    i64 r_addend = get_addend(*isec, r);    SectionFragment&lt;E&gt; *frag;    i64 in_frag_offset;    std::tie(frag, in_frag_offset) = m-&gt;get_fragment(esym.st_value + r_addend);    if (!frag)      Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: bad relocation at &quot; &lt;&lt; r.r_sym;    Symbol&lt;E&gt; &amp;sym = this-&gt;frag_syms[idx];    sym.file = this;    sym.set_name(&quot;&lt;fragment&gt;&quot;);    sym.sym_idx = r.r_sym;    sym.visibility = STV_HIDDEN;    sym.set_frag(frag);    sym.value = in_frag_offset - r_addend;    r.r_sym = this-&gt;elf_syms.size() + idx;    idx++;  &#125;&#125;template &lt;typename E&gt;inline i64 get_addend(u8 *loc, const ElfRel&lt;E&gt; &amp;rel) &#123;  return rel.r_addend;&#125;template &lt;typename E&gt;std::pair&lt;SectionFragment&lt;E&gt; *, i64&gt;MergeableSection&lt;E&gt;::get_fragment(i64 offset) &#123;  std::vector&lt;u32&gt; &amp;vec = frag_offsets;  auto it = std::upper_bound(vec.begin(), vec.end(), offset);  i64 idx = it - 1 - vec.begin();  return &#123;fragments[idx], offset - vec[idx]&#125;;&#125;\n\n简单的对新的sym设置了基本信息，主要是进行双向的关联。\nsym.sym_idx = r.r_sym;r.r_sym = this-&gt;elf_syms.size() + idx;// Symbol:sym_idx// Index into the symbol table of the owner file.i32 sym_idx = -1;\n\n这里将rel中的sym指向了elf_syms后面的位置，后面会将执行frag_syms逐一添加到elf_syms之后。\n最后将frag_syms都添加到ObjectFile的symbols中，整个过程就全部结束了。\nassert(idx == this-&gt;frag_syms.size());for (Symbol&lt;E&gt; &amp;sym : this-&gt;frag_syms)  this-&gt;symbols.push_back(&amp;sym);\n\nMergedSection::inserttemplate &lt;typename E&gt;SectionFragment&lt;E&gt; *MergedSection&lt;E&gt;::insert(std::string_view data, u64 hash, i64 p2align) &#123;  std::call_once(once_flag, [&amp;] &#123;    // We aim 2/3 occupation ratio    map.resize(estimator.get_cardinality() * 3 / 2);  &#125;);  SectionFragment&lt;E&gt; *frag;  bool inserted;  std::tie(frag, inserted) = map.insert(data, hash, SectionFragment(this));  assert(frag);  update_maximum(frag-&gt;p2align, p2align);  return frag;&#125;ConcurrentMap&lt;SectionFragment&lt;E&gt;&gt; map;\n\n第一次insert的时候进行预估大小，之后进行insert。\n在看到这里的实现我在想，在merge string的时候是要比较长度吗，在这里我得到了答案，是直接通过之前保存的hash保证unique。\n另外这里用到了estimator，estimator的类型是hyperloglog，根据注释\n\nThis file implements HyperLogLog algorithm, which estimates the number of unique items in a given multiset.\n\n谷歌的结果是这样的\n\nHyperLogLog is an algorithm for the count-distinct problem, approximating the number of distinct elements in a multiset. Calculating the exact cardinality of the distinct elements of a multiset requires an amount of memory proportional to the cardinality, which is impractical for very large data sets.\n\n有兴趣的可以去看wiki或者更多资料，这不在此系列博客的研究范围内。\n整个过程的回顾resolve_section_pieces由两部分操作组成\n\n针对所有mergeable的段进行split，将InputSection转换为对应的MergeableSection\n针对所有MergeableSection进行merge\nstrings Merge到相关联的MergedSection中\nsymbols attach to piece section\n针对rel的symbol关联到一个新创建的dummy的symbol上\n\n\n\n","categories":["Linker"],"tags":["mold","Section"]},{"title":"2023.4.10-4.16 下陷","url":"/2023/04/16/Life/2023-4-16/","content":"和每个周一样，这周一如既往的168个小时，但不一样的是这周我十分清晰的见证了自己一周内的身心变化，并且大概也是我最后一次心理咨询，另外这周也发了不少想法，因此我想要将这些记录下来。正像我一个朋友说的，将一些想法记录下来，以便未来再回来看，不论未来和现在是怎样的，过去就这样存在于这里。\n本周的变化这周我几乎看到了自己从动力十足的状态逐渐一步步变烂的整个过程，我觉得有必要来回顾一下这周发生了什么。\n状态周一正常的工作，但是到点早早回到家开始修改自己的sideproj，难得的好状态，因此一直肝到了晚上十二点多，太上头甚至没怎么练琴。\n周二正常的工作，大部分事情和周一相同，状态也是比较好。这天花了不少时间去练琴，练的是新的部分，还是比较吃力。\n前两天都是打车上下班，大风加沙尘暴的恶劣天气加上早上起不来，仅有的一点运动都缺失了。\n但周三开始就不对劲了，研究dwarf的时候迟迟没有什么所想的进展，渐渐开始紧张，烦躁，给自己加压，最后把自己逼迫到了出现负面想法的情况。之后出去走了一公里，情绪渐渐缓解了一点，但回来就开始感到疲惫，勉强看完书后身体就开始想要刷视频，刷完视频后练琴有些不在状态，很快就停下了。也没有精力去做sideproj，之后继续刷视频，最后晚睡。\n周四也遇到了问题，开始觉得发懵，觉得意识与行动的联系变弱了，开始有一种恍惚感：不知道该做什么，不知道对错，无法深入理性思考，只能看到什么做什么，而且是不用脑子的那种。这一天也开始眼睛感到不适，除了休息不好以及最近可能用不干净的手频繁触摸眼睛周围外，高强度的用眼也是难逃其责。工作期间起身去厕所的时候也能明显感受到身体的疲劳。晚上迟迟搞不定工作上的问题，开始钻牛角尖，缺乏耐心，攻击自己，最后也是很晚回家，并且同样多走了一段路（都是为了一定程度的锻炼身体），但是这两天自我攻击比较严重，现在看来这个时候多走路反而是负担。到了家优先趴在了床上，勉强看了一点书，之后也没怎么练琴。\n周五更是严重，前一天晚上睡眠平均心率增加到了79，早上到公司的时候开始有些轻微头晕，易怒。下午一直没有搞出周四没解决的问题，越来越钻牛角尖，感到更多压力，紧张，开始觉得任务会无法完成。其实这个时候已经几乎无法正常思考问题的解决方案了，但仍然只是在那里堆时间，胡乱操作。\n时间记录首先是写代码的时间，周一到周四线性的减少了\n\n练琴开启节拍器的时间。但有两个部分没有记录，一个是识谱，另一个是在使用另一个app的时间没有记录，但是这两部分在周三和周四也都是没在用的。\n\n睡眠心率平均值，最近的常规值是70出头，周四的晚上到了最高值79，不过这个的影响因素很多，很难直接断定。\n\n另外则是睡眠的时间，这个难以准确记录。\n根据其他信息记录，上床时间分别为\n\n1:26\n1:00\n1:30\n1:40\n1:40\n\n屏幕使用时间难以准确记录，但是周三开始回家就想看动画，刷视频，也刷了蛮久\n我出了什么问题？自大与碰壁。周一周二sideproj良好的进度让我觉得dwarf那边也能随便解决，但实际上我想要的资料几乎没有，开始觉得自己不行。\n发现自己在钻牛角尖没能及时停下来。不论是dwarf的问题还是工作上的问题，我都多少有点意识到自己进入了死胡同，但是都没能及时停下，而是加速朝着墙冲过去。过度集中使得我反而迷失了方向。这是我一直以来的坏毛病。\n没有根据自己身体的疲劳调整。这几天多次行动使得自己开始累积压力，积压疲劳，而此时我并没有停下，而是尽可能的再去做些什么。我就像一个机器人一样，只是给自己安排任务，不到难以控制的情况是不会停下来的。\n心理咨询的结束大概是最后一次心理咨询，谈了一下近况，聊了一些问题。\n首先是最近的情况怎么样？我提到之前被人问及的最焦虑的事情，我一时之间不知道怎么回答，后来回答的是不安，工作的焦虑，但其实自己一方面觉得焦虑一方面又觉得无所谓，最近这种无所谓的态度特别强烈。而我不论是否那么关心这个问题，不论怎么折腾，现实也就这个样，没什么变化。\n那你是觉得不论怎么样生活都是一样的，就因此不折腾了吗？并不是该折腾折腾，能折腾到什么样就是什么样。\n又从我之前说过遇到问题时可能有人一起会更好开始，问我如果和别人在一起呢？而我前两天则开始觉得，似乎跟朋友在一起也是一样，女朋友又不可能有。后来讲下去谈到了找女朋友的问题，这部分还讲了半天。\n之后问到我要解决的现实问题怎么办？我的答复是只能每个方面磨下去，自己没办法像钻头一样，逐个击破，所以需要自己在更漫长时间的努力，将每个方面一点点磨下去。有点像是无奈之举，除此之外只有等待什么机会，或者什么事件。\n说到自我贬低的部分，我说自己不接受赞美只接受批评，因为我认为别人的赞美是因为看到了我的一些表象。\n咨询师说别人看到的都是不对的吗？我的回答是有许多错觉的部分，当然也有正确的部分。\n又问我那你能不能相信一下别人说的夸奖的内容？我说不信，本质上是我没有认同自己，主要是我发自内心不觉得自己是多么好的人。尽管有一点点好的部分，但自己有着数不尽的问题。自己做的好的那么一点点也都是“应该”，做的不好的地方就是自己的问题。\n后来说到自己脑中一闪而过的“给别人挑刺，贬低别人”的想法，自己也正如这样对待自己。“如果自己变厉害了就不会这样不认同自己了”，如果一直怀有这样的想法，即便站上顶点也依然不会放过自己。因为即便在顶点，也可以站的更高，这也有一部分是因为人上进的本性，不接受自己，批评自己的想法也是有促进自己前进的正面意义，只是这样的自己像是严酷的监工（-1hp +2atk）。\n又说到自己最近一周，由于不放过自己，持续逼迫自己，使得自己的情况十分清晰可见的越来越不好。我觉得自己要做的还是应该多放过自己一些，感受自己的想法，避免进入泥潭，而未掉入泥潭的我相比于掉入的我还是会多不少处理能力。\n最后要结束的时候咨询师说我实际上很强大，希望我能记得。不过我对此其实还是没有什么实感，没有什么想法，还是会继续当监工，只是监督力度可能会开始有意识的减弱，否则我会继续倒下去。我的心理咨询大概到这里就彻底结束了。\n本周其他想法的一些记录4.12dwarf没有什么我想要的例子，看了半天连个开头都没搞明白，瞬间变得特别沮丧了…又开始意识到自己是个废物，准备出门走走，起身来才意识到刚才自己看的时候压力多大，明显感到十分疲惫，呼吸短浅，渐渐察觉自己又到了这种极其负面的状态，意识到自己又在和以往一样遇到点解不出的难题就开始烦，给身体不断施加压力，同时想到自己只是想根据潜意识解决，或者找一个现有的东西抄，而没想过怎么用现有知识去进一步思考…\n4.13感觉到自己的精力太少远远不够用的…前两天有些拼，这两天已经明显开始觉得身体在抗议，疲惫，想要享乐这个想法变得更强烈，更难抵抗，最近每日有效工作加学习时间逐日渐少…\n今天我又感觉到那种因为疲劳而感到抽离于现实的感觉。这种时候能做的就是看到什么能做的去做什么，而没有办法去思考自己该怎么做，自己该做什么，如果工作996的话简直不敢想会变成什么样子\n不仅是精力不足以及身体疲劳，昨天遇到搞不懂的东西后自己对自己的心理压迫也是一个很大的影响因素…\n4.14\n这样说了，心里在欺骗自己说自己本来就是个废物，爱咋咋地，就这样摆烂吧。转去练琴的时候想到了自己练琴也都很慢，就潜意识中加快了速度，选择了我跟不上的节拍练习…\n想起白天好几个同事来问我问题，我当时其实有点虚荣，觉得大家都来问我，这样好啊，但又知道自己也就那一点点东西。但是没办法，这件事情上并不是为了荣誉什么的，反而是觉得被人需要了很开心…虽然如此，但还是像我上面说的有虚荣心在，自己没有什么过硬的水准，只好从这种方面和角度给自己找信心，这样说出来也蛮丢人的\n觉得比别人好的自己，觉得比别人差的自己，自傲的自己，自卑的自己，无一例外都是自己，真的是分裂\n感觉负面想法开始冒出来了，这是我没有好好照顾自己，没有重视自己感受到一个结果吧。不知道这几天里疲劳和负面情绪是谁先动的手，反正现在是两败俱伤，我也一直没有太关注平常的身体状态。对我来说不论状态好还是不好，要做的事情都是一样的，只是说做多做少，逼不逼自己的区别罢了，只想无止境的压榨着远不如常人的精力\n4.15看到别人在参与复杂的项目，讨论相关技术，想到自己只是一直在做自己的玩具项目，而且进度非常非常慢，觉得自己大概只有做这点玩具的份了，技术和其他条件都不行，以后能不能在编译器的岗位都很成问题…\n担心失业，担心做什么都只能在入门处徘徊。虽然失业也不是就没路了，但我终归想在这条路走下去，也想做的更深入更好想起两年前全程找工作的那个月，觉得以我的条件根本就找不到，也不可能找得上做编译器的工作，现在也这样觉得，只是之前运气好一点做了ai编译器，但霉运的我不可能以后都去依靠运气…\n做玩具也挺开心的，能实现些什么东西我觉得很棒，不然我也不会花时间去做只是当这件事情与生活的压力产生了交集，与我停滞不前的水平产生了交集，加上我的扭曲思考方式，最后这件事情产生了完全不一样的性质…\n","categories":["Thinking"]},{"title":"莫失莫忘","url":"/2023/04/17/Reading/never-let-me-go/","content":"这本书从平淡的校园生活回忆开始，一点一点揭露出整个故事的真相。\n从我对于这本书的感觉开始。一开始我看这个故事是有些摸不着头脑的，作者的意图有些让我捉摸不透，我不明白作者想借此表达什么。但是当我读到真相，似乎开始明白了一些作者的用意。对于捐献一词我一开始也一直抱有疑问，是否和我所想的一样，后来证明了这一点。不知道原版的用词带给母语者的感受是怎么样的，如果会让人引起和我相同的想法那或许是作者有意为之。在后面揭露更多真相的时候，作者都是用了类似的做法，先透露出一点似乎不那么令人意外的线索，后来又从对话中传达真相并使读者感到震惊。至于为什么这么写，或许是提前进行漫长的铺垫，使得读者读到这里的时候有更强烈的感受。\n回到书中的内容。凯西、汤米、露丝显然是整个故事中最核心的角色。凯西和汤米对一切进行了思考，而不是一直只有接受。\n露丝则是很明显被用于对比的角色，她的态度更倾向于接受外部的一切，不论是汤米和凯西的看法还是当汤米实际与她讨论可能的真相时她都表现出了如此的特质。但同时露丝也是一个传达许多真相并且推进的角色，当一切都铺垫好以后，也就不再需要这样一个只是接受的角色一起参与探索背后的真相，自然的将故事舞台的主导权完全交给了汤米和凯西。汤米则是推动这一切进展的角色，思考一切背后的真相，去做各种尝试。而”我“，也就是凯西，更像是观察这一切，关联起这一切的角色。不论是和汤米接触，还是和露丝的关系，又或者是直到最后看着这一切。最后提到了“我”记忆中的黑尔舍姆，“我”从未寻找黑尔舍姆，却到处都能发现黑尔舍姆的点点滴滴，到不同的地方，看到不同的东西，找到黑尔舍姆也许是意味着回忆起了曾经的时光。后面还有这样一段话\n\n就像是我对汤米和露丝的回忆。一旦我能够过上比较平静的生活，不论他们把我送到哪间康复中心，黑尔舍姆都会始终跟我在一起，安全的保留在我脑海中，这是任何人都无法拿走的。\n\n在书中一开始的剧情中，艺廊或许是一个令人疑惑的存在，而对艺廊的疑问直到最终才被揭开。在提及艺廊的真相时，不论是汤米的推论还是实际的真相，都谈到了从作品中揭示出人的灵魂，或者说证明他们有灵魂。那么我想可以反过来，换一个非常极端的说法：人若无法创造出什么，那么无法证明这个人有灵魂。或许是缺少内在、无法产生自己的想法、没有自我、无法对外部质疑，不论怎么说都无法被称为人，而是一类什么。\n说到做了，我想再提及之前凯西提出的质疑：“如果我们反正只是为了捐献，然后死去，那么上那些课是为什么？”答案并没有直说，但我想是让学生通过这样的课程，能够在活着的时间内形成自己独特的灵魂，尽管是部分受限的（因为接收到的信息是经过挑选的）。而这个问题，即便对普通人也是一样的，我来换个问法：如果我们生来只是为了活几十年，然后死去，那么做现在这些事情是为什么？这件事情一定没有什么标准答案。首先我认同的是人生无意义的观点，但我认为人灵魂的存在可以选择在离去之前选择填充自己的灵魂并留下些什么，也并非一定要有什么意义，我们不需要满世界去寻找什么意义，这种东西本就不存在于任何地方，也不应当一切用意义来蒙蔽自己的眼睛。\n看到最后的真相我才明白为什么这本书被归结为科幻小说。对于科幻小说的定位我起初也有些费解，认为科幻小说就是各种未来世界、充满了不存在的科技等等，尤其是当我看到最终真相之前，绝大部分的内容完全没有看到科技的痕迹。这本书与我所想的科幻小说相差巨大，尤其是在我没读到最后的时候。但偶然有一天我听到一档播客节目，里面谈到各种各样科幻小说的形式，提及作者石黑一雄的小说相比于科幻更注重于人与人之间的关系，才明白科幻小说还可以这样来写。\n在这些正文后还有译后记，在这部分内容提到一个从我完全没想到的角度提到的细思恐极的事情\n\n当艾米丽小姐坐着轮椅从阴影中出来的时候，读者不禁期望她会有更多的情感流露。她为之奋斗终生的黑尔舍姆事业已经告终，但这两个孩子是她事业的成果，他们的成就值得她自豪。然而她一心都放在要卖掉的柜子上，甚至基本的待客礼仪都欠奉，终究“我们”和“他们”的壁垒如此森严，毕竟她要从轮椅上站起来、恢复健康，多半还要指望从“他们”身上收获的器官。\n\n写到这里我联想到了一个很重要的细节，当真相大白的时候，夫人和艾米丽小姐也都提到其实她们是和外人一样对他们是抱有恐惧的，甚至艾米丽小姐还会对他们感到厌恶。此时艾米丽小姐说“可我下决心不让这种情绪阻止我去做正确的事。我跟这些情绪作战，并且战胜了。”这句话在当时读的时候我没觉得有什么，但现在回头看来，她所说的正确的事情到底是什么，到底是让他们成为人，还是让他们成为捐献者呢？另外此时我才意识到过去夫人对他们的害怕也是真的对他们这些人自身，而不是其他东西感到害怕。许多事情和夫人对他们的害怕一样，在前面只是未提及，有的很晚才给出解释，有的甚至并未直白的给出解释。但当我们无意中发现真相时，又会感受到骇人。这种处处埋藏线索与问题的写法，除了让我们感受强烈，我认为可以有另一种过度的解读，这或许是作者刻意这样做的，是为了让我们去思考问题，而不只是去接受这一切。\n另外译者认为他们不质疑人生，不反抗生来的宿命，关于这一点我有一些想法。他们获得的信息都是经过精挑细选的，因此对他们来说根本没有质疑人生和反抗宿命的概念。对他们来说，能去思考背后的真相以及想要尝试延迟几乎可以说是能做到的极限了。如果是作为反乌托邦小说来讲，和我之前看过的美丽新世界和1984相同，这样的设定下人们都是会被各种方式所影响，几乎不会产生这样的概念，我目前看的不多，但就我看过的几本来说，反乌托邦总是离不开人们被“教育”成接受一切，无法反抗的状态，同时主线也是类似探寻真相与反抗的故事，不知其他同类书籍怀有怎样的观点和故事。\n","categories":["Reading"],"tags":["石黑一雄"]},{"title":"斯通纳","url":"/2023/04/18/Reading/Stoner/","content":"刚开始读到主人公斯通纳在大学时的境遇，那种无法融入，无法理解一些东西的感觉时，我感到非常触动，也许是因为我过去经常有这样的体会吧，这种情况下能感受到的只有无助。想到书腰中有这样一段话：第一眼故事，第二眼经典，第三眼生活，第四眼自己。或许我们都会在书中寻求与自己的关联，不论是找到故事中角色与自己的相似之处，又或是将自己代入到角色中。\n文中讲述了斯通纳的一生，从大学开始，到爱情，事业，直至最后的死亡。他在大学结交了非常好的朋友，不论是精神上，还是实际行为上都对他有所支持。他经历了一见钟情的爱情，也顺势结了婚，但却毫无幸福可言，唯一的幸福也只有饱受非议的婚外情。他在事业上还算成功，兢兢业业工作直至退休。在这些过程中斯通纳的傲骨也是十分明显的，遇到问题不愿低头，一直保有自己的骄傲。我想大部分人读完这本书后，都会对斯通纳留下正直，不寻求权利，不愿低头，遇到什么事情都不愿让步的印象。面对舞弊的行为坚守原则，即便这导致了他频繁受到针对，甚至调离到了偏远的岗位。\n他的人生充满坎坷，无法说是幸福的，但\n\n即使没有完美的一生，所幸追求过完整的自我\n\n不论他的一生经历了多少苦难，出现了多少问题，但他内心的自我，他的本性，他的灵魂仍未变质，这是让人十分欣慰的。\n刚开始读的时候感觉略微不适应，后来发现是因为最初的部分没什么环境描写，对话相对较少，内容更倾向于流水账一样，和前段时间刚读完的《虞美人草》形成了非常明显的对比，这个问题读到后面觉得多少有些缓解。不过用这样篇幅的一本书讲述一个人的一生，同时想要保持细节是完全不可能的，也只能去掉许多描写性质的部分，同时只选取最典型的一些故事。另外不知是翻译问题还是原文就是这样写的，许多地方让我感觉比较粗糙。\n读完整本书后最让我意外的感受是我开始害怕一切。看到斯通纳的经历，我觉得越阅读，越学习，反而越是害怕。害怕对人性的恶看的更透彻，害怕被人的恶所影响，害怕不平和的未来，害怕和一个不合适的人结婚，害怕自己也像书中的故事的痛苦的一面一般，害怕自己极度抑制的充满恶的本性泄漏出去。\n","categories":["Reading"],"tags":["约翰·威廉斯"]},{"title":"mold源码阅读五 符号相关","url":"/2023/04/29/mold/mold-5-symbol/","content":"\npixiv:73005507 \n\n上期讲完了resolve_section_pieces，在这之后本应是combine_object，但是combine_object几乎包含了后面的所有过程，因此等到整个流程讲完后或许会再回来讲，这一期的内容以符号版本的处理为主。\n为common symbol创建bss段// Create .bss sections for common symbols.convert_common_symbols(ctx);\n\ntemplate &lt;typename E&gt;void convert_common_symbols(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;convert_common_symbols&quot;);  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;convert_common_symbols(ctx);  &#125;);&#125;\n\ncommon symbol首先解释一下common symbol。根据mold的注释所讲，common symbols被用于C的tentative definition，tentative definition是指C语言在一个头文件中允许全局变量定义省略extern。header会存在于多个翻译单元中，但这个符号不会导致duplicate symbol error，相反linker会将他们merge到一个单一的实例中。\n还给出了一个例子，比如说一个头文件中有一个tentative definition是int foo，在一个C文件中包含了其包含初始值定义，比如说int foo = 5（real definition），那么这个tentative definition的符号会被resolve到real definition上。如果没有real definition，那么tentative definition会得到默认值。\nAbout Tentative definition\n参考这个stackoverflow的回答，C语言中纯变量声明会被处理为extern的，我想这就是允许省略extern的原因，编译器帮你做了这件事情，尽管这或许与你的预期不符。\n简单总结来说就是头文件中一个全局的声明在不同编译单元有不同定义的时候需要进行resolve一个单一实现，声明的symbol其实是属于多个文件的，因此是common的。\n实现template &lt;typename E&gt;void ObjectFile&lt;E&gt;::convert_common_symbols(Context&lt;E&gt; &amp;ctx) &#123;  if (!has_common_symbol)    return;\n\nhas_common_symbol初始化的地方是在input-files.cc中的void ObjectFile::initialize_symbols\n// initialize_symbolsthis-&gt;symbols[i] = insert_symbol(ctx, esym, key, name);    if (esym.is_common())      has_common_symbol = true;  &#125;&#125;\n\n实际的处理是针对所有global的common符号\nfor (i64 i = this-&gt;first_global; i &lt; this-&gt;elf_syms.size(); i++) &#123;  if (!this-&gt;elf_syms[i].is_common())    continue;  Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[i];  std::scoped_lock lock(sym.mu);  if (sym.file != this) &#123;    if (ctx.arg.warn_common)      Warn(ctx) &lt;&lt; *this &lt;&lt; &quot;: multiple common symbols: &quot; &lt;&lt; sym;    continue;  &#125;...\n\n提示warning\n// in forelf_sections2.push_back(&#123;&#125;);ElfShdr&lt;E&gt; &amp;shdr = elf_sections2.back();memset(&amp;shdr, 0, sizeof(shdr));std::string_view name;if (sym.get_type() == STT_TLS) &#123;  name = &quot;.tls_common&quot;;  shdr.sh_flags = SHF_ALLOC | SHF_WRITE | SHF_TLS;&#125; else &#123;  name = &quot;.common&quot;;  shdr.sh_flags = SHF_ALLOC | SHF_WRITE;&#125;shdr.sh_type = SHT_NOBITS;shdr.sh_size = this-&gt;elf_syms[i].st_size;shdr.sh_addralign = this-&gt;elf_syms[i].st_value;\n\n关于SHF_TLS\n\nSHF_TLS: This section holds Thread-Local Storage, meaning that each separate execution flow has its own distinct instance of this data. Implementations need not support this flag.\n\nhttps://refspecs.linuxbase.org/elf/gabi4+/ch4.sheader.html\n对每个global common符号创建了一个ElfShdr后开始设置其基本信息\ni64 idx = this-&gt;elf_sections.size() + elf_sections2.size() - 1;std::unique_ptr&lt;InputSection&lt;E&gt;&gt; isec =  std::make_unique&lt;InputSection&lt;E&gt;&gt;(ctx, *this, name, idx);sym.file = this;sym.set_input_section(isec.get());sym.value = 0;sym.sym_idx = i;sym.ver_idx = ctx.default_version;sym.is_weak = false;sym.is_imported = false;sym.is_exported = false;sections.push_back(std::move(isec));// for end\n\n创建了一个指向elf_sections的InputSecion，之后添加到sections中。\napply_version_script// Apply version scripts.apply_version_script(ctx);\n\nsimpletemplate &lt;typename E&gt;void apply_version_script(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;apply_version_script&quot;);  // If all patterns are simple (i.e. not containing any meta-  // characters and is not a C++ name), we can simply look up  // symbols.  auto is_simple = [&amp;] &#123;    for (VersionPattern &amp;v : ctx.version_patterns)      if (v.is_cpp || v.pattern.find_first_of(&quot;*?[&quot;) != v.pattern.npos)        return false;    return true;  &#125;;\n\n首先定义了is_simple。\nsimple的定义\n\n非cpp name。VersionPattern是根据链接器参数创建与添加的，is_cpp也同样是在那时指定的。\n不包含meta字符的名字。根据代码中，meta字符即是*[?中的char\n\nif (is_simple()) &#123;    for (VersionPattern &amp;v : ctx.version_patterns) &#123;      Symbol&lt;E&gt; *sym = get_symbol(ctx, v.pattern);      if (!sym-&gt;file &amp;&amp; !ctx.arg.undefined_version)        Warn(ctx) &lt;&lt; v.source &lt;&lt; &quot;: cannot assign version `&quot; &lt;&lt; v.ver_str                  &lt;&lt; &quot;` to symbol `&quot; &lt;&lt; *sym &lt;&lt; &quot;`: symbol not found&quot;;      if (sym-&gt;file &amp;&amp; !sym-&gt;file-&gt;is_dso)        sym-&gt;ver_idx = v.ver_idx;    &#125;    return;  &#125;\n\n如果是simple的那么直接针对所有的version_pattern找到对应的符号，并且将其通过设置ver_idx的方式与VersionPattern进行关联\notherwise// Otherwise, use glob pattern matchers.MultiGlob matcher;MultiGlob cpp_matcher;for (i64 i = 0; i &lt; ctx.version_patterns.size(); i++) &#123;  VersionPattern &amp;v = ctx.version_patterns[i];  if (v.is_cpp) &#123;    if (!cpp_matcher.add(v.pattern, i))      Fatal(ctx) &lt;&lt; &quot;invalid version pattern: &quot; &lt;&lt; v.pattern;  &#125; else &#123;    if (!matcher.add(v.pattern, i))      Fatal(ctx) &lt;&lt; &quot;invalid version pattern: &quot; &lt;&lt; v.pattern;  &#125;&#125;\n\n首先将cpp和其他复杂的符号区分开\ntbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;  for (Symbol&lt;E&gt; *sym : file-&gt;get_global_syms()) &#123;    if (sym-&gt;file != file)      continue;    std::string_view name = sym-&gt;name();    i64 match = INT64_MAX;    if (std::optional&lt;u32&gt; idx = matcher.find(name))      match = std::min&lt;i64&gt;(match, *idx);    // Match non-mangled symbols against the C++ pattern as well.    // Weird, but required to match other linkers&#x27; behavior.    if (!cpp_matcher.empty()) &#123;      if (std::optional&lt;std::string_view&gt; s = cpp_demangle(name))        name = *s;      if (std::optional&lt;u32&gt; idx = cpp_matcher.find(name))        match = std::min&lt;i64&gt;(match, *idx);    &#125;    if (match != INT64_MAX)      sym-&gt;ver_idx = ctx.version_patterns[match].ver_idx;  &#125;&#125;);\n\n在所有obj文件中找到所有global symbol\n如果普通matcher中能找到其名字，那么更新match的index\n如果cpp matcher非空，那么对其进行demangle操作，之后在cpp matcher中寻找其名字并且更新match的index\n最后将符号与对应VersionPattern进行关联。\n而这里的demangle操作是直接调用对应平台的abi。starts_with(”_Z”)是代表这是一个mangling的名字。关于mangling的规则参考\nhttps://github.com/gchatelet/gcc_cpp_mangling_documentation\nstd::optional&lt;std::string_view&gt; cpp_demangle(std::string_view name) &#123;  static thread_local char *buf;  static thread_local size_t buflen;  // TODO(cwasser): Actually demangle Symbols on Windows using e.g.  // `UnDecorateSymbolName` from Dbghelp, maybe even Itanium symbols?#ifndef _WIN32  if (name.starts_with(&quot;_Z&quot;)) &#123;    int status;    char *p = abi::__cxa_demangle(std::string(name).c_str(), buf, &amp;buflen, &amp;status);    if (status == 0) &#123;      buf = p;      return p;    &#125;  &#125;#endif  return &#123;&#125;;&#125;\n\nobj only我在读到这里，很好奇为什么只针对的是obj而不考虑dso，看了下相关的命令行参数的介绍才明白过来\n\n-E, –export-dynamic Put symbols in the dynamic symbol table –no-export-dynamic\n\nparse_symbol_version// Parse symbol version suffixes (e.g. &quot;foo@ver1&quot;).parse_symbol_version(ctx);\n\ntemplate &lt;typename E&gt;void parse_symbol_version(Context&lt;E&gt; &amp;ctx) &#123;  if (!ctx.arg.shared)    return;\n\n这是针对生成shared库的操作，因为只有动态链接才需要考虑加载符号版本的问题，符号版本是为了加载动态库的时候确保更新后符号的实现一致，如果和预想的实现不一致可能引起其他问题。\nstd::unordered_map&lt;std::string_view, u16&gt; verdefs;for (i64 i = 0; i &lt; ctx.arg.version_definitions.size(); i++)  verdefs[ctx.arg.version_definitions[i]] = i + VER_NDX_LAST_RESERVED + 1;\n\n实现中首先是将每一个version信息绑定到一个i + VER_NDX_LAST_RESERVED + 1的值（其中的version_definitions则是在read_version_script中读取的）。\n接下来是针对了所有的global object进行操作。\ntbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (i64 i = 0; i &lt; file-&gt;elf_syms.size() - file-&gt;first_global; i++) &#123;      // Match VERSION part of symbol foo@VERSION with version definitions.      // The symbols&#x27; VERSION parts are in file-&gt;symvers.      if (!file-&gt;symvers[i])        continue;      Symbol&lt;E&gt; *sym = file-&gt;symbols[i + file-&gt;first_global];      if (sym-&gt;file != file)        continue;      std::string_view ver = file-&gt;symvers[i];\t\t\t...  &#125;);\n\n首先找到了对应文件的global符号\nbool is_default = false;if (ver.starts_with(&#x27;@&#x27;)) &#123;  is_default = true;  ver = ver.substr(1);&#125;\n\n获取符号的版本具体的值\nauto it = verdefs.find(ver);if (it == verdefs.end()) &#123;  Error(ctx) &lt;&lt; *file &lt;&lt; &quot;: symbol &quot; &lt;&lt; *sym &lt;&lt;  &quot; has undefined version &quot;             &lt;&lt; ver;  continue;&#125;\n\n根据具体的值查找到上面保存的index\nsym-&gt;ver_idx = it-&gt;second;if (!is_default)  sym-&gt;ver_idx |= VERSYM_HIDDEN;\n\n非default行为的版本，也就是非@开头的版本则ver_idx设置为HIDDEN。关于非default的情况，这种符号version则是在default_symver选项中添加的。\n该选项对应的介绍以及代码实现处\n\nUse soname as a symbol version and append that version to all symbols.\n\nif (ctx.arg.default_symver) &#123;    std::string ver = ctx.arg.soname.empty() ?      filepath(ctx.arg.output).filename().string() : std::string(ctx.arg.soname);    ctx.arg.version_definitions.push_back(ver);    ctx.default_version = VER_NDX_LAST_RESERVED + 1;  &#125;\n\n// If both symbol `foo` and `foo@VERSION` are defined, `foo@VERSION`// hides `foo` so that all references to `foo` are resolved to a// versioned symbol. Likewise, if `foo@VERSION` and `foo@@VERSION` are// defined, the default one takes precedence.Symbol&lt;E&gt; *sym2 = get_symbol(ctx, sym-&gt;name());if (sym2-&gt;file == file &amp;&amp; !file-&gt;symvers[sym2-&gt;sym_idx - file-&gt;first_global])  if (sym2-&gt;ver_idx == ctx.default_version ||      (sym2-&gt;ver_idx &amp; ~VERSYM_HIDDEN) == (sym-&gt;ver_idx &amp; ~VERSYM_HIDDEN))    sym2-&gt;ver_idx = VER_NDX_LOCAL;\n\n最后是一个符号名同时存在带有version和没有version的两种定义，那么带有version信息的则会对外隐藏不带有特殊version信息的实现（设置为local）。通过当前sym的名字在ctx中查找同名符号，之后进行处理操作。\ncompute_import_export// Set is_imported and is_exported bits for each symbol.compute_import_export(ctx);\n\ntemplate &lt;typename E&gt;void compute_import_export(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;compute_import_export&quot;);  // If we are creating an executable, we want to export symbols referenced  // by DSOs unless they are explicitly marked as local by a version script.  if (!ctx.arg.shared) &#123;    tbb::parallel_for_each(ctx.dsos, [&amp;](SharedFile&lt;E&gt; *file) &#123;      for (Symbol&lt;E&gt; *sym : file-&gt;symbols) &#123;        if (sym-&gt;file &amp;&amp; !sym-&gt;file-&gt;is_dso &amp;&amp; sym-&gt;visibility != STV_HIDDEN) &#123;          if (sym-&gt;ver_idx != VER_NDX_LOCAL || !ctx.default_version_from_version_script) &#123;            std::scoped_lock lock(sym-&gt;mu);            sym-&gt;is_exported = true;          &#125;        &#125;      &#125;    &#125;);  &#125;\n\n在不生成shared库的情况下，针对所有的dso进行处理，在创建可执行文件的时候，导出被dso引用的且不被标记为local的符号。\n// Export symbols that are not hidden or marked as local.// We also want to mark imported symbols as such.tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;  for (Symbol&lt;E&gt; *sym : file-&gt;get_global_syms()) &#123;    if (!sym-&gt;file || sym-&gt;visibility == STV_HIDDEN ||        sym-&gt;ver_idx == VER_NDX_LOCAL)      continue;    if (sym-&gt;file != file &amp;&amp; sym-&gt;file-&gt;is_dso &amp;&amp; !sym-&gt;is_absolute()) &#123;      std::scoped_lock lock(sym-&gt;mu);      sym-&gt;is_imported = true;      continue;    &#125;    // If we are creating a DSO, all global symbols are exported by default.    if (sym-&gt;file == file) &#123;      std::scoped_lock lock(sym-&gt;mu);      sym-&gt;is_exported = true;      if (ctx.arg.shared &amp;&amp; sym-&gt;visibility != STV_PROTECTED &amp;&amp;          !ctx.arg.Bsymbolic &amp;&amp;          !(ctx.arg.Bsymbolic_functions &amp;&amp; sym-&gt;get_type() == STT_FUNC))        sym-&gt;is_imported = true;    &#125;  &#125;&#125;);\n\nobjs中找到global符号，对于HIDDEN或者NDX_LOCAL的符号都跳过。\n如果使用一个在dso中的符号，就需要运行时import它，因此需要设置对应符号为imported\n如果创建dso，那么所有的global符号默认都要export。\n总结convert_common_symbols：给所有global的common符号创建一个对应的InputSection段\napply_version_script：将解析命令行参数产生的VersionPatten关联到对应的obj文件中的symbol\nparse_symbol_version：读取symbol version信息，处理对应的ver_idx，以及针对不同版本符号的处理\ncompute_import_export：对所有符号计算对应的import和export信息\n","categories":["Linker"],"tags":["mold"]},{"title":"游植物园","url":"/2023/05/02/Life/china-national-botanical-garden/","content":"到了植物园，最先映入眼帘的不是什么植物，而是人山人海，且颇为吵闹，坏了兴致，不过这也是在预料之中的事情。\n在观光车排队排了很久，在大概还要等两车人的时候前面问有没有独自前来的，正好有一个空位。便因此“合理插队”，提前坐上了观光车。上了观光车后感受到的炎热被迎面而来的微风一扫而光，一直沉浸于风所带来的清凉中，不知不觉车辆就到站了。下了车也不知道附近哪里有花，就开始一边看地图一边乱转了起来。偶尔也看到了一些花，或许是前些天未能承受住风雨的洗礼，都已是风中残烛。\n此时正好已是正午，天气炎热加上并没有看到预期的百花绽放，便开始失去了继续游玩的兴趣。不过这里本身并不是花园而是植物园，只为花而来，也颇为奇怪。并不是为了欣赏什么植物，认识什么植物，而是单纯为了出来走走，或者是为了看花而来，从这样的角度来说或许对植物园是一种大不敬。\n总之走的很累了，找到一处树荫下的凳子坐下。听着旁边风吹树叶窸窸窣窣的声音，想着多久没有听到过这样的声音了呢？每天都在办公室，在家里，听着电子音乐，听着人声，和大自然距离实在太远了。没多久又听到了聒噪的鸟叫声，听到这阵声音想到的不是美好的大自然，反而是今天早上五点醒来的时候被鸟叫吵到睡不着的痛苦。\n恢复一些精力后继续逛了下去，走到了郁金香区，看到了成片的郁金香总算觉得不枉此行。由于这边花开的状态比较好，人还是比较多的，到了郁金香区的高台，到处都是拍照的人，等了很久才勉强有一个适合拍照的位置。由于今天的着装比较特别，机会难得因此想用相机自拍纪念下，虽然最后也成功拍到了，但是拍的过程中总是会有旁边在拍花的人上镜，加上没什么自拍经验，拍了非常多次才拍到还算能看的照片。\n\n之后又沿路拍了一些还算好看的花，决定要走了，发现温室还没去，于是匆匆赶往那边。一进热带植物区和热带雨林区感受到的只有炎热，相比之下，中午在室外的炎热已经算不上什么了。顾不上耐心拍照，只有拍几张感兴趣的然后匆匆出去，最后全身已被汗水湿透。\n\n最后出了植物园大门的时候，由于水喝的比较少，嘴里已经开始渗出了苦味。今天没有装东西的兜，手里拿着相机和手机，还夹着伞，实在不方便拿水喝，尽管一直比较渴，但就喝了带的一小瓶水。看西郊线人比较多，因此约了滴滴。在等滴滴的路上看到门口有一个人因为孩子差点被人贩子直接拉走，好像还控制住对方一会，同时在喊警察，但警察一直没来。我看到的时候他已经带着孩子去找周围警察了，很生气，责备警察无用，也能理解他的愤怒，另外又觉得这些人真的是胆大妄为。之后车来了，我已经比较疲惫，也无心做些什么，就只是任由风将我的头发吹飞，看着窗外的风景，看着一片片绿色的树林，不加以任何思考与判断，只是这样看着过去的事物。\n","categories":["Life"],"tags":["植物园"]},{"title":"艾尔登法环","url":"/2023/05/03/elden-ring/","content":"二月底前入手了PS5以及艾尔登法环，打了一个月总算白金了，现在随便讲讲自己的感受。以下内容基本上避免了剧透，可安心食用。\n首先作为宫崎英高老贼的作品，受苦是大家最深刻的印象，不过这作在难度上确实降低了不少。首先是遍地都是的传送点，不再像魂系列一样跑路跑半天才能找到一个传送点，再加上玛丽卡楔石的帮助，几乎不需要花费太多的时间在打boss的路上。\n招魂机制可以通过骨灰召唤角色出来吸引仇恨，你可以安心输出，当然魂系列其他作品也是有召唤npc的机制存在，但是都远不如这作骨灰的强大，后期召唤大哥甚至可以单挑许多boss，玩家被称为摇铃仆人。其次由于开放世界的设计，你可以绕过绝大多数boss，同时可以提前跑到中后期的地区捡垃圾，把自己的装备和等级提升一下再回来砍boss。\n不过说到这里就要提到宫崎英高的恶意了，开局的大树守卫估计是很多人的阴影，可能很多人也没想到可以直接绕过，不过我想这里的设计是为了让玩家理解后面遇到的许多boss是可以直接跑的。另外有的玩家会选择直接到史东威尔去打恶兆，恶兆对于低级入门玩家还是不太友好，我觉得这里也有让你再去其他区域多探索的一个想法，只是这些设计都比较隐晦。\n不熟悉的玩家个人开荒还是有些费劲的，我一开始也吃了很多瘪，后来“学习”了一下装备选择以及跑路捡强化石，以及去龙墓升级，也慢慢开始舒服多了。从数值方面降低了受苦的要素，之后作为一个探索类游戏真的非常棒，地图是真的大，而且景色非常棒。尤其是当你一开始走出了漆黑的新手洞窟后，当你通过升降梯到达了王城后，看到的那美丽的景色。\n整体来说还是有许多有特色的boss。恶兆王给我的印象是比较深刻的，除了早期受苦的原因，另外独特的配音，在整个故事中其所在的位置，整个角色的塑造，以及经典的怒斥众臣等让这个角色深深的引入了我的脑海。\n除了boss，许多精英怪也让大家印象深刻，比如说虾薪王，熊薪王，王室幽魂等，虽然受苦，但是也给网上的视频创作添加了许多素材，通过这种方式也给玩家们带来了很多欢乐，虽然这点或许并不在设计的初衷内。\n这一作内容非常多，最首先感受到这一点的地方是地图。当我第一次打开地图，心想地图就这吗？但是随着后来我收集了一块又一块的地图碎片，整个地图也逐渐显现出了它原本的样子，这个过程中逐渐意识到原来一开始所能看到的部分只是整个交界地的冰山一角。\n这一作的细节也非常非常多，游戏内容远超以往的魂系列，我一周目认真收集花了一百个小时才结束，但依然漏了许多东西。尽管不可避免的有一些偏向重复的要素，或者有一些玩家觉得很应付的要素，比如说一个后期的精英怪作为前中期区域的一些小boss，但是瑕不掩瑜。\n泥头车的设计者你这样搞晚上睡得着觉吗？！\n同时法环继承了魂系列一如既往的叙事，尽管拥有非常庞大的故事背景，但将故事隐藏在各种支线，以及各种道具的说明之中，给足了玩家们发掘、思考和想象的空间。\n总体来说《艾尔登法环》是当之无愧的2022年度最佳游戏。\n","categories":["Game"],"tags":["魂系列"]},{"title":"局外人","url":"/2023/05/03/Reading/thr-outsider-by-albert-camus/","content":"对我来说读了这本书后最先能感受到的是默尔索的那种觉得许多事情都无所谓的心态，仿佛发生一切事情都与自己无关，对于母亲的去世没有什么特别的感受，第二天也该做什么做什么。我对于许多大多数人所认为很有必要的事情，或者大多数的日常都是抱有同样的态度，所以有些感同身受。加缪想要通过这种态度来传达给我们什么呢？是想表达出他所认为的人生无意义吗？\n在序言中讲到局外人的直接含义是默尔索在审判过程被隔离在外，整个审判过程自己参与了但是又没有参与。想到了故事中律师说到了这样一句话：“这就是这场审讯的形象，所有一切都是真的，但又没有任何东西是真的！”网上一个评价的重点则是提到是因为对母亲的死无动于衷被判了死刑，这点过于荒谬。\n在第一部分中出现了许多的角色，都有一些非常看似矛盾的行为：沙拉玛诺老头每天都在骂狗，但实际丢了又是那么牵挂。雷蒙虽然说这跟人打架自己没去惹对方，是对方来冒犯自己，但他却供养着对方的老婆，作者这里还添加了一句“我没有答言。”\n\n他对我说，他一直供养着这个女人。我没有答言。接着他又说，他知道附近一带关于他的流言飞语，但他问心无愧，他确实是一个仓库保管员。\n\n这个样子甚至还能问心无愧，我觉得实属荒谬。还有第二部中最后出现的神父，他不顾主角的心情和想法，只是想要将自己的想法强加，这可以说是他自大，但是最让人感到惊讶与荒谬的是他居然也是囚犯，身为神父还做出犯罪之举。\n我感觉到默尔索与现实世界的分离，联想到文章后面的内容并且结合加缪的思想来看，也许是因为他觉得现实世界是无理的且不可掌控的。\n\n他的神气不是那么确信有把握吗？但他的确信不值女人的一根头发，他甚至连自己是否活着都没有把握，因为他干脆就像行尸走肉。而我，我好像是两手空空，一无所有，但我对自己很有把握，对我所有的一切都有把握，比他有把握得多，对我的生命，对我即将来到的死亡，都有把握。是的，我只有这份把握，但至少我掌握了这个真理，正如这个真理抓住了我一样。我以前有理，现在有理，将来永远有理。\n\n后面他对即将到来的死亡是有把握的，这种分离在后面也有谈及\n\n正当我的律师在继续发言时，一个卖冰的小贩吹响了喇叭，声音从街上穿过一个个大厅与法庭，传到了我耳边，对过去生活的种种回忆突然涌入我的脑海，那生活已经不属于我了。\n\n回到书名与故事中。局外人这个名字所象征的事情，在故事中的主角身上充分表现了出来。主角在许多发生的事情上像局外人一样存在，而他在这个世界像一个局外人一样存在。两章的内容中，第一章中默尔索那漠不关心的态度，像是在说默尔索自己主动选择作为一切的局外人，而第二章中则是处于审判中，虽然参与其中，但是整个过程并没有任何说话与行动的权利。\n\n我呢，我认为这仍然是把我这个人排斥出审判过程，把我化成一个零，又以某种方式，由他取代了我。\n\n我想加缪正是想要通过这样一则有些不讲理的故事来表达出他对这个世界的看法，他所认为的荒谬，在序言中译者也提到了\n\n人类对理性、和谐、永恒的渴求与向往和自然社会生存有限性之间的“断裂”，人类的奋斗作为与徒劳无功这一后果之间的断裂。\n\n这样一则不讲理的故事，正是这种看法的体现。\n","categories":["Reading"],"tags":["加缪"]},{"title":"”荒原狼训练者的奇迹“","url":"/2023/05/04/Reading/def-steppenwolr/","content":"当我开始阅读这本书，不出意外被哈里，被荒原狼，被这本书，被作者扼住了灵魂。作者与译者的描写，作者对哈里·荒原狼的刻画，哈里对那无聊人生的态度，我喜欢这种夹杂着内心深处嘶吼的疯狂。正文的副标题为：专为狂人而作，而书中所刻画出来的一切都被狂人的人格碎片所填满，哈里的自我压抑，荒原狼双重人格的痛苦，而这一切碎片，又唤醒了我疯狂的那一面。\n哈里的个性使得他成为了一个非市民般的存在，但为了生存，依然住在市民所在的城市，银行里有着一定的财产，这些都约束住了他。而在市民之中，他那强烈的个性使得他与这个社会格格不入，无法被理解，亦无法被接受。\n他既超脱于人，却又受限于人，对于他来说内心中人和狼的关系似乎也是如此矛盾，与他的身份不同，人和狼必须要有一方战胜另一方并且存在，为此他的内心中几乎每天都在上演一场人狼大战。但这场战争不可能有他想要的结果，除非他选择自我了断，使得这场战争成立的条件本身不复存在。\n但他过去却一直未能注意到，即便不这样做，这场战争仍可以不复存在，而且本身其实是无意义的。因为人和狼的战争并非是为了争夺什么领土，它们本来是在这里和平相处，但受到了作为主观意识的哈里影响，所以他们认为必须要战胜对方，统一这个世界。除此之外哈里还未注意到的一个真相是这里除了人和狼之外，这里还有非常多种类的存在。\n直到另一个“自己”，赫尔米娜的出现，这一切才开始发生改变。身为另一个哈里，她十分理解哈里所想，同时哈里带入崭新的世界，将他所忽视的、遗漏的东西再度展现在他的面前，哈里也因此开始看到自己内心中更多的角色。\n这一切最终都在魔剧院中由哈里亲眼见证。当哈里暂时杀死了荒原狼的存在，哈里内心中的其他存在不再受到其抑制，因此它们全部从镜子中跳了出来，而哈里跟着内心中的无数个“我“前往了它们各自所在的区域，看到这些被遗忘、忽略了的自己。直到最后，哈里如另一个“自己”所想，亲手处决了另一个“自己”，并且迎来了自我的绞刑。\n","categories":["Reading"],"tags":["黑塞"]},{"title":"mold源码阅读六 section size优化","url":"/2023/05/07/mold/mold-6-section-size-reduce/","content":"\npixiv:101015341 p2 \n\n上一期我们讲解了一些符号相关的处理，这一期我们来讲一些对于section size的优化处理。\nmark_addrsig// Read address-significant section information.if (ctx.arg.icf &amp;&amp; !ctx.arg.icf_all)  mark_addrsig(ctx);template &lt;typename E&gt;void mark_addrsig(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;mark_addrsig&quot;);  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;mark_addrsig(ctx);  &#125;);&#125;\n\n相关的命令行参数\n\n-icf=[all,safe,none] Fold identical code–no-icf\n\n针对所有的obj处理，因为dso的地址相关信息是在运行时加载进行处理\ntemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::mark_addrsig(Context&lt;E&gt; &amp;ctx) &#123;  // Parse a .llvm_addrsig section.  if (llvm_addrsig) &#123;    u8 *cur = (u8 *)llvm_addrsig-&gt;contents.data();    u8 *end = cur + llvm_addrsig-&gt;contents.size();    while (cur != end) &#123;      Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[read_uleb(cur)];      if (sym.file == this)        if (InputSection&lt;E&gt; *isec = sym.get_input_section())          isec-&gt;address_significant = true;    &#125;  &#125;  // We treat a symbol&#x27;s address as significant if  //  // 1. we have no address significance information for the symbol, or  // 2. the symbol can be referenced from the outside in an address-  //    significant manner.  for (Symbol&lt;E&gt; *sym : this-&gt;symbols)    if (sym-&gt;file == this)      if (InputSection&lt;E&gt; *isec = sym-&gt;get_input_section())        if (!llvm_addrsig || sym-&gt;is_exported)          isec-&gt;address_significant = true;&#125;\n\n关于llvm_addrsig，处理的是一个范围的Symbol，将这个范围的Symbol的address_significant设置为True\n// in ObjectFile&lt;E&gt;::initialize_sectionsstd::unique_ptr&lt;InputSection&lt;E&gt;&gt; llvm_addrsig;// Save .llvm_addrsig for --icf=safe.if (shdr.sh_type == SHT_LLVM_ADDRSIG &amp;&amp; !ctx.arg.relocatable) &#123;  llvm_addrsig = std::make_unique&lt;InputSection&lt;E&gt;&gt;(ctx, *this, name, i);  continue;&#125;\n\n普通的symbol address，针对非llvm_addrsig或者exported的symbol将address_significant为True\n那么address_significant是什么呢\nhttps://llvm.org/docs/Extensions.html#sht-llvm-addrsig-section-address-significance-table\n\nthe address of the symbol is used in a comparison or leaks outside the translation unit\n\n简单来说就是这个地址会被用于比较或者用于翻译单元之外，这个变量的具体含义到后面使用的时候会结合场景进一步讲述。\ngc_sections// Garbage-collect unreachable sections.if (ctx.arg.gc_sections)  gc_sections(ctx);template &lt;typename E&gt;void gc_sections(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;gc&quot;);  mark_nonalloc_fragments(ctx);  tbb::concurrent_vector&lt;InputSection&lt;E&gt; *&gt; rootset;  collect_root_set(ctx, rootset);  mark(ctx, rootset);  sweep(ctx);&#125;\n\ngc_sections主要是对section像GC一样进行mark and sweep，清理掉未被使用的段，关于gc_sections的选项\n\n–gc-sections               Remove unreferenced sections\n\nmark_nonalloc_fragments// Non-alloc section fragments are not subject of garbage collection.// This function marks such fragments.template &lt;typename E&gt;static void mark_nonalloc_fragments(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;mark_nonalloc_fragments&quot;);  tbb::parallel_for_each(ctx.objs, [](ObjectFile&lt;E&gt; *file) &#123;    for (std::unique_ptr&lt;MergeableSection&lt;E&gt;&gt; &amp;m : file-&gt;mergeable_sections)      if (m)        for (SectionFragment&lt;E&gt; *frag : m-&gt;fragments)          if (!(frag-&gt;output_section.shdr.sh_flags &amp; SHF_ALLOC))            frag-&gt;is_alive.store(true, std::memory_order_relaxed);  &#125;);&#125;\n\nNon-alloc的fragment不是垃圾回收的对象，因此这里只是标记，避免后续被sweep\ncollect_root_settemplate &lt;typename E&gt;static void collect_root_set(Context&lt;E&gt; &amp;ctx,                             tbb::concurrent_vector&lt;InputSection&lt;E&gt; *&gt; &amp;rootset) &#123;  Timer t(ctx, &quot;collect_root_set&quot;);  auto enqueue_section = [&amp;](InputSection&lt;E&gt; *isec) &#123;    if (mark_section(isec))      rootset.push_back(isec);  &#125;;  auto enqueue_symbol = [&amp;](Symbol&lt;E&gt; *sym) &#123;    if (sym) &#123;      if (SectionFragment&lt;E&gt; *frag = sym-&gt;get_frag())        frag-&gt;is_alive.store(true, std::memory_order_relaxed);      else        enqueue_section(sym-&gt;get_input_section());    &#125;  &#125;;  // Add sections that are not subject to garbage collection.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : file-&gt;sections) &#123;      if (!isec || !isec-&gt;is_alive)        continue;      // -gc-sections discards only SHF_ALLOC sections. If you want to      // reduce the amount of non-memory-mapped segments, you should      // use `strip` command, compile without debug info or use      // -strip-all linker option.      u32 flags = isec-&gt;shdr().sh_flags;      if (!(flags &amp; SHF_ALLOC))        isec-&gt;is_visited = true;      if (should_keep(*isec))        enqueue_section(isec.get());    &#125;  &#125;);  // Add sections containing exported symbols  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (Symbol&lt;E&gt; *sym : file-&gt;symbols)      if (sym-&gt;file == file &amp;&amp; sym-&gt;is_exported)        enqueue_symbol(sym);  &#125;);  // Add sections referenced by root symbols.  enqueue_symbol(get_symbol(ctx, ctx.arg.entry));  for (std::string_view name : ctx.arg.undefined)    enqueue_symbol(get_symbol(ctx, name));  for (std::string_view name : ctx.arg.require_defined)    enqueue_symbol(get_symbol(ctx, name));  // .eh_frame consists of variable-length records called CIE and FDE  // records, and they are a unit of inclusion or exclusion.  // We just keep all CIEs and everything that are referenced by them.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (CieRecord&lt;E&gt; &amp;cie : file-&gt;cies)      for (const ElfRel&lt;E&gt; &amp;rel : cie.get_rels())        enqueue_symbol(file-&gt;symbols[rel.r_sym]);  &#125;);&#125;\n\n这里主要是进行收集root，以便之后进行mark and sweep。\n主要收集的方向有两个\n\n对section直接添加，这里主要是针对一些不受垃圾回收影响的段。具体条件参考should_keep的实现。\n\n针对符号进行处理，如果是在fragment中则会设置其为alive，因为fragment并非扫描的root。如果是在普通的段中则将符号引用的section添加到root中。\n而符号的来源分为这么几种\n\nis_exported\nundefined\nrequire_defined\ncie中的rel符号\n\n\n\ntemplate &lt;typename E&gt;static bool should_keep(const InputSection&lt;E&gt; &amp;isec) &#123;  u32 type = isec.shdr().sh_type;  u32 flags = isec.shdr().sh_flags;  std::string_view name = isec.name();  return (flags &amp; SHF_GNU_RETAIN) ||         type == SHT_NOTE ||         type == SHT_INIT_ARRAY ||         type == SHT_FINI_ARRAY ||         type == SHT_PREINIT_ARRAY ||         (std::is_same_v&lt;E, ARM32&gt; &amp;&amp; type == SHT_ARM_EXIDX) ||         name.starts_with(&quot;.ctors&quot;) ||         name.starts_with(&quot;.dtors&quot;) ||         name.starts_with(&quot;.init&quot;) ||         name.starts_with(&quot;.fini&quot;) ||         is_c_identifier(name);&#125;\n\nmark// Mark all reachable sectionstemplate &lt;typename E&gt;static void mark(Context&lt;E&gt; &amp;ctx,                 tbb::concurrent_vector&lt;InputSection&lt;E&gt; *&gt; &amp;rootset) &#123;  Timer t(ctx, &quot;mark&quot;);  tbb::parallel_for_each(rootset, [&amp;](InputSection&lt;E&gt; *isec,                                    tbb::feeder&lt;InputSection&lt;E&gt; *&gt; &amp;feeder) &#123;    visit(ctx, isec, feeder, 0);  &#125;);&#125;\n\ntemplate &lt;typename E&gt;static void visit(Context&lt;E&gt; &amp;ctx, InputSection&lt;E&gt; *isec,                  tbb::feeder&lt;InputSection&lt;E&gt; *&gt; &amp;feeder, i64 depth) &#123;  assert(isec-&gt;is_visited);  // If this is a text section, .eh_frame may contain records  // describing how to handle exceptions for that function.  // We want to keep associated .eh_frame records.  for (FdeRecord&lt;E&gt; &amp;fde : isec-&gt;get_fdes())    for (const ElfRel&lt;E&gt; &amp;rel : fde.get_rels(isec-&gt;file).subspan(1))      if (Symbol&lt;E&gt; *sym = isec-&gt;file.symbols[rel.r_sym])        if (mark_section(sym-&gt;get_input_section()))          feeder.add(sym-&gt;get_input_section());  for (const ElfRel&lt;E&gt; &amp;rel : isec-&gt;get_rels(ctx)) &#123;    Symbol&lt;E&gt; &amp;sym = *isec-&gt;file.symbols[rel.r_sym];    // Symbol can refer either a section fragment or an input section.    // Mark a fragment as alive.    if (SectionFragment&lt;E&gt; *frag = sym.get_frag()) &#123;      frag-&gt;is_alive.store(true, std::memory_order_relaxed);      continue;    &#125;    if (!mark_section(sym.get_input_section()))      continue;    // Mark a section alive. For better performacne, we don&#x27;t call    // `feeder.add` too often.    if (depth &lt; 3)      visit(ctx, sym.get_input_section(), feeder, depth + 1);    else      feeder.add(sym.get_input_section());  &#125;&#125;\n\n从rootset出发\n\n针对fde record中的rel符号所在的section进行标记，并且添加到feeder中（本质是加到了rootset中，后续会继续从这些节点开始遍历）\n针对rel段中的符号进行遍历，如果是fragment则设置其alive，之后对sym的input section进行标记，标记成功的话则继续递归执行。\n\nsweep// Remove unreachable sectionstemplate &lt;typename E&gt;static void sweep(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;sweep&quot;);  static Counter counter(&quot;garbage_sections&quot;);  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : file-&gt;sections) &#123;      if (isec &amp;&amp; isec-&gt;is_alive &amp;&amp; !isec-&gt;is_visited) &#123;        if (ctx.arg.print_gc_sections)          SyncOut(ctx) &lt;&lt; &quot;removing unused section &quot; &lt;&lt; *isec;        isec-&gt;kill();        counter++;      &#125;    &#125;  &#125;);&#125;\n\ntemplate &lt;typename E&gt;inline void InputSection&lt;E&gt;::kill() &#123;  if (is_alive.exchange(false))    for (FdeRecord&lt;E&gt; &amp;fde : get_fdes())      fde.is_alive = false;&#125;\n\n在ehframe那一期提到会清理未用到的record，而在这里实际执行了fde的清理工作。\nicf_sections这段内容比较长，建议单独查看源码对应位置进行对照，相关实现在elf/icf.cc中\nicf的全拼推测是identical code folding\n// Merge identical read-only sections.if (ctx.arg.icf)\ticf_sections(ctx);\n\ntemplate &lt;typename E&gt;void icf_sections(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;icf&quot;);  if (ctx.objs.empty())    return;  uniquify_cies(ctx);  merge_leaf_nodes(ctx);\t...&#125;\n\nuniquify_ciestemplate &lt;typename E&gt;static void uniquify_cies(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;uniquify_cies&quot;);  std::vector&lt;CieRecord&lt;E&gt; *&gt; cies;  for (ObjectFile&lt;E&gt; *file : ctx.objs) &#123;    for (CieRecord&lt;E&gt; &amp;cie : file-&gt;cies) &#123;      for (i64 i = 0; i &lt; cies.size(); i++) &#123;        if (cie.equals(*cies[i])) &#123;          cie.icf_idx = i;          goto found;        &#125;      &#125;      cie.icf_idx = cies.size();      cies.push_back(&amp;cie);    found:;    &#125;  &#125;&#125;\n\n针对所有obj中的所有cie，如果cie和cies中的任何一个相同，也就是出现了重复，则继续查看下一个cie是否重复，没有重复则将cie加进去。\n这里我不太明白，为什么不保存一个CieRecord的Set，避免了再写一个循环的麻烦？如果有读者能解答我的疑惑欢迎邮件联系我。\nmerge_leaf_nodes// Early merge of leaf nodes, which can be processed without constructing the// entire graph. This reduces the vertex count and improves memory efficiency.template &lt;typename E&gt;static void merge_leaf_nodes(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;merge_leaf_nodes&quot;);  static Counter eligible(&quot;icf_eligibles&quot;);  static Counter non_eligible(&quot;icf_non_eligibles&quot;);  static Counter leaf(&quot;icf_leaf_nodes&quot;);  tbb::concurrent_unordered_map&lt;InputSection&lt;E&gt; *, InputSection&lt;E&gt; *,                                LeafHasher&lt;E&gt;, LeafEq&lt;E&gt;&gt; map;  tbb::parallel_for((i64)0, (i64)ctx.objs.size(), [&amp;](i64 i) &#123;    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : ctx.objs[i]-&gt;sections) &#123;      if (!isec || !isec-&gt;is_alive)        continue;      if (!is_eligible(ctx, *isec)) &#123;        non_eligible++;        continue;      &#125;      if (is_leaf(ctx, *isec)) &#123;        leaf++;        isec-&gt;icf_leaf = true;        auto [it, inserted] = map.insert(&#123;isec.get(), isec.get()&#125;);        if (!inserted &amp;&amp; isec-&gt;get_priority() &lt; it-&gt;second-&gt;get_priority())          it-&gt;second = isec.get();      &#125; else &#123;        eligible++;        isec-&gt;icf_eligible = true;      &#125;    &#125;  &#125;);  tbb::parallel_for((i64)0, (i64)ctx.objs.size(), [&amp;](i64 i) &#123;    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : ctx.objs[i]-&gt;sections) &#123;      if (isec &amp;&amp; isec-&gt;is_alive &amp;&amp; isec-&gt;icf_leaf) &#123;        auto it = map.find(isec.get());        assert(it != map.end());        isec-&gt;leader = it-&gt;second;      &#125;    &#125;  &#125;);&#125;\n\n针对所有obj中eligible的sections来处理。\n是leaf则设置leaf并且插入到map中，但是如果insert失败，且priority更高，那么就更新对应的section\n非leaf的情况下只设置eligible，留到后面进行处理。\n之后针对所有obj的sections，如果是icf_leaf，那么更新其leader为map中对应的值\n关于其中出现的InputSection的字段// in InputSection// For ICF//// `leader` is the section that this section has been merged with.// Three kind of values are possible:// - `leader == nullptr`: This section was not eligible for ICF.// - `leader == this`: This section was retained.// - `leader != this`: This section was merged with another identical section.InputSection&lt;E&gt; *leader = nullptr;u32 icf_idx = -1;bool icf_eligible = false;bool icf_leaf = false;\n\n简单来说这个leader实际上是用于指向当前section的一个唯一实现。\n如果leader存在且为自己，那么对应内容的段只访问过一次，如果不为自己的话，那么代表这不是第一次访问对应内容的段了。\n用实际实现结合注释来说明leader这个字段。\n\n==nullptr：这种情况表明这个section是not eligible的，也就是说会在上面的循环被忽略掉\n==this：这种情况表明这个section是对应内容的段第一次出现，在后面更新leader的过程中是找到的section和自身相同。\n≠this：这种情况表明后面更新leader的查找过程中，找到的section其实是其对应内容在前面第一次出现的段，也就是指向了对应的leader\n\n举个例子，假设有s1, s2, s3三个section，s1是not eligible的，s2和s3是相同的，按照s1-s3的顺序进行扫描\ns1 = nullptr\ns2 = s2 # leader\ns3 = s2\nis_eligibletemplate &lt;typename E&gt;static bool is_eligible(Context&lt;E&gt; &amp;ctx, InputSection&lt;E&gt; &amp;isec) &#123;  const ElfShdr&lt;E&gt; &amp;shdr = isec.shdr();  std::string_view name = isec.name();  bool is_alloc = (shdr.sh_flags &amp; SHF_ALLOC);  bool is_exec = (shdr.sh_flags &amp; SHF_EXECINSTR) ||                 ctx.arg.ignore_data_address_equality;  bool is_relro = (name == &quot;.data.rel.ro&quot; ||                   name.starts_with(&quot;.data.rel.ro.&quot;));  bool is_readonly = !(shdr.sh_flags &amp; SHF_WRITE) || is_relro;  bool is_bss = (shdr.sh_type == SHT_NOBITS);  bool is_empty = (shdr.sh_size == 0);  bool is_init = (shdr.sh_type == SHT_INIT_ARRAY || name == &quot;.init&quot;);  bool is_fini = (shdr.sh_type == SHT_FINI_ARRAY || name == &quot;.fini&quot;);  bool is_enumerable = is_c_identifier(name);  bool is_addr_taken = !ctx.arg.icf_all &amp;&amp; isec.address_significant;  return is_alloc &amp;&amp; is_exec &amp;&amp; is_readonly &amp;&amp; !is_bss &amp;&amp; !is_empty &amp;&amp;         !is_init &amp;&amp; !is_fini &amp;&amp; !is_enumerable &amp;&amp; !is_addr_taken;&#125;\n\n如果不满足这些情况的话无法被fold，具体条件以及判断方式无需再多讲解，纯粹是对应的规则。\n注意这里出现了上面说的address_significant，需要为false才能满足，也就是说需要用地址比较的情况是无法被fold的。\ngather_sections// Prepare for the propagation rounds.std::vector&lt;InputSection&lt;E&gt; *&gt; sections = gather_sections(ctx);\n\ntemplate &lt;typename E&gt;static std::vector&lt;InputSection&lt;E&gt; *&gt; gather_sections(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;gather_sections&quot;);  // Count the number of input sections for each input file.  std::vector&lt;i64&gt; num_sections(ctx.objs.size());  tbb::parallel_for((i64)0, (i64)ctx.objs.size(), [&amp;](i64 i) &#123;    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : ctx.objs[i]-&gt;sections)      if (isec &amp;&amp; isec-&gt;is_alive &amp;&amp; isec-&gt;icf_eligible)        num_sections[i]++;  &#125;);  std::vector&lt;i64&gt; section_indices(ctx.objs.size());  for (i64 i = 0; i &lt; ctx.objs.size() - 1; i++)    section_indices[i + 1] = section_indices[i] + num_sections[i];  std::vector&lt;InputSection&lt;E&gt; *&gt; sections(    section_indices.back() + num_sections.back());  // Fill `sections` contents.  tbb::parallel_for((i64)0, (i64)ctx.objs.size(), [&amp;](i64 i) &#123;    i64 idx = section_indices[i];    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : ctx.objs[i]-&gt;sections)      if (isec &amp;&amp; isec-&gt;is_alive &amp;&amp; isec-&gt;icf_eligible)        sections[idx++] = isec.get();  &#125;);  tbb::parallel_for((i64)0, (i64)sections.size(), [&amp;](i64 i) &#123;    sections[i]-&gt;icf_idx = i;  &#125;);  return sections;&#125;\n\n这里出现了三个vector，先来理清对应的作用\n\nnum_sections：每个obj中icf_eligible的input sections数量\nsection_indices：由前一个section_indices和num_sections的值决定，其实是用于标记每个位置的objs的input section的起始在最终的sections中的坐标\nsections：初始化的容量是其实是section_indices[ctx.objs.size()]的值\n\n这样说可能比较抽象，举个例子\nnum_sections: 2, 3, 4, 5\nsection_indices: 0, 2+0, 3+2+0, 4+3+2+0\n5+4+3+2+0\n算出来的其实是所有obj中icf_eligible的input sections的数量\n之后是fill content的部分，并行的获取每个obj中的所有icf_eligible的input section的指针\nDigest接下来的部分都是在计算digest，具体算法有兴趣的可以去实现中自行查看细节。\n什么是digest，这个链接中的一个回答说的比较明白了，我选取了关键内容放出来\nhttps://crypto.stackexchange.com/questions/51243/what-is-the-difference-between-a-digest-and-a-hash-function\n\nThe digest is the output of the hash function.For example, sha256 has a digest of 256 bits, i.e. its digest has a length of 32 bytes.\n\ntypedef std::array&lt;uint8_t, HASH_SIZE&gt; Digest;...// We allocate 3 arrays to store hashes for each vertex.//// Index 0 and 1 are used for tree hashes from the previous// iteration and the current iteration. They switch roles every// iteration. See `slot` below.//// Index 2 stores the initial, single-vertex hash. This is combined// with hashes from the connected vertices to form the tree hash// described above.std::vector&lt;std::vector&lt;Digest&gt;&gt; digests(3);digests[0] = compute_digests&lt;E&gt;(ctx, sections);digests[1].resize(digests[0].size());digests[2] = digests[0];std::vector&lt;u32&gt; edges;std::vector&lt;u32&gt; edge_indices;gather_edges&lt;E&gt;(ctx, sections, edges, edge_indices);BitVector converged(digests[0].size());bool slot = 0;\n\n// Execute the propagation rounds until convergence is obtained.&#123;  Timer t(ctx, &quot;propagate&quot;);  tbb::affinity_partitioner ap;  // A cheap test that the graph hasn&#x27;t converged yet.  // The loop after this one uses a strict condition, but it&#x27;s expensive  // as it requires sorting the entire hash collection.  //  // For nodes that have a cycle in downstream (i.e. recursive  // functions and functions that calls recursive functions) will always  // change with the iterations. Nodes that doesn&#x27;t (i.e. non-recursive  // functions) will stop changing as soon as the propagation depth reaches  // the call tree depth.  // Here, we test whether we have reached sufficient depth for the latter,  // which is a necessary (but not sufficient) condition for convergence.  i64 num_changed = -1;  for (;;) &#123;    i64 n = propagate&lt;E&gt;(digests, edges, edge_indices, slot, converged, ap);    if (n == num_changed)      break;    num_changed = n;  &#125;\t// Run the pass until the unique number of hashes stop increasing, at which  // point we have achieved convergence (proof omitted for brevity).  i64 num_classes = -1;  for (;;) &#123;    // count_num_classes requires sorting which is O(n log n), so do a little    // more work beforehand to amortize that log factor.    for (i64 i = 0; i &lt; 10; i++)      propagate&lt;E&gt;(digests, edges, edge_indices, slot, converged, ap);    i64 n = count_num_classes&lt;E&gt;(digests[slot], ap);    if (n == num_classes)      break;    num_classes = n;  &#125;&#125;\n\ngroup sections// Group sections by SHA digest.&#123;  Timer t(ctx, &quot;group&quot;);  auto *map = new tbb::concurrent_unordered_map&lt;Digest, InputSection&lt;E&gt; *&gt;;  std::span&lt;Digest&gt; digest = digests[slot];  tbb::parallel_for((i64)0, (i64)sections.size(), [&amp;](i64 i) &#123;    InputSection&lt;E&gt; *isec = sections[i];    auto [it, inserted] = map-&gt;insert(&#123;digest[i], isec&#125;);    if (!inserted &amp;&amp; isec-&gt;get_priority() &lt; it-&gt;second-&gt;get_priority())      it-&gt;second = isec;  &#125;);  tbb::parallel_for((i64)0, (i64)sections.size(), [&amp;](i64 i) &#123;    auto it = map-&gt;find(digest[i]);    assert(it != map-&gt;end());    sections[i]-&gt;leader = it-&gt;second;  &#125;);  // Since free&#x27;ing the map is slow, postpone it.  ctx.on_exit.push_back([=] &#123; delete map; &#125;);&#125;if (ctx.arg.print_icf_sections)  print_icf_sections(ctx);\n\n这里我们暂时忽略digest是怎么来的细节，直接看这里使用的过程。将digest关联一个input section，这里的逻辑很像merge_leaf_nodes，只是key换成了Digest，本质更换了一种hash方式，另外不再是只针对leaf的了\nsweep sections// Eliminate duplicate sections.// Symbols pointing to eliminated sections will be redirected on the fly when// exporting to the symtab.&#123;  Timer t(ctx, &quot;sweep&quot;);  static Counter eliminated(&quot;icf_eliminated&quot;);  tbb::parallel_for_each(ctx.objs, [](ObjectFile&lt;E&gt; *file) &#123;    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : file-&gt;sections) &#123;      if (isec &amp;&amp; isec-&gt;is_alive &amp;&amp; isec-&gt;is_killed_by_icf()) &#123;        isec-&gt;kill();        eliminated++;      &#125;    &#125;  &#125;);&#125;template&lt;typename E&gt;inline bool InputSection&lt;E&gt;::is_killed_by_icf() const &#123;  return this-&gt;leader &amp;&amp; this-&gt;leader != this;&#125;\n\n最后消除掉重复的section。判断重复的依据是leader不等于自身。\nicf_sections 总结\nCieRecord去重\nmerge leaf node\n取出所有需要处理的section\n计算digest\n根据digest处理所有需要处理的section\n消除重复的section\n\n","categories":["Linker"],"tags":["mold"]},{"title":"mold源码阅读七 创建输出段之前","url":"/2023/05/20/mold/mold-7-before-create-output-section/","content":"\npixiv:101015341 p7 \n\n上期的内容主要是section size相关的优化，这期内容是创建输出段前的最后一些处理\nCompute Merged Section Size// Compute sizes of sections containing mergeable strings.compute_merged_section_sizes(ctx);\n\ntemplate &lt;typename E&gt;void compute_merged_section_sizes(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;compute_merged_section_sizes&quot;);  // Mark section fragments referenced by live objects.  if (!ctx.arg.gc_sections) &#123;    tbb::parallel_for_each(ctx.objs, [](ObjectFile&lt;E&gt; *file) &#123;      for (std::unique_ptr&lt;MergeableSection&lt;E&gt;&gt; &amp;m : file-&gt;mergeable_sections)        if (m)          for (SectionFragment&lt;E&gt; *frag : m-&gt;fragments)            frag-&gt;is_alive.store(true, std::memory_order_relaxed);    &#125;);  &#125;  // Add an identification string to .comment.  if (!ctx.arg.oformat_binary)    add_comment_string(ctx, mold_version);  // Embed command line arguments for debugging.  if (char *env = getenv(&quot;MOLD_DEBUG&quot;); env &amp;&amp; env[0])    add_comment_string(ctx, &quot;mold command line: &quot; + get_cmdline_args(ctx));  Timer t2(ctx, &quot;MergedSection assign_offsets&quot;);  tbb::parallel_for_each(ctx.merged_sections,                         [&amp;](std::unique_ptr&lt;MergedSection&lt;E&gt;&gt; &amp;sec) &#123;    sec-&gt;assign_offsets(ctx);  &#125;);&#125;\n\n这个过程做了三件事情\n\n对非gc_sections的情况下标记fragment，在开启这个选项时会在之前的过程标记过\n之后是添加comment string。\n最后是针对每一个merged_section调用assign_offsets\n\n关于上面的oformat，其命令行的描述如下\n\n-oformat=binary Omit ELF, section and program headers\n\nadd_comment_string的实现\ntemplate &lt;typename E&gt;void add_comment_string(Context&lt;E&gt; &amp;ctx, std::string str) &#123;  MergedSection&lt;E&gt; *sec =    MergedSection&lt;E&gt;::get_instance(ctx, &quot;.comment&quot;, SHT_PROGBITS,                                   SHF_MERGE | SHF_STRINGS);  std::string_view buf = save_string(ctx, str);  std::string_view data(buf.data(), buf.size() + 1);  SectionFragment&lt;E&gt; *frag = sec-&gt;insert(data, hash_string(data), 0);  frag-&gt;is_alive = true;&#125;\n\n这个过程获取对应的MergeSecgtion的instance，之后插入comment str中一个新的fragment。\n接下来看一下assign_offsets的实现\ntemplate &lt;typename E&gt;void MergedSection&lt;E&gt;::assign_offsets(Context&lt;E&gt; &amp;ctx) &#123;  std::vector&lt;i64&gt; sizes(map.NUM_SHARDS);  std::vector&lt;i64&gt; max_p2aligns(map.NUM_SHARDS);  shard_offsets.resize(map.NUM_SHARDS + 1);  i64 shard_size = map.nbuckets / map.NUM_SHARDS;  tbb::parallel_for((i64)0, map.NUM_SHARDS, [&amp;](i64 i) &#123;    struct KeyVal &#123;      std::string_view key;      SectionFragment&lt;E&gt; *val;    &#125;;    std::vector&lt;KeyVal&gt; fragments;    fragments.reserve(shard_size);    for (i64 j = shard_size * i; j &lt; shard_size * (i + 1); j++)      if (SectionFragment&lt;E&gt; &amp;frag = map.values[j]; frag.is_alive)        fragments.push_back(&#123;&#123;map.keys[j], map.key_sizes[j]&#125;, &amp;frag&#125;);    // Sort fragments to make output deterministic.    tbb::parallel_sort(fragments.begin(), fragments.end(),                       [](const KeyVal &amp;a, const KeyVal &amp;b) &#123;      return std::tuple&#123;(u32)a.val-&gt;p2align, a.key.size(), a.key&#125; &lt;             std::tuple&#123;(u32)b.val-&gt;p2align, b.key.size(), b.key&#125;;    &#125;);    // Assign offsets.    i64 offset = 0;    i64 p2align = 0;    for (KeyVal &amp;kv : fragments) &#123;      SectionFragment&lt;E&gt; &amp;frag = *kv.val;      offset = align_to(offset, 1 &lt;&lt; frag.p2align);      frag.offset = offset;      offset += kv.key.size();      p2align = std::max&lt;i64&gt;(p2align, frag.p2align);    &#125;    sizes[i] = offset;    max_p2aligns[i] = p2align;    static Counter merged_strings(&quot;merged_strings&quot;);    merged_strings += fragments.size();  &#125;);  i64 p2align = 0;  for (i64 x : max_p2aligns)    p2align = std::max(p2align, x);  for (i64 i = 1; i &lt; map.NUM_SHARDS + 1; i++)    shard_offsets[i] =      align_to(shard_offsets[i - 1] + sizes[i - 1], 1 &lt;&lt; p2align);  tbb::parallel_for((i64)1, map.NUM_SHARDS, [&amp;](i64 i) &#123;    for (i64 j = shard_size * i; j &lt; shard_size * (i + 1); j++)      if (SectionFragment&lt;E&gt; &amp;frag = map.values[j]; frag.is_alive)        frag.offset += shard_offsets[i];  &#125;);  this-&gt;shdr.sh_size = shard_offsets[map.NUM_SHARDS];  this-&gt;shdr.sh_addralign = 1 &lt;&lt; p2align;&#125;\n\nassign_offsets主要目的是设置对应MergedSection的section header中的sh_size和sh_addralign\n这里的实现首先为了并行计算，将数据划分为了map.NUM_SHARDS个shard块。在每个并行的body中，先构建了对应的KeyVal，之后为了输出的确定性进行排序，最后计算其section fragment的p2aligns，以及将其长度设置为offset的初始值\n在这之后算出一个最大的p2align用于设置MergedSection的section header的sh_addralign，以及计算出每一个shard块中fragment的shared_offset，最后将最后一个shard的offset(下标为n的元素，类似于vector的end的位置）作为整个MergedSection的size\nCreate Synthetic Sections这里主要创建一些特殊的段\n// Create linker-synthesized sections such as .got or .plt.  create_synthetic_sections(ctx);\n\ntemplate &lt;typename E&gt;void create_synthetic_sections(Context&lt;E&gt; &amp;ctx) &#123;  auto push = [&amp;]&lt;typename T&gt;(T *x) &#123;    ctx.chunks.push_back(x);    ctx.chunk_pool.emplace_back(x);    return x;  &#125;;  if (!ctx.arg.oformat_binary) &#123;    auto find = [&amp;](std::string_view name) &#123;      for (SectionOrder &amp;ord : ctx.arg.section_order)        if (ord.type == SectionOrder::SECTION &amp;&amp; ord.name == name)          return true;      return false;    &#125;;    if (ctx.arg.section_order.empty() || find(&quot;EHDR&quot;))      ctx.ehdr = push(new OutputEhdr&lt;E&gt;(SHF_ALLOC));    else      ctx.ehdr = push(new OutputEhdr&lt;E&gt;(0));    if (ctx.arg.section_order.empty() || find(&quot;PHDR&quot;))      ctx.phdr = push(new OutputPhdr&lt;E&gt;(SHF_ALLOC));    else      ctx.phdr = push(new OutputPhdr&lt;E&gt;(0));    ctx.shdr = push(new OutputShdr&lt;E&gt;);  &#125;  ctx.got = push(new GotSection&lt;E&gt;);  if constexpr (!is_sparc&lt;E&gt;)    ctx.gotplt = push(new GotPltSection&lt;E&gt;);  ctx.reldyn = push(new RelDynSection&lt;E&gt;);  ctx.relplt = push(new RelPltSection&lt;E&gt;);  if (ctx.arg.pack_dyn_relocs_relr)    ctx.relrdyn = push(new RelrDynSection&lt;E&gt;);  ctx.strtab = push(new StrtabSection&lt;E&gt;);  ctx.plt = push(new PltSection&lt;E&gt;);  ctx.pltgot = push(new PltGotSection&lt;E&gt;);  ctx.symtab = push(new SymtabSection&lt;E&gt;);  ctx.dynsym = push(new DynsymSection&lt;E&gt;);  ctx.dynstr = push(new DynstrSection&lt;E&gt;);  ctx.eh_frame = push(new EhFrameSection&lt;E&gt;);  ctx.copyrel = push(new CopyrelSection&lt;E&gt;(false));  ctx.copyrel_relro = push(new CopyrelSection&lt;E&gt;(true));  if (!ctx.arg.oformat_binary)    ctx.shstrtab = push(new ShstrtabSection&lt;E&gt;);  if (!ctx.arg.dynamic_linker.empty())    ctx.interp = push(new InterpSection&lt;E&gt;);  if (ctx.arg.build_id.kind != BuildId::NONE)    ctx.buildid = push(new BuildIdSection&lt;E&gt;);  if (ctx.arg.eh_frame_hdr)    ctx.eh_frame_hdr = push(new EhFrameHdrSection&lt;E&gt;);  if (ctx.arg.gdb_index)    ctx.gdb_index = push(new GdbIndexSection&lt;E&gt;);  if (ctx.arg.z_relro &amp;&amp; ctx.arg.section_order.empty() &amp;&amp;      ctx.arg.z_separate_code != SEPARATE_LOADABLE_SEGMENTS)    ctx.relro_padding = push(new RelroPaddingSection&lt;E&gt;);  if (ctx.arg.hash_style_sysv)    ctx.hash = push(new HashSection&lt;E&gt;);  if (ctx.arg.hash_style_gnu)    ctx.gnu_hash = push(new GnuHashSection&lt;E&gt;);  if (!ctx.arg.version_definitions.empty())    ctx.verdef = push(new VerdefSection&lt;E&gt;);  if (ctx.arg.emit_relocs)    ctx.eh_frame_reloc = push(new EhFrameRelocSection&lt;E&gt;);  if (ctx.arg.shared || !ctx.dsos.empty() || ctx.arg.pie)    ctx.dynamic = push(new DynamicSection&lt;E&gt;);  ctx.versym = push(new VersymSection&lt;E&gt;);  ctx.verneed = push(new VerneedSection&lt;E&gt;);  ctx.note_package = push(new NotePackageSection&lt;E&gt;);  ctx.note_property = push(new NotePropertySection&lt;E&gt;);  if (ctx.arg.is_static) &#123;    if constexpr (is_s390x&lt;E&gt;)      ctx.s390x_tls_get_offset = push(new S390XTlsGetOffsetSection);    if constexpr (is_sparc&lt;E&gt;)      ctx.sparc_tls_get_addr = push(new SparcTlsGetAddrSection);  &#125;  if constexpr (std::is_same_v&lt;E, PPC64V1&gt;)    ctx.ppc64_opd = push(new PPC64OpdSection);  // If .dynamic exists, .dynsym and .dynstr must exist as well  // since .dynamic refers them.  if (ctx.dynamic) &#123;    ctx.dynstr-&gt;keep();    ctx.dynsym-&gt;keep();  &#125;  ctx.tls_get_addr = get_symbol(ctx, &quot;__tls_get_addr&quot;);  ctx.tls_get_offset = get_symbol(ctx, &quot;__tls_get_offset&quot;);&#125;\n\n在这里其实已经开始创建输出的内容了，因为是直接push到chunk中。在mold中chunk则是表示用于输出的一片区域，关于Chunk类源码中有这样的注释\n\nChunk represents a contiguous region in an output file.\n\n首先是oformat_binary选项控制的EHDR和PHDR。\nEHDR和PHDR分别是ELF Header和Program Header\nEHDR和PHDR在不指定section_order或者指定的情况下存在对应的section则作为一个ALLOC的chunk加入到chunks中。\n之后是添加了一些常见的段，以及各种参数控制的段，不再一一赘述。\n最后提一下如果dynamic section存在的话，那么保留dynstr和dynsym段，也就是设置其size为1\nvoid keep() &#123; this-&gt;shdr.sh_size = 1; &#125;\n\nCheck Duplicate Symbol// Make sure that there&#x27;s no duplicate symbolif (!ctx.arg.allow_multiple_definition)  check_duplicate_symbols(ctx);\n\ntemplate &lt;typename E&gt;void check_duplicate_symbols(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;check_duplicate_symbols&quot;);  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (i64 i = file-&gt;first_global; i &lt; file-&gt;elf_syms.size(); i++) &#123;      const ElfSym&lt;E&gt; &amp;esym = file-&gt;elf_syms[i];      Symbol&lt;E&gt; &amp;sym = *file-&gt;symbols[i];      // Skip if our symbol is undef or weak      if (sym.file == file || sym.file == ctx.internal_obj ||          esym.is_undef() || esym.is_common() || (esym.st_bind == STB_WEAK))        continue;      // Skip if our symbol is in a dead section. In most cases, the      // section has been eliminated due to comdat deduplication.      if (!esym.is_abs()) &#123;        InputSection&lt;E&gt; *isec = file-&gt;get_section(esym);        if (!isec || !isec-&gt;is_alive)          continue;      &#125;      Error(ctx) &lt;&lt; &quot;duplicate symbol: &quot; &lt;&lt; *file &lt;&lt; &quot;: &quot; &lt;&lt; *sym.file                 &lt;&lt; &quot;: &quot; &lt;&lt; sym;    &#125;  &#125;);  ctx.checkpoint();&#125;\n\n针对所有的obj进行检查，遍历所有的global symbol。\n首先通过sym.file ==file 检查符号owner是否为当前文件\n// A symbol is owned by a file. If two or more files define the// same symbol, the one with the strongest definition owns the symbol.// If `file` is null, the symbol is equivalent to nonexistent.InputFile&lt;E&gt; *file = nullptr;\n\n以及如果是internal_obj中的符号，也进行跳过。剩下的就是可能有冲突的情况，但undef、weak、common的符号冲突不会造成影响，只有重复定义会导致冲突，因此这些情况也进行跳过。\n最后跳过在dead section的符号，未满足前面条件的符号则是重复符号\nCheck Symbol Types// Warn if symbols with different types are defined under the same name.  check_symbol_types(ctx);\n\ntemplate &lt;typename E&gt;void check_symbol_types(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;check_symbol_types&quot;);  auto normalize_type = [](u32 type) &#123;    if (type == STT_GNU_IFUNC)      return STT_FUNC;    return type;  &#125;;  auto check = [&amp;](InputFile&lt;E&gt; *file) &#123;    for (i64 i = file-&gt;first_global; i &lt; file-&gt;elf_syms.size(); i++) &#123;      const ElfSym&lt;E&gt; &amp;esym = file-&gt;elf_syms[i];      Symbol&lt;E&gt; &amp;sym = *file-&gt;symbols[i];      if (!sym.file)        continue;      u32 their_type = normalize_type(sym.esym().st_type);      u32 our_type = normalize_type(esym.st_type);      if (their_type != STT_NOTYPE &amp;&amp; our_type != STT_NOTYPE &amp;&amp;          their_type != our_type)        Warn(ctx) &lt;&lt; &quot;symbol type mismatch: &quot; &lt;&lt; sym &lt;&lt; &#x27;\\n&#x27;                  &lt;&lt; &quot;&gt;&gt;&gt; defined in &quot; &lt;&lt; *sym.file &lt;&lt; &quot; as &quot;                  &lt;&lt; stt_to_string(sym.esym().st_type) &lt;&lt; &#x27;\\n&#x27;                  &lt;&lt; &quot;&gt;&gt;&gt; defined in &quot; &lt;&lt; *file &lt;&lt; &quot; as &quot;                  &lt;&lt; stt_to_string(esym.st_type);    &#125;  &#125;;  tbb::parallel_for_each(ctx.objs, check);  tbb::parallel_for_each(ctx.dsos, check);&#125;\n\n这里针对的是所有的obj和dso里的所有global_symbol进行检查。检查实际的Symbol和ElfSym中的type是否一致，但这里只是warning，而不像之前重复符号的检查一样直接报错。检查的方式是首先对两者的type进行normalize的操作，之后进行比较，都不为空NOTYPE的情况下判断相等性。我觉得这里更像是一种针对resolve的结果检查，因为一个esym是不会被修改的，只有Symbol引用的esym对象会发生改变。\n","categories":["Linker"],"tags":["mold"]},{"title":"mold源码阅读八 创建输出段","url":"/2023/06/10/mold/mold-8-create-output-section/","content":"\npixiv:101015341_p18 \n\n上一期介绍了一些创建输出段之前的工作，本期主要是把创建输出相关的最后一些前置准备讲解完成。根据代码中的注释，add_synthetic_symbols以后，不会再有任何新的文件添加到ctx.objs和ctx.dsos中了。之后会再讲解简单的命令行参数处理，下一期再讲对于输出chunk中的一些处理\ncreate output sections// Create output sections for input sections.template &lt;typename E&gt;void create_output_sections(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;create_output_sections&quot;);  struct Cmp &#123;    size_t operator()(const OutputSectionKey &amp;k) const &#123;      u64 h = hash_string(k.name);      h = combine_hash(h, std::hash&lt;u64&gt;&#123;&#125;(k.type));      h = combine_hash(h, std::hash&lt;u64&gt;&#123;&#125;(k.flags));      return h;    &#125;  &#125;;  std::unordered_map&lt;OutputSectionKey, OutputSection&lt;E&gt; *, Cmp&gt; map;  std::shared_mutex mu;\n\n\n首先针对所有的InputSection生成一个key，并且根据key创建所有的OutputSection\n将所有obj中的InputSection加入到对应OutputSection的members中\n对所有的output section和mergeable section加入到chunks\n将所有的chunk进行排序\n所有的chunk加入到ctx.chunks中（在加入之前chunks中有一些synthetic的chunk，在上一期中有提及）\n\n以下是这五个过程的代码\n// Instantiate output sectionstbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;  for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : file-&gt;sections) &#123;    if (!isec || !isec-&gt;is_alive)      continue;    OutputSectionKey key = get_output_section_key(ctx, *isec);    &#123;      std::shared_lock lock(mu);      auto it = map.find(key);      if (it != map.end()) &#123;        isec-&gt;output_section = it-&gt;second;        continue;      &#125;    &#125;    std::unique_ptr&lt;OutputSection&lt;E&gt;&gt; osec =      std::make_unique&lt;OutputSection&lt;E&gt;&gt;(key.name, key.type, key.flags);    std::unique_lock lock(mu);    auto [it, inserted] = map.insert(&#123;key, osec.get()&#125;);    isec-&gt;output_section = it-&gt;second;    if (inserted)      ctx.osec_pool.emplace_back(std::move(osec));  &#125;&#125;);\n\n// Add input sections to output sections  for (ObjectFile&lt;E&gt; *file : ctx.objs)    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : file-&gt;sections)      if (isec &amp;&amp; isec-&gt;is_alive)        isec-&gt;output_section-&gt;members.push_back(isec.get());\n\n// Add output sections and mergeable sections to ctx.chunks  std::vector&lt;Chunk&lt;E&gt; *&gt; vec;  for (std::pair&lt;const OutputSectionKey, OutputSection&lt;E&gt; *&gt; &amp;kv : map)    vec.push_back(kv.second);  for (std::unique_ptr&lt;MergedSection&lt;E&gt;&gt; &amp;osec : ctx.merged_sections)    if (osec-&gt;shdr.sh_size)      vec.push_back(osec.get());\n\n// Sections are added to the section lists in an arbitrary order  // because they are created in parallel. Sort them to to make the  // output deterministic.  tbb::parallel_sort(vec.begin(), vec.end(), [](Chunk&lt;E&gt; *x, Chunk&lt;E&gt; *y) &#123;    return std::tuple(x-&gt;name, x-&gt;shdr.sh_type, x-&gt;shdr.sh_flags) &lt;           std::tuple(y-&gt;name, y-&gt;shdr.sh_type, y-&gt;shdr.sh_flags);  &#125;);\n\nappend(ctx.chunks, vec);\n\nget_output_section_key这个函数的作用是从一个InputSection构造一个OutputSectionKey\ntemplate &lt;typename E&gt;static OutputSectionKeyget_output_section_key(Context&lt;E&gt; &amp;ctx, InputSection&lt;E&gt; &amp;isec) &#123;  const ElfShdr&lt;E&gt; &amp;shdr = isec.shdr();  std::string_view name = get_output_name(ctx, isec.name(), shdr.sh_flags);  u64 type = canonicalize_type&lt;E&gt;(name, shdr.sh_type);  u64 flags = shdr.sh_flags &amp; ~(u64)SHF_COMPRESSED;  if (!ctx.arg.relocatable)    flags &amp;= ~(u64)SHF_GROUP &amp; ~(u64)SHF_GNU_RETAIN;  // .init_array is usually writable. We don&#x27;t want to create multiple  // .init_array output sections, so make it always writable.  // So is .fini_array.  if (type == SHT_INIT_ARRAY || type == SHT_FINI_ARRAY)    flags |= SHF_WRITE;  return &#123;name, type, flags&#125;;&#125;\n\nstruct OutputSectionKey &#123;  std::string_view name;  u64 type;  u64 flags;  bool operator==(const OutputSectionKey &amp;other) const &#123;    return name == other.name &amp;&amp; type == other.type &amp;&amp; flags == other.flags;  &#125;&#125;;\n\n从InputSection获取的output name。这里有以下几种情况\n\n返回原始名字\n\n忽略段名字的后缀\n不知道这里应该用什么术语，还是举个例子，比如说里面的.ARM.exidx，如果有.ARM.exidx.f1以及.ARM.exidx.f2，那么这两个的名字都会归为.ARM.exidx\n\n将一些特殊的text段单独分开，而不是合并为一个text。这里涉及到了一个z_keep_text_section_prefix的编译选项，命令行的介绍是\n\nz keep-text-section-prefix Keep .text.{hot,unknown,unlikely,startup,exit} as separate sections in the final binary\n\n\n对于text等特定段则是只保留原始前缀，比如说所有的.text.xxx最后都会合并到一个.text段。这个对于函数定义非常常见，查看编译产物的时候，经常会看到一些.text.function_name，最后都会合并为一个.text，这种合并其实就是这里实现的。\n\n\ntemplate &lt;typename E&gt;std::string_viewget_output_name(Context&lt;E&gt; &amp;ctx, std::string_view name, u64 flags) &#123;  if (ctx.arg.relocatable &amp;&amp; !ctx.arg.relocatable_merge_sections)    return name;  if (ctx.arg.unique &amp;&amp; ctx.arg.unique-&gt;match(name))    return name;  if (flags &amp; SHF_MERGE)    return name;  if (name.starts_with(&quot;.ARM.exidx&quot;))    return &quot;.ARM.exidx&quot;;  if (name.starts_with(&quot;.ARM.extab&quot;))    return &quot;.ARM.extab&quot;;  if (ctx.arg.z_keep_text_section_prefix) &#123;    static std::string_view prefixes[] = &#123;      &quot;.text.hot.&quot;, &quot;.text.unknown.&quot;, &quot;.text.unlikely.&quot;, &quot;.text.startup.&quot;,      &quot;.text.exit.&quot;    &#125;;    for (std::string_view prefix : prefixes) &#123;      std::string_view stem = prefix.substr(0, prefix.size() - 1);      if (name == stem || name.starts_with(prefix))        return stem;    &#125;  &#125;  static std::string_view prefixes[] = &#123;    &quot;.text.&quot;, &quot;.data.rel.ro.&quot;, &quot;.data.&quot;, &quot;.rodata.&quot;, &quot;.bss.rel.ro.&quot;, &quot;.bss.&quot;,    &quot;.init_array.&quot;, &quot;.fini_array.&quot;, &quot;.tbss.&quot;, &quot;.tdata.&quot;, &quot;.gcc_except_table.&quot;,    &quot;.ctors.&quot;, &quot;.dtors.&quot;, &quot;.gnu.warning.&quot;,  &#125;;  for (std::string_view prefix : prefixes) &#123;    std::string_view stem = prefix.substr(0, prefix.size() - 1);    if (name == stem || name.starts_with(prefix))      return stem;  &#125;  return name;&#125;\n\nadd synthetic symbols这里的功能如名字一样，就是添加一些synthetic的符号，添加后将这些符号关联到ctx.symtab中\ntemplate &lt;typename E&gt;void add_synthetic_symbols(Context&lt;E&gt; &amp;ctx) &#123;  ObjectFile&lt;E&gt; &amp;obj = *ctx.internal_obj;  auto add = [&amp;](std::string_view name) &#123;    ElfSym&lt;E&gt; esym;    memset(&amp;esym, 0, sizeof(esym));    esym.st_type = STT_NOTYPE;    esym.st_shndx = SHN_ABS;    esym.st_bind = STB_GLOBAL;    esym.st_visibility = STV_HIDDEN;    ctx.internal_esyms.push_back(esym);    Symbol&lt;E&gt; *sym = get_symbol(ctx, name);    sym-&gt;value = 0xdeadbeef; // unique dummy value    obj.symbols.push_back(sym);    return sym;  &#125;;\n\nctx.__ehdr_start = add(&quot;__ehdr_start&quot;);ctx.__init_array_start = add(&quot;__init_array_start&quot;);ctx.__init_array_end = add(&quot;__init_array_end&quot;);ctx.__fini_array_start = add(&quot;__fini_array_start&quot;);ctx.__fini_array_end = add(&quot;__fini_array_end&quot;);ctx.__preinit_array_start = add(&quot;__preinit_array_start&quot;);ctx.__preinit_array_end = add(&quot;__preinit_array_end&quot;);ctx._DYNAMIC = add(&quot;_DYNAMIC&quot;);ctx._GLOBAL_OFFSET_TABLE_ = add(&quot;_GLOBAL_OFFSET_TABLE_&quot;);ctx._PROCEDURE_LINKAGE_TABLE_ = add(&quot;_PROCEDURE_LINKAGE_TABLE_&quot;);ctx.__bss_start = add(&quot;__bss_start&quot;);ctx._end = add(&quot;_end&quot;);ctx._etext = add(&quot;_etext&quot;);ctx._edata = add(&quot;_edata&quot;);ctx.__executable_start = add(&quot;__executable_start&quot;);ctx.__rel_iplt_start =  add(is_rela&lt;E&gt; ? &quot;__rela_iplt_start&quot; : &quot;__rel_iplt_start&quot;);ctx.__rel_iplt_end =  add(is_rela&lt;E&gt; ? &quot;__rela_iplt_end&quot; : &quot;__rel_iplt_end&quot;);if (ctx.arg.eh_frame_hdr)  ctx.__GNU_EH_FRAME_HDR = add(&quot;__GNU_EH_FRAME_HDR&quot;);if (!get_symbol(ctx, &quot;end&quot;)-&gt;file)  ctx.end = add(&quot;end&quot;);if (!get_symbol(ctx, &quot;etext&quot;)-&gt;file)  ctx.etext = add(&quot;etext&quot;);if (!get_symbol(ctx, &quot;edata&quot;)-&gt;file)  ctx.edata = add(&quot;edata&quot;);if (!get_symbol(ctx, &quot;__dso_handle&quot;)-&gt;file)  ctx.__dso_handle = add(&quot;__dso_handle&quot;);\n\n添加通用的特殊符号\nif constexpr (supports_tlsdesc&lt;E&gt;)  ctx._TLS_MODULE_BASE_ = add(&quot;_TLS_MODULE_BASE_&quot;);if constexpr (is_riscv&lt;E&gt;)  if (!ctx.arg.shared)    ctx.__global_pointer = add(&quot;__global_pointer$&quot;);if constexpr (std::is_same_v&lt;E, ARM32&gt;) &#123;  ctx.__exidx_start = add(&quot;__exidx_start&quot;);  ctx.__exidx_end = add(&quot;__exidx_end&quot;);&#125;if constexpr (is_ppc&lt;E&gt;)  ctx.TOC = add(&quot;.TOC.&quot;);\n\n针对特殊平台添加特定的符号\nfor (Chunk&lt;E&gt; *chunk : ctx.chunks) &#123;    if (std::optional&lt;std::string&gt; name = get_start_stop_name(ctx, *chunk)) &#123;      add(save_string(ctx, &quot;__start_&quot; + *name));      add(save_string(ctx, &quot;__stop_&quot; + *name));      if (ctx.arg.physical_image_base) &#123;        add(save_string(ctx, &quot;__phys_start_&quot; + *name));        add(save_string(ctx, &quot;__phys_stop_&quot; + *name));      &#125;    &#125;  &#125;\n\n针对特殊名字的trunk的处理\nobj.elf_syms = ctx.internal_esyms;obj.symvers.resize(ctx.internal_esyms.size() - 1);obj.resolve_symbols(ctx);\n\n对internal_obj进行symbol resolve\n// Make all synthetic symbols relative ones by associating them to// a dummy output section.for (Symbol&lt;E&gt; *sym : obj.symbols)  if (sym-&gt;file == &amp;obj)    sym-&gt;set_output_section(ctx.symtab);\n\n符号关联到symtab这个output section里\n// Handle --defsym symbols.for (i64 i = 0; i &lt; ctx.arg.defsyms.size(); i++) &#123;  Symbol&lt;E&gt; *sym = ctx.arg.defsyms[i].first;  std::variant&lt;Symbol&lt;E&gt; *, u64&gt; val = ctx.arg.defsyms[i].second;  Symbol&lt;E&gt; *target = nullptr;  if (Symbol&lt;E&gt; **ref = std::get_if&lt;Symbol&lt;E&gt; *&gt;(&amp;val))    target = *ref;  // If the alias refers another symobl, copy ELF symbol attributes.  if (target) &#123;    ElfSym&lt;E&gt; &amp;esym = obj.elf_syms[i + 1];    esym.st_type = target-&gt;esym().st_type;    if constexpr (requires &#123; esym.ppc_local_entry; &#125;)      esym.ppc_local_entry = target-&gt;esym().ppc_local_entry;  &#125;  // Make the target absolute if necessary.  if (!target || target-&gt;is_absolute())    sym-&gt;origin = 0;&#125;\n\n对于—defsym指定的符号进行处理\ncheck_cet_errors// Handle `-z cet-report`.  if (ctx.arg.z_cet_report != CET_REPORT_NONE)    check_cet_errors(ctx);\n\n首先，cet是Control Flow Enforcement Technology的缩写。简单来说就是预防控制流攻击的一种技术\n\nControl-flow Enforcement Technology (CET) covers several related x86 processor features that provide protection against control flow hijacking attacks. CET can protect both applications and the kernel.\nCET introduces shadow stack and indirect branch tracking (IBT). A shadow stack is a secondary stack allocated from memory which cannot be directly modified by applications. When executing a CALL instruction, the processor pushes the return address to both the normal stack and the shadow stack. Upon function return, the processor pops the shadow stack copy and compares it to the normal stack copy. If the two differ, the processor raises a control-protection fault. IBT verifies indirect CALL/JMP targets are intended as marked by the compiler with ‘ENDBR’ opcodes. Not all CPU’s have both Shadow Stack and Indirect Branch Tracking. Today in the 64-bit kernel, only userspace shadow stack and kernel IBT are supported.\n\nControl-flow Enforcement Technology (CET) Shadow Stack — The Linux Kernel  documentation\ncet_report有三类\ntypedef enum &#123;  CET_REPORT_NONE,  CET_REPORT_WARNING,  CET_REPORT_ERROR,&#125; CetReportKind;\n\n这个函数是用于进行针对每个file检查对应的gnu_properties，如果没有满足特定feature的话抛出warning或者error。\nELF中必须包含GNU_PROPERTY_X86_FEATURE_1_IBT和GNU_PROPERTY_X86_FEATURE_1_SHSTK属性才能支持cet。\nvoid check_cet_errors(Context&lt;E&gt; &amp;ctx) &#123;  bool warning = (ctx.arg.z_cet_report == CET_REPORT_WARNING);  assert(warning || (ctx.arg.z_cet_report == CET_REPORT_ERROR));  auto has_feature = [](ObjectFile&lt;E&gt; *file, u32 feature) &#123;    return std::any_of(file-&gt;gnu_properties.begin(), file-&gt;gnu_properties.end(),                       [&amp;](auto kv) &#123;                         return kv.first == GNU_PROPERTY_X86_FEATURE_1_AND                             &amp;&amp; (kv.second &amp; feature);                       &#125;);  &#125;;  for (ObjectFile&lt;E&gt; *file : ctx.objs) &#123;    if (file == ctx.internal_obj)      continue;    if (!has_feature(file, GNU_PROPERTY_X86_FEATURE_1_IBT)) &#123;      if (warning)        Warn(ctx) &lt;&lt; *file &lt;&lt; &quot;: -cet-report=warning: &quot;                  &lt;&lt; &quot;missing GNU_PROPERTY_X86_FEATURE_1_IBT&quot;;      else        Error(ctx) &lt;&lt; *file &lt;&lt; &quot;: -cet-report=error: &quot;                   &lt;&lt; &quot;missing GNU_PROPERTY_X86_FEATURE_1_IBT&quot;;    &#125;    if (!has_feature(file, GNU_PROPERTY_X86_FEATURE_1_SHSTK)) &#123;      if (warning)        Warn(ctx) &lt;&lt; *file &lt;&lt; &quot;: -cet-report=warning: &quot;                  &lt;&lt; &quot;missing GNU_PROPERTY_X86_FEATURE_1_SHSTK&quot;;      else        Error(ctx) &lt;&lt; *file &lt;&lt; &quot;: -cet-report=error: &quot;                   &lt;&lt; &quot;missing GNU_PROPERTY_X86_FEATURE_1_SHSTK&quot;;    &#125;  &#125;&#125;\n\nexecstack-if-needed// Handle `-z execstack-if-needed`.if (ctx.arg.z_execstack_if_needed)  for (ObjectFile&lt;E&gt; *file : ctx.objs)    if (file-&gt;needs_executable_stack)      ctx.arg.z_execstack = true;\n\n所有的obj中，如果有needs_executable_stack为true的情况，那么设置ctx中的arg。obj中的这个属性是在ObjectFile::initialize_sections中设置的。而全局的z_execstack会在后面被用到，此时先不过多提及。\n// .note.GNU-stack section controls executable-ness of the stack// area in GNU linkers. We ignore that section because silently// making the stack area executable is too dangerous. Tell our// users about the difference if that matters.if (name == &quot;.note.GNU-stack&quot; &amp;&amp; !ctx.arg.relocatable) &#123;  if (shdr.sh_flags &amp; SHF_EXECINSTR) &#123;    if (!ctx.arg.z_execstack &amp;&amp; !ctx.arg.z_execstack_if_needed)      Warn(ctx) &lt;&lt; *this &lt;&lt; &quot;: this file may cause a segmentation&quot;        &quot; fault because it requires an executable stack. See&quot;        &quot; https://github.com/rui314/mold/tree/main/docs/execstack.md&quot;        &quot; for more info.&quot;;    needs_executable_stack = true;  &#125;  continue;&#125;\n","categories":["Linker"],"tags":["mold"]},{"title":"mold源码阅读九 未解析符号的处理","url":"/2023/06/19/mold/mold-9-unresolve-symbol/","content":"\npixiv:101015341_p16 \n\n本期内容主要是claim_unresolved_symbols的部分，其次是其他一些简单的处理\nclaim_unresolved_symbols// If we are linking a .so file, remaining undefined symbols does// not cause a linker error. Instead, they are treated as if they// were imported symbols.//// If we are linking an executable, weak undefs are converted to// weakly imported symbols so that they&#x27;ll have another chance to be// resolved.claim_unresolved_symbols(ctx);\n\ntemplate &lt;typename E&gt;void claim_unresolved_symbols(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;claim_unresolved_symbols&quot;);  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;claim_unresolved_symbols(ctx);  &#125;);&#125;\n\n这个函数主要还是针对需要在链接期就确定定义的符号进行检查，针对部分符号产生一些修改，在这个过程之后，不会再有符号发生新的变动了\n对so来说undef是可以存在的，因此将避免报错，将undef的符号转换为imported，并且修改相关信息。\n但是如果是protected或者hidden的符号即便链接了运行时也无法访问到，此时即便是undef也无法再在运行时找到定义，因此需要在链接时确定定义。也正因为这些条件，这里只需要对global符号做检查即可。\n以下是具体处理过程\ntemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::claim_unresolved_symbols(Context&lt;E&gt; &amp;ctx) &#123;  if (!this-&gt;is_alive)    return;\t...  for (i64 i = this-&gt;first_global; i &lt; this-&gt;elf_syms.size(); i++) &#123;    const ElfSym&lt;E&gt; &amp;esym = this-&gt;elf_syms[i];    Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[i];    if (!esym.is_undef())      continue;    std::scoped_lock lock(sym.mu);    // If a protected/hidden undefined symbol is resolved to an    // imported symbol, it&#x27;s handled as if no symbols were found.    if (sym.file &amp;&amp; sym.file-&gt;is_dso &amp;&amp;        (sym.visibility == STV_PROTECTED || sym.visibility == STV_HIDDEN)) &#123;      report_undef(sym);      continue;    &#125;    if (sym.file &amp;&amp;        (!sym.esym().is_undef() || sym.file-&gt;priority &lt;= this-&gt;priority))      continue;    // If a symbol name is in the form of &quot;foo@version&quot;, search for    // symbol &quot;foo&quot; and check if the symbol has version &quot;version&quot;.    std::string_view key = this-&gt;symbol_strtab.data() + esym.st_name;    if (i64 pos = key.find(&#x27;@&#x27;); pos != key.npos) &#123;      Symbol&lt;E&gt; *sym2 = get_symbol(ctx, key.substr(0, pos));      if (sym2-&gt;file &amp;&amp; sym2-&gt;file-&gt;is_dso &amp;&amp;          sym2-&gt;get_version() == key.substr(pos + 1)) &#123;        this-&gt;symbols[i] = sym2;        continue;      &#125;    &#125;\t\t\t\t...    if (esym.is_undef_weak()) &#123;      if (ctx.arg.shared &amp;&amp; sym.visibility != STV_HIDDEN &amp;&amp;          ctx.arg.z_dynamic_undefined_weak) &#123;        // Global weak undefined symbols are promoted to dynamic symbols        // when when linking a DSO, unless `-z nodynamic_undefined_weak`        // was given.        claim(true);      &#125; else &#123;        // Otherwise, weak undefs are converted to absolute symbols with value 0.        claim(false);      &#125;      continue;    &#125;    if (ctx.arg.unresolved_symbols == UNRESOLVED_WARN)      report_undef(sym);    // Traditionally, remaining undefined symbols cause a link failure    // only when we are creating an executable. Undefined symbols in    // shared objects are promoted to dynamic symbols, so that they&#x27;ll    // get another chance to be resolved at run-time. You can change the    // behavior by passing `-z defs` to the linker.    //    // Even if `-z defs` is given, weak undefined symbols are still    // promoted to dynamic symbols for compatibility with other linkers.    // Some major programs, notably Firefox, depend on the behavior    // (they use this loophole to export symbols from libxul.so).    if (ctx.arg.shared &amp;&amp; sym.visibility != STV_HIDDEN &amp;&amp;        (!ctx.arg.z_defs || ctx.arg.unresolved_symbols != UNRESOLVED_ERROR)) &#123;      claim(true);      continue;    &#125;    // Convert remaining undefined symbols to absolute symbols with value 0.    if (ctx.arg.unresolved_symbols != UNRESOLVED_ERROR || ctx.arg.noinhibit_exec)      claim(false);  &#125;&#125;\n\n如同上面所说，整个过程描述如下\n\n从全局符号开始，先跳过了已经有定义的esym\n\n将protected和hidden的符号进行报错\n\n对esym对应位置的sym进行判断，如果sym所对应的esym是有定义的也跳过。\n这种情况是esym实际的定义在其他位置，sym是esym resolve的结果\n\n解析符号名，如果带有版本信息则再次尝试进行重新将esym和sym进行关联。这个关联体现在esym对应index的symbols重新设置值\nif (sym2-&gt;file &amp;&amp; sym2-&gt;file-&gt;is_dso &amp;&amp;    sym2-&gt;get_version() == key.substr(pos + 1)) &#123;  this-&gt;symbols[i] = sym2;  continue;&#125;\n针对undef_weak进行claim\n\n剩下的undef的符号在创建executable的时候导致链接失败，但在dso中会被提升为dynamic symbols\n\n\nclaim和report_undef的实现\nauto report_undef = [&amp;](Symbol&lt;E&gt; &amp;sym) &#123;  std::stringstream ss;  if (std::string_view source = this-&gt;get_source_name(); !source.empty())    ss &lt;&lt; &quot;&gt;&gt;&gt; referenced by &quot; &lt;&lt; source &lt;&lt; &quot;\\n&quot;;  else    ss &lt;&lt; &quot;&gt;&gt;&gt; referenced by &quot; &lt;&lt; *this &lt;&lt; &quot;\\n&quot;;  typename decltype(ctx.undef_errors)::accessor acc;  ctx.undef_errors.insert(acc, &#123;sym.name(), &#123;&#125;&#125;);  acc-&gt;second.push_back(ss.str());&#125;;// tbb::concurrent_hash_map&lt;std::string_view, std::vector&lt;std::string&gt;&gt; undef_errors;\n\nauto claim = [&amp;](bool is_imported) &#123;  if (sym.traced)    SyncOut(ctx) &lt;&lt; &quot;trace-symbol: &quot; &lt;&lt; *this &lt;&lt; &quot;: unresolved&quot;                 &lt;&lt; (esym.is_weak() ? &quot; weak&quot; : &quot;&quot;)                 &lt;&lt; &quot; symbol &quot; &lt;&lt; sym;  sym.file = this;  sym.origin = 0;  sym.value = 0;  sym.sym_idx = i;  sym.is_weak = false;  sym.is_imported = is_imported;  sym.is_exported = false;  sym.ver_idx = is_imported ? 0 : ctx.default_version;&#125;;\n\nprint dependencies// Handle --print-dependenciesif (ctx.arg.print_dependencies == 1)  print_dependencies(ctx);else if (ctx.arg.print_dependencies == 2)  print_dependencies_full(ctx);\n\n针对所有的obj和dso打印其依赖，那么具体怎么样才算依赖呢？在一个obj a里面，有一个未定义的符号，链接的时候另一个obj b包含了这个符号的定义，那么这就算是a依赖b。\ntemplate &lt;typename E&gt;void print_dependencies(Context&lt;E&gt; &amp;ctx) &#123;  SyncOut(ctx) &lt;&lt;R&quot;(# This is an output of the mold linker&#x27;s --print-dependencies option.## Each line consists of three fields, &lt;file1&gt;, &lt;file2&gt; and &lt;symbol&gt;# separated by tab characters. It indicates that &lt;file1&gt; depends on# &lt;file2&gt; to use &lt;symbol&gt;.)&quot;;  auto print = [&amp;](InputFile&lt;E&gt; *file) &#123;    for (i64 i = file-&gt;first_global; i &lt; file-&gt;elf_syms.size(); i++) &#123;      ElfSym&lt;E&gt; &amp;esym = file-&gt;elf_syms[i];      Symbol&lt;E&gt; &amp;sym = *file-&gt;symbols[i];      if (esym.is_undef() &amp;&amp; sym.file &amp;&amp; sym.file != file)        SyncOut(ctx) &lt;&lt; *file &lt;&lt; &quot;\\t&quot; &lt;&lt; *sym.file &lt;&lt; &quot;\\t&quot; &lt;&lt; sym;    &#125;  &#125;;  for (InputFile&lt;E&gt; *file : ctx.objs)    print(file);  for (InputFile&lt;E&gt; *file : ctx.dsos)    print(file);&#125;\n\n这种是最简单的遍历所有文件打印其依赖，包含了obj a，obj b以及对应符号的名字\ntemplate &lt;typename E&gt;void print_dependencies_full(Context&lt;E&gt; &amp;ctx) &#123;  SyncOut(ctx) &lt;&lt;R&quot;(# This is an output of the mold linker&#x27;s --print-dependencies=full option.## Each line consists of 4 fields, &lt;section1&gt;, &lt;section2&gt;, &lt;symbol-type&gt; and# &lt;symbol&gt;, separated by tab characters. It indicates that &lt;section1&gt; depends# on &lt;section2&gt; to use &lt;symbol&gt;. &lt;symbol-type&gt; is either &quot;u&quot; or &quot;w&quot; for# regular undefined or weak undefined, respectively.## If you want to obtain dependency information per function granularity,# compile source files with the -ffunction-sections compiler flag.)&quot;;  auto println = [&amp;](auto &amp;src, Symbol&lt;E&gt; &amp;sym, ElfSym&lt;E&gt; &amp;esym) &#123;    if (InputSection&lt;E&gt; *isec = sym.get_input_section())      SyncOut(ctx) &lt;&lt; src &lt;&lt; &quot;\\t&quot; &lt;&lt; *isec                   &lt;&lt; &quot;\\t&quot; &lt;&lt; (esym.is_weak() ? &#x27;w&#x27; : &#x27;u&#x27;)                   &lt;&lt; &quot;\\t&quot; &lt;&lt; sym;    else      SyncOut(ctx) &lt;&lt; src &lt;&lt; &quot;\\t&quot; &lt;&lt; *sym.file                   &lt;&lt; &quot;\\t&quot; &lt;&lt; (esym.is_weak() ? &#x27;w&#x27; : &#x27;u&#x27;)                   &lt;&lt; &quot;\\t&quot; &lt;&lt; sym;  &#125;;  for (ObjectFile&lt;E&gt; *file : ctx.objs) &#123;    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : file-&gt;sections) &#123;      if (!isec)        continue;      std::unordered_set&lt;void *&gt; visited;      for (const ElfRel&lt;E&gt; &amp;r : isec-&gt;get_rels(ctx)) &#123;        if (r.r_type == R_NONE)          continue;        ElfSym&lt;E&gt; &amp;esym = file-&gt;elf_syms[r.r_sym];        Symbol&lt;E&gt; &amp;sym = *file-&gt;symbols[r.r_sym];        if (esym.is_undef() &amp;&amp; sym.file &amp;&amp; sym.file != file &amp;&amp;            visited.insert((void *)&amp;sym).second)          println(*isec, sym, esym);      &#125;    &#125;  &#125;  for (SharedFile&lt;E&gt; *file : ctx.dsos) &#123;    for (i64 i = file-&gt;first_global; i &lt; file-&gt;symbols.size(); i++) &#123;      ElfSym&lt;E&gt; &amp;esym = file-&gt;elf_syms[i];      Symbol&lt;E&gt; &amp;sym = *file-&gt;symbols[i];      if (esym.is_undef() &amp;&amp; sym.file &amp;&amp; sym.file != file)        println(*file, sym, esym);    &#125;  &#125;&#125;\n\n这种更复杂一些，不仅打印依赖，还包含了符号到底是undefined还是weak这一信息。\n另外遍历objs的时候还针对每个obj遍历InputSection及其包含的rel，根据这些信息来进行打印。\n遍历dsos的判断条件则是和上面最简单的打印是相同的。\nwrite_repro_file// Handle -reproif (ctx.arg.repro)  write_repro_file(ctx);\n\n\n–repro                     Embed input files to .repro section\n\nrepro file是Reproducible Example Routine file的简称，包含最小可复现用例，用于调试。具体写的过程并非这里关注的重点，有兴趣可以自行查看更多细节，这里只简单看一下由哪些部分组成。\ntemplate &lt;typename E&gt;void write_repro_file(Context&lt;E&gt; &amp;ctx) &#123;  std::string path = ctx.arg.output + &quot;.repro.tar&quot;;  std::unique_ptr&lt;TarWriter&gt; tar =    TarWriter::open(path, filepath(ctx.arg.output).filename().string() + &quot;.repro&quot;);  if (!tar)    Fatal(ctx) &lt;&lt; &quot;cannot open &quot; &lt;&lt; path &lt;&lt; &quot;: &quot; &lt;&lt; errno_string();  tar-&gt;append(&quot;response.txt&quot;, save_string(ctx, create_response_file(ctx)));  tar-&gt;append(&quot;version.txt&quot;, save_string(ctx, mold_version + &quot;\\n&quot;));  std::unordered_set&lt;std::string&gt; seen;  for (std::unique_ptr&lt;MappedFile&lt;Context&lt;E&gt;&gt;&gt; &amp;mf : ctx.mf_pool) &#123;    if (!mf-&gt;parent) &#123;      std::string path = to_abs_path(mf-&gt;name).string();      if (seen.insert(path).second) &#123;        // We reopen a file because we may have modified the contents of mf        // in memory, which is mapped with PROT_WRITE and MAP_PRIVATE.        MappedFile&lt;Context&lt;E&gt;&gt; *mf2 = MappedFile&lt;Context&lt;E&gt;&gt;::must_open(ctx, path);        tar-&gt;append(path, mf2-&gt;get_contents());        mf2-&gt;unmap();      &#125;    &#125;  &#125;&#125;template &lt;typename E&gt;static std::string create_response_file(Context&lt;E&gt; &amp;ctx) &#123;  std::string buf;  std::stringstream out;  std::string cwd = std::filesystem::current_path().string();  out &lt;&lt; &quot;-C &quot; &lt;&lt; cwd.substr(1) &lt;&lt; &quot;\\n&quot;;  if (cwd != &quot;/&quot;) &#123;    out &lt;&lt; &quot;--chroot ..&quot;;    i64 depth = std::count(cwd.begin(), cwd.end(), &#x27;/&#x27;);    for (i64 i = 1; i &lt; depth; i++)      out &lt;&lt; &quot;/..&quot;;    out &lt;&lt; &quot;\\n&quot;;  &#125;  for (i64 i = 1; i &lt; ctx.cmdline_args.size(); i++) &#123;    std::string_view arg = ctx.cmdline_args[i];    if (arg != &quot;-repro&quot; &amp;&amp; arg != &quot;--repro&quot;)      out &lt;&lt; arg &lt;&lt; &quot;\\n&quot;;  &#125;  return out.str();&#125;\n\n根据代码我们得知，主要分为三部分\n\nresponse_file，本质上是编译命令以及参数\nmold的version info\n所有的输入文件\n\n也就表示这三者就是确定问题的必要条件，另外还可以认为执行到这里之后符号不会再发生什么改动，也不会产生新的用户引发的问题（比如说少链接文件，或者什么参数错了导致符号决议出问题等）\nrequired-defined// Handle --require-definedfor (std::string_view name : ctx.arg.require_defined)  if (!get_symbol(ctx, name)-&gt;file)    Error(ctx) &lt;&lt; &quot;--require-defined: undefined symbol: &quot; &lt;&lt; name;\n\n强制要求某些符号是必须在链接时就包含定义的，对这些符号进行检查并且进行报错。\n","categories":["Linker"],"tags":["mold"]},{"title":"mold源码阅读十 段排序","url":"/2023/06/24/mold/mold-10-sort-section/","content":"\npixiv:76218989 \n\n段排序本篇文章提到的mold中出现的段排序，包含了一个chunk内的段与段的排序，还包含了chunk与chunk之间的排序。或者也可以说是对于输入角度来看待的排序，以及从输出角度看待的段进行排序。对于输入来讲，段的基本单位是InputSection，比如说一个输入文件中的一个text段，而对于输出来讲，也就是目标文件来讲，段的基本单位是一个chunk，而一个chunk是由多个输入的段组成的，比如说大的text段是由所有的输入文件中的text段组合而成。\n首先要说明为什么需要进行排序\nsort_init_fini，sort_ctor_dtor以及shuffle_sections属于chunk内的段与段之间的排序，在这里来说是为了满足mold的特殊需求。不过完全随机以及reverse的shuffle我还是不明白为什么需要这样来做。对于init这样的段来说，链接器需要将所有输入文件的同名段合并到同一个输出段中，因此必须要在chunk内的段与段之间的排序。\nsort_output_sections属于chunk与chunk之间的排序，这里排序的目的很大一部分是为了满足特定规则的需要，不论是regular顺序的还是指定的顺序都会使得ehdr/phdr在最前，而shdr在最后。\n对于中间灵活可变的部分，和对齐以及跳转指令都有关系。跳转指令这个问题我在实际遇到过，JAL指令的立即数字段的长度是固定的，而所要跳转的地址超出了JAL这个字段所能代表的长度，最后通过修改链接脚本中相关段的顺序使得地址控制在了立即数的范围之内。\nsort_init_finitemplate &lt;typename E&gt;void sort_init_fini(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;sort_init_fini&quot;);  auto get_priority = [](InputSection&lt;E&gt; *isec) &#123;    static std::regex re(R&quot;(\\.(\\d+)$)&quot;, std::regex_constants::optimize);    std::string_view name = isec-&gt;name();    std::cmatch m;    if (std::regex_search(name.data(), name.data() + name.size(), m, re))      return std::stoi(m[1]);    return 65536;  &#125;;  for (Chunk&lt;E&gt; *chunk : ctx.chunks) &#123;    if (OutputSection&lt;E&gt; *osec = chunk-&gt;to_osec()) &#123;      if (osec-&gt;name == &quot;.init_array&quot; || osec-&gt;name == &quot;.preinit_array&quot; ||          osec-&gt;name == &quot;.fini_array&quot;) &#123;        if (ctx.arg.shuffle_sections == SHUFFLE_SECTIONS_REVERSE)          std::reverse(osec-&gt;members.begin(), osec-&gt;members.end());        sort(osec-&gt;members, [&amp;](InputSection&lt;E&gt; *a, InputSection&lt;E&gt; *b) &#123;          return get_priority(a) &lt; get_priority(b);        &#125;);      &#125;    &#125;  &#125;&#125;\n\n将所有的chunk转换为OutputSection，其中对init_array，preinit_array，fini_array段的所有成员按照priority进行排序。\n\n–shuffle-sections[=SEED]   Randomize the output by shuffling input sections\n\n关于init以及后面ctor相关的段，参考maskray聚聚的博客\n.init, .ctors, and .init_array\n其中有这样一段示例汇编\n.section\t.text.startup,&quot;ax&quot;,@progbits_GLOBAL__sub_I_a.cc:  callq\t_Znwm  callq\t_ZN1SC1Ev  callq\tgetpid.section\t.init_array.101,&quot;aw&quot;,@init_array## legacy: .section .ctors.65434,&quot;aw&quot;,@progbits.p2align\t3.quad\t_Z7init101v.section\t.init_array.102,&quot;aw&quot;,@init_array## legacy: .section .ctors.65433,&quot;aw&quot;,@progbits.p2align\t3.quad\t_Z7init102v.section\t.init_array,&quot;aw&quot;,@init_array## legacy: .section .ctors,&quot;aw&quot;,@progbits.p2align\t3.quad\t_Z4initv.quad\t_GLOBAL__sub_I_a.cc\n\n这里面的init_array根据不同的priority增加不同的后缀数字，而这里的排序正是针对这些\nsort_ctor_dtortemplate &lt;typename E&gt;void sort_ctor_dtor(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;sort_ctor_dtor&quot;);  auto get_priority = [](InputSection&lt;E&gt; *isec) &#123;    auto opts = std::regex_constants::optimize | std::regex_constants::ECMAScript;    static std::regex re1(R&quot;((?:clang_rt\\.)?crtbegin)&quot;, opts);    static std::regex re2(R&quot;((?:clang_rt\\.)?crtend)&quot;, opts);    static std::regex re3(R&quot;(\\.(\\d+)$)&quot;, opts);    // crtbegin.o and crtend.o contain marker symbols such as    // __CTOR_LIST__ or __DTOR_LIST__. So they have to be at the    // beginning or end of the section.    std::smatch m;    if (std::regex_search(isec-&gt;file.filename, m, re1))      return -2;    if (std::regex_search(isec-&gt;file.filename, m, re2))      return 65536;    std::string name(isec-&gt;name());    if (std::regex_search(name, m, re3))      return std::stoi(m[1]);    return -1;  &#125;;  for (Chunk&lt;E&gt; *chunk : ctx.chunks) &#123;    if (OutputSection&lt;E&gt; *osec = chunk-&gt;to_osec()) &#123;      if (osec-&gt;name == &quot;.ctors&quot; || osec-&gt;name == &quot;.dtors&quot;) &#123;        if (ctx.arg.shuffle_sections != SHUFFLE_SECTIONS_REVERSE)          std::reverse(osec-&gt;members.begin(), osec-&gt;members.end());        sort(osec-&gt;members, [&amp;](InputSection&lt;E&gt; *a, InputSection&lt;E&gt; *b) &#123;          return get_priority(a) &lt; get_priority(b);        &#125;);      &#125;    &#125;  &#125;&#125;\n\n和sort init类似的逻辑，除了priority的计算方式不同。这里针对了clang_rt的crtbegin和crtend做了特殊的处理，最后再对其余的按照编号进行排序。\nshuffle_sections// Handle --shuffle-sectionsif (ctx.arg.shuffle_sections != SHUFFLE_SECTIONS_NONE)  shuffle_sections(ctx);\n\n\n-shuffle-sections[=SEED] Randomize the output by shuffling input sections\n\ntemplate &lt;typename E&gt;void shuffle_sections(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;shuffle_sections&quot;);  auto is_eligible = [](OutputSection&lt;E&gt; &amp;osec) &#123;    return osec.name != &quot;.init&quot; &amp;&amp; osec.name != &quot;.fini&quot; &amp;&amp;           osec.name != &quot;.ctors&quot; &amp;&amp; osec.name != &quot;.dtors&quot; &amp;&amp;           osec.name != &quot;.init_array&quot; &amp;&amp; osec.name != &quot;.preinit_array&quot; &amp;&amp;           osec.name != &quot;.fini_array&quot;;  &#125;;  switch (ctx.arg.shuffle_sections) &#123;  case SHUFFLE_SECTIONS_NONE:    unreachable();  case SHUFFLE_SECTIONS_SHUFFLE: &#123;    u64 seed;    if (ctx.arg.shuffle_sections_seed)      seed = *ctx.arg.shuffle_sections_seed;    else      seed = ((u64)std::random_device()() &lt;&lt; 32) | std::random_device()();    tbb::parallel_for_each(ctx.chunks, [&amp;](Chunk&lt;E&gt; *chunk) &#123;      if (OutputSection&lt;E&gt; *osec = chunk-&gt;to_osec())        if (is_eligible(*osec))          shuffle(osec-&gt;members, seed + hash_string(osec-&gt;name));    &#125;);    break;  &#125;  case SHUFFLE_SECTIONS_REVERSE:    tbb::parallel_for_each(ctx.chunks, [&amp;](Chunk&lt;E&gt; *chunk) &#123;      if (OutputSection&lt;E&gt; *osec = chunk-&gt;to_osec())        if (is_eligible(*osec))          std::reverse(osec-&gt;members.begin(), osec-&gt;members.end());    &#125;);    break;  &#125;&#125;\n\n这里跳过了上面sort_init_fini以及sort_ctor_dtor的特殊段，对剩下段的members根据shuffle_sections选项进行shuffle或者reverse\ncopy str// Copy string referred by .dynamic to .dynstr.for (SharedFile&lt;E&gt; *file : ctx.dsos)  ctx.dynstr-&gt;add_string(file-&gt;soname);for (std::string_view str : ctx.arg.auxiliary)  ctx.dynstr-&gt;add_string(str);for (std::string_view str : ctx.arg.filter)  ctx.dynstr-&gt;add_string(str);if (!ctx.arg.rpaths.empty())  ctx.dynstr-&gt;add_string(ctx.arg.rpaths);if (!ctx.arg.soname.empty())  ctx.dynstr-&gt;add_string(ctx.arg.soname);\n\n拷贝所有动态库所需要用的字符串到dynstr中，主要是soname和一些路径之类的信息，而这些信息只是通过段合并是无法添加到dynstr中的，因为这些属于链接时的信息，无法通过链接输入的编译产物获取。\n关于这几个链接选项的介绍\n\n-f SHLIB, –auxiliary SHLIB Set DT_AUXILIARY to the specified value\n\n\n-F LIBNAME, –filter LIBNAMESet DT_FILTER to the specified value\n\n\n–rpath DIR                 Add DIR to runtime search path\n\n\nh LIBNAME, –soname LIBNAME Set shared library name\n\nscan_relocations// Scan relocations to find symbols that need entries in .got, .plt,// .got.plt, .dynsym, .dynstr, etc.scan_relocations(ctx);\n\ntemplate &lt;typename E&gt;void scan_relocations(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;scan_relocations&quot;);  // Scan relocations to find dynamic symbols.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;scan_relocations(ctx);  &#125;);\t...&#125;\n\n为了保证输出文件中的got和plt等section包含对应rel的信息，递归所有所有的rel找到在got和plt中需要的符号，并且添加到got/plt中。而got和plt本身就是synthetic的段，无法从编译产物中获取，只能在链接的时候产生，为了确保rel段符号的正确查找，一定需要这一步骤。\n这里主要做了三部分\n\n扫描每个obj里所有段中的符号，另外标记rel段中要处理的符合条件的符号为NEEDS_PLT\n将flag不为空，或者是imported/exported的符号保留，过滤掉其他符号\n对过滤后的符号，根据其flga添加到对应的chunk中，比如说got或者plt等，最后再清空其flag\n\nrel scantemplate &lt;typename E&gt;void scan_relocations(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;scan_relocations&quot;);  // Scan relocations to find dynamic symbols.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;scan_relocations(ctx);  &#125;);  // Exit if there was a relocation that refers an undefined symbol.  ctx.checkpoint();  ...&#125;\n\n针对每个obj进行scan_relocations\nobject filetemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::scan_relocations(Context&lt;E&gt; &amp;ctx) &#123;  // Scan relocations against seciton contents  for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : sections)    if (isec &amp;&amp; isec-&gt;is_alive &amp;&amp; (isec-&gt;shdr().sh_flags &amp; SHF_ALLOC))      isec-&gt;scan_relocations(ctx);  // Scan relocations against exception frames  for (CieRecord&lt;E&gt; &amp;cie : cies) &#123;    for (ElfRel&lt;E&gt; &amp;rel : cie.get_rels()) &#123;      Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[rel.r_sym];      if (sym.is_imported) &#123;        if (sym.get_type() != STT_FUNC)          Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: &quot; &lt;&lt; sym                     &lt;&lt; &quot;: .eh_frame CIE record with an external data reference&quot;                     &lt;&lt; &quot; is not supported&quot;;        sym.flags |= NEEDS_PLT;      &#125;    &#125;  &#125;&#125;\n\n在讲InputSection之前先看一下CIE的部分。CIE的代码中也会包含rel的部分。\nInputSectionisec-&gt;scan_relocations(ctx);\n这里针对不同的arch有着不同的特化实现\n\n这里我们拿i386和riscv的实现做对比看一下差异\n\n可以看到前面的内容几乎一致，获取rels之后遍历，针对不同的rel type做出不同的处理\n关于riscv的rel type，可以参考这两个链接\nhttps://github.com/riscv-non-isa/riscv-elf-psabi-doc\nRISC-V ELF规范和函数调用规范 - 国内芯片技术交流 - RISC-V单片机中文网——全球首家只专注于RISC-V单片机行业应用的中文网站\n然后我们看针对不同rel type处理的部分\n本质都是调用了InputSection的一些辅助函数，挑几个看一下。在此之前先补充两个缩写的全拼\nabsrel: absolute relocations\npcrel: PC-relative relocations\nswitch (rel.r_type) &#123;  case R_RISCV_32:    if constexpr (E::is_64)      scan_absrel(ctx, sym, rel);    else      scan_dyn_absrel(ctx, sym, rel);    break;  case R_RISCV_HI20:    scan_absrel(ctx, sym, rel);    break;  case R_RISCV_64:    if constexpr (!E::is_64)      Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: R_RISCV_64 cannot be used on RV32&quot;;    scan_dyn_absrel(ctx, sym, rel);    break;  case R_RISCV_CALL:  case R_RISCV_CALL_PLT:    if (sym.is_imported)      sym.flags.fetch_or(NEEDS_PLT, std::memory_order_relaxed);    break;  case R_RISCV_GOT_HI20:    sym.flags.fetch_or(NEEDS_GOT, std::memory_order_relaxed);    break;  case R_RISCV_TLS_GOT_HI20:    ctx.has_gottp_rel.store(true, std::memory_order_relaxed);    sym.flags.fetch_or(NEEDS_GOTTP, std::memory_order_relaxed);    break;  case R_RISCV_TLS_GD_HI20:    sym.flags.fetch_or(NEEDS_TLSGD, std::memory_order_relaxed);    break;  case R_RISCV_32_PCREL:    scan_pcrel(ctx, sym, rel);    break;\n\nfetch_or是执行按位or运算，可以简单视为 flags |= NEEDS_XXX，相当于更新了flag，前面也说过在这个scan的过程本质就是要更新其flag\n这里主要的内容就是scan_xxx，而这些scan的实现都是调用的scan_rel，区别是传入了不同的action\ntemplate &lt;typename E&gt;void InputSection&lt;E&gt;::scan_pcrel(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym,                                 const ElfRel&lt;E&gt; &amp;rel) &#123;  scan_rel(ctx, *this, sym, rel, get_pcrel_action(ctx, sym));&#125;template &lt;typename E&gt;void InputSection&lt;E&gt;::scan_absrel(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym,                                  const ElfRel&lt;E&gt; &amp;rel) &#123;  scan_rel(ctx, *this, sym, rel, get_absrel_action(ctx, sym));&#125;template &lt;typename E&gt;void InputSection&lt;E&gt;::scan_dyn_absrel(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym,                                      const ElfRel&lt;E&gt; &amp;rel) &#123;  scan_rel(ctx, *this, sym, rel, get_dyn_absrel_action(ctx, sym));&#125;template &lt;typename E&gt;void InputSection&lt;E&gt;::scan_toc_rel(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym,                                   const ElfRel&lt;E&gt; &amp;rel) &#123;  scan_rel(ctx, *this, sym, rel, get_ppc64_toc_action(ctx, sym));&#125;\n\n而不同的action则是通过查表的方式来获取。每个不同的类别有着自己的表，将这个表传递给get_rel_action后进行获取。在get_rel_action中则是通过output type和sym type进行查表\ntemplate &lt;typename E&gt;static Action get_pcrel_action(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym) &#123;  // This is for PC-relative relocations (e.g. R_X86_64_PC32).  // We cannot promote them to dynamic relocations because the dynamic  // linker generally does not support PC-relative relocations.  constexpr static Action table[3][4] = &#123;    // Absolute  Local    Imported data  Imported code    &#123;  ERROR,    NONE,    ERROR,         PLT    &#125;,  // Shared object    &#123;  ERROR,    NONE,    COPYREL,       PLT    &#125;,  // Position-independent exec    &#123;  NONE,     NONE,    COPYREL,       CPLT   &#125;,  // Position-dependent exec  &#125;;  return get_rel_action(ctx, sym, table);&#125;template &lt;typename E&gt;static Action get_absrel_action(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym) &#123;  // This is a decision table for absolute relocations that is smaller  // than the word size (e.g. R_X86_64_32). Since the dynamic linker  // generally does not support dynamic relocations smaller than the  // word size, we need to report an error if a relocation cannot be  // resolved at link-time.  constexpr static Action table[3][4] = &#123;    // Absolute  Local    Imported data  Imported code    &#123;  NONE,     ERROR,   ERROR,         ERROR &#125;,  // Shared object    &#123;  NONE,     ERROR,   ERROR,         ERROR &#125;,  // Position-independent exec    &#123;  NONE,     NONE,    COPYREL,       CPLT  &#125;,  // Position-dependent exec  &#125;;  return get_rel_action(ctx, sym, table);&#125;template &lt;typename E&gt;static Action get_dyn_absrel_action(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym) &#123;  if (sym.is_ifunc())    return IFUNC;  // This is a decision table for absolute relocations for the word  // size data (e.g. R_X86_64_64). Unlike the absrel_table, we can emit  // a dynamic relocation if we cannot resolve an address at link-time.  constexpr static Action table[3][4] = &#123;    // Absolute  Local    Imported data  Imported code    &#123;  NONE,     BASEREL, DYNREL,        DYNREL   &#125;,  // Shared object    &#123;  NONE,     BASEREL, DYNREL,        DYNREL   &#125;,  // Position-independent exec    &#123;  NONE,     NONE,    DYN_COPYREL,   DYN_CPLT &#125;,  // Position-dependent exec  &#125;;  return get_rel_action(ctx, sym, table);&#125;template &lt;typename E&gt;static Action get_ppc64_toc_action(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym) &#123;  if (sym.is_ifunc())    return IFUNC;  // As a special case, we do not create copy relocations nor canonical  // PLTs for .toc sections. PPC64&#x27;s .toc is a compiler-generated  // GOT-like section, and no user-generated code directly uses values  // in it.  constexpr static Action table[3][4] = &#123;    // Absolute  Local    Imported data  Imported code    &#123;  NONE,     BASEREL, DYNREL,        DYNREL &#125;,  // Shared object    &#123;  NONE,     BASEREL, DYNREL,        DYNREL &#125;,  // Position-independent exec    &#123;  NONE,     NONE,    DYNREL,        DYNREL &#125;,  // Position-dependent exec  &#125;;  return get_rel_action(ctx, sym, table);&#125;\n\ntemplate &lt;typename E&gt;static Action get_rel_action(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym,                             const Action table[3][4]) &#123;  auto get_output_type = [&amp;] &#123;    if (ctx.arg.shared)      return 0;    if (ctx.arg.pie)      return 1;    return 2;  &#125;;  auto get_sym_type = [&amp;] &#123;    if (sym.is_absolute())      return 0;    if (!sym.is_imported)      return 1;    if (sym.get_type() != STT_FUNC)      return 2;    return 3;  &#125;;  return table[get_output_type()][get_sym_type()];&#125;\n\nscan_rel这里是对符号进行标记的地方，根据传入的不同action使用不同处理以及标记方式\ntemplate &lt;typename E&gt;static void scan_rel(Context&lt;E&gt; &amp;ctx, InputSection&lt;E&gt; &amp;isec, Symbol&lt;E&gt; &amp;sym,                     const ElfRel&lt;E&gt; &amp;rel, Action action) &#123;  bool writable = (isec.shdr().sh_flags &amp; SHF_WRITE);  auto error = [&amp;] &#123;    std::string msg = sym.is_absolute() ? &quot;-fno-PIC&quot; : &quot;-fPIC&quot;;    Error(ctx) &lt;&lt; isec &lt;&lt; &quot;: &quot; &lt;&lt; rel &lt;&lt; &quot; relocation at offset 0x&quot;               &lt;&lt; std::hex &lt;&lt; rel.r_offset &lt;&lt; &quot; against symbol `&quot;               &lt;&lt; sym &lt;&lt; &quot;&#x27; can not be used; recompile with &quot; &lt;&lt; msg;  &#125;;  auto check_textrel = [&amp;] &#123;    if (!writable) &#123;      if (ctx.arg.z_text) &#123;        error();      &#125; else if (ctx.arg.warn_textrel) &#123;        Warn(ctx) &lt;&lt; isec &lt;&lt; &quot;: relocation against symbol `&quot; &lt;&lt; sym                  &lt;&lt; &quot;&#x27; in read-only section&quot;;      &#125;      ctx.has_textrel = true;    &#125;  &#125;;  auto copyrel = [&amp;] &#123;    assert(sym.is_imported);    if (sym.esym().st_visibility == STV_PROTECTED) &#123;      Error(ctx) &lt;&lt; isec                 &lt;&lt; &quot;: cannot make copy relocation for protected symbol &#x27;&quot; &lt;&lt; sym                 &lt;&lt; &quot;&#x27;, defined in &quot; &lt;&lt; *sym.file &lt;&lt; &quot;; recompile with -fPIC&quot;;    &#125;    sym.flags |= NEEDS_COPYREL;  &#125;;  auto dynrel = [&amp;] &#123;    check_textrel();    isec.file.num_dynrel++;  &#125;;  switch (action) &#123;  case NONE:    break;  case ERROR:    error();    break;  case COPYREL:    if (!ctx.arg.z_copyreloc)      error();    copyrel();    break;  case DYN_COPYREL:    if (writable || !ctx.arg.z_copyreloc)      dynrel();    else      copyrel();    break;  case PLT:    sym.flags |= NEEDS_PLT;    break;  case CPLT:    sym.flags |= NEEDS_CPLT;    break;  case DYN_CPLT:    if (writable)      dynrel();    else      sym.flags |= NEEDS_CPLT;    break;  case DYNREL:  case IFUNC:    dynrel();    break;  case BASEREL:    check_textrel();    if (!isec.is_relr_reloc(ctx, rel))      isec.file.num_dynrel++;    break;  default:    unreachable();  &#125;&#125;\n\nsymbols to a vectemplate &lt;typename E&gt;void scan_relocations(Context&lt;E&gt; &amp;ctx) &#123;\t...\t// Aggregate dynamic symbols to a single vector.\tstd::vector&lt;InputFile&lt;E&gt; *&gt; files;\tappend(files, ctx.objs);\tappend(files, ctx.dsos);\t\tstd::vector&lt;std::vector&lt;Symbol&lt;E&gt; *&gt;&gt; vec(files.size());\t\ttbb::parallel_for((i64)0, (i64)files.size(), [&amp;](i64 i) &#123;\t  for (Symbol&lt;E&gt; *sym : files[i]-&gt;symbols)\t    if (sym-&gt;file == files[i])\t      if (sym-&gt;flags || sym-&gt;is_imported || sym-&gt;is_exported)\t        vec[i].push_back(sym);\t&#125;);\t\tstd::vector&lt;Symbol&lt;E&gt; *&gt; syms = flatten(vec);\tctx.symbol_aux.reserve(syms.size());\t...&#125;\n\n这里将所有的文件中所有符合条件的symbol收集起来，其中flag则是在前面的阶段进行标记的\n关于这里的symbol_aux\n// Symbol auxiliary datastd::vector&lt;SymbolAux&gt; symbol_aux;\n\nSymbolAux\n// Additional class members for dynamic symbols. Because most symbols// don&#x27;t need them and we allocate tens of millions of symbol objects// for large programs, we separate them from `Symbol` class to save// memory.struct SymbolAux &#123;  i32 got_idx = -1;  i32 gottp_idx = -1;  i32 tlsgd_idx = -1;  i32 tlsdesc_idx = -1;  i32 plt_idx = -1;  i32 pltgot_idx = -1;  i32 opd_idx = -1;  i32 dynsym_idx = -1;  u32 djb_hash = 0;&#125;;\n\nadd to tabletemplate &lt;typename E&gt;void scan_relocations(Context&lt;E&gt; &amp;ctx) &#123;\t...\t\t// Assign offsets in additional tables for each dynamic symbol.  for (Symbol&lt;E&gt; *sym : syms) &#123;    add_aux(sym);    if (sym-&gt;is_imported || sym-&gt;is_exported)      ctx.dynsym-&gt;add_symbol(ctx, sym);    if (sym-&gt;flags &amp; NEEDS_GOT)      ctx.got-&gt;add_got_symbol(ctx, sym);    if (sym-&gt;flags &amp; NEEDS_CPLT) &#123;      sym-&gt;is_canonical = true;      // A canonical PLT needs to be visible from DSOs.      sym-&gt;is_exported = true;      // We can&#x27;t use .plt.got for a canonical PLT because otherwise      // .plt.got and .got would refer each other, resulting in an      // infinite loop at runtime.      ctx.plt-&gt;add_symbol(ctx, sym);    &#125; else if (sym-&gt;flags &amp; NEEDS_PLT) &#123;      if (sym-&gt;flags &amp; NEEDS_GOT)        ctx.pltgot-&gt;add_symbol(ctx, sym);      else        ctx.plt-&gt;add_symbol(ctx, sym);    &#125;    if (sym-&gt;flags &amp; NEEDS_GOTTP)      ctx.got-&gt;add_gottp_symbol(ctx, sym);    if (sym-&gt;flags &amp; NEEDS_TLSGD)      ctx.got-&gt;add_tlsgd_symbol(ctx, sym);    if (sym-&gt;flags &amp; NEEDS_TLSDESC)      ctx.got-&gt;add_tlsdesc_symbol(ctx, sym);    if (sym-&gt;flags &amp; NEEDS_COPYREL) &#123;      assert(sym-&gt;file-&gt;is_dso);      SharedFile&lt;E&gt; *file = (SharedFile&lt;E&gt; *)sym-&gt;file;      sym-&gt;copyrel_readonly = file-&gt;is_readonly(ctx, sym);      if (sym-&gt;copyrel_readonly)        ctx.copyrel_relro-&gt;add_symbol(ctx, sym);      else        ctx.copyrel-&gt;add_symbol(ctx, sym);      // If a symbol needs copyrel, it is considered both imported      // and exported.      assert(sym-&gt;is_imported);      sym-&gt;is_exported = true;      // Aliases of this symbol are also copied so that they will be      // resolved to the same address at runtime.      for (Symbol&lt;E&gt; *alias : file-&gt;find_aliases(sym)) &#123;        add_aux(alias);        alias-&gt;is_imported = true;        alias-&gt;is_exported = true;        alias-&gt;has_copyrel = true;        alias-&gt;value = sym-&gt;value;        alias-&gt;copyrel_readonly = sym-&gt;copyrel_readonly;        ctx.dynsym-&gt;add_symbol(ctx, alias);      &#125;    &#125;    if constexpr (std::is_same_v&lt;E, PPC64V1&gt;)      if (sym-&gt;flags &amp; NEEDS_OPD)        ctx.ppc64_opd-&gt;add_symbol(ctx, sym);    sym-&gt;flags = 0;  &#125;  if (ctx.needs_tlsld)    ctx.got-&gt;add_tlsld(ctx);  if (ctx.has_textrel &amp;&amp; ctx.arg.warn_textrel)    Warn(ctx) &lt;&lt; &quot;creating a DT_TEXTREL in an output file&quot;;&#125;\n\n将所有符合条件的符号添加到ctx.symbol_aux中，之后加入到对应的表中\ncompute_section_sizes// Compute sizes of output sections while assigning offsets// within an output section to input sections.compute_section_sizes(ctx);\n\n这里做了如下几件事情\n\nchunks里面找到所有符合条件的osec进行处理\n划分group并且处理每个group的size和p2align\n计算与设置group的offset以及p2align\n\n\n处理ARM的特殊情况\n根据arg的section_align设定特定osec的sh_addralign\n\nchunks的处理template &lt;typename E&gt;void compute_section_sizes(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;compute_section_sizes&quot;);  struct Group &#123;    i64 size = 0;    i64 p2align = 0;    i64 offset = 0;    std::span&lt;InputSection&lt;E&gt; *&gt; members;  &#125;;\ttbb::parallel_for_each(ctx.chunks, [&amp;](Chunk&lt;E&gt; *chunk) &#123;    OutputSection&lt;E&gt; *osec = chunk-&gt;to_osec();    if (!osec)      return;    // This pattern will be processed in the next loop.    if constexpr (needs_thunk&lt;E&gt;)      if ((osec-&gt;shdr.sh_flags &amp; SHF_EXECINSTR) &amp;&amp; !ctx.arg.relocatable)        return;    // Since one output section may contain millions of input sections,    // we first split input sections into groups and assign offsets to    // groups.    std::vector&lt;Group&gt; groups;    constexpr i64 group_size = 10000;    for (std::span&lt;InputSection&lt;E&gt; *&gt; span : split(osec-&gt;members, group_size))      groups.push_back(Group&#123;.members = span&#125;);    tbb::parallel_for_each(groups, [](Group &amp;group) &#123;      for (InputSection&lt;E&gt; *isec : group.members) &#123;        group.size = align_to(group.size, 1 &lt;&lt; isec-&gt;p2align) + isec-&gt;sh_size;        group.p2align = std::max&lt;i64&gt;(group.p2align, isec-&gt;p2align);      &#125;    &#125;);    i64 offset = 0;    i64 p2align = 0;    for (i64 i = 0; i &lt; groups.size(); i++) &#123;      offset = align_to(offset, 1 &lt;&lt; groups[i].p2align);      groups[i].offset = offset;      offset += groups[i].size;      p2align = std::max(p2align, groups[i].p2align);    &#125;    osec-&gt;shdr.sh_size = offset;    osec-&gt;shdr.sh_addralign = 1 &lt;&lt; p2align;    // Assign offsets to input sections.    tbb::parallel_for_each(groups, [](Group &amp;group) &#123;      i64 offset = group.offset;      for (InputSection&lt;E&gt; *isec : group.members) &#123;        offset = align_to(offset, 1 &lt;&lt; isec-&gt;p2align);        isec-&gt;offset = offset;        offset += isec-&gt;sh_size;      &#125;    &#125;);  &#125;);\n\n\n找到chunks中的osec\n将osec中的InputSections拆分为几个group并行计算\n针对每个group的每个InputSection\n将group size根据isec的p2align计算出一个对齐的size，之后加上当前isec的size\np2align更新为最大值\n\n\n更新所有group的offset以及p2align\n更新osec的size和addralign\n对所有group中的input section设置offset\n\nARM的处理template &lt;typename E&gt;void compute_section_sizes(Context&lt;E&gt; &amp;ctx) &#123;\t...\t// On ARM32 or ARM64, we may need to create so-called &quot;range extension  // thunks&quot; to extend branch instructions reach, as they can jump only  // to ±16 MiB or ±128 MiB, respecitvely.  //  // In the following loop, We compute the sizes of sections while  // inserting thunks. This pass cannot be parallelized. That is,  // create_range_extension_thunks is parallelized internally, but the  // function itself is not thread-safe.  if constexpr (needs_thunk&lt;E&gt;) &#123;    for (Chunk&lt;E&gt; *chunk : ctx.chunks) &#123;      OutputSection&lt;E&gt; *osec = chunk-&gt;to_osec();      if (osec &amp;&amp; (osec-&gt;shdr.sh_flags &amp; SHF_EXECINSTR) &amp;&amp; !ctx.arg.relocatable) &#123;        create_range_extension_thunks(ctx, *osec);        for (InputSection&lt;E&gt; *isec : osec-&gt;members)          osec-&gt;shdr.sh_addralign =            std::max&lt;u32&gt;(osec-&gt;shdr.sh_addralign, 1 &lt;&lt; isec-&gt;p2align);      &#125;    &#125;  &#125;  ...&#125;\n\n设定osec的sh_addraligntemplate &lt;typename E&gt;void compute_section_sizes(Context&lt;E&gt; &amp;ctx) &#123;\t...\tfor (Chunk&lt;E&gt; *chunk : ctx.chunks)    if (OutputSection&lt;E&gt; *osec = chunk-&gt;to_osec())      if (u32 align = ctx.arg.section_align[osec-&gt;name])        osec-&gt;shdr.sh_addralign = std::max&lt;u32&gt;(osec-&gt;shdr.sh_addralign, align);&#125;\n\nsort_output_sections// Sort sections by section attributes so that we&#x27;ll have to// create as few segments as possible.sort_output_sections(ctx);\n\ntemplate &lt;typename E&gt;void sort_output_sections(Context&lt;E&gt; &amp;ctx) &#123;  if (ctx.arg.section_order.empty())    sort_output_sections_regular(ctx);  else    sort_output_sections_by_order(ctx);&#125;\n\n这里对所有chunk进行了排序。\n其中顺序为\nELF Headerprogram headernormal memory allocated sectionsnon-memory-allocated sectionssection header\n\nnormal memory allocated sections的顺序会根据用户指定的顺序，或者使用一套regular的规则\nregulartemplate &lt;typename E&gt;void sort_output_sections_regular(Context&lt;E&gt; &amp;ctx) &#123;\t...\tsort(ctx.chunks, [&amp;](Chunk&lt;E&gt; *a, Chunk&lt;E&gt; *b) &#123;\t    // Sort sections by segments\t    i64 x = get_rank1(a);\t    i64 y = get_rank1(b);\t    if (x != y)\t      return x &lt; y;\t\t    // Ties are broken by additional rules\t    return get_rank2(a) &lt; get_rank2(b);\t  &#125;);&#125;\n\n注释中对排序的规则进行了说明\n// We want to sort output chunks in the following order.////   &lt;ELF header&gt;//   &lt;program header&gt;//   .interp//   .note//   .hash//   .gnu.hash//   .dynsym//   .dynstr//   .gnu.version//   .gnu.version_r//   .rela.dyn//   .rela.plt//   &lt;readonly data&gt;//   &lt;readonly code&gt;//   &lt;writable tdata&gt;//   &lt;writable tbss&gt;//   &lt;writable RELRO data&gt;//   .got//   .toc//   &lt;writable RELRO bss&gt;//   .relro_padding//   &lt;writable non-RELRO data&gt;//   &lt;writable non-RELRO bss&gt;//   &lt;non-memory-allocated sections&gt;//   &lt;section header&gt;\n\n代码实现\nauto get_rank1 = [&amp;](Chunk&lt;E&gt; *chunk) &#123;  u64 type = chunk-&gt;shdr.sh_type;  u64 flags = chunk-&gt;shdr.sh_flags;  if (chunk == ctx.ehdr)    return 0;  if (chunk == ctx.phdr)    return 1;  if (chunk == ctx.interp)    return 2;  if (type == SHT_NOTE &amp;&amp; (flags &amp; SHF_ALLOC))    return 3;  if (chunk == ctx.hash)    return 4;  if (chunk == ctx.gnu_hash)    return 5;  if (chunk == ctx.dynsym)    return 6;  if (chunk == ctx.dynstr)    return 7;  if (chunk == ctx.versym)    return 8;  if (chunk == ctx.verneed)    return 9;  if (chunk == ctx.reldyn)    return 10;  if (chunk == ctx.relplt)    return 11;  if (chunk == ctx.shdr)    return INT32_MAX;  bool alloc = (flags &amp; SHF_ALLOC);  bool writable = (flags &amp; SHF_WRITE);  bool exec = (flags &amp; SHF_EXECINSTR);  bool tls = (flags &amp; SHF_TLS);  bool relro = is_relro(ctx, chunk);  bool is_bss = (type == SHT_NOBITS);  return (1 &lt;&lt; 10) | (!alloc &lt;&lt; 9) | (writable &lt;&lt; 8) | (exec &lt;&lt; 7) |         (!tls &lt;&lt; 6) | (!relro &lt;&lt; 5) | (is_bss &lt;&lt; 4);&#125;;auto get_rank2 = [&amp;](Chunk&lt;E&gt; *chunk) -&gt; i64 &#123;  if (chunk-&gt;shdr.sh_type == SHT_NOTE)    return -chunk-&gt;shdr.sh_addralign;  if (chunk == ctx.relro_padding)    return INT_MAX;  if (chunk-&gt;name == &quot;.toc&quot;)    return 2;  if (chunk == ctx.got)    return 1;  return 0;&#125;;\n\n\ntls: This section holds Thread-Local Storage, meaning that each separate execution flow has its own distinct instance of this data.\n\norder// Sort sections according to a --section-order argument.template &lt;typename E&gt;void sort_output_sections_by_order(Context&lt;E&gt; &amp;ctx) &#123;\t...\t// It is an error if a section order cannot be determined by a given\t// section order list.\tfor (Chunk&lt;E&gt; *chunk : ctx.chunks)\t  chunk-&gt;sect_order = get_rank(chunk);\t\t// Sort output sections by --section-order\tsort(ctx.chunks, [&amp;](Chunk&lt;E&gt; *a, Chunk&lt;E&gt; *b) &#123;\t  return a-&gt;sect_order &lt; b-&gt;sect_order;\t&#125;);&#125;\n\n所有的chunk设置sect_order，之后根据这个排序。这个功能我觉得就是类似于在链接脚本中按顺序写下段的名字然后按照脚本的顺序来排序\nauto get_rank = [&amp;](Chunk&lt;E&gt; *chunk) -&gt; i64 &#123;  u64 flags = chunk-&gt;shdr.sh_flags;  if (chunk == ctx.ehdr &amp;&amp; !(chunk-&gt;shdr.sh_flags &amp; SHF_ALLOC))    return -2;  if (chunk == ctx.phdr &amp;&amp; !(chunk-&gt;shdr.sh_flags &amp; SHF_ALLOC))    return -1;  if (chunk == ctx.shdr)    return INT32_MAX;  if (!(flags &amp; SHF_ALLOC))    return INT32_MAX - 1;  for (i64 i = 0; const SectionOrder &amp;arg : ctx.arg.section_order) &#123;    if (arg.type == SectionOrder::SECTION &amp;&amp; arg.name == chunk-&gt;name)      return i;    i++;  &#125;  std::string_view group = get_section_order_group(*chunk);  for (i64 i = 0; i &lt; ctx.arg.section_order.size(); i++) &#123;    SectionOrder arg = ctx.arg.section_order[i];    if (arg.type == SectionOrder::GROUP &amp;&amp; arg.name == group)      return i;  &#125;  Error(ctx) &lt;&lt; &quot;--section-order: missing section specification for &quot;             &lt;&lt; chunk-&gt;name;  return 0;&#125;;\n\n针对ehdr，phdr，以及shdr强制指定一个rank\n之后根据arg的order查找优先级。如果没指定，则根据section_order_group再查优先级\ntemplate &lt;typename E&gt;static std::string_view get_section_order_group(Chunk&lt;E&gt; &amp;chunk) &#123;  if (chunk.shdr.sh_type == SHT_NOBITS)    return &quot;BSS&quot;;  if (chunk.shdr.sh_flags &amp; SHF_EXECINSTR)    return &quot;TEXT&quot;;  if (chunk.shdr.sh_flags &amp; SHF_WRITE)    return &quot;DATA&quot;;  return &quot;RODATA&quot;;&#125;;\n","categories":["Linker"],"tags":["mold"]},{"title":"mold源码阅读十一  relr and dynsym","url":"/2023/07/02/mold/mold-11-rel-and-dynsym/","content":"\n推特画师Lyytoaoitori \n\nconstruct_relr// If --packed_dyn_relocs=relr was given, base relocations are stored// to a .relr.dyn section in a compressed form. Construct a compressed// relocations now so that we can fix section sizes and file layout.if (ctx.arg.pack_dyn_relocs_relr)  construct_relr(ctx);\n\n\n-z pack-relative-relocs Alias for –pack-dyn-relocs=relr-z nopack-relative-relocs\n\n将OutputSection以及Got中的relocations以压缩的形式存储到relr.dyn，在这之后rel段的大小和layout就固定了。\ntemplate &lt;typename E&gt;void construct_relr(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;construct_relr&quot;);  tbb::parallel_for_each(ctx.chunks, [&amp;](Chunk&lt;E&gt; *chunk) &#123;    if (OutputSection&lt;E&gt; *osec = chunk-&gt;to_osec())      osec-&gt;construct_relr(ctx);  &#125;);  ctx.got-&gt;construct_relr(ctx);&#125;\n\noutput section将output section中所有符合条件的rel段收集起来，最后再压缩。\ntemplate &lt;typename E&gt;void OutputSection&lt;E&gt;::construct_relr(Context&lt;E&gt; &amp;ctx) &#123;  if (!ctx.arg.pic)    return;  if (!(this-&gt;shdr.sh_flags &amp; SHF_ALLOC))    return;  if (this-&gt;shdr.sh_addralign % sizeof(Word&lt;E&gt;))    return;  // Skip it if it is a text section because .text doesn&#x27;t usually  // contain any dynamic relocations.  if (this-&gt;shdr.sh_flags &amp; SHF_EXECINSTR)    return;  // Collect base relocations  std::vector&lt;std::vector&lt;u64&gt;&gt; shards(members.size());  tbb::parallel_for((i64)0, (i64)members.size(), [&amp;](i64 i) &#123;    InputSection&lt;E&gt; &amp;isec = *members[i];    if ((1 &lt;&lt; isec.p2align) &lt; sizeof(Word&lt;E&gt;))      return;    for (const ElfRel&lt;E&gt; &amp;r : isec.get_rels(ctx))      if (r.r_type == E::R_ABS &amp;&amp; (r.r_offset % sizeof(Word&lt;E&gt;)) == 0)        if (Symbol&lt;E&gt; &amp;sym = *isec.file.symbols[r.r_sym];            !sym.is_absolute() &amp;&amp; !sym.is_imported)          shards[i].push_back(isec.offset + r.r_offset);  &#125;);  // Compress them  std::vector&lt;u64&gt; pos = flatten(shards);  relr = encode_relr(pos, sizeof(Word&lt;E&gt;));&#125;\n\n这里要讲的是开头是否为pic的判断\n\n–pie, –pic-executable Create a position independent executable–no-pie, –no-pic-executable\n\nelse if (read_flag(&quot;pie&quot;) || read_flag(&quot;pic-executable&quot;)) &#123;  ctx.arg.pic = true;  ctx.arg.pie = true;&#125; else if (read_flag(&quot;no-pie&quot;) || read_flag(&quot;no-pic-executable&quot;)) &#123;  ctx.arg.pic = false;  ctx.arg.pie = false;\n\n有两个概念，pic和pie\npic：position-independent code\npie：position-independent executable\npic和pie是看似类似却是完全冲突的两个选项。\npie是生成位置无关的可执行程序，所有变量（静态和全局变量，或者说局部变量外的变量）的地址在executable中已经确定，由于这个位置确定因此不需要got表，尽管地址确定但是executable可以加载到任意地址，因为确定的是executable的内部偏移。\n而pic通常是一个动态库，在运行时可以加载到任意位置，也就是说相对于加载这个pic库的executable的地址也是未知的，可能加载到前面，也可能加载到后面，确定的地址只有相对于这个pic库内部起始地址的偏移，因此需要利用got中的信息再计算具体加载后的地址。\n看到这些内容也就明白为什么不是pic的话就返回了，因为pie的话并不需要进行重定位来支持动态加载\ngotgot(global offset table)，保存了global符号的内存地址，比如说function或者全局变量，用于运行时重定位来解析这些地址。程序首次运行时got被初始化为未解析的地址，调用函数的时候通过rel.plt/rela.plt解析对应符号的地址，之后地址会被保存到got，供下次解析使用。\ntemplate &lt;typename E&gt;void GotSection&lt;E&gt;::construct_relr(Context&lt;E&gt; &amp;ctx) &#123;  assert(ctx.arg.pack_dyn_relocs_relr);  std::vector&lt;u64&gt; pos;  for (GotEntry&lt;E&gt; &amp;ent : get_got_entries(ctx))    if (ent.is_relr(ctx))      pos.push_back(ent.idx * sizeof(Word&lt;E&gt;));  relr = encode_relr(pos, sizeof(Word&lt;E&gt;));&#125;\n\nget_got_entries这个过程主要是从各个位置获取GotEntry\ntemplate &lt;typename E&gt;struct GotEntry &#123;  bool is_relr(Context&lt;E&gt; &amp;ctx) const &#123;    return r_type == E::R_RELATIVE &amp;&amp; ctx.arg.pack_dyn_relocs_relr;  &#125;  i64 idx = 0;  u64 val = 0;  i64 r_type = R_NONE;  Symbol&lt;E&gt; *sym = nullptr;&#125;;\n\n关于rel_type\n\nRelocation entries describe how to alter the following instruction and data fields (bit numbers appear in the lower box corners).\n\n这里提前引用部分elf spec中提到的在i386中下面会用到的几种rel type的含义\nR*_386_GLOB_DAT*\n\nThis relocation type is used to set a global offset table entry to the address of the specified symbol. The special relocation type allows one to determine the correspondence between symbols and global offset table entries.\n\nR_386_RELATIVE\n\nThe link editor creates this relocation type for dynamic linking. Its offset member gives a location within a shared object that contains a value representing a relative address. The dynamic linker computes the corresponding virtual address by adding the virtual address at which the shared object was loaded to the relative address. Relocation entries for this type must specify 0 for the symbol table index.\n\n关于其他的rel type参考信息\nhttps://docs.oracle.com/cd/E19683-01/817-3677/x-j1h4h/index.html\n\nA R_386_TLS_TPOFF relocation is left outstanding against the GOT table for the runtime linker to fill in with the static TLS offset for symbol x.\n\n\nordinary symbols\n\n针对imported的符号：需要dynamic linker resolve，因此rel_type设置为GLOB_DAT。同时链接时地址未知，因此地址为0\n\nifunc的符号，通常需要dynamic linker fix up，因此rel_type为R_IRELATIVE\nifun: 间接函数。支持对一个函数创建多个实现，通过自己编写的resolver在运行时选择实现\nhttp://sourceware.org/glibc/wiki/GNU_IFUNC\n\npic且relative的情况，需要rel_type为R_IRELATIVE，否则不需要rel_type\n\n\n针对ordinary symbols获取地址时都是NO_PLT的，因为都是已知实现和地址，不需要动态链接。\n\nTLVs\nTLV: thread local variarble\n根据是否为static的情况做不同的处理，是否为static由这两个编译选项所控制\n\n–Bdynamic, –dy Link against shared libraries (default)–Bstatic, –dn, –static Do not link against shared libraries\n\n\ntls\n\n针对符号是否为_TLS_MODULE_BASE_进行处理，唯一的区别是是否将符号关联进去，但是两者都需要设置rel_type为TLS_DESC\n\n\ngottp_syms\ntp: thread pointer\n\nimported，这种符号所有信息未知，需要dynamic linker填充got entry，rel_type为R_TPOFF\nshared，知道offset，需要dynamic linker调整，rel_type为R_TPOFF\nother，链接时知道相对于tp的offset，所以能直接填写got entry\n\n\ntlsld_idx\n\n是否为static。static的情况下不需要rel，同时设置地址为1（表示main executable)否则需要设置rel为R_DTPMOD\n\n\n\n总结一下\n不需要设置rel_type的情况如下\n\nordinary symbol，pic且非relative符号的情况下，也就是说非pic或者pic但是没有relative符号（即不需要重定位）的情况下），不需要设置rel_type\nTLVS为static的情况下不需要设置rel_type\n非shared以及imported的gottp symbol\ntlsld_idx不为1且是static的情况\n\n不过这里我有一个不明白的地方，为什么不需要rel_type的符号会在got中。查到的答案是\n\n作为函数的间接跳转入口:所有函数,包括不需要重定位的函数,在第一次调用时都需要通过.got表来间接跳转。即使函数在链接时就已经获得了绝对地址,但仍需要通过.got表调用。\n访问全局变量:程序中所有全局变量,包括不需要重定位的变量,都需要通过基址寄存器加上.got中的偏移量来访问。即使变量的值在链接时就已经确定,但程序仍需要通过.got表访问。\n作为函数指针:函数的地址可以被用作函数指针。而所有的函数指针,包括指向不需要重定位的函数的函数指针,都需要通过.got表来存取。\n链接器的要求:链接器要求所有函数和变量,无论是否需要重定位,都需要一个.got表项。这样它才能在程序加载时准确构建.got表。\n兼容性考虑:加入所有符号大大提高程序的兼容性。如果后续添加了需要重定位的符号,程序无需任何改动。所以,总之,.got表中的所有符号都是程序加载时解析的。即使符号不需要重定位,但仍需要通过.got表间接存取。主要是作为函数入口和变量、函数指针的访问入口。另外链接器及兼容性的要求也促使符号加入.got表。\n\n// Get .got and .rel.dyn contents.//// .got is a linker-synthesized constant pool whose entry is of pointer// size. If we know a correct value for an entry, we&#x27;ll just set that value// to the entry. Otherwise, we&#x27;ll create a dynamic relocation and let the// dynamic linker to fill the entry at load-time.//// Most GOT entries contain addresses of global variable. If a global// variable is an imported symbol, we don&#x27;t know its address until runtime.// GOT contains the addresses of such variables at runtime so that we can// access imported global variables via GOT.//// Thread-local variables (TLVs) also use GOT entries. We need them because// TLVs are accessed in a different way than the ordinary global variables.// Their addresses are not unique; each thread has its own copy of TLVs.template &lt;typename E&gt;static std::vector&lt;GotEntry&lt;E&gt;&gt; get_got_entries(Context&lt;E&gt; &amp;ctx) &#123;  std::vector&lt;GotEntry&lt;E&gt;&gt; entries;  // Create GOT entries for ordinary symbols  for (Symbol&lt;E&gt; *sym : ctx.got-&gt;got_syms) &#123;    i64 idx = sym-&gt;get_got_idx(ctx);    // If a symbol is imported, let the dynamic linker to resolve it.    if (sym-&gt;is_imported) &#123;      entries.push_back(&#123;idx, 0, E::R_GLOB_DAT, sym&#125;);      continue;    &#125;    // IFUNC always needs to be fixed up by the dynamic linker.    if (sym-&gt;is_ifunc()) &#123;      entries.push_back(&#123;idx, sym-&gt;get_addr(ctx, NO_PLT), E::R_IRELATIVE&#125;);      continue;    &#125;    // If we know an address at link-time, fill that GOT entry now.    // It may need a base relocation, though.    if (ctx.arg.pic &amp;&amp; sym-&gt;is_relative())      entries.push_back(&#123;idx, sym-&gt;get_addr(ctx, NO_PLT), E::R_RELATIVE&#125;);    else      entries.push_back(&#123;idx, sym-&gt;get_addr(ctx, NO_PLT)&#125;);  &#125;  // Create GOT entries for TLVs.  for (Symbol&lt;E&gt; *sym : ctx.got-&gt;tlsgd_syms) &#123;    i64 idx = sym-&gt;get_tlsgd_idx(ctx);    if (ctx.arg.is_static) &#123;      entries.push_back(&#123;idx, 1&#125;); // One indicates the main executable file      entries.push_back(&#123;idx + 1, sym-&gt;get_addr(ctx) - ctx.dtp_addr&#125;);    &#125; else &#123;      entries.push_back(&#123;idx, 0, E::R_DTPMOD, sym&#125;);      entries.push_back(&#123;idx + 1, 0, E::R_DTPOFF, sym&#125;);    &#125;  &#125;  if constexpr (supports_tlsdesc&lt;E&gt;) &#123;    for (Symbol&lt;E&gt; *sym : ctx.got-&gt;tlsdesc_syms) &#123;      // _TLS_MODULE_BASE_ is a linker-synthesized virtual symbol that      // refers the begining of the TLS block.      if (sym == ctx._TLS_MODULE_BASE_)        entries.push_back(&#123;sym-&gt;get_tlsdesc_idx(ctx), 0, E::R_TLSDESC&#125;);      else        entries.push_back(&#123;sym-&gt;get_tlsdesc_idx(ctx), 0, E::R_TLSDESC, sym&#125;);    &#125;  &#125;  for (Symbol&lt;E&gt; *sym : ctx.got-&gt;gottp_syms) &#123;    i64 idx = sym-&gt;get_gottp_idx(ctx);    // If we know nothing about the symbol, let the dynamic linker    // to fill the GOT entry.    if (sym-&gt;is_imported) &#123;      entries.push_back(&#123;idx, 0, E::R_TPOFF, sym&#125;);      continue;    &#125;    // If we know the offset within the current thread vector,    // let the dynamic linker to adjust it.    if (ctx.arg.shared) &#123;      entries.push_back(&#123;idx, sym-&gt;get_addr(ctx) - ctx.tls_begin, E::R_TPOFF&#125;);      continue;    &#125;    // Otherwise, we know the offset from the thread pointer (TP) at    // link-time, so we can fill the GOT entry directly.    entries.push_back(&#123;idx, sym-&gt;get_addr(ctx) - ctx.tp_addr&#125;);  &#125;  if (ctx.got-&gt;tlsld_idx != -1) &#123;    if (ctx.arg.is_static)      entries.push_back(&#123;ctx.got-&gt;tlsld_idx, 1&#125;); // 1 means the main executable    else      entries.push_back(&#123;ctx.got-&gt;tlsld_idx, 0, E::R_DTPMOD&#125;);  &#125;  return entries;&#125;\n\nget_addr这个函数是确定地址的过程。\n首先说明PLT（Procedure Linkage Table），用于存放函数调用的跳转指令。主要用于提供函数入口点，实现间接调用。第一次调用对应函数时plt段被链接器处理，链接到函数的真实地址，也就是GOT中存放的具体值。\n比如说某些符号在链接的时候是\ncall fun@PLT\n\n当调用fun后，这里的代码就会变成\ncall *foo@GOT\n\n另外是absolute符号，简单来说就是有一个固定的绝对地址的符号，因此可以直接获得其地址\nhttps://stackoverflow.com/questions/33324076/what-is-absolute-symbol-and-how-to-define-it-in-c\n\n针对frag，非alive则是0，否则从frag中获取地址，\nhas copy rel，去从ctx中的copy_rel获取基地址\nPPC64\nplt，直接get_plt_addr\ninput section为空，absolute符号直接返回value的地址\ninput section非alive的情况\nkilled by icf，从leader中获取地址\neh_frame，根据符号名获取eh_frame中对应位置的地址\n否则返回0\n\n\n普通的input section，直接isec→get_addr + value\n\n下面代码中出现的value的含义如下，属于Symbol的成员\n// `value` contains symbol value. If it&#x27;s an absolute symbol, it is// equivalent to its address. If it belongs to an input section or a// section fragment, value is added to the base of the input section// to yield an address.// u64 value = 0;\n\ntemplate &lt;typename E&gt;inline u64 SectionFragment&lt;E&gt;::get_addr(Context&lt;E&gt; &amp;ctx) const &#123;  return output_section.shdr.sh_addr + offset;&#125;// `value` contains symbol value. If it&#x27;s an absolute symbol, it is// equivalent to its address. If it belongs to an input section or a// section fragment, value is added to the base of the input section// to yield an address.// u64 value = 0;template &lt;typename E&gt;inline u64 Symbol&lt;E&gt;::get_plt_addr(Context&lt;E&gt; &amp;ctx) const &#123;  if (i32 idx = get_plt_idx(ctx); idx != -1)    return ctx.plt-&gt;shdr.sh_addr + E::plt_hdr_size + idx * E::plt_size;  return ctx.pltgot-&gt;shdr.sh_addr + get_pltgot_idx(ctx) * E::pltgot_size;&#125;template &lt;typename E&gt;inline i32 Symbol&lt;E&gt;::get_pltgot_idx(Context&lt;E&gt; &amp;ctx) const &#123;  return (aux_idx == -1) ? -1 : ctx.symbol_aux[aux_idx].pltgot_idx;&#125;template&lt;typename E&gt;inline bool InputSection&lt;E&gt;::is_killed_by_icf() const &#123;  return this-&gt;leader &amp;&amp; this-&gt;leader != this;&#125;template &lt;typename E&gt;inline u64 Symbol&lt;E&gt;::get_addr(Context&lt;E&gt; &amp;ctx, i64 flags) const &#123;  if (SectionFragment&lt;E&gt; *frag = get_frag()) &#123;    if (!frag-&gt;is_alive) &#123;      // This condition is met if a non-alloc section refers an      // alloc section and if the referenced piece of data is      // garbage-collected. Typically, this condition occurs if a      // debug info section refers a string constant in .rodata.      return 0;    &#125;    return frag-&gt;get_addr(ctx) + value;  &#125;  if (has_copyrel) &#123;    return copyrel_readonly      ? ctx.copyrel_relro-&gt;shdr.sh_addr + value      : ctx.copyrel-&gt;shdr.sh_addr + value;  &#125;  if constexpr (std::is_same_v&lt;E, PPC64V1&gt;)    if (!(flags &amp; NO_OPD) &amp;&amp; has_opd(ctx))      return get_opd_addr(ctx);  if (!(flags &amp; NO_PLT) &amp;&amp; has_plt(ctx)) &#123;    assert(is_imported || is_ifunc());    return get_plt_addr(ctx);  &#125;  InputSection&lt;E&gt; *isec = get_input_section();  if (!isec)    return value; // absolute symbol  if (!isec-&gt;is_alive) &#123;    if (isec-&gt;is_killed_by_icf())      return isec-&gt;leader-&gt;get_addr() + value;    if (isec-&gt;name() == &quot;.eh_frame&quot;) &#123;      // .eh_frame contents are parsed and reconstructed by the linker,      // so pointing to a specific location in a source .eh_frame      // section doesn&#x27;t make much sense. However, CRT files contain      // symbols pointing to the very beginning and ending of the section.      if (name() == &quot;__EH_FRAME_BEGIN__&quot; || name() == &quot;__EH_FRAME_LIST__&quot; ||          name() == &quot;.eh_frame_seg&quot; || esym().st_type == STT_SECTION)        return ctx.eh_frame-&gt;shdr.sh_addr;      if (name() == &quot;__FRAME_END__&quot; || name() == &quot;__EH_FRAME_LIST_END__&quot;)        return ctx.eh_frame-&gt;shdr.sh_addr + ctx.eh_frame-&gt;shdr.sh_size;      // ARM object files contain &quot;$d&quot; local symbol at the beginning      // of data sections. Their values are not significant for .eh_frame,      // so we just treat them as offset 0.      if (name() == &quot;$d&quot; || name().starts_with(&quot;$d.&quot;))        return ctx.eh_frame-&gt;shdr.sh_addr;      Fatal(ctx) &lt;&lt; &quot;symbol referring .eh_frame is not supported: &quot;                 &lt;&lt; *this &lt;&lt; &quot; &quot; &lt;&lt; *file;    &#125;    // The control can reach here if there&#x27;s a relocation that refers    // a local symbol belonging to a comdat group section. This is a    // violation of the spec, as all relocations should use only global    // symbols of comdat members. However, .eh_frame tends to have such    // relocations.    return 0;  &#125;  return isec-&gt;get_addr() + value;&#125;\n\ndynsym finalize// Reserve a space for dynamic symbol strings in .dynstr and sort// .dynsym contents if necessary. Beyond this point, no symbol will// be added to .dynsym.ctx.dynsym-&gt;finalize(ctx);\n\n为dynamic symbol的字符串在dynstr中留出空间，并且排序dynsym的内容。在这之后不会有符号被加入到dynsym，因此这里dynstr section的大小以及排布确定下来了。\n具体的处理过程如下\n\nsymbols排序，local在前global在后，和elf中的格式一样。\n处理gnu_hash的情况\n设置dynsym_offset后计算dynstr的size\n更新DynsymSection的shdr的信息\n\ntemplate &lt;typename E&gt;void DynsymSection&lt;E&gt;::finalize(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;DynsymSection::finalize&quot;);  if (symbols.empty())    return;  // Sort symbols. In any symtab, local symbols must precede global symbols.  auto first_global = std::stable_partition(symbols.begin() + 1, symbols.end(),                                            [&amp;](Symbol&lt;E&gt; *sym) &#123;    return sym-&gt;is_local(ctx);  &#125;);  // We also place undefined symbols before defined symbols for .gnu.hash.  // Defined symbols are sorted by their hashes for .gnu.hash.  if (ctx.gnu_hash) &#123;    // Count the number of exported symbols to compute the size of .gnu.hash.    i64 num_exported = 0;    for (i64 i = 1; i &lt; symbols.size(); i++)      if (symbols[i]-&gt;is_exported)        num_exported++;    u32 num_buckets = num_exported / ctx.gnu_hash-&gt;LOAD_FACTOR + 1;    ctx.gnu_hash-&gt;num_buckets = num_buckets;    tbb::parallel_for((i64)(first_global - symbols.begin()), (i64)symbols.size(),                      [&amp;](i64 i) &#123;      Symbol&lt;E&gt; &amp;sym = *symbols[i];      sym.set_dynsym_idx(ctx, i);      sym.set_djb_hash(ctx, djb_hash(sym.name()));    &#125;);    tbb::parallel_sort(first_global, symbols.end(),                       [&amp;](Symbol&lt;E&gt; *a, Symbol&lt;E&gt; *b) &#123;      if (a-&gt;is_exported != b-&gt;is_exported)        return b-&gt;is_exported;      u32 h1 = a-&gt;get_djb_hash(ctx) % num_buckets;      u32 h2 = b-&gt;get_djb_hash(ctx) % num_buckets;      return std::tuple(h1, a-&gt;get_dynsym_idx(ctx)) &lt;             std::tuple(h2, b-&gt;get_dynsym_idx(ctx));    &#125;);  &#125;  // Compute .dynstr size  ctx.dynstr-&gt;dynsym_offset = ctx.dynstr-&gt;shdr.sh_size;  for (i64 i = 1; i &lt; symbols.size(); i++) &#123;    symbols[i]-&gt;set_dynsym_idx(ctx, i);    ctx.dynstr-&gt;shdr.sh_size += symbols[i]-&gt;name().size() + 1;  &#125;  // ELF&#x27;s symbol table sh_info holds the offset of the first global symbol.  this-&gt;shdr.sh_info = first_global - symbols.begin();&#125;\n\ntemplate &lt;typename E&gt;inline void Symbol&lt;E&gt;::set_dynsym_idx(Context&lt;E&gt; &amp;ctx, i32 idx) &#123;  assert(aux_idx != -1);  ctx.symbol_aux[aux_idx].dynsym_idx = idx;&#125;\n\n这里的ctx.symbol_aux[aux_idx].dynsym_idx是在之前的scan_relocations的过程中设置的，对应的dynsym_idx默认为-1\nreport_undef_error// Print reports about undefined symbols, if needed.if (ctx.arg.unresolved_symbols == UNRESOLVED_ERROR)  report_undef_errors(ctx);\n\n// Report all undefined symbols, grouped by symbol.template &lt;typename E&gt;void report_undef_errors(Context&lt;E&gt; &amp;ctx) &#123;  constexpr i64 max_errors = 3;  for (auto &amp;pair : ctx.undef_errors) &#123;    std::string_view sym_name = pair.first;    std::span&lt;std::string&gt; errors = pair.second;    if (ctx.arg.demangle)      sym_name = demangle(sym_name);    std::stringstream ss;    ss &lt;&lt; &quot;undefined symbol: &quot; &lt;&lt; sym_name &lt;&lt; &quot;\\n&quot;;    for (i64 i = 0; i &lt; errors.size() &amp;&amp; i &lt; max_errors; i++)      ss &lt;&lt; errors[i];    if (errors.size() &gt; max_errors)      ss &lt;&lt; &quot;&gt;&gt;&gt; referenced &quot; &lt;&lt; (errors.size() - max_errors) &lt;&lt; &quot; more times\\n&quot;;    if (ctx.arg.unresolved_symbols == UNRESOLVED_ERROR)      Error(ctx) &lt;&lt; ss.str();    else if (ctx.arg.unresolved_symbols == UNRESOLVED_WARN)      Warn(ctx) &lt;&lt; ss.str();  &#125;  ctx.checkpoint();&#125;\n\n报告之前在claim_unresolved_symbols中收集的undef的错误信息\n","categories":["Linker"],"tags":["mold","got","rel"]},{"title":"令人劝退的自我介绍","url":"/2023/07/02/Other/dissuasive-self-presentation/","content":"\n思来想去，还是决定写这篇详尽的自我介绍。这里不会介绍我的兴趣爱好，如果想看那些请到我的博客关于页面。这里不是作为某种特殊角色的我，并非程序员，并非一个社畜，并非一个二十多岁的青年，而是仅仅作为一个人，关于这个人到底是什么样的，或者说关于这个人在我的眼里到底是什么样的。\n首先是很孤单的人。总的来说我一直是一个比较孤单的人，但和每个人一样十分渴求亲密关系，甚至渴求的程度比大部分人还要强烈。这样的我却又讨厌人，认为大部分人和自己一样无聊，或者比我更无趣，因此对大部分人会普通交流但不会有太强烈的热情。加上在只有自己的世界生活习惯了，在没有特别大的热情的情况下，会不太适应一些场景下的交流，更别说去主动推进关系了。\n比较自卑，没有信心，但有的时候又会有些自大。跟别人交流时，尤其是讨论问题时，无形中会认为自己就是对的，想要说服对方。除此之外在交流上很多时候比较有障碍，我个人经常觉得没什么可以说的，个人知识量和见识都很少，加上认为很多事情都无所谓，因此偶尔说不上话的时候会强行交流而说出一些不适当的话。\n上面的这些因素也促成了我的赛博精神病，情绪到了不能控制的痛苦时，无法排解，因此会在社交平台上发一些很烦人的东西。原因也很简单，觉得很无助，但我也无法去依靠某个人，如果理解为网络精神乞丐那我也认，自己也是这么想的。\n基于以上这些问题，我经常会在一些来不及思考自己说的话是否合适的情况说出不合适的话。\n除此之外，我会关注自身的想法，近年来也开始逐渐关注感受，理性的想法和感性的感受缺一不可。关注的同时也会为自身的一些想法痛苦不已，很多时候也非常想去改正，只是很难。尽管在关注自己，但也不是很明白自己，对前路还是有些迷茫，不过这初入社会不久的人来说也是常态了。同时注重自己的想法，较少受到环境的影响，不在乎他人看法，除非特别在乎对方对自己的态度的情况下。脑袋里每天也会有各种乱七八糟的想法，其中一部分也会通过各种途径输出，目前输出频率最高的大概就是推特了。\n这样的我，活着只是活着，对我目前来讲没什么目的和意义，对一切也毫无牵挂。如果一定要说一个活着的目的那就是顺着自己的心愿，尽可能去做想做的事情，要说我现在想做什么的话除了找到伴侣我还真没什么想做的，绝大部分事情其实都无所谓。几乎没有什么特别喜欢的事情，但同时也没什么特别讨厌的。尽管很多事情无所谓，自身的道德感却会重一些，一些情况下会给自己施加过多的道德约束，自身行为也会尽可能的符合自身认知中的道德标准，经常会使得自己徒增烦恼。\n另外过于理想主义，讨厌这种现实世界，很多情况也不愿去接受。这种不愿接受有些孩子气了，但我也没有抛弃的念头，继续这样也没什么不好。但问题是也不愿接受现在这样无能的自己，对自己许多时候也过于严苛，也不认为他人能完全接受这样的自己。\n尽管这么多问题，但我还是想成为一个更好的人，包括更能接纳自己，能力达到自己满意的程度，自己的一些问题都解决掉，等等，但是前方的路还要走非常非常远。虽然也在尝试去控制自己，但自己的一些本质问题无法改正的情况下还是很难做到的，这些都不是靠意志力就能做到的事情，许多时候人对于自己行为的掌控，远比自己所想象的要弱小很多。当然这不是在找借口，想要改变也是我的另一面。\n不论好坏，不可避免的都会偏离现实。对于我来说，以自己看到或感知到的自己为主。对于读者来说，以读者所看到或感知到的我为主。别人的自我介绍都是表现出自己最好的一面，但这篇介绍却是有劝退的成分。看到了我是这样的人，如果你选择与我接触，那么希望你能做好心理预期，如果借此劝退，也无妨，避免双方留下不愉快的回忆。\n","categories":["Thinking"],"tags":["自我"]},{"title":"mold源码阅读十二 创建一些输出段","url":"/2023/07/09/mold/mold-12-create-some-output-section/","content":"\npixiv:105296500_p0 \n\nFill gnu.version section contents// Fill .gnu.version_d section contents.if (ctx.verdef)  ctx.verdef-&gt;construct(ctx);// Fill .gnu.version_r section contents.ctx.verneed-&gt;construct(ctx);\n\n这里对verdef和verneed段进行构造，实际写入内容。其中包含了字符串信息，因此还会将字符串写入dynstr中。\nverdef对于VerdefSection中的contents是多组ElfVerDef + ElfVerdaux。前者是verdef的信息，后者则是指向对应字符串在dynstr中的offset。\n需要将ctx.arg.version_definitions以及output自身的信息写入到verdef段中，因此这样的数据实际有ctx.arg.version_definitions.size() + 1组。\n| verdef | verdaux | verdef | verdaux |\t\t\t\t\t\t/                  /\t|     dynstr0    |    dynstr1    | ... | dynstrn |\n\ntemplate &lt;typename E&gt;class VerdefSection : public Chunk&lt;E&gt; &#123;public:  VerdefSection() &#123;    this-&gt;name = &quot;.gnu.version_d&quot;;    this-&gt;shdr.sh_type = SHT_GNU_VERDEF;    this-&gt;shdr.sh_flags = SHF_ALLOC;    this-&gt;shdr.sh_addralign = 8;  &#125;  void construct(Context&lt;E&gt; &amp;ctx);  void update_shdr(Context&lt;E&gt; &amp;ctx) override;  void copy_buf(Context&lt;E&gt; &amp;ctx) override;  std::vector&lt;u8&gt; contents;&#125;;\n\n每次写入的时候会先在当前位置写入ElfVerDef的信息，之后写入ElfVerdaux的信息，同时在这个过程中更新当前位置的指针。传入的verstr实际保存在ctx.dynstr中，而Verdaux中保存的是则是verstr在dynstr中的offset，而VerDef仅保存索引，hash等信息。\ntemplate &lt;typename E&gt;void VerdefSection&lt;E&gt;::construct(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;fill_verdef&quot;);  if (ctx.arg.version_definitions.empty())    return;  // Resize .gnu.version  ctx.versym-&gt;contents.resize(ctx.dynsym-&gt;symbols.size(), 1);  ctx.versym-&gt;contents[0] = 0;  // Allocate a buffer for .gnu.version_d.  contents.resize((sizeof(ElfVerdef&lt;E&gt;) + sizeof(ElfVerdaux&lt;E&gt;)) *                  (ctx.arg.version_definitions.size() + 1));  u8 *buf = (u8 *)&amp;contents[0];  u8 *ptr = buf;  ElfVerdef&lt;E&gt; *verdef = nullptr;  auto write = [&amp;](std::string_view verstr, i64 idx, i64 flags) &#123;    this-&gt;shdr.sh_info++;    if (verdef)      verdef-&gt;vd_next = ptr - (u8 *)verdef;    verdef = (ElfVerdef&lt;E&gt; *)ptr;    ptr += sizeof(ElfVerdef&lt;E&gt;);    verdef-&gt;vd_version = 1;    verdef-&gt;vd_flags = flags;    verdef-&gt;vd_ndx = idx;    verdef-&gt;vd_cnt = 1;    verdef-&gt;vd_hash = elf_hash(verstr);    verdef-&gt;vd_aux = sizeof(ElfVerdef&lt;E&gt;);    ElfVerdaux&lt;E&gt; *aux = (ElfVerdaux&lt;E&gt; *)ptr;    ptr += sizeof(ElfVerdaux&lt;E&gt;);    aux-&gt;vda_name = ctx.dynstr-&gt;add_string(verstr);  &#125;;  std::string_view basename = ctx.arg.soname.empty() ?    ctx.arg.output : ctx.arg.soname;  write(basename, 1, VER_FLG_BASE);  i64 idx = 2;  for (std::string_view verstr : ctx.arg.version_definitions)    write(verstr, idx++, 0);  for (Symbol&lt;E&gt; *sym : std::span&lt;Symbol&lt;E&gt; *&gt;(ctx.dynsym-&gt;symbols).subspan(1))    ctx.versym-&gt;contents[sym-&gt;get_dynsym_idx(ctx)] = sym-&gt;ver_idx;&#125;\n\nver_idx的值是\nstatic constexpr u32 VER_NDX_LOCAL = 0;static constexpr u32 VER_NDX_GLOBAL = 1;static constexpr u32 VER_NDX_LAST_RESERVED = 1;\n\nverneed这里的数据格式和vardef不太一样，content是一个Verneed接着多个Vednaux构成。每个Verneed表示一个文件的开始。由于这里是针对dynsym处理，因此实际Vednaux的数量和dynsym的数量相同。在分配空间的时候注释也有写到allocate large enought buffer，避免了每个文件一个dynsym的极端场景。\n|verneed|vednaux|vednaux|...|verneed|vednaux|vednaux|vednaux|\n\n另外不在dso或者sym-&gt;ver_idx &lt;= VER_NDX_LAST_RESERVED的sym，这些符号并不需要填充verneed字段，因此会先被过滤掉。之后由于content是以一个文件为一个小组，为了后面添加信息方便会根据soname以及ver_idx进行排序。\ntemplate &lt;typename E&gt;void VerneedSection&lt;E&gt;::construct(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;fill_verneed&quot;);  if (ctx.dynsym-&gt;symbols.empty())    return;  // Create a list of versioned symbols and sort by file and version.  std::vector&lt;Symbol&lt;E&gt; *&gt; syms(ctx.dynsym-&gt;symbols.begin() + 1,                                ctx.dynsym-&gt;symbols.end());  std::erase_if(syms, [](Symbol&lt;E&gt; *sym) &#123;    return !sym-&gt;file-&gt;is_dso || sym-&gt;ver_idx &lt;= VER_NDX_LAST_RESERVED;  &#125;);  if (syms.empty())    return;  sort(syms, [](Symbol&lt;E&gt; *a, Symbol&lt;E&gt; *b) &#123;    return std::tuple(((SharedFile&lt;E&gt; *)a-&gt;file)-&gt;soname, a-&gt;ver_idx) &lt;           std::tuple(((SharedFile&lt;E&gt; *)b-&gt;file)-&gt;soname, b-&gt;ver_idx);  &#125;);  // Resize of .gnu.version  ctx.versym-&gt;contents.resize(ctx.dynsym-&gt;symbols.size(), 1);  ctx.versym-&gt;contents[0] = 0;  // Allocate a large enough buffer for .gnu.version_r.  contents.resize((sizeof(ElfVerneed&lt;E&gt;) + sizeof(ElfVernaux&lt;E&gt;)) * syms.size());  // Fill .gnu.version_r.  u8 *buf = (u8 *)&amp;contents[0];  u8 *ptr = buf;  ElfVerneed&lt;E&gt; *verneed = nullptr;  ElfVernaux&lt;E&gt; *aux = nullptr;  u16 veridx = VER_NDX_LAST_RESERVED + ctx.arg.version_definitions.size();  for (i64 i = 0; i &lt; syms.size(); i++) &#123;    if (i == 0 || syms[i - 1]-&gt;file != syms[i]-&gt;file) &#123;      start_group(syms[i]-&gt;file);      add_entry(syms[i]);    &#125; else if (syms[i - 1]-&gt;ver_idx != syms[i]-&gt;ver_idx) &#123;      add_entry(syms[i]);    &#125;    ctx.versym-&gt;contents[syms[i]-&gt;get_dynsym_idx(ctx)] = veridx;  &#125;  // Resize .gnu.version_r to fit to its contents.  contents.resize(ptr - buf);&#125;\n\n处理过程中根据如果是第一个符号或者连续两个符号不是相同的file就start_group。\n要注意ctx.versym-&gt;contents又重新resize了一次，在后面遍历符号的时候又会再次写入，或许是因为verdef是根据选项来决定是否执行的。两次resize实际上size是相同的，而verneed中并非所有符号都会写入versym→content，部分被过滤的符号是没有再次写入的，也就是说被过滤的符号会保留verneed的部分。\n接着来看一下start_group的部分。这个函数中会sh_info递增，处理verneed（关联一个file），并且aux置空。也就是说VerneedSection的sh_info存放的是ElfVerneed的数量。每个ElfVerneed关联了一个文件，以及aux的size。\nauto start_group = [&amp;](InputFile&lt;E&gt; *file) &#123;  this-&gt;shdr.sh_info++;  if (verneed)    verneed-&gt;vn_next = ptr - (u8 *)verneed;  verneed = (ElfVerneed&lt;E&gt; *)ptr;  ptr += sizeof(*verneed);  verneed-&gt;vn_version = 1;  verneed-&gt;vn_file = ctx.dynstr-&gt;find_string(((SharedFile&lt;E&gt; *)file)-&gt;soname);  verneed-&gt;vn_aux = sizeof(ElfVerneed&lt;E&gt;);  aux = nullptr;&#125;;\n\n在add_entry中会递增当前的verneed的计数，将信息填写到ElfVernaux中，并且更新当前aux的指针\nauto add_entry = [&amp;](Symbol&lt;E&gt; *sym) &#123;  verneed-&gt;vn_cnt++;  if (aux)    aux-&gt;vna_next = sizeof(ElfVernaux&lt;E&gt;);  aux = (ElfVernaux&lt;E&gt; *)ptr;  ptr += sizeof(*aux);  std::string_view verstr = sym-&gt;get_version();  aux-&gt;vna_hash = elf_hash(verstr);  aux-&gt;vna_other = ++veridx;  aux-&gt;vna_name = ctx.dynstr-&gt;add_string(verstr);&#125;;\n\ncreate_output_symtab这个过程是用于创建symtab和strtab，创建的时候会实际选择哪些符号要写到文件中。我们熟悉的strip，如果添加了链接选项那么就是在这里开始生效的。\n相关的链接选项在mold中有如下几个\n\n-s, –strip-all             Strip .symtab section\n\n\n–retain-symbols-file FILE  Keep only symbols listed in FILE\n\n\ndiscard_all\n\nstrip大家都很熟悉了，就是去掉生成文件中的symtab段\nretain-symbols-file则是会产生一个符号文件，包含程序的调试信息，也就是说生成的文件说不包含符号信息，所有符号都在符号文件中。\ndiscard_all是丢弃目标程序中未直接使用的信息，其中就包含符号表和调试信息。\n// Compute .symtab and .strtab sizes for each file.create_output_symtab(ctx);\n\ntemplate &lt;typename E&gt;void create_output_symtab(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;compute_symtab_size&quot;);  tbb::parallel_for_each(ctx.chunks, [&amp;](Chunk&lt;E&gt; *chunk) &#123;    chunk-&gt;compute_symtab_size(ctx);  &#125;);  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;compute_symtab_size(ctx);  &#125;);  tbb::parallel_for_each(ctx.dsos, [&amp;](SharedFile&lt;E&gt; *file) &#123;    file-&gt;compute_symtab_size(ctx);  &#125;);&#125;\n\nchunk// Chunk::compute_symtab_size// Some synethetic sections add local symbols to the output.// For example, range extension thunks adds function_name@thunk// symbol for each thunk entry. The following members are used// for such synthesizing symbols.virtual void compute_symtab_size(Context&lt;E&gt; &amp;ctx) &#123;&#125;;\n\n对于chunk来说，不是所有的都需要做这一步操作的。在mold中仅针对OutputSection，Got，Plt，PltGot这几个chunk来处理。\n实际要做的就是遍历所有符号更新其strtab_size以及num_local_symtab（用于标记local符号的数量，也就是这个阶段要计算的symtab size），不论是哪一种chunk都是如此，下面就不再赘述，只贴代码了。\nOutputSection// Compute spaces needed for thunk symbolstemplate &lt;typename E&gt;void OutputSection&lt;E&gt;::compute_symtab_size(Context&lt;E&gt; &amp;ctx) &#123;  if (ctx.arg.strip_all || ctx.arg.retain_symbols_file || ctx.arg.relocatable)    return;  if constexpr (needs_thunk&lt;E&gt;) &#123;    this-&gt;strtab_size = 0;    this-&gt;num_local_symtab = 0;    if constexpr (std::is_same_v&lt;E, ARM32&gt;)      this-&gt;strtab_size = 9; // for &quot;$t&quot;, &quot;$a&quot; and &quot;$d&quot; symbols    for (std::unique_ptr&lt;RangeExtensionThunk&lt;E&gt;&gt; &amp;thunk : thunks) &#123;      // For ARM32, we emit additional symbol &quot;$t&quot;, &quot;$a&quot; and &quot;$d&quot; for      // each thunk to mark the beginning of ARM code.      if constexpr (std::is_same_v&lt;E, ARM32&gt;)        this-&gt;num_local_symtab += thunk-&gt;symbols.size() * 4;      else        this-&gt;num_local_symtab += thunk-&gt;symbols.size();      for (Symbol&lt;E&gt; *sym : thunk-&gt;symbols)        this-&gt;strtab_size += sym-&gt;name().size() + sizeof(&quot;$thunk&quot;);    &#125;  &#125;&#125;\n\n注意这里relocatable的段也不会算入symtab size中，因为地址并非固定，需要加载时重定位，如果把符号放入输出文件中，会使得重定位更加困难，并且加载时会失效。\nneed_thunk：\n\n输出段中代码间隔比较大，直接跳转无法到达的时候需要thunk来中专\n跳转的src和dest指令集不兼容需要thunk翻译\n地址随机化(ASLR: Address space layout randomization)时需要thunk动态计算目标地址\n地址运行时才能确定时需要thunk计算地址\n\n基本上都是一些无法直接跳转的情况，也因此会引入新的符号。而thunk本质上是一个新的代码段，需要符号进行表示，用以被其他代码识别。\ntemplate &lt;typename E&gt;static constexpr bool needs_thunk = requires &#123; E::thunk_size; &#125;;\n\n根据mold代码中的实现，目前需要thunk的是ARM32，ARM64，PPC64V1，PPC64V2\ngottemplate &lt;typename E&gt;void GotSection&lt;E&gt;::compute_symtab_size(Context&lt;E&gt; &amp;ctx) &#123;  if (ctx.arg.strip_all || ctx.arg.retain_symbols_file)    return;  this-&gt;strtab_size = 0;  this-&gt;num_local_symtab = 0;  for (Symbol&lt;E&gt; *sym : got_syms) &#123;    this-&gt;strtab_size += sym-&gt;name().size() + sizeof(&quot;$got&quot;);    this-&gt;num_local_symtab++;  &#125;  for (Symbol&lt;E&gt; *sym : gottp_syms) &#123;    this-&gt;strtab_size += sym-&gt;name().size() + sizeof(&quot;$gottp&quot;);    this-&gt;num_local_symtab++;  &#125;  for (Symbol&lt;E&gt; *sym : tlsgd_syms) &#123;    this-&gt;strtab_size += sym-&gt;name().size() + sizeof(&quot;$tlsgd&quot;);    this-&gt;num_local_symtab++;  &#125;  for (Symbol&lt;E&gt; *sym : tlsdesc_syms) &#123;    this-&gt;strtab_size += sym-&gt;name().size() + sizeof(&quot;$tlsdesc&quot;);    this-&gt;num_local_symtab++;  &#125;  if (tlsld_idx != -1) &#123;    this-&gt;strtab_size += sizeof(&quot;$tlsld&quot;);    this-&gt;num_local_symtab++;  &#125;&#125;\n\nPLTtemplate &lt;typename E&gt;void PltSection&lt;E&gt;::compute_symtab_size(Context&lt;E&gt; &amp;ctx) &#123;  if (ctx.arg.strip_all || ctx.arg.retain_symbols_file)    return;  this-&gt;num_local_symtab = symbols.size();  this-&gt;strtab_size = 0;  for (Symbol&lt;E&gt; *sym : symbols)    this-&gt;strtab_size += sym-&gt;name().size() + sizeof(&quot;$plt&quot;);&#125;\n\nPLTGOTtemplate &lt;typename E&gt;void PltGotSection&lt;E&gt;::compute_symtab_size(Context&lt;E&gt; &amp;ctx) &#123;  if (ctx.arg.strip_all || ctx.arg.retain_symbols_file)    return;  this-&gt;num_local_symtab = symbols.size();  this-&gt;strtab_size = 0;  for (Symbol&lt;E&gt; *sym : symbols)    this-&gt;strtab_size += sym-&gt;name().size() + sizeof(&quot;$pltgot&quot;);&#125;\n\nobj在obj中，主要计算了local和global符号的名字占用的空间，用于更新strtable_size，另外还会更新对应的output_sym_indices\n要注意的是计算名字空间的时候，这里的名字需要使用null结尾，因此size还需要加一。\ntemplate &lt;typename E&gt;void ObjectFile&lt;E&gt;::compute_symtab_size(Context&lt;E&gt; &amp;ctx) &#123;  if (ctx.arg.strip_all)    return;  this-&gt;output_sym_indices.resize(this-&gt;elf_syms.size(), -1);  auto is_alive = [&amp;](Symbol&lt;E&gt; &amp;sym) -&gt; bool &#123;    if (!ctx.arg.gc_sections)      return true;    if (SectionFragment&lt;E&gt; *frag = sym.get_frag())      return frag-&gt;is_alive;    if (InputSection&lt;E&gt; *isec = sym.get_input_section())      return isec-&gt;is_alive;    return true;  &#125;;  // Compute the size of local symbols  if (!ctx.arg.discard_all &amp;&amp; !ctx.arg.strip_all &amp;&amp; !ctx.arg.retain_symbols_file) &#123;    for (i64 i = 1; i &lt; this-&gt;first_global; i++) &#123;      Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[i];      if (is_alive(sym) &amp;&amp; should_write_to_local_symtab(ctx, sym)) &#123;        this-&gt;strtab_size += sym.name().size() + 1;        this-&gt;output_sym_indices[i] = this-&gt;num_local_symtab++;        sym.write_to_symtab = true;      &#125;    &#125;  &#125;  // Compute the size of global symbols.  for (i64 i = this-&gt;first_global; i &lt; this-&gt;elf_syms.size(); i++) &#123;    Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[i];    if (sym.file == this &amp;&amp; is_alive(sym) &amp;&amp;        (!ctx.arg.retain_symbols_file || sym.write_to_symtab)) &#123;      this-&gt;strtab_size += sym.name().size() + 1;      // Global symbols can be demoted to local symbols based on visibility,      // version scripts etc.      if (sym.is_local(ctx))        this-&gt;output_sym_indices[i] = this-&gt;num_local_symtab++;      else        this-&gt;output_sym_indices[i] = this-&gt;num_global_symtab++;      sym.write_to_symtab = true;    &#125;  &#125;&#125;\n\n对于local symbol除了要判断alive之外，还有一个should_write_to_local_symtab的判断，除了更新size外还会更新write_to_symtab\ntemplate &lt;typename E&gt;static bool should_write_to_local_symtab(Context&lt;E&gt; &amp;ctx, Symbol&lt;E&gt; &amp;sym) &#123;  if (sym.get_type() == STT_SECTION)    return false;  // Local symbols are discarded if --discard-local is given or they  // are in a mergeable section. I *believe* we exclude symbols in  // mergeable sections because (1) there are too many and (2) they are  // merged, so their origins shouldn&#x27;t matter, but I don&#x27;t really  // know the rationale. Anyway, this is the behavior of the  // traditional linkers.  if (sym.name().starts_with(&quot;.L&quot;)) &#123;    if (ctx.arg.discard_locals)      return false;    if (InputSection&lt;E&gt; *isec = sym.get_input_section())      if (isec-&gt;shdr().sh_flags &amp; SHF_MERGE)        return false;  &#125;  return true;&#125;\n\n\n-X, –discard-locals        Discard temporary local symbols\n\n本地符号以本地标签为前缀开头，这个标签通常为.L，这里主要是对discard_locals进行处理，另外属于SHF_MERGE的段也不会写到local，根据这里注释的意思是SHF_MERGE段段符号太多了，并且是merge以后的，所以其来源不重要，并且传统的链接器都是这么做的。（我对这块也不了解，只能按照注释所说的来看了）\n还有一个sym.is_local的判断看起来比较疑惑。根据注释所描述，global sym会基于visibility和version scripts等因素变成local sym，比如说设置某个global sym的可见性为特定范围，或者对应的脚本。当全局符号降级为local的时候则不再对外可见，因此不再占用全局符号表的空间。\n代码里的判断是这样的\ntemplate &lt;typename E&gt;inline bool Symbol&lt;E&gt;::is_local(Context&lt;E&gt; &amp;ctx) const &#123;  if (ctx.arg.relocatable)    return esym().st_bind == STB_LOCAL;  return !is_imported &amp;&amp; !is_exported;&#125;\n\n对于relocatable来说，如果st_bind为STB_LOCAL，那么这个符号一定是local的\n对于非imported以及非exported的全局符号，通常是模块内部实现细节使用，不能外部访问。比如说有如下几种情况\n\n静态全局符号，只能模块内部可见（因为静态符号的作用域限定在模块内，因此会被认为是local符号，对全局静态变量的访问只需要通过内存地址，而不需要符号名进行绑定）\n匿名全局符号，没有被显示的使用export或者extern等进行标记，并且对外部是不可见的。比如说在.c中定义了一个全局变量，但是外部无法访问到。\n未使用的全局符号，不会被访问，同时会被优化掉\n\n因此这些情况属于local，记入num_local_symtab\n关于imported和exported的计算过程，可以参考之前第五期的文章，其中有根据可见性来设置exported和imported的部分\nhttps://homura.live/2023/04/29/mold/mold-5-symbol/\ndsotemplate &lt;typename E&gt;void SharedFile&lt;E&gt;::compute_symtab_size(Context&lt;E&gt; &amp;ctx) &#123;  if (ctx.arg.strip_all)    return;  this-&gt;output_sym_indices.resize(this-&gt;elf_syms.size(), -1);  // Compute the size of global symbols.  for (i64 i = this-&gt;first_global; i &lt; this-&gt;symbols.size(); i++) &#123;    Symbol&lt;E&gt; &amp;sym = *this-&gt;symbols[i];    if (sym.file == this &amp;&amp; (sym.is_imported || sym.is_exported) &amp;&amp;        (!ctx.arg.retain_symbols_file || sym.write_to_symtab)) &#123;      this-&gt;strtab_size += sym.name().size() + 1;      this-&gt;output_sym_indices[i] = this-&gt;num_global_symtab++;      sym.write_to_symtab = true;    &#125;  &#125;&#125;\n\n这里的要点就是imported或者exported才需要计入num_global_symtab\neh_frame_construct// .eh_frame is a special section from the linker&#x27;s point of view,// as its contents are parsed and reconstructed by the linker,// unlike other sections that are regarded as opaque bytes.// Here, we construct output .eh_frame contents.ctx.eh_frame-&gt;construct(ctx);\n\n由于eh_frame在mold中自行做了parse的，因此需要再手动构造output中eh_frame的部分，在构造的过程中主要是消除重复的部分，另外各个段是由offset以及idx关联起来的，更新这些信息也是必要的工作。\n关于mold自行parse eh_frame的部分可以参考第二期的内容https://homura.live/2023/04/05/mold/mold-2-read-shared-files/\n在构造的过程主要由如下几部分组成\n\n确保输入存在eh_frame，不存在则无需构造\n删除dead fed，重新设置offset\nuniquify cie，重新设置offset\nfde idx的更新\n重新设置文件中存储的fde的offset\n填充最后的null word\n\ntemplate &lt;typename E&gt;class EhFrameSection : public Chunk&lt;E&gt; &#123;public:  EhFrameSection() &#123;    this-&gt;name = &quot;.eh_frame&quot;;    this-&gt;shdr.sh_type = SHT_PROGBITS;    this-&gt;shdr.sh_flags = SHF_ALLOC;    this-&gt;shdr.sh_addralign = sizeof(Word&lt;E&gt;);  &#125;  void construct(Context&lt;E&gt; &amp;ctx);  void apply_reloc(Context&lt;E&gt; &amp;ctx, const ElfRel&lt;E&gt; &amp;rel, u64 offset, u64 val);  void copy_buf(Context&lt;E&gt; &amp;ctx) override;&#125;;\n\ntemplate &lt;typename E&gt;void EhFrameSection&lt;E&gt;::construct(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;eh_frame&quot;);  // If .eh_frame is missing in all input files, we don&#x27;t want to  // create an output .eh_frame section.  if (std::all_of(ctx.objs.begin(), ctx.objs.end(),                  [](ObjectFile&lt;E&gt; *file) &#123; return file-&gt;cies.empty(); &#125;)) &#123;    this-&gt;shdr.sh_size = 0;    return;  &#125;  // Remove dead FDEs and assign them offsets within their corresponding  // CIE group.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    std::erase_if(file-&gt;fdes, [](FdeRecord&lt;E&gt; &amp;fde) &#123; return !fde.is_alive; &#125;);    i64 offset = 0;    for (FdeRecord&lt;E&gt; &amp;fde : file-&gt;fdes) &#123;      fde.output_offset = offset;      offset += fde.size(*file);    &#125;    file-&gt;fde_size = offset;  &#125;);  // Uniquify CIEs and assign offsets to them.  std::vector&lt;CieRecord&lt;E&gt; *&gt; leaders;  auto find_leader = [&amp;](CieRecord&lt;E&gt; &amp;cie) -&gt; CieRecord&lt;E&gt; * &#123;    for (CieRecord&lt;E&gt; *leader : leaders)      if (cie.equals(*leader))        return leader;    return nullptr;  &#125;;  i64 offset = 0;  for (ObjectFile&lt;E&gt; *file : ctx.objs) &#123;    for (CieRecord&lt;E&gt; &amp;cie : file-&gt;cies) &#123;      if (CieRecord&lt;E&gt; *leader = find_leader(cie)) &#123;        cie.output_offset = leader-&gt;output_offset;      &#125; else &#123;        cie.output_offset = offset;        cie.is_leader = true;        offset += cie.size();        leaders.push_back(&amp;cie);      &#125;    &#125;  &#125;  // Assign FDE offsets to files.  i64 idx = 0;  for (ObjectFile&lt;E&gt; *file : ctx.objs) &#123;    file-&gt;fde_idx = idx;    idx += file-&gt;fdes.size();    file-&gt;fde_offset = offset;    offset += file-&gt;fde_size;  &#125;  // .eh_frame must end with a null word.  this-&gt;shdr.sh_size = offset + 4;&#125;\n\ngdb indexgdb-index是用于加速gdb的段，对应的链接选项\n\n–gdb-index                 Create .gdb_index for faster gdb startup\n\n这边就不具体详细介绍了，有兴趣的可以自行看一下资料\nhttps://sourceware.org/gdb/onlinedocs/gdb/Index-Files.html\n// Handle --gdb-index.if (ctx.arg.gdb_index)  ctx.gdb_index-&gt;construct(ctx);\n\n// This page explains the format of .gdb_index:// https://sourceware.org/gdb/onlinedocs/gdb/Index-Section-Format.htmltemplate &lt;typename E&gt;void GdbIndexSection&lt;E&gt;::construct(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;GdbIndexSection::construct&quot;);  std::atomic_bool has_debug_info = false;  // Read debug sections  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    if (file-&gt;debug_info) &#123;      // Read compilation units from .debug_info.      file-&gt;compunits = read_compunits(ctx, *file);      // Count the number of address areas contained in this file.      file-&gt;num_areas = estimate_address_areas(ctx, *file);      has_debug_info = true;    &#125;  &#125;);  if (!has_debug_info)    return;  // Initialize `area_offset` and `compunits_idx`.  for (i64 i = 0; i &lt; ctx.objs.size() - 1; i++) &#123;    ctx.objs[i + 1]-&gt;area_offset =      ctx.objs[i]-&gt;area_offset + ctx.objs[i]-&gt;num_areas * 20;    ctx.objs[i + 1]-&gt;compunits_idx =      ctx.objs[i]-&gt;compunits_idx + ctx.objs[i]-&gt;compunits.size();  &#125;  // Read .debug_gnu_pubnames and .debug_gnu_pubtypes.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    file-&gt;gdb_names = read_pubnames(ctx, *file);  &#125;);  // Estimate the unique number of pubnames.  HyperLogLog estimator;  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    HyperLogLog e;    for (GdbIndexName &amp;name : file-&gt;gdb_names)      e.insert(name.hash);    estimator.merge(e);  &#125;);  // Uniquify pubnames by inserting all name strings into a concurrent  // hashmap.  map.resize(estimator.get_cardinality() * 2);  tbb::enumerable_thread_specific&lt;i64&gt; num_names;  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (GdbIndexName &amp;name : file-&gt;gdb_names) &#123;      MapEntry *ent;      bool inserted;      std::tie(ent, inserted) = map.insert(name.name, name.hash, &#123;file, name.hash&#125;);      if (inserted)        num_names.local()++;      ObjectFile&lt;E&gt; *old_val = ent-&gt;owner;      while (file-&gt;priority &lt; old_val-&gt;priority &amp;&amp;             !ent-&gt;owner.compare_exchange_weak(old_val, file));      ent-&gt;num_attrs++;      name.entry_idx = ent - map.values;    &#125;  &#125;);  // Assign offsets for names and attributes within each file.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (GdbIndexName &amp;name : file-&gt;gdb_names) &#123;      MapEntry &amp;ent = map.values[name.entry_idx];      if (ent.owner == file) &#123;        ent.attr_offset = file-&gt;attrs_size;        file-&gt;attrs_size += (ent.num_attrs + 1) * 4;        ent.name_offset = file-&gt;names_size;        file-&gt;names_size += name.name.size() + 1;      &#125;    &#125;  &#125;);  // Compute per-file name and attributes offsets.  for (i64 i = 0; i &lt; ctx.objs.size() - 1; i++)    ctx.objs[i + 1]-&gt;attrs_offset =      ctx.objs[i]-&gt;attrs_offset + ctx.objs[i]-&gt;attrs_size;  ctx.objs[0]-&gt;names_offset =    ctx.objs.back()-&gt;attrs_offset + ctx.objs.back()-&gt;attrs_size;  for (i64 i = 0; i &lt; ctx.objs.size() - 1; i++)    ctx.objs[i + 1]-&gt;names_offset =      ctx.objs[i]-&gt;names_offset + ctx.objs[i]-&gt;names_size;  // .gdb_index contains an on-disk hash table for pubnames and  // pubtypes. We aim 75% utilization. As per the format specification,  // It must be a power of two.  i64 num_symtab_entries =    std::max&lt;i64&gt;(bit_ceil(num_names.combine(std::plus()) * 4 / 3), 16);  // Now that we can compute the size of this section.  ObjectFile&lt;E&gt; &amp;last = *ctx.objs.back();  i64 compunits_size = (last.compunits_idx + last.compunits.size()) * 16;  i64 areas_size = last.area_offset + last.num_areas * 20;  i64 offset = sizeof(header);  header.cu_list_offset = offset;  offset += compunits_size;  header.cu_types_offset = offset;  header.areas_offset = offset;  offset += areas_size;  header.symtab_offset = offset;  offset += num_symtab_entries * 8;  header.const_pool_offset = offset;  offset += last.names_offset + last.names_size;  this-&gt;shdr.sh_size = offset;&#125;\n","categories":["Linker"],"tags":["mold","eh_frame","symtab"]},{"title":"mold源码阅读十三 计算shdr以及osec offset","url":"/2023/07/15/mold/mold-13-compute-shdr-and-set-osec-offsets/","content":"\npixiv:94763079 \n\n本期的内容主要是更新section header以及set output section offsets相关。当这些操作结束后，虚拟地址会固定，因此输出文件的memory layout就固定下来了。\ncreate_reloc_sections// If --emit-relocs is given, we&#x27;ll copy relocation sections from input// files to an output file.if (ctx.arg.emit_relocs)  create_reloc_sections(ctx);\n\n这里主要做了2件事情\n\n这里将relocation段从input拷贝到output中，即设置所有OutputSection中reloc_sec\n加入到chunks中\n\ntemplate &lt;typename E&gt;void create_reloc_sections(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;create_reloc_sections&quot;);  // Create .rela.* sections  tbb::parallel_for((i64)0, (i64)ctx.chunks.size(), [&amp;](i64 i) &#123;    if (OutputSection&lt;E&gt; *osec = ctx.chunks[i]-&gt;to_osec())      osec-&gt;reloc_sec.reset(new RelocSection&lt;E&gt;(ctx, *osec));  &#125;);  for (i64 i = 0, end = ctx.chunks.size(); i &lt; end; i++)    if (OutputSection&lt;E&gt; *osec = ctx.chunks[i]-&gt;to_osec())      if (RelocSection&lt;E&gt; *x = osec-&gt;reloc_sec.get())        ctx.chunks.push_back(x);&#125;\n\ntemplate &lt;typename E&gt;class RelocSection : public Chunk&lt;E&gt; &#123;public:  RelocSection(Context&lt;E&gt; &amp;ctx, OutputSection&lt;E&gt; &amp;osec);  void update_shdr(Context&lt;E&gt; &amp;ctx) override;  void copy_buf(Context&lt;E&gt; &amp;ctx) override;private:  OutputSection&lt;E&gt; &amp;output_section;  std::vector&lt;i64&gt; offsets;&#125;;\n\n其中构造rel段的过程主要还是填写shdr的信息\ntemplate &lt;typename E&gt;RelocSection&lt;E&gt;::RelocSection(Context&lt;E&gt; &amp;ctx, OutputSection&lt;E&gt; &amp;osec)  : output_section(osec) &#123;  if constexpr (is_rela&lt;E&gt;) &#123;    this-&gt;name = save_string(ctx, &quot;.rela&quot; + std::string(osec.name));    this-&gt;shdr.sh_type = SHT_RELA;  &#125; else &#123;    this-&gt;name = save_string(ctx, &quot;.rel&quot; + std::string(osec.name));    this-&gt;shdr.sh_type = SHT_REL;  &#125;  this-&gt;shdr.sh_flags = SHF_INFO_LINK;  this-&gt;shdr.sh_addralign = sizeof(Word&lt;E&gt;);  this-&gt;shdr.sh_entsize = sizeof(ElfRel&lt;E&gt;);  // Compute an offset for each input section  offsets.resize(osec.members.size());  auto scan = [&amp;](const tbb::blocked_range&lt;i64&gt; &amp;r, i64 sum, bool is_final) &#123;    for (i64 i = r.begin(); i &lt; r.end(); i++) &#123;      InputSection&lt;E&gt; &amp;isec = *osec.members[i];      if (is_final)        offsets[i] = sum;      sum += isec.get_rels(ctx).size();    &#125;    return sum;  &#125;;  i64 num_entries = tbb::parallel_scan(    tbb::blocked_range&lt;i64&gt;(0, osec.members.size()), 0, scan, std::plus());  this-&gt;shdr.sh_size = num_entries * sizeof(ElfRel&lt;E&gt;);&#125;\n\n构造RelocSection的时候需要计算出rel的数量。每个OutputSection由多个InputSection组成，每个InputSection中又有多个rel段，这里遍历扫描计算出sum的数量。\n这里构造的时候有rel和rela两种情况，它们有如下几种区别\n\nrel只是简单的保存了需要被resolve的地址\nrela保存了额外信息，其中的a是append。具体什么信息\n\n\nSHT_RELA The section holds relocation entries with explicit addends, such as typeElf32_Rela for the 32-bit class of object files. An object file may havemultiple relocation sections. See “Relocation’’ below for details.\n\n另外RelocSection的shdr flag为SHF_INFO_LINK，意义如下\n\nThis section headers sh_info field holds a section header table index.\n\n设置sh_info的过程则是在后续compute_section_headers中\ncompute_section_headers// Compute the section header values for all sections.compute_section_headers(ctx);\n\n这里主要做了这么几件事\n\n所有输出段更新shdr\n移除所有空的chunk\n重新设置所有chunk的index（因为上面移除了chunk，index发生了改变）\nSymtabShndxSection的处理\n再次更新所有的shdr\n\ntemplate &lt;typename E&gt;void compute_section_headers(Context&lt;E&gt; &amp;ctx) &#123;  // Update sh_size for each chunk.  for (Chunk&lt;E&gt; *chunk : ctx.chunks)    chunk-&gt;update_shdr(ctx);  // Remove empty chunks.  std::erase_if(ctx.chunks, [](Chunk&lt;E&gt; *chunk) &#123;    return chunk-&gt;kind() != OUTPUT_SECTION &amp;&amp; chunk-&gt;shdr.sh_size == 0;  &#125;);  // Set section indices.  i64 shndx = 1;  for (i64 i = 0; i &lt; ctx.chunks.size(); i++)    if (ctx.chunks[i]-&gt;kind() != HEADER)      ctx.chunks[i]-&gt;shndx = shndx++;  if (ctx.symtab &amp;&amp; SHN_LORESERVE &lt;= shndx) &#123;    SymtabShndxSection&lt;E&gt; *sec = new SymtabShndxSection&lt;E&gt;;    sec-&gt;shndx = shndx++;    sec-&gt;shdr.sh_link = ctx.symtab-&gt;shndx;    ctx.symtab_shndx = sec;    ctx.chunks.push_back(sec);    ctx.chunk_pool.emplace_back(sec);  &#125;  if (ctx.shdr)    ctx.shdr-&gt;shdr.sh_size = shndx * sizeof(ElfShdr&lt;E&gt;);  // Some types of section header refer other section by index.  // Recompute the section header to fill such fields with correct values.  for (Chunk&lt;E&gt; *chunk : ctx.chunks)    chunk-&gt;update_shdr(ctx);  if (ctx.symtab_shndx) &#123;    i64 symtab_size = ctx.symtab-&gt;shdr.sh_size / sizeof(ElfSym&lt;E&gt;);    ctx.symtab_shndx-&gt;shdr.sh_size = symtab_size * 4;  &#125;&#125;\n\nupdate_shdr大多数synthetic的chunk都有自己的实现，一些类型的section header通过index引用了其他段，因此需要重新计算shdr中对应字段的值\n// Chunk represents a contiguous region in an output file.template &lt;typename E&gt;class Chunk &#123;  ...  virtual void update_shdr(Context&lt;E&gt; &amp;ctx) &#123;&#125;\t...&#125;\n\n比如说OutputPhdr，在这里就需要update\ntemplate &lt;typename E&gt;void OutputPhdr&lt;E&gt;::update_shdr(Context&lt;E&gt; &amp;ctx) &#123;  phdrs = create_phdr(ctx);  this-&gt;shdr.sh_size = phdrs.size() * sizeof(ElfPhdr&lt;E&gt;);&#125;\n\n移除空的chunk这里选择了空的非OutputSection进行移除，判断是否为OutputSection则是根据ChunkKind\ntypedef enum &#123; HEADER, OUTPUT_SECTION, SYNTHETIC &#125; ChunkKind;\n\n其中HEADER是用于output的phdr，ehdr，shdr，chunk默认是SYNTHETIC，也就是说相当于最终只是删除一些空的synthetic的段\n重新更新索引在普通的根据chunk的序列设置索引后有一个SHN_LORESERVE的判断，和SHN_LORESERVE相关的信息有这些\nhttps://man7.org/linux/man-pages/man5/elf.5.html\ne_shnum              This member holds the number of entries in the section              header table.  Thus the product of e_shent size and e_shnum              gives the section header table&#x27;s size in bytes.  If a file              has no section header table,e_shnum holds the value of              zero.              If the number of entries in the section header table is              larger than or equal to SHN_LORESERVE(0xff00), e_shnum              holds the value zero and the real number of entries in the              section header table is held in the sh_size member of the              initial entry in section header table.  Otherwise, the\t\t\t\t\t\t\tsh_size member of the initial entry in the section header              table holds the value zero.e_shstrndx              This member holds the section header table index of the              entry associated with the section name string table.  If              the file has no section name string table, this member              holds the value SHN_UNDEF.              If the index of section name string table section is              larger than or equal to SHN_LORESERVE(0xff00), this              member holds SHN_XINDEX(0xffff) and the real index of the              section name string table section is held in thesh_link              member of the initial entry in section header table.              Otherwise, thesh_link member of the initial entry in              section header table contains the value zero.\n\ne_shnum和e_shstrndx是在EHDR中的信息。首先是shnum，当shdr table，也就是说section的数量超过SHN_LORESERVE的时候，e_shnum会设置为0，实际的数量会保存在shdr table的初始条目中的sh_size的字段里，其他情况这个条目的sh_size的字段是0。\n这里创建了一个SymtabShndxSection，也就是”symtab_shndx”段，这个段保留了特殊的symbol table section index arrry，指向与符号表关联的shdr的索引。\n\n.symtab_shndx\nThis section holds the special symbol table section index array, as described above. The section’s attributes will include the SHF_ALLOC bit if the associated symbol table section does; otherwise that bit will be off.\n\n这个section的sh_type为SHT_SYMTAB_SHNDX\n\nSHT_SYMTAB_SHNDX\nThis section is associated with a section of type SHT_SYMTAB and is required if any of the section header indexes referenced by that symbol table contain the escape value SHN_XINDEX. The section is an array of Elf32_Word values. Each value corresponds one to one with a symbol table entry and appear in the same order as those entries. The values represent the section header indexes against which the symbol table entries are defined. Only if corresponding symbol table entry’s st_shndx field contains the escape value SHN_XINDEX will the matching Elf32_Word hold the actual section header index; otherwise, the entry must be SHN_UNDEF (0).\n\n关于e_shstrndx，这里也设置了ctx中的symtab_shndx。不论是e_shnum还是e_shstrndx都是在后续的过程中实际计算或者使用其信息，等到后面讲的时候再联系前面这些来看。\n创建了SymtabShndxSection后则是设置其基本信息，至此compute_section_headers的过程就结束了。\nset_osec_offsets// Assign offsets to output sectionsi64 filesize = set_osec_offsets(ctx);\n\n设置所有output section的offset，根据是否有section_order会选择不同的排列方式，导致output的offset是不同的。\n主要分为如下几部分\n\n设置段的虚拟地址\n设置段在文件中的offset\n处理phdr并且返回文件的长度\n\n// Assign virtual addresses and file offsets to output sections.template &lt;typename E&gt;i64 set_osec_offsets(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;set_osec_offsets&quot;);  for (;;) &#123;    if (ctx.arg.section_order.empty())      set_virtual_addresses_regular(ctx);    else      set_virtual_addresses_by_order(ctx);    i64 fileoff = set_file_offsets(ctx);    // Assigning new offsets may change the contents and the length    // of the program header, so repeat it until converge.    if (!ctx.phdr)      return fileoff;    i64 sz = ctx.phdr-&gt;shdr.sh_size;    ctx.phdr-&gt;update_shdr(ctx);    if (sz == ctx.phdr-&gt;shdr.sh_size)      return fileoff;  &#125;&#125;\n\nvirtual address设置规则// This function assigns virtual addresses to output sections. Assigning// addresses is a bit tricky because we want to pack sections as tightly// as possible while not violating the constraints imposed by the hardware// and the OS kernel. Specifically, we need to satisfy the following// constraints://// - Memory protection (readable, writable and executable) works at page//   granularity. Therefore, if we want to set different memory attributes//   to two sections, we need to place them into separate pages.//// - The ELF spec requires that a section&#x27;s file offset is congruent to//   its virtual address modulo the page size. For example, a section at//   virtual address 0x401234 on x86-64 (4 KiB, or 0x1000 byte page//   system) can be at file offset 0x3234 or 0x50234 but not at 0x1000.//// We need to insert paddings between sections if we can&#x27;t satisfy the// above constraints without them.//// We don&#x27;t want to waste too much memory and disk space for paddings.// There are a few tricks we can use to minimize paddings as below://// - We want to place sections with the same memory attributes//   contiguous as possible.//// - We can map the same file region to memory more than once. For//   example, we can write code (with R and X bits) and read-only data//   (with R bit) adjacent on file and map it twice as the last page of//   the executable segment and the first page of the read-only data//   segment. This doesn&#x27;t save memory but saves disk space.\n\nmold中不论是指定order还是不指定都是遵循基本的两条规则\n\nmemory protection: 不同attr的section分配到不同的页中，为了满足每个段只有一个attr的条件\nELF spec requires: vaddr的地址的模要是page size，这里会在设置地址的时候进行align，也就是insert padding。\n\n这里提及的ticks:\n\nplace sections with the same memory attributes contiguous as possible. 相同attr尽可能连续。（因为不同attr需要放入不同的页）\nmap the same file region to memory more than once. map两次，因此不会节约内存空间，但是会节约磁盘空间\n\nset_virtual_addresses_regular在设置地址之前，需要先对tls chunk计算一个align。因为tls chunk需要满足如下条件\n\ntls块在vaddr中的起始地址地址需要对齐（普通内存块的要求是相同的）\n当被拷贝到新线程区域时tls_begin的offset也必须对齐。更具体的说，tls会有多个块，而每个块都有一个tls_begin，实际上是这个值要求对齐。\n\n而mold的做法是选择其中最大的align值。\n之后设置了起始地址image_base：默认0x200000\n\n-image-base ADDR Set the base address to a given value\n\nregular设置地址的过程有如下几种情况\n\n跳过不需要alloc的段，因为并不需要加载到内存中\nrelro_padding，一定是满足memory protection的。\n指定section_start，不需要考虑memory protection，因为后面考虑这个的时候会和前一个的段进行比较。假设说连续两个都指定了start，即便不满足，那也是指定的行为。\n满足memory protection的条件。当前chunk和下一个chunk都不是relro_padding的情况，如果两个chunk的attr不同，那么处理。处理后继续执行后面的代码\ntbss：SHF_TLS &amp; SHT_NOBITS\n剩余的情况就是简单的进行align然后更新addr信息\n\ntemplate &lt;typename E&gt;static void set_virtual_addresses_regular(Context&lt;E&gt; &amp;ctx) &#123;  constexpr i64 RELRO = 1LL &lt;&lt; 32;  auto get_flags = [&amp;](Chunk&lt;E&gt; *chunk) &#123;    i64 flags = to_phdr_flags(ctx, chunk);    if (is_relro(ctx, chunk))      return flags | RELRO;    return flags;  &#125;;  // Assign virtual addresses  std::vector&lt;Chunk&lt;E&gt; *&gt; &amp;chunks = ctx.chunks;  u64 addr = ctx.arg.image_base;  // TLS chunks alignments are special: in addition to having their virtual  // addresses aligned, they also have to be aligned when the region of  // tls_begin is copied to a new thread&#x27;s storage area. In other words, their  // offset against tls_begin also has to be aligned.  //  // A good way to achieve this is to take the largest alignment requirement  // of all TLS sections and make tls_begin also aligned to that.  Chunk&lt;E&gt; *first_tls_chunk = nullptr;  u64 tls_alignment = 1;  for (Chunk&lt;E&gt; *chunk : chunks) &#123;    if (chunk-&gt;shdr.sh_flags &amp; SHF_TLS) &#123;      if (!first_tls_chunk)        first_tls_chunk = chunk;      tls_alignment = std::max(tls_alignment, (u64)chunk-&gt;shdr.sh_addralign);    &#125;  &#125;  auto alignment = [&amp;](Chunk&lt;E&gt; *chunk) &#123;    return chunk == first_tls_chunk ? tls_alignment : (u64)chunk-&gt;shdr.sh_addralign;  &#125;;  for (i64 i = 0; i &lt; chunks.size(); i++) &#123;    if (!(chunks[i]-&gt;shdr.sh_flags &amp; SHF_ALLOC))      continue;    // .relro_padding is a padding section to extend a PT_GNU_RELRO    // segment to cover an entire page. Technically, we don&#x27;t need a    // .relro_padding section because we can leave a trailing part of a    // segment an unused space. However, the `strip` command would delete    // such an unused trailing part and make an executable invalid.    // So we add a dummy section.    if (chunks[i] == ctx.relro_padding) &#123;      chunks[i]-&gt;shdr.sh_addr = addr;      chunks[i]-&gt;shdr.sh_size = align_to(addr, ctx.page_size) - addr;      addr += ctx.page_size;      continue;    &#125;    // Handle --section-start first    if (auto it = ctx.arg.section_start.find(chunks[i]-&gt;name);        it != ctx.arg.section_start.end()) &#123;      addr = it-&gt;second;      chunks[i]-&gt;shdr.sh_addr = addr;      addr += chunks[i]-&gt;shdr.sh_size;      continue;    &#125;    // Memory protection works at page size granularity. We need to    // put sections with different memory attributes into different    // pages. We do it by inserting paddings here.    if (i &gt; 0 &amp;&amp; chunks[i - 1] != ctx.relro_padding) &#123;      i64 flags1 = get_flags(chunks[i - 1]);      i64 flags2 = get_flags(chunks[i]);      if (flags1 != flags2) &#123;        switch (ctx.arg.z_separate_code) &#123;        case SEPARATE_LOADABLE_SEGMENTS:          addr = align_to(addr, ctx.page_size);          break;        case SEPARATE_CODE:          if ((flags1 &amp; PF_X) != (flags2 &amp; PF_X)) &#123;            addr = align_to(addr, ctx.page_size);            break;          &#125;          [[fallthrough]];        case NOSEPARATE_CODE:          if (addr % ctx.page_size != 0)            addr += ctx.page_size;          break;        default:          unreachable();        &#125;      &#125;    &#125;    // TLS BSS sections are laid out so that they overlap with the    // subsequent non-tbss sections. Overlapping is fine because a STT_TLS    // segment contains an initialization image for newly-created threads,    // and no one except the runtime reads its contents. Even the runtime    // doesn&#x27;t need a BSS part of a TLS initialization image; it just    // leaves zero-initialized bytes as-is instead of copying zeros.    // So no one really read tbss at runtime.    //    // We can instead allocate a dedicated virtual address space to tbss,    // but that would be just a waste of the address and disk space.    if (is_tbss(chunks[i])) &#123;      u64 addr2 = addr;      for (;;) &#123;        addr2 = align_to(addr2, alignment(chunks[i]));        chunks[i]-&gt;shdr.sh_addr = addr2;        addr2 += chunks[i]-&gt;shdr.sh_size;        if (i + 2 == chunks.size() || !is_tbss(chunks[i + 1]))          break;        i++;      &#125;      continue;    &#125;    addr = align_to(addr, alignment(chunks[i]));    chunks[i]-&gt;shdr.sh_addr = addr;    addr += chunks[i]-&gt;shdr.sh_size;  &#125;&#125;\n\nrelro_paddingrelro_padding用于确保RELRO页对齐，通常无需考虑，但是strip后会删除未使用的尾部空间，导致可执行文件无效。因此这里计算size的过程是用align的size减去当前的地址，之后addr直接递增一个page_size\n关于PT_GNU_RELRO\n\nThe array element specifies the location and size of a segment which may be made read-only after relocation shave been processed.\n\nsection_start根据命令行参数指定对应段的地址为指定的位置，更新当前段地址，并且递增对应段的size。其中提到的命令行参数的介绍\n\n-Tbss=ADDR Set address to .bss-Tdata Set address to .data-Ttext Set address to .text\n\n满足memory protection这里主要是针对相邻两个chunk的attr不同的情况。\n根据链接选项可以分为三类\n\nSEPARATE_LOADABLE_SEGMENTS\n这里只是更新了当前的addr为根据page size进行align的值\n\n\nSEPARATE_CODE\n两个都不是PF_X（执行的权限）的情况下进行align\n\n\nNOSEPARATE_CODE\n如果当前的地址不是整除page size，那么直接增加一个page_size \n\n\n\nto_phdr_flagstemplate &lt;typename E&gt;i64 to_phdr_flags(Context&lt;E&gt; &amp;ctx, Chunk&lt;E&gt; *chunk) &#123;  // All sections are put into a single RWX segment if --omagic  if (ctx.arg.omagic)    return PF_R | PF_W | PF_X;  bool write = (chunk-&gt;shdr.sh_flags &amp; SHF_WRITE);  bool exec = (chunk-&gt;shdr.sh_flags &amp; SHF_EXECINSTR);  // .text is not readable if --execute-only  if (exec &amp;&amp; ctx.arg.execute_only) &#123;    if (write)      Error(ctx) &lt;&lt; &quot;--execute-only is not compatible with writable section: &quot;                 &lt;&lt; chunk-&gt;name;    return PF_X;  &#125;  // .rodata is merged with .text if --no-rosegment  if (!write &amp;&amp; !ctx.arg.rosegment)    exec = true;  return PF_R | (write ? PF_W : 0) | (exec ? PF_X : 0);&#125;\n\n对于页来说attr只有三种，读，写，执行。\n如果指定omagic那么所有段都会塞到一个segment里面，因此其attr都是RWX的\n\n-N, –omagic Do not page align data, do not make text readonly–no-omagic\n\n之后则是根据shdr的flag判断是否可写可执行返回对应的flag\ntbss这里是针对tbss(tls bss) section的处理，其判断逻辑为\ntemplate &lt;typename E&gt;static bool is_tbss(Chunk&lt;E&gt; *chunk) &#123;  return (chunk-&gt;shdr.sh_type == SHT_NOBITS) &amp;&amp; (chunk-&gt;shdr.sh_flags &amp; SHF_TLS);&#125;\n\n.bss的SHT为SHT_NOBITS，并且其Flag为SHF_ALLOC &amp; SHF_WRITE，因此这里只需要判断sh_type是否为SHT_NOBITS以及tls的判断条件就可以确定是否为tbss\n\nsh_offset: The byte offset from the beginning of the file to the first byte in the section. Section type SHT_NOBITS occupies no space in the file. Its sh_offset member locates the conceptual placement in the file.\nsh_size: The section’s size in bytes. Unless the section type is SHT_NOBITS, the section occupies sh_size bytes in the file. A section of type SHT_NOBITS can have a nonzero size, but it occupies no space in the file.\nSHT_NOBITS: Identifies a section that occupies no space in the file but otherwise resembles SHT_PROGBITS. Although this section contains no bytes, the sh_offset member contains the conceptual file offset.\n\ntbss会和后续的非tbss段重叠，因为STT_TLS segment包含了一个初始化image，运行时才会读取，运行时也不需要tbss的初始化image，会保留零初始的变化字节不变，所以运行时不会实际读取。尽管可以单独给tbss分配空间，但是会浪费地址和磁盘空间。\n所以这里的代码单独创建了一个地址进行递增，不会影响到正常更新的地址。\nset_virtual_addresses_by_order根据order的信息来设置地址\nenum &#123; NONE, SECTION, GROUP, ADDR, ALIGN, SYMBOL &#125; type = NONE;\n\n根据SectionOrder信息的不同有如下几种情况处理\n\nSECTION\n计算一个地址赋给对应section的sh_addr以及更新当前的addr\n\n\nGROUP\n针对group段所有成员做和SECTION情况下相同的操作\n\n\nADDR\n当前地址设置为SectionOrder中的值\n\n\nALIGN\n当前地址设置为根据给定value对齐后的地址\n\n\nSYMBOL\n特定符号的地址设置为当前的地址\n\n\n\n针对section的过程具体分为如下几步\n\n判断相邻段的attr，不同则进行将section根据page size进行padding\n根据对应段的align计算一个地址，赋给section并且更新shdr以及当前addr的信息\n找到下一个alloc的段\n\ntemplate &lt;typename E&gt;static void set_virtual_addresses_by_order(Context&lt;E&gt; &amp;ctx) &#123;  std::vector&lt;Chunk&lt;E&gt; *&gt; &amp;c = ctx.chunks;  u64 addr = ctx.arg.image_base;  i64 i = 0;  while (i &lt; c.size() &amp;&amp; !(c[i]-&gt;shdr.sh_flags &amp; SHF_ALLOC))    i++;  auto assign_addr = [&amp;] &#123;    if (i != 0) &#123;      i64 flags1 = to_phdr_flags(ctx, c[i - 1]);      i64 flags2 = to_phdr_flags(ctx, c[i]);      // Memory protection works at page size granularity. We need to      // put sections with different memory attributes into different      // pages. We do it by inserting paddings here.      if (flags1 != flags2) &#123;        switch (ctx.arg.z_separate_code) &#123;        case SEPARATE_LOADABLE_SEGMENTS:          addr = align_to(addr, ctx.page_size);          break;        case SEPARATE_CODE:          if ((flags1 &amp; PF_X) != (flags2 &amp; PF_X))            addr = align_to(addr, ctx.page_size);          break;        default:          break;        &#125;      &#125;    &#125;    addr = align_to(addr, c[i]-&gt;shdr.sh_addralign);    c[i]-&gt;shdr.sh_addr = addr;    addr += c[i]-&gt;shdr.sh_size;    do &#123;      i++;    &#125; while (i &lt; c.size() &amp;&amp; !(c[i]-&gt;shdr.sh_flags &amp; SHF_ALLOC));  &#125;;  for (i64 j = 0; j &lt; ctx.arg.section_order.size(); j++) &#123;    SectionOrder &amp;ord = ctx.arg.section_order[j];    switch (ord.type) &#123;    case SectionOrder::SECTION:      if (i &lt; c.size() &amp;&amp; j == c[i]-&gt;sect_order)        assign_addr();      break;    case SectionOrder::GROUP:      while (i &lt; c.size() &amp;&amp; j == c[i]-&gt;sect_order)        assign_addr();      break;    case SectionOrder::ADDR:      addr = ord.value;      break;    case SectionOrder::ALIGN:      addr = align_to(addr, ord.value);      break;    case SectionOrder::SYMBOL:      get_symbol(ctx, ord.name)-&gt;value = addr;      break;    default:      unreachable();    &#125;  &#125;&#125;\n\nset_file_offsets在设置完段的虚拟地址后，需要设定段在文件中的offset\n\n不需要alloc的情况，仍然需要计算其align更新size。有一些段需要占用空间，但是不需要载入内存，因此前面设置虚拟地址的时候跳过了所有不需要alloc的段，这里计算offset的时候还是要考虑到的。\nbss段不做处理直接跳过\n对offset做一次align。因为有的段可能并没有完整填充一个page size的空间，前面设置虚拟地址的过程并没有使得所有的size都满足page align。\n给alloc section设置尽可能连续的文件的offset，因此会从当前的chunk开始循环设置offset。这样连续加载提高了效率，并且减少碎片空间。不符合条件的情况如下\n非alloc或者是bss\n如果是给定了start_section的段，这样就无法设置连续的offset了，需要单独处理。包含了两种情况\nstart的位置在开始循环的first chunk之前\n相邻两个chunk的size过大，超过了page_size\n\n\n\n\n使用最后一个设置offset的chunk的信息更新offset\n找到下一个alloc的并且非SHT_NOBITS的chunk的index，之后处理下一个chunk\n\n// Assign file offsets to output sections.template &lt;typename E&gt;static i64 set_file_offsets(Context&lt;E&gt; &amp;ctx) &#123;  std::vector&lt;Chunk&lt;E&gt; *&gt; &amp;chunks = ctx.chunks;  u64 fileoff = 0;  i64 i = 0;  while (i &lt; chunks.size()) &#123;    Chunk&lt;E&gt; &amp;first = *chunks[i];    if (!(first.shdr.sh_flags &amp; SHF_ALLOC)) &#123;      fileoff = align_to(fileoff, first.shdr.sh_addralign);      first.shdr.sh_offset = fileoff;      fileoff += first.shdr.sh_size;      i++;      continue;    &#125;    if (first.shdr.sh_type == SHT_NOBITS) &#123;      i++;      continue;    &#125;    if (first.shdr.sh_addralign &gt; ctx.page_size)      fileoff = align_to(fileoff, first.shdr.sh_addralign);    else      fileoff = align_with_skew(fileoff, ctx.page_size, first.shdr.sh_addr);    // Assign ALLOC sections contiguous file offsets as long as they    // are contiguous in memory.    for (;;) &#123;      chunks[i]-&gt;shdr.sh_offset =        fileoff + chunks[i]-&gt;shdr.sh_addr - first.shdr.sh_addr;      i++;      if (i &gt;= chunks.size() ||          !(chunks[i]-&gt;shdr.sh_flags &amp; SHF_ALLOC) ||          chunks[i]-&gt;shdr.sh_type == SHT_NOBITS)        break;      // If --start-section is given, addresses may not increase      // monotonically.      if (chunks[i]-&gt;shdr.sh_addr &lt; first.shdr.sh_addr)        break;      i64 gap_size = chunks[i]-&gt;shdr.sh_addr - chunks[i - 1]-&gt;shdr.sh_addr -                     chunks[i - 1]-&gt;shdr.sh_size;      // If --start-section is given, there may be a large gap between      // sections. We don&#x27;t want to allocate a disk space for a gap if      // exists.      if (gap_size &gt;= ctx.page_size)        break;    &#125;    fileoff = chunks[i - 1]-&gt;shdr.sh_offset + chunks[i - 1]-&gt;shdr.sh_size;    while (i &lt; chunks.size() &amp;&amp;           (chunks[i]-&gt;shdr.sh_flags &amp; SHF_ALLOC) &amp;&amp;           chunks[i]-&gt;shdr.sh_type == SHT_NOBITS)      i++;  &#125;  return fileoff;&#125;\n\nriscv_resize_sections// On RISC-V, branches are encode using multiple instructions so// that they can jump to anywhere in ±2 GiB by default. They may// be replaced with shorter instruction sequences if destinations// are close enough. Do this optimization.if constexpr (is_riscv&lt;E&gt;)  filesize = riscv_resize_sections(ctx);\n\n这里主要是针对riscv跳转在2GB范围的限制做的优化，优化后重新计算shdr\n做了如下几个步骤\n\n获取eflag，unix通常假设RV64GC是baseline，所以这里flag要加上C扩展的flag（EF_RISCV_RVC），而C扩展则是允许压缩指令集，使用2字节编码指令。\n针对resizeable的section进行shrink\n修正符号值\n重新执行上一步的计算offset操作\n\n// Shrink sections by interpreting relocations.//// This operation seems to be optional, because by default longest// instructions are being used. However, calling this function is actually// mandatory because of R_RISCV_ALIGN. R_RISCV_ALIGN is a directive to the// linker to align the location referred to by the relocation to a// specified byte boundary. We at least have to interpret them to satisfy// the alignment constraints.template &lt;typename E&gt;i64 riscv_resize_sections(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;riscv_resize_sections&quot;);  // True if we can use the 2-byte instructions. This is usually true on  // Unix because RV64GC is generally considered the baseline hardware.  bool use_rvc = get_eflags(ctx) &amp; EF_RISCV_RVC;  // Find all the relocations that can be relaxed.  // This step should only shrink sections.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;isec : file-&gt;sections)      if (is_resizable(ctx, isec.get()))        shrink_section(ctx, *isec, use_rvc);  &#125;);  // Fix symbol values.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (Symbol&lt;E&gt; *sym : file-&gt;symbols) &#123;      if (sym-&gt;file != file)        continue;      InputSection&lt;E&gt; *isec = sym-&gt;get_input_section();      if (!isec || isec-&gt;extra.r_deltas.empty())        continue;      std::span&lt;const ElfRel&lt;E&gt;&gt; rels = isec-&gt;get_rels(ctx);      auto it = std::lower_bound(rels.begin(), rels.end(), sym-&gt;value,                                 [&amp;](const ElfRel&lt;E&gt; &amp;r, u64 val) &#123;        return r.r_offset &lt; val;      &#125;);      sym-&gt;value -= isec-&gt;extra.r_deltas[it - rels.begin()];    &#125;  &#125;);  // Re-compute section offset again to finalize them.  compute_section_sizes(ctx);  return set_osec_offsets(ctx);&#125;\n\ntemplate &lt;typename E&gt;u64 get_eflags(Context&lt;E&gt; &amp;ctx) &#123;  if constexpr (std::is_same_v&lt;E, ARM32&gt;)    return EF_ARM_EABI_VER5;  if constexpr (is_riscv&lt;E&gt;) &#123;    std::vector&lt;ObjectFile&lt;E&gt; *&gt; objs = ctx.objs;    std::erase(objs, ctx.internal_obj);    if (objs.empty())      return 0;    u32 ret = objs[0]-&gt;get_ehdr().e_flags;    for (i64 i = 1; i &lt; objs.size(); i++)      if (objs[i]-&gt;get_ehdr().e_flags &amp; EF_RISCV_RVC)        ret |= EF_RISCV_RVC;    return ret;  &#125;  if constexpr (std::is_same_v&lt;E, PPC64V2&gt;)    return 2;  return 0;&#125;\n\nresizabletemplate &lt;typename E&gt;static bool is_resizable(Context&lt;E&gt; &amp;ctx, InputSection&lt;E&gt; *isec) &#123;  return isec &amp;&amp; isec-&gt;is_alive &amp;&amp; (isec-&gt;shdr().sh_flags &amp; SHF_ALLOC) &amp;&amp;         (isec-&gt;shdr().sh_flags &amp; SHF_EXECINSTR);&#125;\n\nSHF_EXECINSTR\n\nThis section contains executable machine instructions.\n\n需要分配空间且包含可执行的指令的段才能进行resize。\nshrink针对所有的rel进行操作，最终为了更新delta值（shrink的size），用于后续fix symbol value\n\n更新delta的值\n\nR_RISCV_ALIGN是用于align的部分，指向nop指令，因此需要删除nop指令使得对齐到指定alignment\n\n针对一些无法优化的情况进行跳过\n\n未开启relax选项\n其中的relax选项是\n\n–relax Optimize instructions (default)–no-relax\n\n\n搜寻到了最后一个re l\n\n另外下一个rel如果不是RELAX的也无法进行优化\n\n\n\n跳过internal_obj，因为synthetic符号还没有最终值，只有确定值的情况才能进行shrink\n\n针对不同rel type进行处理，添加不同的delta值。这里细节不再深究\n\n减少当前input section的size并且更新deltas的值\n\n\n// Scan relocations to shrink sections.template &lt;typename E&gt;static void shrink_section(Context&lt;E&gt; &amp;ctx, InputSection&lt;E&gt; &amp;isec, bool use_rvc) &#123;  std::span&lt;const ElfRel&lt;E&gt;&gt; rels = isec.get_rels(ctx);  isec.extra.r_deltas.resize(rels.size() + 1);  i64 delta = 0;  for (i64 i = 0; i &lt; rels.size(); i++) &#123;    const ElfRel&lt;E&gt; &amp;r = rels[i];    Symbol&lt;E&gt; &amp;sym = *isec.file.symbols[r.r_sym];    isec.extra.r_deltas[i] = delta;    // Handling R_RISCV_ALIGN is mandatory.    //    // R_RISCV_ALIGN refers NOP instructions. We need to eliminate some    // or all of the instructions so that the instruction that immediately    // follows the NOPs is aligned to a specified alignment boundary.    if (r.r_type == R_RISCV_ALIGN) &#123;      // The total bytes of NOPs is stored to r_addend, so the next      // instruction is r_addend away.      u64 loc = isec.get_addr() + r.r_offset - delta;      u64 next_loc = loc + r.r_addend;      u64 alignment = bit_ceil(r.r_addend + 1);      assert(alignment &lt;= (1 &lt;&lt; isec.p2align));      delta += next_loc - align_to(loc, alignment);      continue;    &#125;    // Handling other relocations is optional.    if (!ctx.arg.relax || i == rels.size() - 1 ||        rels[i + 1].r_type != R_RISCV_RELAX)      continue;    // Linker-synthesized symbols haven&#x27;t been assigned their final    // values when we are shrinking sections because actual values can    // be computed only after we fix the file layout. Therefore, we    // assume that relocations against such symbols are always    // non-relaxable.    if (sym.file == ctx.internal_obj)      continue;    switch (r.r_type) &#123;    case R_RISCV_CALL:    case R_RISCV_CALL_PLT: &#123;      // These relocations refer an AUIPC + JALR instruction pair to      // allow to jump to anywhere in PC ± 2 GiB. If the jump target is      // close enough to PC, we can use C.J, C.JAL or JAL instead.      i64 dist = compute_distance(ctx, sym, isec, r);      if (dist &amp; 1)        break;      std::string_view contents = isec.contents;      i64 rd = get_rd(*(ul32 *)(contents.data() + r.r_offset + 4));      if (rd == 0 &amp;&amp; sign_extend(dist, 11) == dist &amp;&amp; use_rvc) &#123;        // If rd is x0 and the jump target is within ±2 KiB, we can use        // C.J, saving 6 bytes.        delta += 6;      &#125; else if (rd == 1 &amp;&amp; sign_extend(dist, 11) == dist &amp;&amp; use_rvc &amp;&amp; !E::is_64) &#123;        // If rd is x1 and the jump target is within ±2 KiB, we can use        // C.JAL. This is RV32 only because C.JAL is RV32-only instruction.        delta += 6;      &#125; else if (sign_extend(dist, 20) == dist) &#123;        // If the jump target is within ±1 MiB, we can use JAL.        delta += 4;      &#125;      break;    &#125;    case R_RISCV_HI20: &#123;      // If the upper 20 bits are all zero, we can remove LUI.      // The corresponding instructions referred by LO12_I/LO12_S      // relocations will use the zero register instead.      i64 val = sym.get_addr(ctx);      if (sign_extend(val, 11) == val)        delta += 4;      break;    &#125;    case R_RISCV_TPREL_HI20:    case R_RISCV_TPREL_ADD: &#123;      // These relocations are used to materialize the upper 20 bits of      // an address relative to the thread pointer as follows:      //      //  lui  a5,%tprel_hi(foo)         # R_RISCV_TPREL_HI20 (symbol)      //  add  a5,a5,tp,%tprel_add(foo)  # R_RISCV_TPREL_ADD (symbol)      //      // Then thread-local variable `foo` is accessed with a 12-bit offset      // like this:      //      //  sw   t0,%tprel_lo(foo)(a5)     # R_RISCV_TPREL_LO12_S (symbol)      //      // However, if the offset is ±2 KiB, we don&#x27;t need to materialize      // the upper 20 bits in a register. We can instead access the      // thread-local variable directly with TP like this:      //      //  sw   t0,%tprel_lo(foo)(tp)      //      // Here, we remove `lui` and `add` if the offset is within ±2 KiB.      i64 val = sym.get_addr(ctx) + r.r_addend - ctx.tp_addr;      if (sign_extend(val, 11) == val)        delta += 4;      break;    &#125;    &#125;  &#125;  isec.extra.r_deltas[rels.size()] = delta;  isec.sh_size -= deltfa;&#125;template &lt;typename E&gt; requires is_riscv&lt;E&gt;struct InputSectionExtras&lt;E&gt; &#123;  std::vector&lt;i32&gt; r_deltas;&#125;;\n","categories":["Linker"],"tags":["mold","shdr"]},{"title":"赶雨","url":"/2023/07/22/Life/catch-the-rain/","content":"清晨七点四十左右，一如既往的在没睡够的情况下就醒来了，听着窗外激烈的雨声，随机看了下天气预报，多个平台的预告基本上都是十点十一点左右停雨。躺在床上犹豫了一下，随即爬了起来收拾东西去颐和园拍雨中的荷花。洗漱以及略微吃了点东西后开始打滴滴，或许是雨天的缘故没有人接单，还要排队许久，等不下去的我又打开了高德地图，这里有更多的平台可以选，随着不断等待与加价，最终总算打到了车。一出门感受到的是与季节不符的冷风，但急着赶时间也就没有回去加衣服。上车后，看着窗外的雨，心里只有祈祷雨能继续下着，并且能下的大些，但天气并不能如我所愿，到目的地后雨已经很小了。\n下车后，首先映入眼帘的是打翻了的调色盘一般的人群，各种颜色的伞和雨衣密密麻麻的排在一起。今天有许多郊游的学生以及旅游团，不知是否周末的早上都是如此，我还是第一次这么早来北京的景点。入口的里外都是这样满满的人，靠近后只会感到吵闹与拥堵，但不过也没有时间和心思去关注这些，趁着还在下小雨直奔目的地谐趣园。\n此时的谐趣园虽然也有一些零零散散的人，但相对于外面显得格外安静。有不少老法师举着相机在拍荷花，也有用手机在旁边拍摄以及录制视频的人。在寻找机位的时候，还看到有一个摄影师在拍一个看起来六七十的并且穿着旗袍的老奶奶，看起来非常开心。另外还遇到一个老法师来问我关于网上卖照片的事情，他说他的照片总是审核不过，平台说尺寸太小需要更大分辨率等等。之后则是安心的当了一阵老法师，可惜的是雨天换镜头不方便就没带长焦，减少了几分老法师的成分。\n以下分享的照片很多裁剪以及除雾等处理后会更合适，这里就懒得裁了，（别说裁了，我都懒得分类入库了，卡里还有上千张照片），总之不要在意那么多细节\n\n\n\n\n拍了一阵觉得也没什么可拍的了，便赶向了我最喜欢的一片“秘境”。这里的人总是最少的，以树林为依靠，以湖水为伴，格外有氛围，我喜欢天气凉爽的时候坐在这附近看书，但是人多的时候体验还是比较差的。\n\n\n\n喜欢坐在这看书\n\n在这里拍了一阵，打算到十七孔桥的位置，原路返回的过程中看到了一只猫，偶然拍到了我认为很棒的照片。\n\n之后则是穿越人群，一路走过去。此时没有太多想拍的，因此更多的注意力放到了对周围的环境，对清新空气的感受上。多久没感受到这种雨后的清新空气了呢，虽然前两天也有在下雨，但是却未曾有这样的感受，也许平时一直在紧绷着神经吧。但我也并没有花费更多的注意力在身体和环境交互的感受上，而是继续寻找着下一个拍摄目标，毕竟这才是我今天最初的目的。路途中看到/听到各种各样的人：和旅伴走散了的旅者，生气的斥责孩子的家长，同样目的的老法师，专心解说的导游，等等。\n没多久看到了这样的荷花，但没带长焦只能进行裁剪了，此时的我又萌生了几千块买一个备用机挂长焦的想法，就不用换镜头了。\n\n焦段的极限了，需要稍微裁减一下才行，起码旁边两朵花不能在画面里\n\n远处朦胧的景色，有一种别样的风味\n\n雨天的佛香阁\n这个时候已经很困了，决定打道回府。看到这里的船还开着，能够避免回头再走一遍，加上从未体验过，选择了付款坐船。由于是雨天的缘故，座位都被雨水浸湿，勉强擦干了坐下。在船上感受到凌烈的“寒风”，但没多久注意力便放到了观看周围的景色上，有没有什么可以拍摄的目标。\n\n路途也不远，没多久也就到了目的地。之后走走停停，看到了一处小的荷花，但是在下一个船坞里。不得已买了船票，但是告诉我不能提前进船坞里面等，而且船来了要立刻坐，不允许等待，结果最后只拍了一张照片，实在是让人很生气。最后到了北宫门的苏州街这里，人还是蛮多的，不论是从上面进入颐和园的人，还是下面在狭窄的道路上观光的人。\n\n费半天劲才拍到的一个荷花\n\n游船的目的地\n在这附近想拍那种雨滴拉线的效果，奈何雨滴太小了，只有偶尔房檐滴下的大雨滴才能拍出，而这雨滴又没法和荷花拍到一起，最后还是放弃了。\n走之前在这里倒是看到一个小插曲，一个游客问旁边卖伞的人价格，听到价格后回答这个价格美团上都能买到两个了，之后轻微争论了两句觉得不值就走了。在出了北门到了地铁站前，看到几步路就有一个卖伞、雨衣的，不知他们能否卖出去。\n","categories":["Life"],"tags":["颐和园","摄影"]},{"title":"mold源码阅读十四 固定文件layout以及创建输出","url":"/2023/07/26/mold/mold-14-fix-file-layout-and-create-output/","content":"mold源码阅读十四 fix file layout and create output\npixiv:92848682 \n\n上一期主要讲解了shdr计算更新的部分以及osec offset的设置，这期则是做链接最后的工作。上期在对段shrink的时候也提到部分synthetic的符号值还未固定，本期就会从这部分的值提起，之后则是对debug_section进行压缩，同时文件的大小也会产生变化，到了这里整个文件内部的layout以及文件的大小也就固定了。\n接下来就是创建output file，将数据实际拷贝到对应的输出buffer中，实际apply relocate，以及一些其他的操作，此时链接的产物已经完成了。\nfix_synthetic_symbols// Set actual addresses to linker-synthesized symbols.fix_synthetic_symbols(ctx);\n\n这里主要的任务是设置synthetic符号的值以及对应的origin。设置值的过程大部分都是设置对应chunk的shdr，origin则是标识符号来源，其他细节暂且不进行介绍，后面会单独一期详细查看所有synthetic的符号以及synthetic的section在整个链接过程中的行为，符号的具体作用等。\ntemplate &lt;typename E&gt;void fix_synthetic_symbols(Context&lt;E&gt; &amp;ctx) &#123;  auto start = [](Symbol&lt;E&gt; *sym, auto &amp;chunk, i64 bias = 0) &#123;    if (sym &amp;&amp; chunk) &#123;      sym-&gt;set_output_section(chunk);      sym-&gt;value = chunk-&gt;shdr.sh_addr + bias;    &#125;  &#125;;  auto stop = [](Symbol&lt;E&gt; *sym, auto &amp;chunk) &#123;    if (sym &amp;&amp; chunk) &#123;      sym-&gt;set_output_section(chunk);      sym-&gt;value = chunk-&gt;shdr.sh_addr + chunk-&gt;shdr.sh_size;    &#125;  &#125;;  std::vector&lt;Chunk&lt;E&gt; *&gt; sections;  for (Chunk&lt;E&gt; *chunk : ctx.chunks)    if (chunk-&gt;kind() != HEADER &amp;&amp; (chunk-&gt;shdr.sh_flags &amp; SHF_ALLOC))      sections.push_back(chunk);  auto find = [&amp;](std::string name) -&gt; Chunk&lt;E&gt; * &#123;    for (Chunk&lt;E&gt; *chunk : sections)      if (chunk-&gt;name == name)        return chunk;    return nullptr;  &#125;;  // __bss_start  if (Chunk&lt;E&gt; *chunk = find(&quot;.bss&quot;))    start(ctx.__bss_start, chunk);  if (ctx.ehdr &amp;&amp; (ctx.ehdr-&gt;shdr.sh_flags &amp; SHF_ALLOC)) &#123;    ctx.__ehdr_start-&gt;set_output_section(sections[0]);    ctx.__ehdr_start-&gt;value = ctx.ehdr-&gt;shdr.sh_addr;    ctx.__executable_start-&gt;set_output_section(sections[0]);    ctx.__executable_start-&gt;value = ctx.ehdr-&gt;shdr.sh_addr;  &#125;  if (ctx.__dso_handle) &#123;    ctx.__dso_handle-&gt;set_output_section(sections[0]);    ctx.__dso_handle-&gt;value = sections[0]-&gt;shdr.sh_addr;  &#125;  // __rel_iplt_start and __rel_iplt_end. These symbols need to be  // defined in a statically-linked non-relocatable executable because  // such executable lacks the .dynamic section and thus there&#x27;s no way  // to find ifunc relocations other than these symbols.  //  // We don&#x27;t want to set values to these symbols if we are creating a  // static PIE due to a glibc bug. Static PIE has a dynamic section.  // If we set values to these symbols in a static PIE, glibc attempts  // to run ifunc initializers twice, with the second attempt with wrong  // function addresses, causing a segmentation fault.  if (ctx.reldyn &amp;&amp; ctx.arg.is_static &amp;&amp; !ctx.arg.pie) &#123;    stop(ctx.__rel_iplt_start, ctx.reldyn);    stop(ctx.__rel_iplt_end, ctx.reldyn);    ctx.__rel_iplt_start-&gt;value -=      get_num_irelative_relocs(ctx) * sizeof(ElfRel&lt;E&gt;);  &#125;  // __&#123;init,fini&#125;_array_&#123;start,end&#125;  for (Chunk&lt;E&gt; *chunk : sections) &#123;    switch (chunk-&gt;shdr.sh_type) &#123;    case SHT_INIT_ARRAY:      start(ctx.__init_array_start, chunk);      stop(ctx.__init_array_end, chunk);      break;    case SHT_PREINIT_ARRAY:      start(ctx.__preinit_array_start, chunk);      stop(ctx.__preinit_array_end, chunk);      break;    case SHT_FINI_ARRAY:      start(ctx.__fini_array_start, chunk);      stop(ctx.__fini_array_end, chunk);      break;    &#125;  &#125;  // _end, _etext, _edata and the like  for (Chunk&lt;E&gt; *chunk : sections) &#123;    if (chunk-&gt;shdr.sh_flags &amp; SHF_ALLOC) &#123;      stop(ctx._end, chunk);      stop(ctx.end, chunk);    &#125;    if (chunk-&gt;shdr.sh_flags &amp; SHF_EXECINSTR) &#123;      stop(ctx._etext, chunk);      stop(ctx.etext, chunk);    &#125;    if (chunk-&gt;shdr.sh_type != SHT_NOBITS &amp;&amp;        (chunk-&gt;shdr.sh_flags &amp; SHF_ALLOC)) &#123;      stop(ctx._edata, chunk);      stop(ctx.edata, chunk);    &#125;  &#125;  // _DYNAMIC  start(ctx._DYNAMIC, ctx.dynamic);  // _GLOBAL_OFFSET_TABLE_. I don&#x27;t know why, but for the sake of  // compatibility with existing code, it must be set to the beginning of  // .got.plt instead of .got only on i386 and x86-64.  if constexpr (is_x86&lt;E&gt;)    start(ctx._GLOBAL_OFFSET_TABLE_, ctx.gotplt);  else    start(ctx._GLOBAL_OFFSET_TABLE_, ctx.got);  // _PROCEDURE_LINKAGE_TABLE_. We need this on SPARC.  start(ctx._PROCEDURE_LINKAGE_TABLE_, ctx.plt);  // _TLS_MODULE_BASE_. This symbol is used to obtain the address of  // the TLS block in the TLSDESC model. I believe GCC and Clang don&#x27;t  // create a reference to it, but Intel compiler seems to be using  // this symbol.  if (ctx._TLS_MODULE_BASE_) &#123;    ctx._TLS_MODULE_BASE_-&gt;set_output_section(sections[0]);    ctx._TLS_MODULE_BASE_-&gt;value = ctx.tls_begin;  &#125;  // __GNU_EH_FRAME_HDR  start(ctx.__GNU_EH_FRAME_HDR, ctx.eh_frame_hdr);  // RISC-V&#x27;s __global_pointer$  if (ctx.__global_pointer) &#123;    if (Chunk&lt;E&gt; *chunk = find(&quot;.sdata&quot;)) &#123;      start(ctx.__global_pointer, chunk, 0x800);    &#125; else &#123;      ctx.__global_pointer-&gt;set_output_section(sections[0]);      ctx.__global_pointer-&gt;value = 0;    &#125;  &#125;  // ARM32&#x27;s __exidx_&#123;start,end&#125;  if (ctx.__exidx_start) &#123;    if (Chunk&lt;E&gt; *chunk = find(&quot;.ARM.exidx&quot;)) &#123;      start(ctx.__exidx_start, chunk);      stop(ctx.__exidx_end, chunk);    &#125;  &#125;  // PPC64&#x27;s &quot;.TOC.&quot; symbol.  if (ctx.TOC) &#123;    if (Chunk&lt;E&gt; *chunk = find(&quot;.got&quot;)) &#123;      start(ctx.TOC, chunk, 0x8000);    &#125; else if (Chunk&lt;E&gt; *chunk = find(&quot;.toc&quot;)) &#123;      start(ctx.TOC, chunk, 0x8000);    &#125; else &#123;      ctx.TOC-&gt;set_output_section(sections[0]);      ctx.TOC-&gt;value = 0;    &#125;  &#125;  // __start_ and __stop_ symbols  for (Chunk&lt;E&gt; *chunk : sections) &#123;    if (std::optional&lt;std::string&gt; name = get_start_stop_name(ctx, *chunk)) &#123;      start(get_symbol(ctx, save_string(ctx, &quot;__start_&quot; + *name)), chunk);      stop(get_symbol(ctx, save_string(ctx, &quot;__stop_&quot; + *name)), chunk);      if (ctx.arg.physical_image_base) &#123;        u64 paddr = to_paddr(ctx, chunk-&gt;shdr.sh_addr);        Symbol&lt;E&gt; *x = get_symbol(ctx, save_string(ctx, &quot;__phys_start_&quot; + *name));        x-&gt;set_output_section(chunk);        x-&gt;value = paddr;        Symbol&lt;E&gt; *y = get_symbol(ctx, save_string(ctx, &quot;__phys_stop_&quot; + *name));        y-&gt;set_output_section(chunk);        y-&gt;value = paddr + chunk-&gt;shdr.sh_size;      &#125;    &#125;  &#125;  // --defsym=sym=value symbols  for (i64 i = 0; i &lt; ctx.arg.defsyms.size(); i++) &#123;    Symbol&lt;E&gt; *sym = ctx.arg.defsyms[i].first;    std::variant&lt;Symbol&lt;E&gt; *, u64&gt; val = ctx.arg.defsyms[i].second;    if (u64 *addr = std::get_if&lt;u64&gt;(&amp;val)) &#123;      sym-&gt;origin = 0;      sym-&gt;value = *addr;      continue;    &#125;    Symbol&lt;E&gt; *sym2 = std::get&lt;Symbol&lt;E&gt; *&gt;(val);    if (!sym2-&gt;file) &#123;      Error(ctx) &lt;&lt; &quot;--defsym: undefined symbol: &quot; &lt;&lt; *sym2;      continue;    &#125;    sym-&gt;value = sym2-&gt;value;    sym-&gt;origin = sym2-&gt;origin;    sym-&gt;visibility = sym2-&gt;visibility.load();  &#125;  // --section-order symbols  for (SectionOrder &amp;ord : ctx.arg.section_order)    if (ord.type == SectionOrder::SYMBOL)      get_symbol(ctx, ord.name)-&gt;set_output_section(sections[0]);&#125;\n\ncompress_debug_sections// If --compress-debug-sections is given, compress .debug_* sections// using zlib.if (ctx.arg.compress_debug_sections != COMPRESS_NONE)  filesize = compress_debug_sections(ctx);\n\n压缩了所有debug相关的section，由于压缩了section，段的size发生改变，offset也会随之改变，因此之后还需要更新相关表的shdr，最后还会返回新的file size。具体的压缩过程这里就不详细看了。\n\n–compress-debug-sections [none,zlib,zlib-gabi,zstd]                                        Compress .debug_* sections\n\ntemplate &lt;typename E&gt;i64 compress_debug_sections(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;compress_debug_sections&quot;);  tbb::parallel_for((i64)0, (i64)ctx.chunks.size(), [&amp;](i64 i) &#123;    Chunk&lt;E&gt; &amp;chunk = *ctx.chunks[i];    if ((chunk.shdr.sh_flags &amp; SHF_ALLOC) || chunk.shdr.sh_size == 0 ||        !chunk.name.starts_with(&quot;.debug&quot;))      return;    Chunk&lt;E&gt; *comp = new CompressedSection&lt;E&gt;(ctx, chunk);    ctx.chunk_pool.emplace_back(comp);    ctx.chunks[i] = comp;  &#125;);  ctx.shstrtab-&gt;update_shdr(ctx);  if (ctx.ehdr)    ctx.ehdr-&gt;update_shdr(ctx);  if (ctx.shdr)    ctx.shdr-&gt;update_shdr(ctx);  return set_osec_offsets(ctx);&#125;\n\ntemplate &lt;typename E&gt;class CompressedSection : public Chunk&lt;E&gt; &#123;public:  CompressedSection(Context&lt;E&gt; &amp;ctx, Chunk&lt;E&gt; &amp;chunk);  void copy_buf(Context&lt;E&gt; &amp;ctx) override;  u8 *get_uncompressed_data() override &#123; return uncompressed.get(); &#125;private:  ElfChdr&lt;E&gt; chdr = &#123;&#125;;  std::unique_ptr&lt;Compressor&gt; compressed;  std::unique_ptr&lt;u8[]&gt; uncompressed;&#125;;\n\ntemplate &lt;typename E&gt;CompressedSection&lt;E&gt;::CompressedSection(Context&lt;E&gt; &amp;ctx, Chunk&lt;E&gt; &amp;chunk) &#123;  assert(chunk.name.starts_with(&quot;.debug&quot;));  this-&gt;name = chunk.name;  uncompressed.reset(new u8[chunk.shdr.sh_size]);  chunk.write_to(ctx, uncompressed.get());  switch (ctx.arg.compress_debug_sections) &#123;  case COMPRESS_ZLIB:    chdr.ch_type = ELFCOMPRESS_ZLIB;    compressed.reset(new ZlibCompressor(uncompressed.get(), chunk.shdr.sh_size));    break;  case COMPRESS_ZSTD:    chdr.ch_type = ELFCOMPRESS_ZSTD;    compressed.reset(new ZstdCompressor(uncompressed.get(), chunk.shdr.sh_size));    break;  default:    unreachable();  &#125;  chdr.ch_size = chunk.shdr.sh_size;  chdr.ch_addralign = chunk.shdr.sh_addralign;  this-&gt;shdr = chunk.shdr;  this-&gt;shdr.sh_flags |= SHF_COMPRESSED;  this-&gt;shdr.sh_addralign = 1;  this-&gt;shdr.sh_size = sizeof(chdr) + compressed-&gt;compressed_size;  this-&gt;shndx = chunk.shndx;  // We don&#x27;t need to keep the original data unless --gdb-index is given.  if (!ctx.arg.gdb_index)    uncompressed.reset(nullptr);&#125;\n\ncreate output file到这个位置，所有memory以及file中的layout都就固定了，因此开始准备创建输出文件并且将chunks拷贝到output file中。\n// Create an output filectx.output_file =  OutputFile&lt;Context&lt;E&gt;&gt;::open(ctx, ctx.arg.output, filesize, 0777);ctx.buf = ctx.output_file-&gt;buf;\n\n这里的filesize是上一期的set_osec中最后得到的offset（如果经过压缩过debug_section那么就是上面压缩后的filesize），0777则是文件的权限\ncopy chunks// Copy input sections to the output file and apply relocations.copy_chunks(ctx);\n\n这里遍历了所有chunk并且每个都拷贝到输出文件中。但是先拷贝了非rel的段，之后才拷贝所有rel段，因为在copy output section的时候会apply relocate，在rel_offset的位置写入数据，而在后面rel段copy_buf的时候还可能向同样的地址写入数据。\n这里会介绍一下一些主要的copy_chunk的实现（RelSection，OutputSection），其他synthetic符号的细节等到之后的文章再看细节。\n// Copy chunks to an output filetemplate &lt;typename E&gt;void copy_chunks(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;copy_chunks&quot;);  auto copy = [&amp;](Chunk&lt;E&gt; &amp;chunk) &#123;    std::string name = chunk.name.empty() ? &quot;(header)&quot; : std::string(chunk.name);    Timer t2(ctx, name, &amp;t);    chunk.copy_buf(ctx);  &#125;;  // For --relocatable and --emit-relocs, we want to copy non-relocation  // sections first. This is because REL-type relocation sections (as  // opposed to RELA-type) stores relocation addends to target sections.  tbb::parallel_for_each(ctx.chunks, [&amp;](Chunk&lt;E&gt; *chunk) &#123;    if (chunk-&gt;shdr.sh_type != (is_rela&lt;E&gt; ? SHT_RELA : SHT_REL))      copy(*chunk);  &#125;);  tbb::parallel_for_each(ctx.chunks, [&amp;](Chunk&lt;E&gt; *chunk) &#123;    if (chunk-&gt;shdr.sh_type == (is_rela&lt;E&gt; ? SHT_RELA : SHT_REL))      copy(*chunk);  &#125;);  report_undef_errors(ctx);  if constexpr (std::is_same_v&lt;E, ARM32&gt;)    fixup_arm_exidx_section(ctx);&#125;\n\nrel的查找过程不论是否为rel的output section，都需要有一个定位rel具体位置的过程。首先会先找到所在的osec，一个osec由多个输入的isec组成，每个isec根据其offset在osec中定位，找到具体的isec后则是找到相关的所有rel段\nOutputSection对nobits的output section写入数据\n\n拷贝InputSections的内容到output file中\ncopy数据本身\napply relocate\n\n\n清理掉trail padding（设置为0）\n处理thunk\n\ntemplate &lt;typename E&gt;void OutputSection&lt;E&gt;::copy_buf(Context&lt;E&gt; &amp;ctx) &#123;  if (this-&gt;shdr.sh_type != SHT_NOBITS)    write_to(ctx, ctx.buf + this-&gt;shdr.sh_offset);&#125;template &lt;typename E&gt;void OutputSection&lt;E&gt;::write_to(Context&lt;E&gt; &amp;ctx, u8 *buf) &#123;  auto clear = [&amp;](u8 *loc, i64 size) &#123;    // As a special case, .init and .fini are filled with NOPs because the    // runtime executes the sections as if they were a single function.    // .init and .fini are superceded by .init_array and .fini_array and    // being actively used only on s390x though.    if (is_s390x&lt;E&gt; &amp;&amp; (this-&gt;name == &quot;.init&quot; || this-&gt;name == &quot;.fini&quot;)) &#123;      for (i64 i = 0; i &lt; size; i += 2)        *(ub16 *)(loc + i) = 0x0700; // nop    &#125; else &#123;      memset(loc, 0, size);    &#125;  &#125;;  tbb::parallel_for((i64)0, (i64)members.size(), [&amp;](i64 i) &#123;    // Copy section contents to an output file    InputSection&lt;E&gt; &amp;isec = *members[i];    isec.write_to(ctx, buf + isec.offset);    // Clear trailing padding    u64 this_end = isec.offset + isec.sh_size;    u64 next_start = (i == members.size() - 1) ?      (u64)this-&gt;shdr.sh_size : members[i + 1]-&gt;offset;    clear(buf + this_end, next_start - this_end);  &#125;);  if constexpr (needs_thunk&lt;E&gt;) &#123;    tbb::parallel_for_each(thunks,                           [&amp;](std::unique_ptr&lt;RangeExtensionThunk&lt;E&gt;&gt; &amp;thunk) &#123;      thunk-&gt;copy_buf(ctx);    &#125;);  &#125;&#125;\n\n\n根据osec→shdr.sh_addr以及isec.offset定位到具体的isec，并对每一个isec进行write_to\ntemplate &lt;typename E&gt;void InputSection&lt;E&gt;::write_to(Context&lt;E&gt; &amp;ctx, u8 *buf) &#123;  if (shdr().sh_type == SHT_NOBITS || sh_size == 0)    return;  // Copy data  if constexpr (is_riscv&lt;E&gt;) &#123;    copy_contents_riscv(ctx, buf);  &#125; else &#123;    uncompress_to(ctx, buf);  &#125;  // Apply relocations  if (!ctx.arg.relocatable) &#123;    if (shdr().sh_flags &amp; SHF_ALLOC)      apply_reloc_alloc(ctx, buf);    else      apply_reloc_nonalloc(ctx, buf);  &#125;&#125;template &lt;typename E&gt;void InputSection&lt;E&gt;::uncompress_to(Context&lt;E&gt; &amp;ctx, u8 *buf) &#123;  if (!(shdr().sh_flags &amp; SHF_COMPRESSED) || uncompressed) &#123;    memcpy(buf, contents.data(), contents.size());    return;  &#125;  if (contents.size() &lt; sizeof(ElfChdr&lt;E&gt;))    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: corrupted compressed section&quot;;  ElfChdr&lt;E&gt; &amp;hdr = *(ElfChdr&lt;E&gt; *)&amp;contents[0];  std::string_view data = contents.substr(sizeof(ElfChdr&lt;E&gt;));  switch (hdr.ch_type) &#123;  case ELFCOMPRESS_ZLIB: &#123;    unsigned long size = sh_size;    if (::uncompress(buf, &amp;size, (u8 *)data.data(), data.size()) != Z_OK)      Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: uncompress failed&quot;;    assert(size == sh_size);    break;  &#125;  case ELFCOMPRESS_ZSTD:    if (ZSTD_decompress(buf, sh_size, (u8 *)data.data(), data.size()) != sh_size)      Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: ZSTD_decompress failed&quot;;    break;  default:    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: unsupported compression type: 0x&quot;               &lt;&lt; std::hex &lt;&lt; hdr.ch_type;  &#125;&#125;\n\ncopy数据针对非压缩的数据则直接copy，对于压缩后的数据则进行解压\ntemplate &lt;typename E&gt;void InputSection&lt;E&gt;::uncompress_to(Context&lt;E&gt; &amp;ctx, u8 *buf) &#123;  if (!(shdr().sh_flags &amp; SHF_COMPRESSED) || uncompressed) &#123;    memcpy(buf, contents.data(), contents.size());    return;  &#125;  if (contents.size() &lt; sizeof(ElfChdr&lt;E&gt;))    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: corrupted compressed section&quot;;  ElfChdr&lt;E&gt; &amp;hdr = *(ElfChdr&lt;E&gt; *)&amp;contents[0];  std::string_view data = contents.substr(sizeof(ElfChdr&lt;E&gt;));  switch (hdr.ch_type) &#123;  case ELFCOMPRESS_ZLIB: &#123;    unsigned long size = sh_size;    if (::uncompress(buf, &amp;size, (u8 *)data.data(), data.size()) != Z_OK)      Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: uncompress failed&quot;;    assert(size == sh_size);    break;  &#125;  case ELFCOMPRESS_ZSTD:    if (ZSTD_decompress(buf, sh_size, (u8 *)data.data(), data.size()) != sh_size)      Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: ZSTD_decompress failed&quot;;    break;  default:    Fatal(ctx) &lt;&lt; *this &lt;&lt; &quot;: unsupported compression type: 0x&quot;               &lt;&lt; std::hex &lt;&lt; hdr.ch_type;  &#125;&#125;\n\napply reloc alloc这个过程也是因架构而异的，下面的代码来自rv\n针对每个rel段的位置填写对应符号的地址，因为ElfRel本身不携带这个信息，对应的参数只有r_offset, r_type, r_sym，rela还会多一个r_addend。但根据rel类型的不同计算的方式也有些许的差异。具体的不同rel的计算方式要参考官方的文档，比如说rv的\nhttps://github.com/riscv-non-isa/riscv-elf-psabi-doc/blob/master/riscv-elf.adoc\n针对每个rel写入的loc的位置如图所示为osec→shdr.sh_addr + isec.offset + r_offset，不过注意这里的r_offset根据架构不同，可能会进行特殊处理，比如说下面rv的实现中有一个rel.r_offset - get_r_delta(i)的过程（之前shrink过程导致这里需要再处理delta的值）\n另外apply_reloc_noalloc的过程也是类似，不再重复展示\n\ntemplate &lt;typename E&gt;void InputSection&lt;E&gt;::apply_reloc_alloc(Context&lt;E&gt; &amp;ctx, u8 *base) &#123;  std::span&lt;const ElfRel&lt;E&gt;&gt; rels = get_rels(ctx);  ElfRel&lt;E&gt; *dynrel = nullptr;  if (ctx.reldyn)    dynrel = (ElfRel&lt;E&gt; *)(ctx.buf + ctx.reldyn-&gt;shdr.sh_offset +                           file.reldyn_offset + this-&gt;reldyn_offset);  auto get_r_delta = [&amp;](i64 idx) &#123;    return extra.r_deltas.empty() ? 0 : extra.r_deltas[idx];  &#125;;  for (i64 i = 0; i &lt; rels.size(); i++) &#123;    const ElfRel&lt;E&gt; &amp;rel = rels[i];    if (rel.r_type == R_NONE || rel.r_type == R_RISCV_RELAX)      continue;    Symbol&lt;E&gt; &amp;sym = *file.symbols[rel.r_sym];    i64 r_offset = rel.r_offset - get_r_delta(i);    i64 removed_bytes = get_r_delta(i + 1) - get_r_delta(i);    u8 *loc = base + r_offset;    auto check = [&amp;](i64 val, i64 lo, i64 hi) &#123;      if (val &lt; lo || hi &lt;= val)        Error(ctx) &lt;&lt; *this &lt;&lt; &quot;: relocation &quot; &lt;&lt; rel &lt;&lt; &quot; against &quot;                   &lt;&lt; sym &lt;&lt; &quot; out of range: &quot; &lt;&lt; val &lt;&lt; &quot; is not in [&quot;                   &lt;&lt; lo &lt;&lt; &quot;, &quot; &lt;&lt; hi &lt;&lt; &quot;)&quot;;    &#125;;#define S   sym.get_addr(ctx)#define A   rel.r_addend#define P   (get_addr() + r_offset)#define G   (sym.get_got_idx(ctx) * sizeof(Word&lt;E&gt;))#define GOT ctx.got-&gt;shdr.sh_addr    switch (rel.r_type) &#123;    case R_RISCV_32:      if constexpr (E::is_64)        *(U32&lt;E&gt; *)loc = S + A;      else        apply_dyn_absrel(ctx, sym, rel, loc, S, A, P, dynrel);      break;    case R_RISCV_64:      assert(E::is_64);      apply_dyn_absrel(ctx, sym, rel, loc, S, A, P, dynrel);      break;    case R_RISCV_BRANCH: &#123;      i64 val = S + A - P;      check(val, -(1 &lt;&lt; 12), 1 &lt;&lt; 12);      write_btype(loc, val);      break;    &#125;    case R_RISCV_JAL: &#123;      i64 val = S + A - P;      check(val, -(1 &lt;&lt; 20), 1 &lt;&lt; 20);      write_jtype(loc, val);      break;    &#125;    case R_RISCV_CALL:    case R_RISCV_CALL_PLT: &#123;      u32 rd = get_rd(*(ul32 *)(contents.data() + rel.r_offset + 4));      if (removed_bytes == 4) &#123;        // auipc + jalr -&gt; jal        *(ul32 *)loc = (rd &lt;&lt; 7) | 0b1101111;        write_jtype(loc, S + A - P);      &#125; else if (removed_bytes == 6 &amp;&amp; rd == 0) &#123;        // auipc + jalr -&gt; c.j        *(ul16 *)loc = 0b101&#x27;00000000000&#x27;01;        write_cjtype(loc, S + A - P);      &#125; else if (removed_bytes == 6 &amp;&amp; rd == 1) &#123;        // auipc + jalr -&gt; c.jal        assert(!E::is_64);        *(ul16 *)loc = 0b001&#x27;00000000000&#x27;01;        write_cjtype(loc, S + A - P);      &#125; else &#123;        assert(removed_bytes == 0);        u64 val = sym.esym().is_undef_weak() ? 0 : S + A - P;        check(val, -(1LL &lt;&lt; 31), 1LL &lt;&lt; 31);        write_utype(loc, val);        write_itype(loc + 4, val);      &#125;      break;    &#125;    case R_RISCV_GOT_HI20:      *(ul32 *)loc = G + GOT + A - P;      break;    case R_RISCV_TLS_GOT_HI20:      *(ul32 *)loc = sym.get_gottp_addr(ctx) + A - P;      break;    case R_RISCV_TLS_GD_HI20:      *(ul32 *)loc = sym.get_tlsgd_addr(ctx) + A - P;      break;    case R_RISCV_PCREL_HI20:      if (sym.esym().is_undef_weak()) &#123;        // Calling an undefined weak symbol does not make sense.        // We make such call into an infinite loop. This should        // help debugging of a faulty program.        *(ul32 *)loc = 0;      &#125; else &#123;        *(ul32 *)loc = S + A - P;      &#125;      break;    case R_RISCV_HI20: &#123;      i64 val = S + A;      if (removed_bytes == 0) &#123;        check(val, -(1LL &lt;&lt; 31), 1LL &lt;&lt; 31);        write_utype(loc, val);      &#125; else &#123;        assert(removed_bytes == 4);        assert(sign_extend(val, 11) == val);      &#125;      break;    &#125;    case R_RISCV_LO12_I:    case R_RISCV_LO12_S: &#123;      i64 val = S + A;      if (rel.r_type == R_RISCV_LO12_I)        write_itype(loc, val);      else        write_stype(loc, val);      // Rewrite `lw t1, 0(t0)` with `lw t1, 0(x0)` if the address is      // accessible relative to the zero register. If the upper 20 bits      // are all zero, the corresponding LUI might have been removed.      if (sign_extend(val, 11) == val)        set_rs1(loc, 0);      break;    &#125;    case R_RISCV_TPREL_HI20:      assert(removed_bytes == 0 || removed_bytes == 4);      if (removed_bytes == 0)        write_utype(loc, S + A - ctx.tp_addr);      break;    case R_RISCV_TPREL_ADD:      break;    case R_RISCV_TPREL_LO12_I:    case R_RISCV_TPREL_LO12_S: &#123;      i64 val = S + A - ctx.tp_addr;      if (rel.r_type == R_RISCV_TPREL_LO12_I)        write_itype(loc, val);      else        write_stype(loc, val);      // Rewrite `lw t1, 0(t0)` with `lw t1, 0(tp)` if the address is      // directly accessible using tp. tp is x4.      if (sign_extend(val, 11) == val)        set_rs1(loc, 4);      break;    &#125;    case R_RISCV_ADD8:      loc += S + A;      break;    case R_RISCV_ADD16:      *(U16&lt;E&gt; *)loc += S + A;      break;    case R_RISCV_ADD32:      *(U32&lt;E&gt; *)loc += S + A;      break;    case R_RISCV_ADD64:      *(U64&lt;E&gt; *)loc += S + A;      break;    case R_RISCV_SUB8:      loc -= S + A;      break;    case R_RISCV_SUB16:      *(U16&lt;E&gt; *)loc -= S + A;      break;    case R_RISCV_SUB32:      *(U32&lt;E&gt; *)loc -= S + A;      break;    case R_RISCV_SUB64:      *(U64&lt;E&gt; *)loc -= S + A;      break;    case R_RISCV_ALIGN: &#123;      // A R_RISCV_ALIGN is followed by a NOP sequence. We need to remove      // zero or more bytes so that the instruction after R_RISCV_ALIGN is      // aligned to a given alignment boundary.      //      // We need to guarantee that the NOP sequence is valid after byte      // removal (e.g. we can&#x27;t remove the first 2 bytes of a 4-byte NOP).      // For the sake of simplicity, we always rewrite the entire NOP sequence.      i64 padding_bytes = rel.r_addend - removed_bytes;      assert((padding_bytes &amp; 1) == 0);      i64 i = 0;      for (; i &lt;= padding_bytes - 4; i += 4)        *(ul32 *)(loc + i) = 0x0000&#x27;0013; // nop      if (i &lt; padding_bytes)        *(ul16 *)(loc + i) = 0x0001;      // c.nop      break;    &#125;    case R_RISCV_RVC_BRANCH: &#123;      i64 val = S + A - P;      check(val, -(1 &lt;&lt; 8), 1 &lt;&lt; 8);      write_cbtype(loc, val);      break;    &#125;    case R_RISCV_RVC_JUMP: &#123;      i64 val = S + A - P;      check(val, -(1 &lt;&lt; 11), 1 &lt;&lt; 11);      write_cjtype(loc, val);      break;    &#125;    case R_RISCV_SUB6:      *loc = (*loc &amp; 0b1100&#x27;0000) | ((*loc - (S + A)) &amp; 0b0011&#x27;1111);      break;    case R_RISCV_SET6:      *loc = (*loc &amp; 0b1100&#x27;0000) | ((S + A) &amp; 0b0011&#x27;1111);      break;    case R_RISCV_SET8:      *loc = S + A;      break;    case R_RISCV_SET16:      *(U16&lt;E&gt; *)loc = S + A;      break;    case R_RISCV_SET32:      *(U32&lt;E&gt; *)loc = S + A;      break;    case R_RISCV_32_PCREL:      *(U32&lt;E&gt; *)loc = S + A - P;      break;    case R_RISCV_PCREL_LO12_I:    case R_RISCV_PCREL_LO12_S:      // These relocations are handled in the next loop.      break;    default:      unreachable();    &#125;#undef S#undef A#undef P#undef G#undef GOT  &#125;  // Handle PC-relative LO12 relocations. In the above loop, pcrel HI20  // relocations overwrote instructions with full 32-bit values to allow  // their corresponding pcrel LO12 relocations to read their values.  for (i64 i = 0; i &lt; rels.size(); i++) &#123;    switch (rels[i].r_type) &#123;    case R_RISCV_PCREL_LO12_I:    case R_RISCV_PCREL_LO12_S: &#123;      Symbol&lt;E&gt; &amp;sym = *file.symbols[rels[i].r_sym];      assert(sym.get_input_section() == this);      u8 *loc = base + rels[i].r_offset - get_r_delta(i);      u32 val = *(ul32 *)(base + sym.value);      if (rels[i].r_type == R_RISCV_PCREL_LO12_I)        write_itype(loc, val);      else        write_stype(loc, val);    &#125;    &#125;  &#125;  // Restore the original instructions pcrel HI20 relocations overwrote.  for (i64 i = 0; i &lt; rels.size(); i++) &#123;    switch (rels[i].r_type) &#123;    case R_RISCV_GOT_HI20:    case R_RISCV_PCREL_HI20:    case R_RISCV_TLS_GOT_HI20:    case R_RISCV_TLS_GD_HI20: &#123;      u8 *loc = base + rels[i].r_offset - get_r_delta(i);      u32 val = *(ul32 *)loc;      memcpy(loc, contents.data() + rels[i].r_offset, 4);      write_utype(loc, val);    &#125;    &#125;  &#125;&#125;\n\nrel\nrel会先计算r_offset，值为对应osec的地址 + isec.offset + r_offset（来自输入的elf文件），r_type则保留，这个计算方式和上面apply_reloc的过程完全一致\n之后的处理过程如下\n\n针对section外的符号直接获取其index，以及addend的信息并且设置值\n\nsection的符号则获取到对应的osec的shndx，设置addend为对应section的offset + get_addend()。其中get_addend的过程因架构而异。\n\n针对SectionFragment则符号更改为output_section.shndx，原始符号或许是指向合并为fragment之前，由于已经merge到了一起，因此只能指向fragment所在的osec\n针对普通section则直接设置为对应osec的shndx\n\n\n设置r_addend\n\nrela直接设置前面计算的addend\n\n如果是relocatable，那么会根据rel的type在base + rel.r_offset的位置写入addend的值。这个base与上面的r_offset不同，但实际上都是指向最初计算的r_offset的位置，只是这里要写入文件，因此要以文件的buf为起点，而不是0。关于write_addend也是类似于get_addend，\nrelocatable的情况最后write_addend的位置，也就是之前apply_reloc_alloc写入信息的位置，针对没有addend的情况只能将信息覆盖到这里\n\n\n\n\ntemplate &lt;typename E&gt;void RelocSection&lt;E&gt;::copy_buf(Context&lt;E&gt; &amp;ctx) &#123;  auto write = [&amp;](ElfRel&lt;E&gt; &amp;out, InputSection&lt;E&gt; &amp;isec, const ElfRel&lt;E&gt; &amp;rel) &#123;    memset(&amp;out, 0, sizeof(out));    out.r_offset = isec.output_section-&gt;shdr.sh_addr + isec.offset + rel.r_offset;    out.r_type = rel.r_type;    Symbol&lt;E&gt; &amp;sym = *isec.file.symbols[rel.r_sym];    if (sym.esym().st_type == STT_SECTION) &#123;      i64 addend;      if (SectionFragment&lt;E&gt; *frag = sym.get_frag()) &#123;        out.r_sym = frag-&gt;output_section.shndx;        addend = frag-&gt;offset + sym.value + get_addend(isec, rel);      &#125; else &#123;        InputSection&lt;E&gt; *target = sym.get_input_section();        OutputSection&lt;E&gt; *osec = target-&gt;output_section;        out.r_sym = osec-&gt;shndx;        addend = get_addend(isec, rel) + target-&gt;offset;      &#125;      if constexpr (is_rela&lt;E&gt;) &#123;        out.r_addend = addend;      &#125; else if (ctx.arg.relocatable) &#123;        u8 *base = ctx.buf + isec.output_section-&gt;shdr.sh_offset + isec.offset;        write_addend(base + rel.r_offset, addend, rel);      &#125;    &#125; else &#123;      if (sym.sym_idx)        out.r_sym = sym.get_output_sym_idx(ctx);      if constexpr (is_rela&lt;E&gt;)        out.r_addend = rel.r_addend;    &#125;  &#125;;  tbb::parallel_for((i64)0, (i64)output_section.members.size(), [&amp;](i64 i) &#123;    ElfRel&lt;E&gt; *buf = (ElfRel&lt;E&gt; *)(ctx.buf + this-&gt;shdr.sh_offset) + offsets[i];    InputSection&lt;E&gt; &amp;isec = *output_section.members[i];    std::span&lt;const ElfRel&lt;E&gt;&gt; rels = isec.get_rels(ctx);    for (i64 j = 0; j &lt; rels.size(); j++)      write(buf[j], isec, rels[j]);  &#125;);&#125;template &lt;typename E&gt;inline i64 Symbol&lt;E&gt;::get_output_sym_idx(Context&lt;E&gt; &amp;ctx) const &#123;  i64 i = file-&gt;output_sym_indices[sym_idx];  assert(i != -1);  if (is_local(ctx))    return file-&gt;local_symtab_idx + i;  return file-&gt;global_symtab_idx + i;&#125;\n\ngdb_index// Some part of .gdb_index couldn&#x27;t be computed until other debug// sections are complete. We have complete debug sections now, so// write the rest of .gdb_index.if (ctx.gdb_index)  ctx.gdb_index-&gt;write_address_areas(ctx);\n\n这里主要是gdb_index写入实际地址，因为在这里符号的地址都已经确定。\ntemplate &lt;typename E&gt;void GdbIndexSection&lt;E&gt;::write_address_areas(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;GdbIndexSection::write_address_areas&quot;);  if (this-&gt;shdr.sh_size == 0)    return;  u8 *base = ctx.buf + this-&gt;shdr.sh_offset;  for (Chunk&lt;E&gt; *chunk : ctx.chunks) &#123;    std::string_view name = chunk-&gt;name;    if (name == &quot;.debug_info&quot;)      ctx.debug_info = chunk;    if (name == &quot;.debug_abbrev&quot;)      ctx.debug_abbrev = chunk;    if (name == &quot;.debug_ranges&quot;)      ctx.debug_ranges = chunk;    if (name == &quot;.debug_addr&quot;)      ctx.debug_addr = chunk;    if (name == &quot;.debug_rnglists&quot;)      ctx.debug_rnglists = chunk;  &#125;  assert(ctx.debug_info);  assert(ctx.debug_abbrev);  struct Entry &#123;    ul64 start;    ul64 end;    ul32 attr;  &#125;;  // Read address ranges from debug sections and copy them to .gdb_index.  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    if (!file-&gt;debug_info)      return;    Entry *begin = (Entry *)(base + header.areas_offset + file-&gt;area_offset);    Entry *e = begin;    u64 offset = file-&gt;debug_info-&gt;offset;    for (i64 i = 0; i &lt; file-&gt;compunits.size(); i++) &#123;      std::vector&lt;u64&gt; addrs = read_address_areas(ctx, *file, offset);      for (i64 j = 0; j &lt; addrs.size(); j += 2) &#123;        // Skip an empty range        if (addrs[j] == addrs[j + 1])          continue;        // Gdb crashes if there are entries with address 0.        if (addrs[j] == 0)          continue;        assert(e &lt; begin + file-&gt;num_areas);        e-&gt;start = addrs[j];        e-&gt;end = addrs[j + 1];        e-&gt;attr = file-&gt;compunits_idx + i;        e++;      &#125;      offset += file-&gt;compunits[i].size();    &#125;    // Fill trailing null entries with dummy values because gdb    // crashes if there are entries with address 0.    u64 filler;    if (e == begin)      filler = ctx.etext-&gt;get_addr(ctx) - 1;    else      filler = e[-1].start;    for (; e &lt; begin + file-&gt;num_areas; e++) &#123;      e-&gt;start = filler;      e-&gt;end = filler;      e-&gt;attr = file-&gt;compunits_idx;    &#125;  &#125;);&#125;\n\nsort reldyn// Dynamic linker works better with sorted .rela.dyn section,// so we sort them.ctx.reldyn-&gt;sort(ctx);\n\n对rel段排序，这么做的原理如注释所描述\n// This is the reason why we sort dynamic relocations. Quote from// https://www.airs.com/blog/archives/186:////   The dynamic linker in glibc uses a one element cache when processing//   relocs: if a relocation refers to the same symbol as the previous//   relocation, then the dynamic linker reuses the value rather than//   looking up the symbol again. Thus the dynamic linker gets the best//   results if the dynamic relocations are sorted so that all dynamic//   relocations for a given dynamic symbol are adjacent.////   Other than that, the linker sorts together all relative relocations,//   which don&#x27;t have symbols. Two relative relocations, or two relocations//   against the same symbol, are sorted by the address in the output//   file. This tends to optimize paging and caching when there are two//   references from the same page.//// We group IFUNC relocations at the end of .rel.dyn because we want to// apply all the other relocations before running user-supplied ifunc// resolver functions.\n\n大意如下：\n\nglibc的linker有一个cache，如果一个relocation和前面的relocation引用了相同符号，那么会直2接引用值，而不是重新查找。\nlinker会将所有没有符号的relative relocation排序，两个relative relocation或者两个针对同一个符号的relocation会按照文件地址排序。存在同一页面的两个引用时可以优化分页和缓存\n\n对于一个符号有多个relocation的情况，比如说一个全局变量被不同代码段引用多次，那么每个引用都需要生成一个条目。另外没有符号的relative relocation，是指重定位的记录中不包含符号，只包含偏移，比如说基于pc的相对寻址。\nmold在.rel.dyn的末尾对IFUNC重定位进行分组,因为希望在运行用户提供的ifunc解析函数之前应用所有其他重定位。\n排序规则基于如下三个方面\n\n根据r_type计算的rank\nr_sym：重定位的符号在符号表中的索引\nr_offset：重定位的位置\n\ntemplate &lt;typename E&gt;void RelDynSection&lt;E&gt;::sort(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;sort_dynamic_relocs&quot;);  ElfRel&lt;E&gt; *begin = (ElfRel&lt;E&gt; *)(ctx.buf + this-&gt;shdr.sh_offset);  ElfRel&lt;E&gt; *end = (ElfRel&lt;E&gt; *)((u8 *)begin + this-&gt;shdr.sh_size);  auto get_rank = [](u32 r_type) &#123;    switch (r_type) &#123;    case E::R_RELATIVE: return 0;    case E::R_IRELATIVE: return 2;    default: return 1;    &#125;  &#125;;  tbb::parallel_sort(begin, end, [&amp;](const ElfRel&lt;E&gt; &amp;a, const ElfRel&lt;E&gt; &amp;b) &#123;    return std::tuple(get_rank(a.r_type), a.r_sym, a.r_offset) &lt;           std::tuple(get_rank(b.r_type), b.r_sym, b.r_offset);  &#125;);&#125;\n\nclear_padding// Zero-clear paddings between sectionsclear_padding(ctx);\n\n将bss外的段中所有padding的空间设置为0，上一期只是设置offset来保证padding，但是padding范围内的值是未定的，在osec写到文件后再来将这部分空间置零。\n   \t\t      size          padding  |                     |         |offset                       next_offset\n\ntemplate &lt;typename E&gt;void clear_padding(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;clear_padding&quot;);  auto zero = [&amp;](Chunk&lt;E&gt; *chunk, i64 next_start) &#123;    i64 pos = chunk-&gt;shdr.sh_offset + chunk-&gt;shdr.sh_size;    memset(ctx.buf + pos, 0, next_start - pos);  &#125;;  std::vector&lt;Chunk&lt;E&gt; *&gt; chunks = ctx.chunks;  std::erase_if(chunks, [](Chunk&lt;E&gt; *chunk) &#123;    return chunk-&gt;shdr.sh_type == SHT_NOBITS;  &#125;);  for (i64 i = 1; i &lt; chunks.size(); i++)    zero(chunks[i - 1], chunks[i]-&gt;shdr.sh_offset);  zero(chunks.back(), ctx.output_file-&gt;filesize);&#125;\n\nbuildid// .note.gnu.build-id section contains a cryptographic hash of the// entire output file. Now that we wrote everything except build-id,// we can compute it.if (ctx.buildid)  ctx.buildid-&gt;write_buildid(ctx);\n\n计算文件哈希，这对于elf来说并非必要的部分，但是有哈希可以用于校验文件是否完整是否有问题等，无需重新计算。\n实际写入到header后的位置，因此写入地址是shdr.sh_offset + HEADER_SIZE。对于几种实现算法这里不再讨论。\n\n–build-id [none,md5,sha1,sha256,uuid,HEXSTRING]                                     Generate build ID–no-build-id\n\ntemplate &lt;typename E&gt;class BuildIdSection : public Chunk&lt;E&gt; &#123;public:  BuildIdSection() &#123;    this-&gt;name = &quot;.note.gnu.build-id&quot;;    this-&gt;shdr.sh_type = SHT_NOTE;    this-&gt;shdr.sh_flags = SHF_ALLOC;    this-&gt;shdr.sh_addralign = 4;    this-&gt;shdr.sh_size = 1;  &#125;  void update_shdr(Context&lt;E&gt; &amp;ctx) override;  void copy_buf(Context&lt;E&gt; &amp;ctx) override;  void write_buildid(Context&lt;E&gt; &amp;ctx);  static constexpr i64 HEADER_SIZE = 16;&#125;;\n\ntemplate &lt;typename E&gt;void BuildIdSection&lt;E&gt;::write_buildid(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;build_id&quot;);  switch (ctx.arg.build_id.kind) &#123;  case BuildId::HEX:    write_vector(ctx.buf + this-&gt;shdr.sh_offset + HEADER_SIZE,                 ctx.arg.build_id.value);    return;  case BuildId::HASH:    // Modern x86 processors have purpose-built instructions to accelerate    // SHA256 computation, and SHA256 outperforms MD5 on such computers.    // So, we always compute SHA256 and truncate it if smaller digest was    // requested.    compute_sha256(ctx, this-&gt;shdr.sh_offset + HEADER_SIZE);    return;  case BuildId::UUID: &#123;    std::array&lt;u8, 16&gt; uuid = get_uuid_v4();    memcpy(ctx.buf + this-&gt;shdr.sh_offset + HEADER_SIZE, uuid.data(), 16);    return;  &#125;  default:    unreachable();  &#125;&#125;\n\nclose file// Close the output file. This is the end of the linker&#x27;s main job.ctx.output_file-&gt;close(ctx);\n\n至此文件已经成功输出，只剩下最后的一些收尾工作，就留到下期再讲。\n","categories":["Linker"],"tags":["mold","rel"]},{"title":"mold源码阅读十五 最后的收尾工作","url":"/2023/07/29/mold/mold-15-end/","content":"\npixiv:92983280 \n\n这一期没什么比较硬的重点知识，仅做为补全整个过程来补充，可以轻松愉快的食用。\nwrite dependency// Handle --dependency-fileif (!ctx.arg.dependency_file.empty())  write_dependency_file(ctx);\n\n将所有依赖，也就是链接过程中所有读取的文件，并且写入到文件中。可以用于确认某个文件是否被加入到链接过程中。\n\n–dependency-file=FILE      Write Makefile-style dependency rules to FILE\n\n// Write Makefile-style dependency rules to a file specified by// --dependency-file. This is analogous to the compiler&#x27;s -M flag.template &lt;typename E&gt;void write_dependency_file(Context&lt;E&gt; &amp;ctx) &#123;  std::vector&lt;std::string&gt; deps;  std::unordered_set&lt;std::string&gt; seen;  for (std::unique_ptr&lt;MappedFile&lt;Context&lt;E&gt;&gt;&gt; &amp;mf : ctx.mf_pool)    if (!mf-&gt;parent)      if (std::string path = path_clean(mf-&gt;name); seen.insert(path).second)        deps.push_back(path);  std::ofstream out;  out.open(ctx.arg.dependency_file);  if (out.fail())    Fatal(ctx) &lt;&lt; &quot;--dependency-file: cannot open &quot; &lt;&lt; ctx.arg.dependency_file               &lt;&lt; &quot;: &quot; &lt;&lt; errno_string();  out &lt;&lt; ctx.arg.output &lt;&lt; &quot;:&quot;;  for (std::string &amp;s : deps)    out &lt;&lt; &quot; &quot; &lt;&lt; s;  out &lt;&lt; &quot;\\n&quot;;  for (std::string &amp;s : deps)    out &lt;&lt; &quot;\\n&quot; &lt;&lt; s &lt;&lt; &quot;:\\n&quot;;  out.close();&#125;\n\nclean lto objectif (ctx.has_lto_object)  lto_cleanup(ctx);\n\n清理lto相关的文件，lto相关的操作都是类似于插件的形式执行的，以适配不同编译器产生的lto文件\ntemplate &lt;typename E&gt;void lto_cleanup(Context&lt;E&gt; &amp;ctx) &#123;  Timer t(ctx, &quot;lto_cleanup&quot;);  if (cleanup_hook)    cleanup_hook();&#125;\n\n这个cleanup_hook也是在前面注册插件的时候要注册的\ntemplate &lt;typename E&gt;static PluginStatus register_cleanup_hook(CleanupHandler fn) &#123;  LOG &lt;&lt; &quot;register_cleanup_hook\\n&quot;;  cleanup_hook = fn;  return LDPS_OK;&#125;\n\nprint mapif (ctx.arg.print_map)    print_map(ctx);\n\n\n–Map FILE Write map file to a given file\n\n收集信息并建立了section到symbol的map，之后遍历所有的chunk，进行打印。\n\n首先会打印一行chunk的信息\n如果不是osec那么会继续打印下一个chunk，否则之后会接着打印osec内部的所有members的信息\n\ntemplate &lt;typename E&gt;void print_map(Context&lt;E&gt; &amp;ctx) &#123;  std::ostream *out = &amp;std::cout;  std::unique_ptr&lt;std::ofstream&gt; file;  if (!ctx.arg.Map.empty()) &#123;    file = open_output_file(ctx);    out = file.get();  &#125;  // Construct a section-to-symbol map.  Map&lt;E&gt; map = get_map(ctx);  // Print a mapfile.  *out &lt;&lt; &quot;               VMA       Size Align Out     In      Symbol\\n&quot;;  for (Chunk&lt;E&gt; *osec : ctx.chunks) &#123;    *out &lt;&lt; std::showbase         &lt;&lt; std::setw(18) &lt;&lt; std::hex &lt;&lt; (u64)osec-&gt;shdr.sh_addr &lt;&lt; std::dec         &lt;&lt; std::setw(11) &lt;&lt; (u64)osec-&gt;shdr.sh_size         &lt;&lt; std::setw(6) &lt;&lt; (u64)osec-&gt;shdr.sh_addralign         &lt;&lt; &quot; &quot; &lt;&lt; osec-&gt;name &lt;&lt; &quot;\\n&quot;;    if (osec-&gt;kind() != OUTPUT_SECTION)      continue;    std::span&lt;InputSection&lt;E&gt; *&gt; members = ((OutputSection&lt;E&gt; *)osec)-&gt;members;    std::vector&lt;std::string&gt; bufs(members.size());    tbb::parallel_for((i64)0, (i64)members.size(), [&amp;](i64 i) &#123;      InputSection&lt;E&gt; *mem = members[i];      std::ostringstream ss;      opt_demangle = ctx.arg.demangle;      u64 addr = osec-&gt;shdr.sh_addr + mem-&gt;offset;      ss &lt;&lt; std::showbase         &lt;&lt; std::setw(18) &lt;&lt; std::hex &lt;&lt; addr &lt;&lt; std::dec         &lt;&lt; std::setw(11) &lt;&lt; (u64)mem-&gt;sh_size         &lt;&lt; std::setw(6) &lt;&lt; (1 &lt;&lt; (u64)mem-&gt;p2align)         &lt;&lt; &quot;         &quot; &lt;&lt; *mem &lt;&lt; &quot;\\n&quot;;      typename Map&lt;E&gt;::const_accessor acc;      if (map.find(acc, mem))        for (Symbol&lt;E&gt; *sym : acc-&gt;second)          ss &lt;&lt; std::showbase             &lt;&lt; std::setw(18) &lt;&lt; std::hex &lt;&lt; sym-&gt;get_addr(ctx) &lt;&lt; std::dec             &lt;&lt; &quot;          0     0                 &quot;             &lt;&lt; *sym &lt;&lt; &quot;\\n&quot;;      bufs[i] = ss.str();    &#125;);    for (std::string &amp;str : bufs)      *out &lt;&lt; str;  &#125;&#125;\n\ntemplate &lt;typename E&gt;static Map&lt;E&gt; get_map(Context&lt;E&gt; &amp;ctx) &#123;  Map&lt;E&gt; map;  tbb::parallel_for_each(ctx.objs, [&amp;](ObjectFile&lt;E&gt; *file) &#123;    for (Symbol&lt;E&gt; *sym : file-&gt;symbols) &#123;      if (sym-&gt;file != file || sym-&gt;get_type() == STT_SECTION)        continue;      if (InputSection&lt;E&gt; *isec = sym-&gt;get_input_section()) &#123;        assert(file == &amp;isec-&gt;file);        typename Map&lt;E&gt;::accessor acc;        map.insert(acc, &#123;isec, &#123;&#125;&#125;);        acc-&gt;second.push_back(sym);      &#125;    &#125;  &#125;);  if (map.size() &lt;= 1)    return map;  tbb::parallel_for(map.range(), [](const typename Map&lt;E&gt;::range_type &amp;range) &#123;    for (auto it = range.begin(); it != range.end(); it++) &#123;      std::vector&lt;Symbol&lt;E&gt; *&gt; &amp;vec = it-&gt;second;      sort(vec, [](Symbol&lt;E&gt; *a, Symbol&lt;E&gt; *b) &#123; return a-&gt;value &lt; b-&gt;value; &#125;);    &#125;  &#125;);  return map;&#125;\n\nstats// Show stats numbersif (ctx.arg.stats)  show_stats(ctx);\n\n在链接的过程中对于许多操作都会使用一个Counter记录数量，比如说符号的个数等，这里就是打印那些记录的信息\n\n–stats                     Print input statistics\n\ntemplate &lt;typename E&gt;void show_stats(Context&lt;E&gt; &amp;ctx) &#123;  for (ObjectFile&lt;E&gt; *obj : ctx.objs) &#123;    static Counter defined(&quot;defined_syms&quot;);    defined += obj-&gt;first_global - 1;    static Counter undefined(&quot;undefined_syms&quot;);    undefined += obj-&gt;symbols.size() - obj-&gt;first_global;    for (std::unique_ptr&lt;InputSection&lt;E&gt;&gt; &amp;sec : obj-&gt;sections) &#123;      if (!sec || !sec-&gt;is_alive)        continue;      static Counter alloc(&quot;reloc_alloc&quot;);      static Counter nonalloc(&quot;reloc_nonalloc&quot;);      if (sec-&gt;shdr().sh_flags &amp; SHF_ALLOC)        alloc += sec-&gt;get_rels(ctx).size();      else        nonalloc += sec-&gt;get_rels(ctx).size();    &#125;    static Counter comdats(&quot;comdats&quot;);    comdats += obj-&gt;comdat_groups.size();    static Counter removed_comdats(&quot;removed_comdat_mem&quot;);    for (ComdatGroupRef&lt;E&gt; &amp;ref : obj-&gt;comdat_groups)      if (ref.group-&gt;owner != obj-&gt;priority)        removed_comdats += ref.members.size();    static Counter num_cies(&quot;num_cies&quot;);    num_cies += obj-&gt;cies.size();    static Counter num_unique_cies(&quot;num_unique_cies&quot;);    for (CieRecord&lt;E&gt; &amp;cie : obj-&gt;cies)      if (cie.is_leader)        num_unique_cies++;    static Counter num_fdes(&quot;num_fdes&quot;);    num_fdes +=  obj-&gt;fdes.size();  &#125;  static Counter num_bytes(&quot;total_input_bytes&quot;);  for (std::unique_ptr&lt;MappedFile&lt;Context&lt;E&gt;&gt;&gt; &amp;mf : ctx.mf_pool)    num_bytes += mf-&gt;size;  static Counter num_input_sections(&quot;input_sections&quot;);  for (ObjectFile&lt;E&gt; *file : ctx.objs)    num_input_sections += file-&gt;sections.size();  static Counter num_output_chunks(&quot;output_chunks&quot;, ctx.chunks.size());  static Counter num_objs(&quot;num_objs&quot;, ctx.objs.size());  static Counter num_dsos(&quot;num_dsos&quot;, ctx.dsos.size());  if constexpr (needs_thunk&lt;E&gt;) &#123;    static Counter thunk_bytes(&quot;thunk_bytes&quot;);    for (Chunk&lt;E&gt; *chunk : ctx.chunks)      if (OutputSection&lt;E&gt; *osec = chunk-&gt;to_osec())        for (std::unique_ptr&lt;RangeExtensionThunk&lt;E&gt;&gt; &amp;thunk : osec-&gt;thunks)          thunk_bytes += thunk-&gt;size();  &#125;  Counter::print();  for (std::unique_ptr&lt;MergedSection&lt;E&gt;&gt; &amp;sec : ctx.merged_sections)    sec-&gt;print_stats(ctx);&#125;\n\n// Counter is used to collect statistics numbers.class Counter &#123;public:  Counter(std::string_view name, i64 value = 0) : name(name), values(value) &#123;    static std::mutex mu;    std::scoped_lock lock(mu);    instances.push_back(this);  &#125;  Counter &amp;operator++(int) &#123;    if (enabled)      values.local()++;    return *this;  &#125;  Counter &amp;operator+=(int delta) &#123;    if (enabled)      values.local() += delta;    return *this;  &#125;  static void print();  static inline bool enabled = false;private:  i64 get_value();  std::string_view name;  tbb::enumerable_thread_specific&lt;i64&gt; values;  static inline std::vector&lt;Counter *&gt; instances;&#125;;void Counter::print() &#123;  sort(instances, [](Counter *a, Counter *b) &#123;    return a-&gt;get_value() &gt; b-&gt;get_value();  &#125;);  for (Counter *c : instances)    std::cout &lt;&lt; std::setw(20) &lt;&lt; std::right &lt;&lt; c-&gt;name              &lt;&lt; &quot;=&quot; &lt;&lt; c-&gt;get_value() &lt;&lt; &quot;\\n&quot;;&#125;\n\nvoid MergedSection&lt;E&gt;::print_stats(Context&lt;E&gt; &amp;ctx) &#123;  i64 used = 0;  for (i64 i = 0; i &lt; map.nbuckets; i++)    if (map.keys[i])      used++;  SyncOut(ctx) &lt;&lt; this-&gt;name               &lt;&lt; &quot; estimation=&quot; &lt;&lt; estimator.get_cardinality()               &lt;&lt; &quot; actual=&quot; &lt;&lt; used;&#125;\n\nperf之前在各个过程中都会创建许多timer，在这个过程中把timer收集到的时间信息全部打印出来\nif (ctx.arg.perf)  print_timer_records(ctx.timer_records);\n\nvoid print_timer_records(    tbb::concurrent_vector&lt;std::unique_ptr&lt;TimerRecord&gt;&gt; &amp;records) &#123;  for (i64 i = records.size() - 1; i &gt;= 0; i--)    records[i]-&gt;stop();  for (i64 i = 0; i &lt; records.size(); i++) &#123;    TimerRecord &amp;inner = *records[i];    if (inner.parent)      continue;    for (i64 j = i - 1; j &gt;= 0; j--) &#123;      TimerRecord &amp;outer = *records[j];      if (outer.start &lt;= inner.start &amp;&amp; inner.end &lt;= outer.end) &#123;        inner.parent = &amp;outer;        outer.children.push_back(&amp;inner);        break;      &#125;    &#125;  &#125;  std::cout &lt;&lt; &quot;     User   System     Real  Name\\n&quot;;  for (std::unique_ptr&lt;TimerRecord&gt; &amp;rec : records)    if (!rec-&gt;parent)      print_rec(*rec, 0);  std::cout &lt;&lt; std::flush;&#125;\n\non_completeif (on_complete)    on_complete();\n\n#if !defined(_WIN32) &amp;&amp; !defined(__APPLE__)  if (ctx.arg.fork)    on_complete = fork_child();#endif\n\n因为退出一个大量内存占用的程序很慢，因此这里会fork一个子进程来进行实际的清理工作，主进程直接退出，能够提升结束的速度，让用户不可见的清理操作放到后台执行。\n#ifdef MOLD_X86_64// Exiting from a program with large memory usage is slow --// it may take a few hundred milliseconds. To hide the latency,// we fork a child and let it do the actual linking work.std::function&lt;void()&gt; fork_child() &#123;  int pipefd[2];  if (pipe(pipefd) == -1) &#123;    perror(&quot;pipe&quot;);    exit(1);  &#125;  pid_t pid = fork();  if (pid == -1) &#123;    perror(&quot;fork&quot;);    exit(1);  &#125;  if (pid &gt; 0) &#123;    // Parent    close(pipefd[1]);    char buf[1];    if (read(pipefd[0], buf, 1) == 1)      _exit(0);    int status;    waitpid(pid, &amp;status, 0);    if (WIFEXITED(status))      _exit(WEXITSTATUS(status));    if (WIFSIGNALED(status))      raise(WTERMSIG(status));    _exit(1);  &#125;  // Child  close(pipefd[0]);  return [=] &#123;    char buf[] = &#123;1&#125;;    [[maybe_unused]] int n = write(pipefd[1], buf, 1);    assert(n == 1);  &#125;;&#125;#endif\n\non_exitif (ctx.arg.quick_exit)  _exit(0);for (std::function&lt;void()&gt; &amp;fn : ctx.on_exit)  fn();ctx.checkpoint();\n\n直接exit或者调用exit的清理的函数\n\n–quick-exit Use quick_exit to exit (default)–no-quick-exit\n\n在mold中有的只有一处，在icf_sections中创建的map需要在这里销毁，但是也可能在lto的过程中注册了其他的exit函数。\n// Since free&#x27;ing the map is slow, postpone it.ctx.on_exit.push_back([=] &#123; delete map; &#125;);\n\n最后在返回之前会再调用checkpoint检查是否有错误。\n至此，整个mold的链接过程已经完全结束了。下一期会进行一个总结，并且记录一下一些自己的想法\n","categories":["Linker"],"tags":["mold"]},{"title":"红与黑","url":"/2023/07/30/Reading/the-red-and-black/","content":"一个穷苦人家的孩子，凭借着自己过人的本领从一个木匠的儿子开始不断向上爬，获取名誉与金钱，但是黑暗一直伴随着他。他在穷苦环境中产生的黑，无论再多名誉与金钱的红都无法掩盖，这是我眼中的红与黑。于连从一个木匠儿子，到市长家的老师，到学院的尖子生，再到侯爵的助手，一路几乎是顺风顺水。一切离不开他的才智，但也和他的性格息息相关，虽然他会自负，虚伪，但他的性格除了穷苦环境中产生的那些黑，但还有正面的红色：忍耐，理智，坚毅。不论好坏全都推动了他顺利前进，但也推动了他走向悲剧。\n在故事结束后作者写下了“献给幸运的少数人”，在我看来是很有吸引力的留言，我想这一定与作者所在的时代背景有关，身处漩涡中的人难以看清漩涡的全貌，那个时代能接触到思想教育的人绝大多数也是受限的，身陷其中的，这样的时代或许很难有作者的知音。\n再来说说这是一个怎样的时代，我对于当时的历史并不了解，但作者的故事中已经完全被那个时代的颜色所填满，其中最显眼混杂在其中的则是出身、权利与地位、金钱这几种妖艳的色彩，之所以妖艳，是因为带来的不仅只有所谓的美好。于连作为一个对此鄙夷的角色，在他攀爬的过程成为了见证者，但他虽然融入上流社会却并没有染上上流社会的恶习，他虽然在获得更高的权利和地位但他所求的事情似乎并不和那些上流社会的人相同。但是纵使他再怎么对此厌恶，他作为个人再怎么厉害，他仍然是一个无力推翻时代洪流的弱小者，他仍然无法抹消出身的卑微。\n对于于连来讲，除了他那隐藏在内心中的黑暗性格外，一直围绕着他的就是他的出身，不只是周围的看法，乃至他自己都一直困在这片思维洼地中。不过这是时代的悲剧，出身至上的时代注定了如此。而他的这个思维也是让他走向悲剧的根源，他对于拉穆尔小姐不断出现的想法还是“他这样出身的人征服了她”。\n可想而知，这样的时代与于连这样的主角搭配，注定了悲剧的发生。但有些意外的是“我们的英雄”最后以这样的形式迎来悲剧的判决。也许此时他已经不再是那个他了，也许他的本性正如此，他选择了枪击报复他其实还爱着的瑞那夫人。更曲折的是拉穆尔小姐明明已经通过权利使得有避免死刑的希望，最后却还是被已经上任、手握权利且曾为瑞那夫人争风吃醋的瓦勒诺确定了死刑，最后还是被他所讨厌的事物所压倒了。\n于连一切变化的开始似乎源于对于瑞那夫人的爱，虽然这份爱源于扭曲的征服欲，但他的人生最终又因为瑞那夫人崩塌，不论是给拉穆尔侯爵的信，还是因为瓦勒诺曾经是情敌，只是他并没有怨恨，反而最后发觉了自己对瑞那夫人的心意。此外与拉穆尔小姐的偷情，也是他最终结局的原因之一，但这些全部起始于他强烈的自尊，以及他无法摆脱自己底层出身这一泥沼，这两段感情的起点都是他认为自己这样的人征服了这么高贵的人。\n现在的时代尽管完全不同，但人们的追求依然没有改变：金钱、地位、阶级等，而人们贪婪，黑暗的本性从未消失，于连一样的人一定存在。如果作者生活在现在的时代，或许也会写出相似内核的故事，从底向上，最后坠落。最后也许是因为犯法，也许是被出卖，我贫瘠的想象力很难想到有什么寓意深刻的结局，这些人们会如何在高空中的钢丝绳上坠落呢，但不论如何一定是会掉下来的。\n","categories":["Reading"],"tags":["司汤达"]},{"title":"初探黑塞文学","url":"/2023/07/30/first-look-at-hesse-literature/","content":"黑塞的作品中我最早有所了解的是《在轮下》，从b站up主黄鸭兄的视频中了解了整个故事，当时觉得从内容到立意都挺有意思。后来看到黄鸭兄视频中提到《荒原狼》的内容，其中魔剧院中从人驯服狼到狼驯服人的场景震撼到了我，因此选择了这本书作为自己接触黑塞文学的开始。书中从开始到结尾都远超预期，处处让我惊叹，剧情本身的安排，对主人公心理的描写，以及最后的魔剧院的部分，全部引诱着我沉迷于黑塞的故事世界，使我对黑塞的作品充满了好感。\n后来想要接触到更多黑塞的作品，看到《悉达多》是其代表作，遂开始读了起来，读完后觉得非常有黑塞的风格，同时开始坚定的认为黑塞的作品就是我想要看到的，黑塞的故事所传达的精神内核就是我想要追寻的。之后朋友回给我的一封邮件中提及到《德米安》，他在大学时也看了许多黑塞的作品，我也不由分说的开始阅读了起来。不出意外，这本书同样也让我感到非常满足。\n黑塞的作品中那种强有力的吸引力到底是什么？对我来说或许是从中表现出的对自我的剖析与追求，对人生的探索，在人群中仍然抱有强烈的自我，等等。词汇匮乏的我难以用一个词语概括这一切，只能粗略的认为它们都属于精神的世界，属于人类的内核，我对这些内容产生的更多是感受，看到相似的内容会觉得“这个东西一定也是属于同一类”。\n看到个别书评提到黑塞的一些书籍都是翻译的功劳之类的，但翻译只是片面的文字描述罢了，而且翻译不论怎么做都要忠实于作者的原意，黑塞的作品中所展现出的灵魂是不会被不同的文字形式所覆写。就像我最初开始接触荒原狼一样，并不是因为文笔是如何的，而是黑塞笔下的故事本身向我伸出了无形的手，而我甘愿被其所拉入黑塞的故事世界。\n不同的人对一本书的评价是不同的，除去每个人角度不同外的原因外，作品的喜好也是因人而异的。对我来说黑塞的作品正是我最喜欢的，同时其传达的内容也是我所追求的。有的人比较喜欢那些比较正面、能鼓励人心的故事，曾看到有人说喜欢西西弗的故事，被其勇气所感染，但我却不会被这种故事所打动。我更喜欢探寻人类的灵魂，或者发掘更多隐藏在故事背后的真相，这样的故事更多是在讲述着什么，而不是着重于赞扬与批判，这种判别是不可避免的，但上升到更显眼的层面似乎就开始有点变质了。\n黑塞的作品还有不少未看，希望这些能给我带来更多的满足与惊喜，也希望能够发现其他笔下故事能带给我类似感受的作家，借此更加深入自我的内核，同时去感受这些作家们的精神世界。\n","categories":["Reading"],"tags":["黑塞"]},{"title":"mold源码阅读十六 回顾整个流程","url":"/2023/08/05/mold/mold-16-summary/","content":"\npixiv:80173499 \n\n内容回顾在以往十六期的博客中，我们沿着mold中的main函数一路追寻了下去，直到结束。\n首先我们熟悉了文件结构以及项目目录等，查看了如何读取不同类型的文件，其中最关键的是obj，dso，lto三种，分析了不同类型的差异及其特有的处理方式。同时在查看如何解析elf的过程中了解elf头，了解了mold对象的构造，以及elf中信息查找段、符号等的方式。\n当我们收集齐输入的文件信息后就要开始对这些文件进行处理。首先做的是dso去重，避免多个同名dso导致的错误。接下来是最重要部分：符号信息解析。符号相关的过程有许多包括符号决议，符号的导入导出，动态链接的符号的版本确定，处理未解析的符号等等。之后还对mergeable的段进行合并。\n处理完符号相关的信息后开始创建输出文件，准备将许多input section合成一个output section。此时需要对于常见synthetic符号与段的构造，并且将它们放到输出的文件中。在实际输出文件之前还需要确定文件内部布局，主要对段排序，其中包括chunks之间排序，以及output section内部保存的input section的顺序。\n当文件布局确定后我们就可以创建rel相关的段，将符号写入对应的符号表，计算段内的一些信息，对部分synthetic段构造等等。之后更新section对应的shdr，以及更新段的虚拟地址，对synthetic符号的值进行修正等。通过这些操作来确定下文件载入内存中的布局。\n最后再将这些拷贝到输出文件中。在拷贝的同时还做了许多操作，比如说段的重定位，填写ehdr以及其他synthetic段中的信息。\n在整个过程中也有许多检查，比如符号重复定义或者未定义。还有许多优化，例如对section进行标记来回收无用段，安排输出段的位置使得相同读写权限的段尽可能在一个页内，消除重复的ehframe项，段压缩等等。\n以上就是链接器mold的概况。\n想法最初会开始看链接器的实现是因为感到好奇，加上之前每次遇到链接相关的问题第一反应是头大，觉得解决不了。后来看到mold这个链接器，其中的代码量还在我能串一遍理解的范畴，因此开始了读代码的过程。读的时候做着记录，后来想着干脆开一个系列博客，我在读的时候经常容易跳过某些细节，写博客的过程中会强制自己对这些细节进行强制思考。\n经过了十六期的文章后，整个mold的链接过程基本上就全部过了一遍，而我对于链接器工作的整个流程有了更详细的认知。以前对于链接的模糊印象就是简单的相似段合并，符号解析（但是不知道符号解析具体是在做什么），生成可执行文件或者library，但现在我对于这些部分有了更多的了解，并且还知道了链接过程不止有这些，还有包括synthetic的符号和段的处理，虚拟地址计算，重定位操作等等。\n除此之外还看到了许多未曾想到的东西，在看到一些处理过程后，对动态链接以及加载的过程也有了更多的了解，还有一些之前从未想过能如何联系到一起的想法，比如说相同attribute的段放在一起，避免单独成页，减少运行时的内存等。\n虽然学到了很多东西但是还是有很多地方其实是一知半解，阅读源码远不如实际写来困难，虽然能够大致讲出整个链接器的结构是怎样的，但是对链接器来说最重要的还是各种边边角角的细节，或者意想不到的东西都会在写的过程中出现。我现在在造各种轮子玩，想自己做出各种东西并且串联起来，或许会有一天也会需要造自己的linker吧。\n在源码通读的过程可能花了过久的时间，有些低效。但很多东西我一开始确实没意识到，很多问题都没有提出，不过查看了前面的这些过程后，现在开始阅读不仅是了解了有什么，还让我能够提出一些问题。\n在博客内容写作的过程也不太熟练，最近也是为自己博客写作感到焦虑。不论是内容详细程度，以及排版，内容划分做的都不太好。在学习的时候看到maskray聚聚的文章，多少受到了一些启发，意识到自己过于注重于原来的代码怎么写，对于代码背后的原理关注的相对较少，这其实才是要学习的本质内容，又不是学习代码技巧。在后面几期也在有意识的进行改正，之后写其他阅读代码的博客时也会继续试着这样来做。\n排版上试了不同的方案，比如说最早是放一段读一段，后来又尝试一次讲完一个流程然后贴整段代码，之后再对其中需要更加深入的细节加入小标题来做。不过感觉怎么都很别扭，markdown似乎没什么办法分成代码和文字两列，最后还是觉得先讲清楚流程再放代码了。\n后续如果后续勤快的话还会继续更新一些东西，除了这样通读外，还想针对特定主题进行贯穿一遍，而且还有一些没有详细看细节但是比较重要的东西。（总觉得说出这样的话就会懒得更了…）\n比如说各种synthetic的符号更详细的介绍， 梳理做的各种优化，header的生成，为动态链接做的准备（got，plt等），数据压缩与解压，为重定位所做的各种操作，最终产物的地址计算与关联等等，这些其实都还比较模糊，没有一个确切的印象，需要单独串联起来理解整个过程。\n","categories":["Linker"],"tags":["mold"]},{"title":"时间的洪流","url":"/2023/08/06/flood-of-time/","content":"时间，一个再熟悉不过的词语，但是我们对其又非常陌生。\n做什么事情都需要时间，发呆需要时间，写这些内容需要时间，看这些内容也需要时间，即便什么都不做，也需要时间。关于时间的话题也有很多，比如最常听到的珍惜时间，但我不打算讲这些听的耳朵出茧的大道理。\n时间在我眼里是自我的一部分。时间由自我来掌控，同时通过对待时间的态度和方式显现出了一部分的自我。生活中有几句经常能听到的话：没时间啊，有时间就好了；能不上班就好了，那样就有时间做自己的事情了，这样的话本质都是类似的。但绝大部分情况下只是自我欺骗，或者说是某件事情对自己来说并没有那么重要，你的自我控制了你去做其他事情。\n我之前经常会因为时间过的太快而焦虑，进一步观察其实是觉得自己没做什么正经事情，但我也没什么想做的事情，这样的我在回看过去的时间时焦虑感是不可避免的。或许当我找到属于自己在时间这一无尽的洪流中漂流的方式时，能够不再会为了体会到这种被迫漂流的感觉而感到害怕和无助，因为我知道这种漂流方式是自己主动选择的。\n","categories":["Thinking"]},{"title":"欲望","url":"/2023/08/08/desire/","content":"人因欲望而前进，但又经常会因为欲望无法实现，又或者不可能实现而苦恼不已。在《诗人十四个》中有这样的一段话\n\n有追求，就有落空的可能。应对此事只有两种策略：一是通过觉悟认识到追求的虚幻性，从而放下我执；二是用人格和意志的力量勉力支撑，直到人生尽头。\n\n尽管原文是针对个人的追求，针对个人遇到的挫折与苦难，但我觉得针对欲望仍然是如此，同时还认为个人追求其实也是一种个人的欲望。要不放下自己的执念，要不就是像西西弗一样不论是否能到达终点，仍然不断前进。\n此时的我正被欲望所吞噬，不论是想要变好的欲望，还是对于金钱或者爱情，但同时又因为自己无法实现其中任何一者而备受折磨。欲望是带给人前进的动力，但是当看不到前进的路时就会感到无力，但同时如果又无法放下到达目的地的执念，只会有心力被消耗。\n恰巧最近还在看《瓦尔登湖》，就目前所看的部分与欲望十分贴近的观点是“简单的生活，减少被世俗欲望所影响”。在俗世中最容易被提及的则是金钱，而在书中最先提及的部分也是和金钱相关，人们为了金钱付出了太多，但是却放弃了许多其他的东西。之后还提及了和别人的交际，认为和人们相处很快会感到乏味，思索或者劳作的人总会孤独，独处更加有益身心。我却觉得这些观点上有些极端。作者的主要观点我觉得实在表达要直接去做真正要做的，而不是被无关的事情所影响，这样的观点我也是非常认同，基于这个观点上来说，如果人的欲望是发自自己内心的，或许也可以等价为自己想做的事情，那即便为此去做些俗世的追求也并没有什么不好。而对作者来说，脱离世俗是他更好的达成自己欲望的一部分，不论是为了追求更多的知识，与大自然接触，这仍然是他的欲望。\n但发自内心的又是什么呢？这个答案的细节一定是因人而异，但每个人发现的答案一定有类似点，即不受外界环境影响，无论在哪里都会有这样的想法。如果只是人云亦云，我想那无法称之为发自内心，而是作为人群的欲望罢了，不论是名声，财富。但是如果你摆脱了人群仍然想要得到这些，那去追寻我想也无妨。\n欲望，一直都被认为是魔鬼般的存在，但我现在却不这样想了。我现在处于认为人生没有意义的状态，甚至对我来说活着就是尽可能满足自己的欲望，没有欲望的人，很难想象要怎么活下去。但我是一个十分贪婪的人，又不肯放弃哪些欲望，而且自身能力不够又无法抵达，这样的人路在何方呢？或许有朝一日会找到答案吧。\n","categories":["Thinking"]},{"title":"看不见的女性","url":"/2023/08/19/Reading/invisible-women/","content":"性别对立，是现在非常容易引起争议的话题。女性们普遍处于弱者的位置，当她们开始寻求自己应有的权利，而不是一直像现在这样，争论也就因为各种原因进一步变多了。那么女性的地位具体到底是怎么样的呢？我觉得这本书已经相当清晰的讲述了在世界上女性的现状，虽然因国家会有微小的不同，但是趋势都是一致的，相对于男性来说处于相当不利的位置。\n即便不看书，我们在生活中也能看到许多例子，包括但不仅限于遭受各种方式的暴力，一些行业的就业歧视，另外在国内一些非常传统家庭中女性被长辈们认为不应该多读什么书，早点找个人结婚生子才是正事。这当然是非常扭曲的事情，不论是男性还是女性，都首先是一个人，在这一层面应当是被同样尊重的，在做到这个前提下接纳彼此差异，针对不同性别做一些差异化的帮助，因为躯体差异确实存在，并且也不是简单几句话就能概括的。\n躯体的差异这本书中关于寻医问药的部分提及了很多，这也是让我看了感觉最不适的部分。不同性别由于身体结构的影响，同一个药物的反应可能是完全不一样甚至相反的，但药物研发的时候甚至没有针对女性做同样数量的测试，影响到人体健康不认真进行测试是比较危险且对患者不负责任的事情。此外对于患者的诊断都是基于男性为标准，也就是说中提到的“燕特尔综合征”，导致许多女性更难及时得到治疗，甚至本可以规避死亡却因为诊断的问题而无法规避。\n除了寻医问药外，书中还提及了女性在日常生活，职场，所用工具的设计，公共生活，以及遇到灾难时这几种情况下女性的权益无法受到保障。许多问题的核心来源正如书的标题所讲，女性被忽视了，甚至在一些场合还会出现歧视，在招聘的时候都不愿意招聘短期内具有生育可能的员工，生育前后的休息时间让女性难以适应工作的变化。\n此外社会也没有教导人们如何去应对性别的差异，使得很长一段时间内女性处于完全不公的状态。但随着互联网时代信息的快速扩散，这种不公的问题也暴露的越来越多，意识到问题的人能够将自己的想法传达给更多的人，使得目前性别地位开始有所变化。过去人类社会在很多方面几乎忽略了这百分之五十的人类，我想在历史的发展中，这样的忽略会付出许多的代价，女性和男性具有同等程度的思考能力，同时不同性别的人思维方式会有所差异，那么发展的过程中相当于抹杀了那一部分的可能性。但是当这个现状开始改变的时候，这些可能性也就慢慢涌现了出来了，或许使得社会走向不同的道路。\n女性的生活实际上比我所要想的要困难，虽然我这么说，但我并没有仔细考虑过这些问题。作为一个男性能做的，或许就是像我前面所说，在尊重作为人的一面的前提下，接纳彼此的差异，同时认清并且牢记现实中被忽略的这部分。\n","categories":["Reading"],"tags":["对立"]},{"title":"25","url":"/2023/08/23/Life/25/","content":"25在我眼里是一个略微规整的数字，是5的平方，是75的三分之一，是一百的四分之一，乘二就能凑满一个十，同时又是一个奇数。不过对此时的我来说，比起数学上的意义，更重要的是年龄上的意义，大家都开玩笑说到了25就该奔三，现在我也到了这个时候了。\n关于年龄这个事情，我觉得继续持续增长也挺好的，因为年龄增长的同时自己所能做到的事情也更多了，不论是知识，人际关系，还是金钱，不出意外在这个阶段都是处于上升的期间。只是如果带着回忆回到过去，那我很大概率会选择回去的，在过去的25年里，不知道做了多少错误的事情，其中还有一些是不可挽回的，但事已至此，我也不会再去计较那么久远的自己。\n不过比起身体的年龄，人格，精神上的年龄似乎更加重要。在这方面我远比周围人开始成长的要晚，大概在18岁左右才开始从一个听到什么做什么的人，只会听从本能的人，到开始产生想法与思考，渐渐成为了现在这个样子。我不知道该如何客观的评价现在的自己，只是有一点可以肯定的，我在不断的改变，尤其是克服了许多缺点，许多不良想法。前些时间写的自我介绍或许算是自我评价的一部分吧，在这里也不再重复描述现在的自己了\nhttps://homura.live/2023/07/02/Other/dissuasive-self-presentation/\n我承认总体有些偏向负面的评价，不过有一点我还是可以认同自己的，着已经远比最初意识觉醒的自己要好很多。过去对我刚开始产生想法时的不良影响还是很大的，不过这些影响已经随着我的改变逐渐减少，尽量克服也是我在未来要做的工作。\n对于这个年龄有一个比较难绕过去的问题：亲密关系，或者更直接地说是恋爱。正巧昨天是七夕，下班路上看到有人在地铁口卖花，生意也不错，路上也有许多情侣。对于寻求亲密关系的我来说，很难不羡慕。我对爱情的渴求，不仅是因为自己是母单，在我变化的过程中，渐渐觉得情感，甚至是爱情是我特别重视的部分。我喜欢魔法少女小圆中圆焰的爱，喜欢利兹与青鸟中霙与伞哥哥的爱，在我意识到这些之前，就已经被焰这个角色对于圆的炽热爱意所吸引，只是近一两年才真正认识到自己的这部分。焰在叛逆的物语中有一句让我印象深刻的台词：\n\n比希望更炽热，比绝望更深邃的，是爱啊\n\n或许只有接近完美的爱，才能达到这种情感的极致，我甚至觉得这种体验是对于我这样情感匮乏的人是必需品。在过去半年我在推特上发了许多自身对这种情感需求很强烈的内容，不过现在这种事情已经自认无缘了，不太想多挣扎了，现在也已不再去发这些内容，虽然有些遗憾，但是也没办法。\n另外我和众多这个年龄的人一样，对人生感到迷茫。虽然我有在做一些事情，但我不能确定自己喜欢什么，想要做什么，要如何做出选择，等等。也有一些事情确实妨碍了我的探寻，无法治愈的抑郁和焦虑环绕着我，经常因此无法行动，甚至对自己的无能，对自己面对的一切感到绝望，因此我开始有些无法判断自己不做某件事情的原因，到底是因为什么。不过随着我对自身感受更多的关注，逐渐能够意识到一些东西并不是我真正所想的，只是被环境胁迫，被自己胁迫，才不得不做的事情。\n这一切都是在面对抑郁和焦虑中查找资料与自身感受逐渐习得的，我无法等待一切痊愈后再去探寻，因为或许永远无法痊愈，不可能等到准备完全的时刻再上场，准备完全也是不存在的。我只能去试着读书，或者看他人的文章，学习他人的经验。在这个过程中，我看到了自身想法的真相，看到了焦虑小人，抑郁小人后面真正的自己，看到了自己内心更深处的需求，自己用着如何扭曲的形式将这些表现出来，这些表现是如何干扰我去了解自己的。（不论怎么说我还是希望这些疾病从未缠绕过我，即便带给了我部分成长，但在我痊愈之前我很难完全接受）。这个过程，或许也可以被称为追寻自我，喜好、想做的事情，其实都是自我的一部分。\n纵使我再迷茫，在上述的探索过程中我也发现了很多关于自我深处的片段。自己对精神层面的追求，包括但不限于情感、道德与自我的完善。我想沿着这些走下去的话，迟早有一天会破除迷茫吧。而这一切，我认为都是从我决定开始独立思考，开始探寻的时候就埋下了种子，我在思考，形成自己的独立意见，输出观点的过程都是在给种子浇水施肥，直到现在这个时间，总算发了一个小芽。另外这个过程中也有外界的温暖阳光和风吹雨打影响着我。带给我比较大改变的也许是我2021年在推特认识的朋友，和他的交流，和他产生的连接，某种程度上也加快了自己成长的脚步，我也被他所影响，受到他许多帮助，总之十分感谢他。\n在这个过程中除了有这些进展，但还有非常多未能解决的问题缠绕着自身，像前面所提到的抑郁和焦虑，我认为都是自身的这些问题未能解决的结果，不论是缺失的情感，还是自身的种种无能。这都非常困难，这几年的时间，让我把情绪的根源问题规约到了这两者上，只是已不能再继续了。我一直在解决问题的失败中重复，一直在类似的错误中重复，像焰一样徘徊在似乎没有尽头的时间迷宫，但与焰不同的是我连唯一的路标也看不到，了解自我也无法成为解决自身问题这一方面的路标。不知道自己何时才能克服这些，或许要几年，搞不好或许要几十年，或者直到我去世都未能克服未能接受。我总是期待贵人出现，给予我指点。甚至会更不切实际的想在他的帮助下一切就随之解决，但这是不可能的，他人最多给予我一个方向，最终必须要靠我自己亲自解决。\n回首过去的一切，我虽然一直觉得自己运气不好，但其实我走过的路中有许多运气成分，许多地方自己真的很难想象走其他的路会有怎样的后果。过去一直觉得自己招人厌，没有人愿意帮助我，但实际上并不是有贵人指点才叫帮助，我从许多人那里以各种形式得到了帮助，也是对这些人们十分感谢。经历的一切，很难说有什么美好的事情，但已经逝去也就不必再为其痛苦。那未来呢？短期的未来或许仍然会迷茫，但仍会继续寻求自我的完善与修正，寻求自我的协调。我想这是自己在毫无意义的人生中唯一的路标，也是绝对不会错的路标。\n以下是人生故事会环节，我选择将过去用文字简单写下，读者可忽略。\n这种文章也难免回忆过去，那么从头讲起吧。我出生在一个算是贫困的家庭，除了能保证基本的衣食住行，其他都是奢望，大家习以为常的旅游，美食，电影，游戏机等均与我无关。之后就这样普通的上了学，在学校渐渐开始觉得被排挤孤立，当时愚笨的我根本不懂为何，都是些现在看来真的活该的原因。后来到了初中感受更加强烈，毕竟大家心智和身体都在成长，而我成长的只有身体，仍没有意识到原因，理解那些事情，已经是前几年的事情了。不过尽管如此，我也上了一个普通高中，此时也是我黑历史最多，并且最难忘却的时段，要是拿出来讲可能三天也写不完这文章了。同时这是我的第一个人生拐点，不过是往下拐。这个时候因为各种原因，包括家里接入网络，有了山寨智能手机等原因，上课睡觉，不学习，考试成绩渐渐到了底。另外高中不再是按地域划分，遇到的同学也开始不一样，现在回想起来，家境、见识、各方面真的是差的非常多，但对当时的我来说根本不懂这些事情，拿自己跟其他人比的话真的是非常丢人。不过在最后的一年想法开始产生了一些改变，迎来了我的第二个人生拐点，我到现在也没明白为什么那个时候突然就变了。尽管如此，仍然敌不过自身的无能，最后也就“顺其自然”地考上个一个专科。\n后来大一下学期，听到一些同学提到知乎，我好奇的搜了下，没想到让当时的我眼界大开，虽然知乎现在很烂，但是那个时候真的是做到了让我这个井底之蛙看到更广的世界，让我愈发感受到了无能，让自觉有点小聪明的自己感受到强烈的自卑。此时开始我的焦虑就愈发严重，之后很长一段时间内都很容易沉入在类似的焦虑中，并且随着我接触的更多，这种感受越强烈，甚至几次想过“我是不是最初就不应该看到这么广阔的世界，一直当井底之蛙就好了”（不过这种感受这两年已经开始小时了）。随后专科即将毕业，我去考了一个专升本，顺利的续了接近两年学生时光。最后一年其实就开始找工作了，一直不顺利。当初想要去上海的，但是boss上投简历均石沉大海，也就没了希望。之后经过各种离奇的经历，我来到了现在的公司实习，转正，并且工作到现在，很感谢内推我的人，没有这个机会我现在很难说在哪里做什么奇怪的工作。\n这就是我人生前25年的人生。\n","categories":["Thinking","Life"]}]